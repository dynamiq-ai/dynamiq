import base64
import io
import json
import re
from typing import Any, Sequence

import filetype
from lxml import etree as LET  # nosec: B410

from dynamiq.nodes.agents.exceptions import JSONParsingError, ParsingError, TagNotFoundError, XMLParsingError
from dynamiq.prompts import (
    Message,
    MessageRole,
    VisionMessage,
    VisionMessageImageContent,
    VisionMessageImageURL,
    VisionMessageTextContent,
)
from dynamiq.utils.logger import logger

TOOL_MAX_TOKENS = 64000


class XMLParser:
    """
    Utility class for parsing XML-like output, often generated by LLMs.
    Prioritizes lxml for robustness, with fallbacks for common issues.
    """

    @staticmethod
    def _clean_content(text: str) -> str:
        """
        Cleans the input string to remove common LLM artifacts and isolate XML.
        - Removes markdown code fences (```json, ```, etc.).
        - Strips leading/trailing whitespace.
        - Attempts to extract the first well-formed XML block if surrounded by text.
        """
        if not isinstance(text, str):
            return ""

        cleaned = re.sub(r"^```(?:[a-zA-Z]+\s*)?|```$", "", text.strip(), flags=re.MULTILINE)
        cleaned = cleaned.strip()

        xml_match = re.search(r"<(\w+)\b[^>]*>.*?</\1>", cleaned, re.DOTALL)
        if xml_match:
            cleaned = xml_match.group(0)

        return cleaned

    @staticmethod
    def _parse_with_lxml(cleaned_text: str) -> LET._Element | None:
        """
        Attempts to parse the cleaned text using lxml with recovery.
        """
        if not cleaned_text:
            return None
        try:
            parser = LET.XMLParser(recover=True, encoding="utf-8")
            root = LET.fromstring(cleaned_text.encode("utf-8"), parser=parser)  # nosec: B320
            return root
        except LET.XMLSyntaxError as e:
            logger.warning(f"XMLParser: lxml parsing failed even with recovery: {e}. Content: {cleaned_text[:200]}...")
            return None
        except Exception as e:
            logger.error(f"XMLParser: Unexpected error during lxml parsing: {e}. Content: {cleaned_text[:200]}...")
            return None

    @staticmethod
    def _extract_data_lxml(
        root: LET._Element, required_tags: Sequence[str], optional_tags: Sequence[str] = None
    ) -> dict[str, str]:
        """
        Extracts text content from specified tags using XPath.
        Handles cases where the provided 'root' might be a child element
        by navigating up to the parent if necessary.
        Distinguishes between missing tags and found-but-empty tags.
        """
        data = {}
        optional_tags = optional_tags or []
        all_tags = list(required_tags) + list(optional_tags)

        for tag in all_tags:
            tag_content = None
            element_found = False
            elements = root.xpath(f".//{tag}")
            if elements:
                element_found = True
                for elem in elements:
                    text = "".join(elem.itertext()).strip()
                    if text:
                        tag_content = text
                        break

            if not element_found:
                try:
                    if root.getparent() is not None:
                        parent_elements = root.xpath(f"../{tag}")
                        if parent_elements:
                            element_found = True
                            for elem in parent_elements:
                                text_parent_child = "".join(elem.itertext()).strip()
                                if text_parent_child:
                                    tag_content = text_parent_child
                                    break
                except AttributeError:
                    logger.debug(
                        f"XMLParser: Root element '{root.tag}' has no parent, cannot search siblings via parent."
                    )
                    pass
                except Exception as e:
                    logger.warning(f"XMLParser: Error during parent navigation XPath for tag '{tag}': {e}")
                    pass

            if tag_content is not None:
                data[tag] = tag_content
            elif element_found and tag in required_tags:
                raise TagNotFoundError(f"Required tag <{tag}> found but contains no text content.")
            elif not element_found and tag in required_tags:
                raise TagNotFoundError(
                    f"Required tag <{tag}> not found in the XML structure "
                    f"relative to the parsed root element ('{root.tag}') or its parent."
                )

        missing_required_after_all = [tag for tag in required_tags if tag not in data]
        if missing_required_after_all:
            raise TagNotFoundError(f"Required tags missing after extraction: {', '.join(missing_required_after_all)}")

        return data

    @staticmethod
    def _parse_json_fields(data: dict[str, str], json_fields: Sequence[str]) -> dict[str, Any]:
        """
        Parses specified fields in the data dictionary as JSON.
        """
        parsed_data = data.copy()
        for field in json_fields:
            if field in parsed_data:
                try:
                    json_string = re.sub(r"^```(?:json)?\s*|```$", "", parsed_data[field].strip())
                    parsed_data[field] = json.loads(json_string)
                except json.JSONDecodeError as e:
                    error_message = (
                        f"Failed to parse JSON content for field '{field}'. "
                        f"Error: {e}. Original content: '{parsed_data[field][:100]}...'"
                    )
                    guidance = (
                        " Ensure the value is valid JSON with double quotes for keys and strings, "
                        'and proper escaping for special characters (e.g., \\n for newlines, \\" for quotes).'
                    )
                    raise JSONParsingError(error_message + guidance)
                except Exception as e:
                    raise JSONParsingError(f"Unexpected error parsing JSON for field '{field}': {e}")
        return parsed_data

    @staticmethod
    def parse(
        text: str,
        required_tags: Sequence[str],
        optional_tags: Sequence[str] = None,
        json_fields: Sequence[str] = None,
        attempt_wrap: bool = True,
    ) -> dict[str, Any]:
        """
        Parses XML-like text to extract structured data.

        Args:
            text (str): The raw text input potentially containing XML.
            required_tags (Sequence[str]): A list/tuple of tag names that MUST be present.
            optional_tags (Sequence[str], optional): A list/tuple of optional tag names. Defaults to None.
            json_fields (Sequence[str], optional): A list/tuple of fields whose content should be parsed as JSON.
            attempt_wrap (bool): If initial parsing fails, try wrapping the content in <root> and parse again.

        Returns:
            dict[str, Any]: A dictionary containing the extracted data.
                           Values for json_fields will be parsed JSON objects/primitives.

        Raises:
            XMLParsingError: If the text cannot be parsed as XML even with recovery/wrapping.
            TagNotFoundError: If any of the required_tags are not found or are empty.
            JSONParsingError: If any field listed in json_fields contains invalid JSON.
            ParsingError: For other generic parsing issues.
        """
        optional_tags = optional_tags or []
        json_fields = json_fields or []

        cleaned_text = XMLParser._clean_content(text)
        if not cleaned_text:
            if required_tags:
                raise ParsingError("Input text is empty or became empty after cleaning.")
            else:
                return {}

        root = XMLParser._parse_with_lxml(cleaned_text)

        if root is None and attempt_wrap:
            logger.info("XMLParser: Initial lxml parse failed, attempting to wrap content in <root>...")
            wrapped_text = f"<root>{cleaned_text}</root>"
            root = XMLParser._parse_with_lxml(wrapped_text)
        if root is None:
            raise XMLParsingError(
                f"Failed to parse content as XML even after cleaning "
                f"and wrapping attempts. Content: {cleaned_text[:200]}..."
            )

        try:
            extracted_data = XMLParser._extract_data_lxml(root, required_tags, optional_tags)
        except TagNotFoundError as e:
            raise e
        except Exception as e:
            raise ParsingError(f"Error extracting data using XPath: {e}")

        if json_fields:
            try:
                final_data = XMLParser._parse_json_fields(extracted_data, json_fields)
            except JSONParsingError as e:
                raise e
            except Exception as e:
                # Catch potential errors during JSON parsing
                raise ParsingError(f"Unexpected error during JSON field processing: {e}")
        else:
            final_data = extracted_data

        return final_data

    @staticmethod
    def extract_first_tag_lxml(text: str, tags: Sequence[str]) -> str | None:
        """
        Extracts the text content of the first tag found from the list using lxml.
        Useful for simple cases like extracting just the final answer.
        """
        cleaned_text = XMLParser._clean_content(text)
        if not cleaned_text:
            return None

        root = XMLParser._parse_with_lxml(cleaned_text)

        if root is None:
            wrapped_text = f"<root>{cleaned_text}</root>"
            root = XMLParser._parse_with_lxml(wrapped_text)

        if root is None:
            logger.warning(f"XMLParser: extract_first_tag_lxml failed to parse: {cleaned_text[:200]}...")
            return None

        for tag in tags:
            elements = root.xpath(f".//{tag}")
            if elements:
                for elem in elements:
                    content = "".join(elem.itertext()).strip()
                    if content:
                        return content
        return None

    @staticmethod
    def extract_first_tag_regex(text: str, tags: Sequence[str]) -> str | None:
        """
        Fallback method: Extracts the text content of the first tag found using regex.
        Less reliable than lxml, use only when lxml fails completely.
        """
        if not isinstance(text, str):
            return None

        for tag in tags:
            match = re.search(f"<{tag}\\b[^>]*>(.*?)</{tag}>", text, re.DOTALL | re.IGNORECASE)
            if match:
                content = match.group(1).strip()
                if content:
                    return content
        return None

    @staticmethod
    def parse_multiple_tool_calls(text: str) -> tuple[str, list[dict[str, Any]]]:
        """
        Parse XML with multiple tool calls within an <actions> block.

        Args:
            text (str): XML text containing thought and tool calls

        Returns:
            tuple: (thought_text, list_of_tool_calls) where each tool call is a dict with:
                - 'tool_name': The name of the tool
                - 'tool_input': The parsed JSON input for the tool

        Raises:
            XMLParsingError: If XML parsing fails
            TagNotFoundError: If required tags are missing
            JSONParsingError: If tool_input JSON parsing fails
        """
        try:
            parsed_data = XMLParser.parse(text, required_tags=["thought", "actions"], optional_tags=["o", "output"])
        except TagNotFoundError:
            try:
                parsed_data = XMLParser.parse(text, required_tags=["thought", "actions"], optional_tags=["output"])
            except Exception as e:
                raise XMLParsingError(f"Failed to extract thought and actions: {e}")

        thought = parsed_data.get("thought", "").strip()
        actions_xml = parsed_data.get("actions", "").strip()

        if not actions_xml:
            raise XMLParsingError("Actions block is empty")

        try:
            wrapped_actions = f"<root>{actions_xml}</root>"
            root = XMLParser._parse_with_lxml(wrapped_actions)

            if root is None:
                raise XMLParsingError("Failed to parse actions XML")

            tool_calls = []
            for tool_call_elem in root.xpath(".//tool_call"):
                tool_name_elem = tool_call_elem.find(".//tool_name")
                tool_input_elem = tool_call_elem.find(".//tool_input")

                if tool_name_elem is None or tool_input_elem is None:
                    logger.warning("XMLParser: Missing tool_name or tool_input in tool_call")
                    continue

                tool_name = "".join(tool_name_elem.itertext()).strip()
                tool_input_raw = "".join(tool_input_elem.itertext()).strip()

                if not tool_name:
                    logger.warning("XMLParser: Empty tool_name in tool_call")
                    continue

                try:
                    tool_input_raw = re.sub(r"^```(?:json)?\s*|```$", "", tool_input_raw.strip())
                    tool_input = json.loads(tool_input_raw)
                except json.JSONDecodeError as e:
                    error_message = f"Failed to parse JSON in tool_input for {tool_name}: {e}"
                    raise JSONParsingError(error_message)

                tool_calls.append({"tool_name": tool_name, "tool_input": tool_input})

            if not tool_calls:
                raise TagNotFoundError("No valid tool_call elements found in actions")

            return thought, tool_calls

        except Exception as e:
            if isinstance(e, (XMLParsingError, TagNotFoundError, JSONParsingError)):
                raise
            raise XMLParsingError(f"Error parsing multiple tool calls: {e}")

        tool_call_pattern = r"<tool_call>\s*(.*?)\s*</tool_call>"
        tool_call_matches = re.findall(tool_call_pattern, actions_xml, re.DOTALL)

        if not tool_call_matches:
            raise XMLParsingError("No tool_call elements found in actions with regex fallback")

        tool_calls = []
        for tool_call in tool_call_matches:
            tool_name_match = re.search(r"<tool_name>\s*(.*?)\s*</tool_name>", tool_call, re.DOTALL)
            tool_input_match = re.search(r"<tool_input>\s*(.*?)\s*</tool_input>", tool_call, re.DOTALL)

            if not tool_name_match or not tool_input_match:
                continue

            tool_name = tool_name_match.group(1).strip()
            tool_input_raw = tool_input_match.group(1).strip()

            if not tool_name:
                continue

            try:
                tool_input_raw = re.sub(r"^```(?:json)?\s*|```$", "", tool_input_raw.strip())
                tool_input = json.loads(tool_input_raw)
            except json.JSONDecodeError as e:
                error_message = f"Failed to parse JSON in tool_input for {tool_name}: {e}"
                raise JSONParsingError(error_message)

            tool_calls.append({"tool_name": tool_name, "tool_input": tool_input})

        if not tool_calls:
            raise TagNotFoundError("No valid tool_call elements found in actions with regex")

        return thought, tool_calls

    @staticmethod
    def parse_react_xml(text: str) -> dict[str, Any]:
        """
        Parse XML content detecting all three formats:
        - Final answer with thought and answer
        - Single tool with thought, action, and action_input
        - Multiple tools with thought and actions containing tool_calls
        """
        try:
            parsed_data = XMLParser.parse(text, required_tags=["thought", "answer"], optional_tags=["o", "output"])
            return {
                "format_type": "final_answer",
                "thought": parsed_data.get("thought"),
                "answer": parsed_data.get("answer"),
            }
        except TagNotFoundError:
            pass

        if "<actions>" in text:
            try:
                parsed_data = XMLParser.parse(text, required_tags=["thought", "actions"], optional_tags=["o", "output"])

                actions_content = parsed_data.get("actions", "")
                tool_calls = []

                tool_call_pattern = r"<tool_call>(.*?)</tool_call>"
                tool_call_matches = re.findall(tool_call_pattern, actions_content, re.DOTALL)

                for tool_call in tool_call_matches:
                    tool_name_match = re.search(r"<tool_name>(.*?)</tool_name>", tool_call, re.DOTALL)
                    tool_input_match = re.search(r"<tool_input>(.*?)</tool_input>", tool_call, re.DOTALL)

                    if tool_name_match and tool_input_match:
                        tool_name = tool_name_match.group(1).strip()
                        tool_input_raw = tool_input_match.group(1).strip()

                        try:
                            tool_input = json.loads(tool_input_raw)
                        except json.JSONDecodeError:
                            continue

                        tool_calls.append({"tool_name": tool_name, "tool_input": tool_input})

                return {
                    "format_type": "multiple_tools",
                    "thought": parsed_data.get("thought"),
                    "tools": tool_calls,
                }
            except Exception:
                raise

        try:
            parsed_data = XMLParser.parse(
                text,
                required_tags=["thought", "action", "action_input"],
                optional_tags=["o", "output"],
                json_fields=["action_input"],
            )
            return {
                "format_type": "single_tool",
                "thought": parsed_data.get("thought"),
                "action": parsed_data.get("action"),
                "action_input": parsed_data.get("action_input"),
            }
        except Exception as e:
            raise XMLParsingError(f"Failed to parse as any valid format: {e}")

    @staticmethod
    def parse_unified_xml_format(text: str) -> dict[str, Any]:
        """
        Parse XML content using a unified structure for both tool calls and final answers.

        Args:
            text (str): The XML content to parse

        Returns:
            dict: A dictionary containing parsed data with the following structure:
                For tool calls:
                {
                    "is_final": False,
                    "thought": "extracted thought text",
                    "tools": [
                        {"name": "tool name", "input": parsed_json_input},
                        {"name": "tool name", "input": parsed_json_input},
                        ...
                    ]
                }

                For final answer:
                {
                    "is_final": True,
                    "thought": "extracted thought text",
                    "answer": "final answer text"
                }

        Raises:
            XMLParsingError: If the XML cannot be parsed
            TagNotFoundError: If required tags are missing
        """
        try:
            cleaned_text = XMLParser._clean_content(text)
            if not cleaned_text:
                raise XMLParsingError("Empty or invalid XML content")

            try:
                parsed_data = XMLParser.parse(cleaned_text, required_tags=["thought", "answer"], optional_tags=["o"])
                return {"is_final": True, "thought": parsed_data.get("thought"), "answer": parsed_data.get("answer")}
            except TagNotFoundError:
                pass

            root = XMLParser._parse_with_lxml(cleaned_text)
            if root is None:

                wrapped_text = f"<root>{cleaned_text}</root>"
                root = XMLParser._parse_with_lxml(wrapped_text)

            if root is None:
                raise XMLParsingError("Failed to parse XML content with lxml")

            thought_elems = root.xpath(".//thought")
            if not thought_elems:
                raise TagNotFoundError("Required tag <thought> not found")

            thought = "".join(thought_elems[0].itertext()).strip()

            tool_calls_elem = None
            for tag_name in ["tool_calls", "tools"]:
                elems = root.xpath(f".//{tag_name}")
                if elems:
                    tool_calls_elem = elems[0]
                    break

            if tool_calls_elem is None:
                raise TagNotFoundError("Required tag <tool_calls> or <tools> not found")

            tools = []
            for tool_elem in tool_calls_elem.xpath(".//tool"):

                name_elem = None
                for name_tag in ["n", "name", "tool_name"]:
                    name_elems = tool_elem.xpath(f".//{name_tag}")
                    if name_elems:
                        name_elem = name_elems[0]
                        break

                if name_elem is None:
                    continue

                input_elem = None
                for input_tag in ["input", "tool_input"]:
                    input_elems = tool_elem.xpath(f".//{input_tag}")
                    if input_elems:
                        input_elem = input_elems[0]
                        break

                if input_elem is None:
                    continue

                tool_name = "".join(name_elem.itertext()).strip()
                input_json_str = "".join(input_elem.itertext()).strip()

                try:

                    input_json_str = re.sub(r"^```(?:json)?\s*|```$", "", input_json_str.strip())
                    tool_input = json.loads(input_json_str)
                except json.JSONDecodeError as e:
                    logger.warning(f"Failed to parse JSON for tool {tool_name}: {e}")
                    continue

                tools.append({"name": tool_name, "input": tool_input})

            if not tools:
                raise TagNotFoundError("No valid tool elements found with both name and input tags")

            return {"is_final": False, "thought": thought, "tools": tools}

        except (XMLParsingError, TagNotFoundError):
            raise
        except Exception as e:
            raise XMLParsingError(f"Error parsing XML: {str(e)}")


def create_message_from_input(input_data: dict) -> Message | VisionMessage:
    """
    Create appropriate message type based on input data,
    automatically detecting and handling images from either images or files fields

    Args:
        input_data (dict): Input data dictionary containing:
            - 'input': Text input string
            - 'images': List of image data (URLs, bytes, or BytesIO objects)
            - 'files': List of file data (bytes or BytesIO objects)

    Returns:
        Message or VisionMessage: Appropriate message type for the input
    """
    text_input = input_data.get("input", "")
    images = input_data.get("images", []) or []
    files = input_data.get("files", []) or []

    if not isinstance(images, list):
        images = [images]
    else:
        images = list(images)

    for file in files:
        if is_image_file(file):
            logger.debug(f"File detected as image, adding to vision processing: {getattr(file, 'name', 'unnamed')}")
            images.append(file)

    if not images:
        return Message(role=MessageRole.USER, content=text_input)

    content = []

    if text_input:
        content.append(VisionMessageTextContent(text=text_input))

    for image in images:
        try:
            if isinstance(image, str):
                if image.startswith(("http://", "https://", "data:")):
                    image_url = image
                else:
                    with open(image, "rb") as file:
                        image_bytes = file.read()
                        image_url = bytes_to_data_url(image_bytes)
            else:
                if isinstance(image, io.BytesIO):
                    image_bytes = image.getvalue()
                else:
                    image_bytes = image
                image_url = bytes_to_data_url(image_bytes)

            content.append(VisionMessageImageContent(image_url=VisionMessageImageURL(url=image_url)))
        except Exception as e:
            logger.error(f"Error processing image: {str(e)}")

    return VisionMessage(content=content, role=MessageRole.USER)


def is_image_file(file) -> bool:
    """
    Determine if a file is an image by examining its content

    Args:
        file: File-like object or bytes

    Returns:
        bool: True if the file is an image, False otherwise
    """
    try:
        if isinstance(file, io.BytesIO):
            pos = file.tell()
            file.seek(0)
            file_bytes = file.read(32)
            file.seek(pos)
        elif isinstance(file, bytes):
            file_bytes = file[:32]
        else:
            return False

        signatures = {
            b"\xff\xd8\xff": "jpg/jpeg",  # JPEG
            b"\x89PNG\r\n\x1a\n": "png",  # PNG
            b"GIF87a": "gif",  # GIF87a
            b"GIF89a": "gif",  # GIF89a
            b"RIFF": "webp",  # WebP
            b"MM\x00*": "tiff",  # TIFF (big endian)
            b"II*\x00": "tiff",  # TIFF (little endian)
            b"BM": "bmp",  # BMP
        }

        for sig, fmt in signatures.items():
            if file_bytes.startswith(sig):
                return True

        if isinstance(file, io.BytesIO):
            pos = file.tell()
            file.seek(0)
            mime = filetype.guess_mime(file.read(4096))
            file.seek(pos)
            return mime is not None and mime.startswith("image/")
        elif isinstance(file, bytes):
            mime = filetype.guess_mime(file)
            return mime is not None and mime.startswith("image/")

        return False
    except Exception as e:
        logger.error(f"Error checking if file is an image: {str(e)}")
        return False


def bytes_to_data_url(image_bytes: bytes) -> str:
    """
    Convert image bytes to a data URL

    Args:
        image_bytes (bytes): Raw image bytes

    Returns:
        str: Data URL string (format: data:image/jpeg;base64,...)
    """
    try:
        mime_type = filetype.guess_mime(image_bytes)
        if not mime_type:
            if image_bytes[:2] == b"\xff\xd8":
                mime_type = "image/jpeg"
            elif image_bytes[:8] == b"\x89PNG\r\n\x1a\n":
                mime_type = "image/png"
            elif image_bytes[:6] in (b"GIF87a", b"GIF89a"):
                mime_type = "image/gif"
            else:
                mime_type = "application/octet-stream"

        encoded = base64.b64encode(image_bytes).decode("utf-8")
        return f"data:{mime_type};base64,{encoded}"
    except Exception as e:
        logger.error(f"Error converting image to data URL: {str(e)}")
        raise ValueError(f"Failed to convert image to data URL: {str(e)}")


def process_tool_output_for_agent(content: Any, max_tokens: int = TOOL_MAX_TOKENS, truncate: bool = True) -> str:
    """
    Process tool output for agent consumption.

    This function converts various types of tool outputs into a string representation.
    It handles dictionaries (with or without a 'content' key), lists, tuples, and other
    types by converting them to a string. If the resulting string exceeds the maximum
    allowed length (calculated from max_tokens), it is truncated.

    Args:
        content: The output from tool execution, which can be of various types.
        max_tokens: Maximum allowed token count for the content. The effective character
            limit is computed as max_tokens * 4 (assuming ~4 characters per token).
        truncate: Whether to truncate the content if it exceeds the maximum length.

    Returns:
        A processed string suitable for agent consumption.
    """
    if not isinstance(content, str):
        if isinstance(content, dict):
            if "content" in content:
                inner_content = content["content"]
                content = inner_content if isinstance(inner_content, str) else json.dumps(inner_content, indent=2)
            else:
                content = json.dumps(content, indent=2)
        elif isinstance(content, (list, tuple)):
            content = "\n".join(str(item) for item in content)
        else:
            content = str(content)

    max_len_in_char: int = max_tokens * 4  # This assumes an average of 4 characters per token.

    if len(content) > max_len_in_char and truncate:
        half_length: int = (max_len_in_char - 100) // 2
        truncation_message: str = "\n...[Content truncated]...\n"
        content = content[:half_length] + truncation_message + content[-half_length:]

    return content


def extract_thought_from_intermediate_steps(intermediate_steps):
    """Extract thought process from the intermediate steps structure."""
    if not intermediate_steps:
        return None

    for step_key, step_value in intermediate_steps.items():
        if isinstance(step_value, dict) and "model_observation" in step_value:
            model_obs = step_value["model_observation"]

            if isinstance(model_obs, dict):
                if "initial" in model_obs:
                    initial = model_obs["initial"]

                    if initial.startswith("{") and '"thought"' in initial:
                        try:
                            json_data = json.loads(initial)
                            if "thought" in json_data:
                                return json_data["thought"]
                        except json.JSONDecodeError:
                            pass

                    if "<thought>" in initial:
                        thought_match = re.search(r"<thought>\s*(.*?)\s*</thought>", initial, re.DOTALL)
                        if thought_match:
                            return thought_match.group(1)

                    thought_match = re.search(r"Thought:\s*(.*?)(?:\n\n|\nAnswer:)", initial, re.DOTALL)
                    if thought_match:
                        return thought_match.group(1)

    return None
