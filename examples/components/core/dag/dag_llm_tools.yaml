connections:
  openai-conn:  # id
    type: OpenAI
    api_key: ${oc.env:OPENAI_API_KEY}

prompt_template: |
  Please answer the following question
  **User Question:** {{query}}
  Answer:

prompts:
  openai-ai-prompt:
    messages:
      - role: user
        content:
          - type: text
            text: "What time is it in San Francisco, Tokyo, and Paris?"
    tools:
      - type: "function"
        function:
          name: "get_current_time"
          description: "Get the current time in a given location"
          parameters:
            type: "object"
            required:
              - "location"
            properties:
              location:
                type: "string"
                description: "The city, e.g. San Francisco"


nodes:
  openai-1:  # id
    type: dynamiq.nodes.llms.OpenAI
    name: OpenAI-1
    model: gpt-4o
    connection: openai-conn
    prompt: openai-ai-prompt
    error_handling:
      timeout_seconds: 60
      retry_interval_seconds: 1
      max_retries: 0
      backoff_rate: 1
    input_transformer:
      path: null
      selector:
        "query": "$.query"
    output_transformer:
      path: null
      selector:
        "answer": "$.content"
        "tool_calls": "$.tool_calls"
    caching:
      enabled: false
    streaming:
      enabled: false


flows:
  retrieval-flow:  # id
    name: LLM answering flow
    nodes:
      - openai-1


# Could specify multiple workflows in single yaml
workflows:

  retrieval-workflow:  # id
    flow: retrieval-flow
