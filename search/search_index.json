{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> Dynamiq is an orchestration framework for agentic AI and LLM applications </p> <p> </p> <p>Welcome to Dynamiq! \ud83e\udd16</p> <p>Dynamiq is your all-in-one Gen AI framework, designed to streamline the development of AI-powered applications. Dynamiq specializes in orchestrating retrieval-augmented generation (RAG) and large language model (LLM) agents.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to dive in? Here's how you can get started with Dynamiq:</p>"},{"location":"#installation","title":"Installation","text":"<p>First, let's get Dynamiq installed. You'll need Python, so make sure that's set up on your machine. Then run:</p> <pre><code>pip install dynamiq\n</code></pre> <p>Or build the Python package from the source code: <pre><code>git clone https://github.com/dynamiq-ai/dynamiq.git\ncd dynamiq\npoetry install\n</code></pre></p>"},{"location":"#documentation","title":"Documentation","text":"<p>For more examples and detailed guides, please refer to our documentation.</p>"},{"location":"#examples","title":"Examples","text":""},{"location":"#simple-llm-flow","title":"Simple LLM Flow","text":"<p>Here's a simple example to get you started with Dynamiq:</p> <pre><code>from dynamiq.nodes.llms.openai import OpenAI\nfrom dynamiq.connections import OpenAI as OpenAIConnection\nfrom dynamiq.prompts import Prompt, Message\n\n# Define the prompt template for translation\nprompt_template = \"\"\"\nTranslate the following text into English: {{ text }}\n\"\"\"\n\n# Create a Prompt object with the defined template\nprompt = Prompt(messages=[Message(content=prompt_template, role=\"user\")])\n\n# Setup your LLM (Large Language Model) Node\nllm = OpenAI(\n    id=\"openai\",  # Unique identifier for the node\n    connection=OpenAIConnection(api_key=\"OPENAI_API_KEY\"),  # Connection using API key\n    model=\"gpt-4o\",  # Model to be used\n    temperature=0.3,  # Sampling temperature for the model\n    max_tokens=1000,  # Maximum number of tokens in the output\n    prompt=prompt  # Prompt to be used for the model\n)\n\n# Run the LLM node with the input data\nresult = llm.run(\n    input_data={\n        \"text\": \"Hola Mundo!\"  # Text to be translated\n    }\n)\n\n# Print the result of the translation\nprint(result.output)\n</code></pre>"},{"location":"#simple-react-agent-with-asynchronous-execution","title":"Simple ReAct Agent with asynchronous execution","text":"<p>An agent that has the access to E2B Code Interpreter and is capable of solving complex coding tasks.</p> <pre><code>from dynamiq.nodes.llms.openai import OpenAI\nfrom dynamiq.connections import OpenAI as OpenAIConnection, E2B as E2BConnection\nfrom dynamiq.nodes.agents import Agent\nfrom dynamiq.nodes.tools.e2b_sandbox import E2BInterpreterTool\n\n# Initialize the E2B tool\ne2b_tool = E2BInterpreterTool(\n    connection=E2BConnection(api_key=\"E2B_API_KEY\")\n)\n\n# Setup your LLM\nllm = OpenAI(\n    id=\"openai\",\n    connection=OpenAIConnection(api_key=\"OPENAI_API_KEY\"),\n    model=\"gpt-4o\",\n    temperature=0.3,\n    max_tokens=1000,\n)\n\n# Create the agent\nagent = Agent(\n    name=\"react-agent\",\n    llm=llm, # Language model instance\n    tools=[e2b_tool],  # List of tools that the agent can use\n    role=\"Senior Data Scientist\",  # Role of the agent\n    max_loops=10, # Limit on the number of processing loops\n)\n\nasync def run_async_agent():\n    # Run the agent asynchronously with an input\n    result = await agent.run(\n        input_data={\n            \"input\": \"Add the first 10 numbers and tell if the result is prime.\",\n        }\n    )\n\n    print(result.output.get(\"content\"))\n\n\n# Execute the async function\nif __name__ == \"__main__\":\n    asyncio.run(run_async_agent())\n</code></pre>"},{"location":"#configuring-two-parallel-agents-with-workflow","title":"Configuring Two Parallel Agents with WorkFlow","text":"<pre><code>from dynamiq import Workflow\nfrom dynamiq.nodes.llms import OpenAI\nfrom dynamiq.connections import OpenAI as OpenAIConnection\nfrom dynamiq.nodes.agents import Agent\n\n# Setup your LLM\nllm = OpenAI(\n    connection=OpenAIConnection(api_key=\"OPENAI_API_KEY\"),\n    model=\"gpt-4o\",\n    temperature=0.1,\n)\n\n# Define the first agent: a question answering agent\nfirst_agent = Agent(\n    name=\"Expert Agent\",\n    llm=llm,\n    role=\"Professional writer with the goal of producing well-written and informative responses.\",\n    id=\"agent_1\",\n    max_loops=5\n)\n\n# Define the second agent: a poetic writer\nsecond_agent = Agent(\n    name=\"Poetic Rewriter Agent\",\n    llm=llm,\n    role=\"Professional writer with the goal of rewriting user input as a poem without changing its meaning.\",\n    id=\"agent_2\",\n    max_loops=5\n)\n\n\n# Create a workflow to run both agents with the same input\n# The `Workflow` class simplifies setting up and executing a series of nodes in a pipeline.\n# It automatically handles running the agents in parallel where possible.\nwf = Workflow()\nwf.flow.add_nodes(first_agent)\nwf.flow.add_nodes(second_agent)\n\n# Equivalent alternative way to define the workflow:\n# from dynamiq.flows import Flow\n# wf = Workflow(flow=Flow(nodes=[agent_first, agent_second]))\n\n# Run the workflow with an input\nresult = wf.run(\n    input_data={\"input\": \"How are sin(x) and cos(x) connected in electrodynamics?\"},\n)\n\n# Print the input and output for both agents\nprint('--- Agent 1: Input ---\\n', result.output[first_agent.id].get(\"input\").get('input'))\nprint('--- Agent 1: Output ---\\n', result.output[first_agent.id].get(\"output\").get('content'))\nprint('--- Agent 2: Input ---\\n', result.output[second_agent.id].get(\"input\").get('input'))\nprint('--- Agent 2: Output ---\\n', result.output[second_agent.id].get(\"output\").get('content'))\n</code></pre>"},{"location":"#configuring-two-sequential-agents-with-workflow","title":"Configuring Two Sequential Agents with WorkFlow","text":"<pre><code>from dynamiq import Workflow\nfrom dynamiq.nodes.llms import OpenAI\nfrom dynamiq.connections import OpenAI as OpenAIConnection\nfrom dynamiq.nodes.agents import Agent\n\nfrom dynamiq.nodes.node import InputTransformer, NodeDependency\n\n# Setup your LLM\nllm = OpenAI(\n    connection=OpenAIConnection(api_key=\"OPENAI_API_KEY\"),\n    model=\"gpt-4o\",\n    temperature=0.1,\n)\n\nfirst_agent = Agent(\n    name=\"Expert Agent\",\n    llm=llm,\n    role=\"Professional writer with the goal of producing well-written and informative responses.\",  # Role of the agent\n    id=\"agent_1\",\n    max_loops=5\n)\n\nsecond_agent = Agent(\n    name=\"Poetic Rewriter Agent\",\n    llm=llm,\n    role=\"Professional writer with the goal of rewriting user input as a poem without changing its meaning.\",  # Role of the agent\n    id=\"agent_2\",\n    depends=[NodeDependency(first_agent)],  # Set dependency on the first agent\n    input_transformer=InputTransformer(\n        selector={\"input\": f\"${[first_agent.id]}.output.content\"}  # Extract the output of the first agent as input\n    ),\n    max_loops=5\n)\n\n# Create a workflow to run the agents sequentially based on dependencies.\n# Without a workflow, you would need to run `first_agent`, collect its output,\n# and then manually pass that output as input to `second_agent`. The workflow automates this process.\nwf = Workflow()\nwf.flow.add_nodes(first_agent)\nwf.flow.add_nodes(second_agent)\n\n# Equivalent alternative way to define the workflow:\n# from dynamiq.flows import Flow\n# wf = Workflow(flow=Flow(nodes=[agent_first, agent_second]))\n\n# Run the workflow with an input\nresult = wf.run(\n    input_data={\"input\": \"How are sin(x) and cos(x) connected in electrodynamics?\"},\n)\n\n# Print the input and output for both agents\nprint('--- Agent 1: Input ---\\n', result.output[first_agent.id].get(\"input\").get('input'))\nprint('--- Agent 1: Output ---\\n', result.output[first_agent.id].get(\"output\").get('content'))\nprint('--- Agent 2: Input ---\\n', result.output[second_agent.id].get(\"input\").get('input'))\nprint('--- Agent 2: Output ---\\n', result.output[second_agent.id].get(\"output\").get('content'))\n</code></pre>"},{"location":"#multi-agent-orchestration","title":"Multi-agent orchestration","text":"<pre><code>from dynamiq import Workflow\nfrom dynamiq.connections import OpenAI as OpenAIConnection, ScaleSerp as ScaleSerpConnection\nfrom dynamiq.flows import Flow\nfrom dynamiq.nodes.agents import Agent\nfrom dynamiq.nodes.llms import OpenAI\nfrom dynamiq.nodes.tools.scale_serp import ScaleSerpTool\nfrom dynamiq.nodes.types import Behavior, InferenceMode\n\nllm = OpenAI(\n    connection=OpenAIConnection(api_key=\"OPENAI_API_KEY\"),\n    model=\"gpt-4o\",\n    temperature=0.1,\n)\n\nsearch_tool = ScaleSerpTool(connection=ScaleSerpConnection(api_key=\"SCALESERP_API_KEY\"))\n\nresearch_agent = Agent(\n    name=\"Research Analyst\",\n    role=\"Find recent market news and provide referenced highlights.\",\n    llm=llm,\n    tools=[search_tool],\n    inference_mode=InferenceMode.XML,\n    max_loops=6,\n    behaviour_on_max_loops=Behavior.RETURN,\n)\n\nwriter_agent = Agent(\n    name=\"Brief Writer\",\n    role=\"Turn research highlights into a concise executive brief.\",\n    llm=llm,\n    inference_mode=InferenceMode.XML,\n    max_loops=4,\n    behaviour_on_max_loops=Behavior.RETURN,\n)\n\nmanager_agent = Agent(\n    name=\"Manager\",\n    role=(\n        \"Delegate research and writing to sub-agents.\\n\"\n        \"Always call tools with {'input': '&lt;task&gt;'} payloads and assemble the final brief.\"\n    ),\n    llm=llm,\n    tools=[research_agent, writer_agent],\n    inference_mode=InferenceMode.XML,\n    parallel_tool_calls_enabled=True,\n    max_loops=8,\n    behaviour_on_max_loops=Behavior.RETURN,\n)\n\nworkflow = Workflow(flow=Flow(nodes=[manager_agent]))\n\nresult = workflow.run(\n    input_data={\"input\": \"Summarize the latest developments in battery technology for investors.\"},\n)\n\nprint(result.output[manager_agent.id][\"output\"][\"content\"])\n</code></pre>"},{"location":"#rag-document-indexing-flow","title":"RAG - document indexing flow","text":"<p>This workflow takes input PDF files, pre-processes them, converts them to vector embeddings, and stores them in the Pinecone vector database. The example provided is for an existing index in Pinecone. You can find examples for index creation on the <code>docs/tutorials/rag</code> page.</p> <pre><code>from io import BytesIO\n\nfrom dynamiq import Workflow\nfrom dynamiq.connections import OpenAI as OpenAIConnection, Pinecone as PineconeConnection\nfrom dynamiq.nodes.converters import PyPDFConverter\nfrom dynamiq.nodes.splitters.document import DocumentSplitter\nfrom dynamiq.nodes.embedders import OpenAIDocumentEmbedder\nfrom dynamiq.nodes.writers import PineconeDocumentWriter\n\nrag_wf = Workflow()\n\n# PyPDF document converter\nconverter = PyPDFConverter(document_creation_mode=\"one-doc-per-page\")\nrag_wf.flow.add_nodes(converter)  # add node to the DAG\n\n# Document splitter\ndocument_splitter = (\n    DocumentSplitter(\n        split_by=\"sentence\",\n        split_length=10,\n        split_overlap=1,\n    )\n    .inputs(documents=converter.outputs.documents)  # map converter node output to the expected input of the current node\n    .depends_on(converter)\n)\nrag_wf.flow.add_nodes(document_splitter)\n\n# OpenAI vector embeddings\nembedder = (\n    OpenAIDocumentEmbedder(\n        connection=OpenAIConnection(api_key=\"OPENAI_API_KEY\"),\n        model=\"text-embedding-3-small\",\n    )\n    .inputs(documents=document_splitter.outputs.documents)\n    .depends_on(document_splitter)\n)\nrag_wf.flow.add_nodes(embedder)\n\n# Pinecone vector storage\nvector_store = (\n    PineconeDocumentWriter(\n        connection=PineconeConnection(api_key=\"PINECONE_API_KEY\"),\n        index_name=\"default\",\n        dimension=1536,\n    )\n    .inputs(documents=embedder.outputs.documents)\n    .depends_on(embedder)\n)\nrag_wf.flow.add_nodes(vector_store)\n\n# Prepare input PDF files\nfile_paths = [\"example.pdf\"]\ninput_data = {\n    \"files\": [\n        BytesIO(open(path, \"rb\").read()) for path in file_paths\n    ],\n    \"metadata\": [\n        {\"filename\": path} for path in file_paths\n    ],\n}\n\n# Run RAG indexing flow\nrag_wf.run(input_data=input_data)\n</code></pre>"},{"location":"#rag-document-retrieval-flow","title":"RAG - document retrieval flow","text":"<p>Simple retrieval RAG flow that searches for relevant documents and answers the original user question using retrieved documents.</p> <pre><code>from dynamiq import Workflow\nfrom dynamiq.connections import OpenAI as OpenAIConnection, Pinecone as PineconeConnection\nfrom dynamiq.nodes.embedders import OpenAITextEmbedder\nfrom dynamiq.nodes.retrievers import PineconeDocumentRetriever\nfrom dynamiq.nodes.llms import OpenAI\nfrom dynamiq.prompts import Message, Prompt\n\n# Initialize the RAG retrieval workflow\nretrieval_wf = Workflow()\n\n# Shared OpenAI connection\nopenai_connection = OpenAIConnection(api_key=\"OPENAI_API_KEY\")\n\n# OpenAI text embedder for query embedding\nembedder = OpenAITextEmbedder(\n    connection=openai_connection,\n    model=\"text-embedding-3-small\",\n)\nretrieval_wf.flow.add_nodes(embedder)\n\n# Pinecone document retriever\ndocument_retriever = (\n    PineconeDocumentRetriever(\n        connection=PineconeConnection(api_key=\"PINECONE_API_KEY\"),\n        index_name=\"default\",\n        dimension=1536,\n        top_k=5,\n    )\n    .inputs(embedding=embedder.outputs.embedding)\n    .depends_on(embedder)\n)\nretrieval_wf.flow.add_nodes(document_retriever)\n\n# Define the prompt template\nprompt_template = \"\"\"\nPlease answer the question based on the provided context.\n\nQuestion: {{ query }}\n\nContext:\n{% for document in documents %}\n- {{ document.content }}\n{% endfor %}\n\n\"\"\"\n\n# OpenAI LLM for answer generation\nprompt = Prompt(messages=[Message(content=prompt_template, role=\"user\")])\n\nanswer_generator = (\n    OpenAI(\n        connection=openai_connection,\n        model=\"gpt-4o\",\n        prompt=prompt,\n    )\n    .inputs(\n        documents=document_retriever.outputs.documents,\n        query=embedder.outputs.query,\n    )  # take documents from the vector store node and query from the embedder\n    .depends_on([document_retriever, embedder])\n)\nretrieval_wf.flow.add_nodes(answer_generator)\n\n# Run the RAG retrieval flow\nquestion = \"What are the line intems provided in the invoice?\"\nresult = retrieval_wf.run(input_data={\"query\": question})\n\nanswer = result.output.get(answer_generator.id).get(\"output\", {}).get(\"content\")\nprint(answer)\n</code></pre>"},{"location":"#simple-chatbot-with-memory","title":"Simple Chatbot with Memory","text":"<p>A simple chatbot that uses the <code>Memory</code> module to store and retrieve conversation history.</p> <pre><code>from dynamiq.connections import OpenAI as OpenAIConnection\nfrom dynamiq.memory import Memory\nfrom dynamiq.memory.backends.in_memory import InMemory\nfrom dynamiq.nodes.agents import Agent\nfrom dynamiq.nodes.llms import OpenAI\n\nAGENT_ROLE = \"helpful assistant, goal is to provide useful information and answer questions\"\nllm = OpenAI(\n    connection=OpenAIConnection(api_key=\"OPENAI_API_KEY\"),\n    model=\"gpt-4o\",\n    temperature=0.1,\n)\n\nmemory = Memory(backend=InMemory())\n\nagent = Agent(\n    name=\"Agent\",\n    llm=llm,\n    role=AGENT_ROLE,\n    id=\"agent\",\n    memory=memory,\n)\n\n\ndef main():\n    print(\"Welcome to the AI Chat! (Type 'exit' to end)\")\n    while True:\n        user_input = input(\"You: \")\n        user_id = \"user\"\n        session_id = \"session\"\n        if user_input.lower() == \"exit\":\n            break\n\n        response = agent.run({\"input\": user_input, \"user_id\": user_id, \"session_id\": session_id})\n        response_content = response.output.get(\"content\")\n        print(f\"AI: {response_content}\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"#graph-orchestrator","title":"Graph Orchestrator","text":"<p>Graph Orchestrator allows to create any architecture tailored to specific use cases. Example of simple workflow that manages iterative process of feedback and refinement of email.</p> <pre><code>from typing import Any\n\nfrom dynamiq.connections import OpenAI as OpenAIConnection\nfrom dynamiq.nodes.agents.orchestrators.graph import END, START, GraphOrchestrator\nfrom dynamiq.nodes.agents.orchestrators.graph_manager import GraphAgentManager\nfrom dynamiq.nodes.agents import Agent\nfrom dynamiq.nodes.llms import OpenAI\n\nllm = OpenAI(\n    connection=OpenAIConnection(api_key=\"OPENAI_API_KEY\"),\n    model=\"gpt-4o\",\n    temperature=0.1,\n)\n\nemail_writer = Agent(\n    name=\"email-writer-agent\",\n    llm=llm,\n    role=\"Write personalized emails taking into account feedback.\",\n)\n\n\ndef gather_feedback(context: dict[str, Any], **kwargs):\n    \"\"\"Gather feedback about email draft.\"\"\"\n    feedback = input(\n        f\"Email draft:\\n\"\n        f\"{context.get('history', [{}])[-1].get('content', 'No draft')}\\n\"\n        f\"Type in SEND to send email, CANCEL to exit, or provide feedback to refine email: \\n\"\n    )\n\n    reiterate = True\n\n    result = f\"Gathered feedback: {feedback}\"\n\n    feedback = feedback.strip().lower()\n    if feedback == \"send\":\n        print(\"####### Email was sent! #######\")\n        result = \"Email was sent!\"\n        reiterate = False\n    elif feedback == \"cancel\":\n        print(\"####### Email was canceled! #######\")\n        result = \"Email was canceled!\"\n        reiterate = False\n\n    return {\"result\": result, \"reiterate\": reiterate}\n\n\ndef router(context: dict[str, Any], **kwargs):\n    \"\"\"Determines next state based on provided feedback.\"\"\"\n    if context.get(\"reiterate\", False):\n        return \"generate_sketch\"\n\n    return END\n\n\norchestrator = GraphOrchestrator(\n    name=\"Graph orchestrator\",\n    manager=GraphAgentManager(llm=llm),\n)\n\n# Attach tasks to the states. These tasks will be executed when the respective state is triggered.\norchestrator.add_state_by_tasks(\"generate_sketch\", [email_writer])\norchestrator.add_state_by_tasks(\"gather_feedback\", [gather_feedback])\n\n# Define the flow between states by adding edges.\n# This configuration creates the sequence of states from START -&gt; \"generate_sketch\" -&gt; \"gather_feedback\".\norchestrator.add_edge(START, \"generate_sketch\")\norchestrator.add_edge(\"generate_sketch\", \"gather_feedback\")\n\n# Add a conditional edge to the \"gather_feedback\" state, allowing the flow to branch based on a condition.\n# The router function will determine whether the flow should go to \"generate_sketch\" (reiterate) or END (finish the process).\norchestrator.add_conditional_edge(\"gather_feedback\", [\"generate_sketch\", END], router)\n\n\nif __name__ == \"__main__\":\n    print(\"Welcome to email writer.\")\n    email_details = input(\"Provide email details: \")\n    orchestrator.run(input_data={\"input\": f\"Write and post email, provide feedback about status of email: {email_details}\"})\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>We love contributions! Whether it's bug reports, feature requests, or pull requests, head over to our CONTRIBUTING.md to see how you can help.</p>"},{"location":"#license","title":"License","text":"<p>Dynamiq is open-source and available under the Apache 2 License.</p> <p>Happy coding! \ud83d\ude80</p>"},{"location":"dynamiq/cache/codecs/","title":"Codecs","text":""},{"location":"dynamiq/cache/codecs/#dynamiq.cache.codecs.Base64Codec","title":"<code>Base64Codec</code>","text":"<p>               Bases: <code>BaseCodec</code></p> <p>Base64 encoding and decoding implementation.</p> Source code in <code>dynamiq/cache/codecs.py</code> <pre><code>class Base64Codec(BaseCodec):\n    \"\"\"Base64 encoding and decoding implementation.\"\"\"\n\n    def encode(self, value: str) -&gt; str:\n        \"\"\"Encode a string using Base64.\n\n        Args:\n            value (str): The string to encode.\n\n        Returns:\n            str: The Base64 encoded string.\n        \"\"\"\n        return base64.b64encode(value.encode()).decode()\n\n    def decode(self, value: str | bytes) -&gt; str:\n        \"\"\"Decode a Base64 encoded string or bytes.\n\n        Args:\n            value (str | bytes): The value to decode.\n\n        Returns:\n            str: The decoded string.\n        \"\"\"\n        return base64.b64decode(value).decode()\n</code></pre>"},{"location":"dynamiq/cache/codecs/#dynamiq.cache.codecs.Base64Codec.decode","title":"<code>decode(value)</code>","text":"<p>Decode a Base64 encoded string or bytes.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str | bytes</code> <p>The value to decode.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The decoded string.</p> Source code in <code>dynamiq/cache/codecs.py</code> <pre><code>def decode(self, value: str | bytes) -&gt; str:\n    \"\"\"Decode a Base64 encoded string or bytes.\n\n    Args:\n        value (str | bytes): The value to decode.\n\n    Returns:\n        str: The decoded string.\n    \"\"\"\n    return base64.b64decode(value).decode()\n</code></pre>"},{"location":"dynamiq/cache/codecs/#dynamiq.cache.codecs.Base64Codec.encode","title":"<code>encode(value)</code>","text":"<p>Encode a string using Base64.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The string to encode.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Base64 encoded string.</p> Source code in <code>dynamiq/cache/codecs.py</code> <pre><code>def encode(self, value: str) -&gt; str:\n    \"\"\"Encode a string using Base64.\n\n    Args:\n        value (str): The string to encode.\n\n    Returns:\n        str: The Base64 encoded string.\n    \"\"\"\n    return base64.b64encode(value.encode()).decode()\n</code></pre>"},{"location":"dynamiq/cache/codecs/#dynamiq.cache.codecs.BaseCodec","title":"<code>BaseCodec</code>","text":"<p>Abstract base class for encoding and decoding.</p> Source code in <code>dynamiq/cache/codecs.py</code> <pre><code>class BaseCodec:\n    \"\"\"Abstract base class for encoding and decoding.\"\"\"\n\n    def encode(self, value: str) -&gt; str:\n        \"\"\"Encode a string value.\n\n        Args:\n            value (str): The string to encode.\n\n        Returns:\n            str: The encoded string.\n        \"\"\"\n        raise NotImplementedError\n\n    def decode(self, value: str | bytes) -&gt; str:\n        \"\"\"Decode a string or bytes value.\n\n        Args:\n            value (str | bytes): The value to decode.\n\n        Returns:\n            str: The decoded string.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/cache/codecs/#dynamiq.cache.codecs.BaseCodec.decode","title":"<code>decode(value)</code>","text":"<p>Decode a string or bytes value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str | bytes</code> <p>The value to decode.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The decoded string.</p> Source code in <code>dynamiq/cache/codecs.py</code> <pre><code>def decode(self, value: str | bytes) -&gt; str:\n    \"\"\"Decode a string or bytes value.\n\n    Args:\n        value (str | bytes): The value to decode.\n\n    Returns:\n        str: The decoded string.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/cache/codecs/#dynamiq.cache.codecs.BaseCodec.encode","title":"<code>encode(value)</code>","text":"<p>Encode a string value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The string to encode.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The encoded string.</p> Source code in <code>dynamiq/cache/codecs.py</code> <pre><code>def encode(self, value: str) -&gt; str:\n    \"\"\"Encode a string value.\n\n    Args:\n        value (str): The string to encode.\n\n    Returns:\n        str: The encoded string.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/cache/config/","title":"Config","text":""},{"location":"dynamiq/cache/config/#dynamiq.cache.config.CacheBackend","title":"<code>CacheBackend</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration for cache backends.</p> Source code in <code>dynamiq/cache/config.py</code> <pre><code>class CacheBackend(str, enum.Enum):\n    \"\"\"Enumeration for cache backends.\"\"\"\n    Redis = \"Redis\"\n</code></pre>"},{"location":"dynamiq/cache/config/#dynamiq.cache.config.CacheConfig","title":"<code>CacheConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for cache settings.</p> <p>Attributes:</p> Name Type Description <code>backend</code> <code>CacheBackend</code> <p>The cache backend to use.</p> <code>namespace</code> <code>str | None</code> <p>Optional namespace for cache keys.</p> <code>ttl</code> <code>int | None</code> <p>Optional time-to-live for cache entries.</p> Source code in <code>dynamiq/cache/config.py</code> <pre><code>class CacheConfig(BaseModel):\n    \"\"\"Configuration for cache settings.\n\n    Attributes:\n        backend (CacheBackend): The cache backend to use.\n        namespace (str | None): Optional namespace for cache keys.\n        ttl (int | None): Optional time-to-live for cache entries.\n    \"\"\"\n    backend: CacheBackend\n    namespace: str | None = None\n    ttl: int | None = None\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Convert config to dictionary.\n\n        Args:\n            **kwargs: Additional arguments.\n\n        Returns:\n            dict: Configuration as dictionary.\n        \"\"\"\n        return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/cache/config/#dynamiq.cache.config.CacheConfig.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Convert config to dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Configuration as dictionary.</p> Source code in <code>dynamiq/cache/config.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Convert config to dictionary.\n\n    Args:\n        **kwargs: Additional arguments.\n\n    Returns:\n        dict: Configuration as dictionary.\n    \"\"\"\n    return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/cache/config/#dynamiq.cache.config.RedisCacheConfig","title":"<code>RedisCacheConfig</code>","text":"<p>               Bases: <code>CacheConfig</code>, <code>RedisConnection</code></p> <p>Configuration for Redis cache.</p> <p>Attributes:</p> Name Type Description <code>backend</code> <code>Literal[Redis]</code> <p>The Redis cache backend.</p> Source code in <code>dynamiq/cache/config.py</code> <pre><code>class RedisCacheConfig(CacheConfig, RedisConnection):\n    \"\"\"Configuration for Redis cache.\n\n    Attributes:\n        backend (Literal[CacheBackend.Redis]): The Redis cache backend.\n    \"\"\"\n    backend: Literal[CacheBackend.Redis] = CacheBackend.Redis\n</code></pre>"},{"location":"dynamiq/cache/utils/","title":"Utils","text":""},{"location":"dynamiq/cache/utils/#dynamiq.cache.utils.cache_wf_entity","title":"<code>cache_wf_entity(entity_id, cache_enabled=False, cache_manager_cls=WorkflowCacheManager, cache_config=None, func_kwargs_to_remove=FUNC_KWARGS_TO_REMOVE)</code>","text":"<p>Decorator to cache workflow entity outputs.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Identifier for the entity.</p> required <code>cache_enabled</code> <code>bool</code> <p>Flag to enable caching.</p> <code>False</code> <code>cache_manager_cls</code> <code>type[WorkflowCacheManager]</code> <p>Cache manager class.</p> <code>WorkflowCacheManager</code> <code>cache_config</code> <code>CacheConfig | None</code> <p>Cache configuration.</p> <code>None</code> <code>func_kwargs_to_remove</code> <code>tuple[str]</code> <p>List of params to remove from callable function kwargs.</p> <code>FUNC_KWARGS_TO_REMOVE</code> <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>Wrapped function with caching.</p> Source code in <code>dynamiq/cache/utils.py</code> <pre><code>def cache_wf_entity(\n    entity_id: str,\n    cache_enabled: bool = False,\n    cache_manager_cls: type[WorkflowCacheManager] = WorkflowCacheManager,\n    cache_config: CacheConfig | None = None,\n    func_kwargs_to_remove: tuple[str] = FUNC_KWARGS_TO_REMOVE,\n) -&gt; Callable:\n    \"\"\"Decorator to cache workflow entity outputs.\n\n    Args:\n        entity_id (str): Identifier for the entity.\n        cache_enabled (bool): Flag to enable caching.\n        cache_manager_cls (type[WorkflowCacheManager]): Cache manager class.\n        cache_config (CacheConfig | None): Cache configuration.\n        func_kwargs_to_remove (tuple[str]): List of params to remove from callable function kwargs.\n\n    Returns:\n        Callable: Wrapped function with caching.\n    \"\"\"\n    def _cache(func: Callable) -&gt; Callable:\n        \"\"\"Inner cache decorator.\n\n        Args:\n            func (Callable): Function to wrap.\n\n        Returns:\n            Callable: Wrapped function.\n        \"\"\"\n        @wraps(func)\n        def wrapper(*args: Any, **kwargs: Any) -&gt; tuple[Any, bool]:\n            \"\"\"Wrapper function to handle caching.\n\n            Args:\n                *args (Any): Positional arguments.\n                **kwargs (Any): Keyword arguments.\n\n            Returns:\n                tuple[Any, bool]: Function output and cache status.\n            \"\"\"\n            cache_manager = None\n            from_cache = False\n            input_data = kwargs.pop(\"input_data\", args[0] if args else {})\n            input_data = dict(input_data) if isinstance(input_data, BaseModel) else input_data\n\n            cleaned_kwargs = {k: v for k, v in kwargs.items() if k not in func_kwargs_to_remove}\n            if cache_enabled and cache_config:\n                logger.debug(f\"Entity_id {entity_id}: cache used\")\n                cache_manager = cache_manager_cls(config=cache_config)\n                if output := cache_manager.get_entity_output(\n                    entity_id=entity_id, input_data=input_data, **cleaned_kwargs\n                ):\n                    from_cache = True\n                    return output, from_cache\n\n            output = func(*args, **kwargs)\n\n            if cache_manager:\n                cache_manager.set_entity_output(\n                    entity_id=entity_id, input_data=input_data, output_data=output, **cleaned_kwargs\n                )\n\n            return output, from_cache\n\n        return wrapper\n\n    return _cache\n</code></pre>"},{"location":"dynamiq/cache/backends/base/","title":"Base","text":""},{"location":"dynamiq/cache/backends/base/#dynamiq.cache.backends.base.BaseCache","title":"<code>BaseCache</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for cache backends.</p> <p>Attributes:</p> Name Type Description <code>client</code> <code>CacheClient</code> <p>Cache client instance.</p> Source code in <code>dynamiq/cache/backends/base.py</code> <pre><code>class BaseCache(ABC):\n    \"\"\"Abstract base class for cache backends.\n\n    Attributes:\n        client (CacheClient): Cache client instance.\n    \"\"\"\n\n    def __init__(self, client: CacheClient):\n        \"\"\"Initialize BaseCache.\n\n        Args:\n            client (CacheClient): Cache client instance.\n        \"\"\"\n        self.client = client\n\n    @classmethod\n    def from_client(cls, client: CacheClient):\n        \"\"\"Create cache instance from client.\n\n        Args:\n            client (CacheClient): Cache client instance.\n\n        Returns:\n            BaseCache: Cache instance.\n        \"\"\"\n        return cls(client=client)\n\n    @classmethod\n    @abstractmethod\n    def from_config(cls, config: CacheConfig):\n        \"\"\"Create cache instance from configuration.\n\n        Args:\n            config (CacheConfig): Cache configuration.\n\n        Raises:\n            NotImplementedError: If not implemented.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get(self, key: str):\n        \"\"\"Retrieve value from cache.\n\n        Args:\n            key (str): Cache key.\n\n        Raises:\n            NotImplementedError: If not implemented.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def set(self, key: str, value: dict):\n        \"\"\"Set value in cache.\n\n        Args:\n            key (str): Cache key.\n            value (dict): Value to cache.\n\n        Raises:\n            NotImplementedError: If not implemented.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def delete(self, key: str):\n        \"\"\"Delete value from cache.\n\n        Args:\n            key (str): Cache key.\n\n        Raises:\n            NotImplementedError: If not implemented.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/cache/backends/base/#dynamiq.cache.backends.base.BaseCache.__init__","title":"<code>__init__(client)</code>","text":"<p>Initialize BaseCache.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>CacheClient</code> <p>Cache client instance.</p> required Source code in <code>dynamiq/cache/backends/base.py</code> <pre><code>def __init__(self, client: CacheClient):\n    \"\"\"Initialize BaseCache.\n\n    Args:\n        client (CacheClient): Cache client instance.\n    \"\"\"\n    self.client = client\n</code></pre>"},{"location":"dynamiq/cache/backends/base/#dynamiq.cache.backends.base.BaseCache.delete","title":"<code>delete(key)</code>  <code>abstractmethod</code>","text":"<p>Delete value from cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented.</p> Source code in <code>dynamiq/cache/backends/base.py</code> <pre><code>@abstractmethod\ndef delete(self, key: str):\n    \"\"\"Delete value from cache.\n\n    Args:\n        key (str): Cache key.\n\n    Raises:\n        NotImplementedError: If not implemented.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/cache/backends/base/#dynamiq.cache.backends.base.BaseCache.from_client","title":"<code>from_client(client)</code>  <code>classmethod</code>","text":"<p>Create cache instance from client.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>CacheClient</code> <p>Cache client instance.</p> required <p>Returns:</p> Name Type Description <code>BaseCache</code> <p>Cache instance.</p> Source code in <code>dynamiq/cache/backends/base.py</code> <pre><code>@classmethod\ndef from_client(cls, client: CacheClient):\n    \"\"\"Create cache instance from client.\n\n    Args:\n        client (CacheClient): Cache client instance.\n\n    Returns:\n        BaseCache: Cache instance.\n    \"\"\"\n    return cls(client=client)\n</code></pre>"},{"location":"dynamiq/cache/backends/base/#dynamiq.cache.backends.base.BaseCache.from_config","title":"<code>from_config(config)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Create cache instance from configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>CacheConfig</code> <p>Cache configuration.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented.</p> Source code in <code>dynamiq/cache/backends/base.py</code> <pre><code>@classmethod\n@abstractmethod\ndef from_config(cls, config: CacheConfig):\n    \"\"\"Create cache instance from configuration.\n\n    Args:\n        config (CacheConfig): Cache configuration.\n\n    Raises:\n        NotImplementedError: If not implemented.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/cache/backends/base/#dynamiq.cache.backends.base.BaseCache.get","title":"<code>get(key)</code>  <code>abstractmethod</code>","text":"<p>Retrieve value from cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented.</p> Source code in <code>dynamiq/cache/backends/base.py</code> <pre><code>@abstractmethod\ndef get(self, key: str):\n    \"\"\"Retrieve value from cache.\n\n    Args:\n        key (str): Cache key.\n\n    Raises:\n        NotImplementedError: If not implemented.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/cache/backends/base/#dynamiq.cache.backends.base.BaseCache.set","title":"<code>set(key, value)</code>  <code>abstractmethod</code>","text":"<p>Set value in cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <code>value</code> <code>dict</code> <p>Value to cache.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented.</p> Source code in <code>dynamiq/cache/backends/base.py</code> <pre><code>@abstractmethod\ndef set(self, key: str, value: dict):\n    \"\"\"Set value in cache.\n\n    Args:\n        key (str): Cache key.\n        value (dict): Value to cache.\n\n    Raises:\n        NotImplementedError: If not implemented.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/cache/backends/redis/","title":"Redis","text":""},{"location":"dynamiq/cache/backends/redis/#dynamiq.cache.backends.redis.RedisCache","title":"<code>RedisCache</code>","text":"<p>               Bases: <code>BaseCache</code></p> <p>Redis cache backend implementation.</p> Source code in <code>dynamiq/cache/backends/redis.py</code> <pre><code>class RedisCache(BaseCache):\n    \"\"\"Redis cache backend implementation.\"\"\"\n\n    @classmethod\n    def from_config(cls, config: RedisCacheConfig):\n        \"\"\"Create RedisCache instance from configuration.\n\n        Args:\n            config (RedisCacheConfig): Redis cache configuration.\n\n        Returns:\n            RedisCache: Redis cache instance.\n        \"\"\"\n        from redis import Redis\n\n        return cls(client=Redis(**config.to_dict()))\n\n    def get(self, key: str) -&gt; Any:\n        \"\"\"Retrieve value from Redis cache.\n\n        Args:\n            key (str): Cache key.\n\n        Returns:\n            Any: Cached value.\n        \"\"\"\n        return self.client.get(key)\n\n    def set(self, key: str, value: dict, ttl: int | None = None) -&gt; Any:\n        \"\"\"Set value in Redis cache.\n\n        Args:\n            key (str): Cache key.\n            value (dict): Value to cache.\n            ttl (int | None): Time-to-live for cache entry.\n\n        Returns:\n            Any: Result of cache set operation.\n        \"\"\"\n        if ttl is None:\n            return self.client.set(key, value)\n        return self.client.setex(key, ttl, value)\n\n    def delete(self, key: str) -&gt; Any:\n        \"\"\"Delete value from Redis cache.\n\n        Args:\n            key (str): Cache key.\n\n        Returns:\n            Any: Result of cache delete operation.\n        \"\"\"\n        return self.client.delete(key)\n</code></pre>"},{"location":"dynamiq/cache/backends/redis/#dynamiq.cache.backends.redis.RedisCache.delete","title":"<code>delete(key)</code>","text":"<p>Delete value from Redis cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Result of cache delete operation.</p> Source code in <code>dynamiq/cache/backends/redis.py</code> <pre><code>def delete(self, key: str) -&gt; Any:\n    \"\"\"Delete value from Redis cache.\n\n    Args:\n        key (str): Cache key.\n\n    Returns:\n        Any: Result of cache delete operation.\n    \"\"\"\n    return self.client.delete(key)\n</code></pre>"},{"location":"dynamiq/cache/backends/redis/#dynamiq.cache.backends.redis.RedisCache.from_config","title":"<code>from_config(config)</code>  <code>classmethod</code>","text":"<p>Create RedisCache instance from configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>RedisCacheConfig</code> <p>Redis cache configuration.</p> required <p>Returns:</p> Name Type Description <code>RedisCache</code> <p>Redis cache instance.</p> Source code in <code>dynamiq/cache/backends/redis.py</code> <pre><code>@classmethod\ndef from_config(cls, config: RedisCacheConfig):\n    \"\"\"Create RedisCache instance from configuration.\n\n    Args:\n        config (RedisCacheConfig): Redis cache configuration.\n\n    Returns:\n        RedisCache: Redis cache instance.\n    \"\"\"\n    from redis import Redis\n\n    return cls(client=Redis(**config.to_dict()))\n</code></pre>"},{"location":"dynamiq/cache/backends/redis/#dynamiq.cache.backends.redis.RedisCache.get","title":"<code>get(key)</code>","text":"<p>Retrieve value from Redis cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Cached value.</p> Source code in <code>dynamiq/cache/backends/redis.py</code> <pre><code>def get(self, key: str) -&gt; Any:\n    \"\"\"Retrieve value from Redis cache.\n\n    Args:\n        key (str): Cache key.\n\n    Returns:\n        Any: Cached value.\n    \"\"\"\n    return self.client.get(key)\n</code></pre>"},{"location":"dynamiq/cache/backends/redis/#dynamiq.cache.backends.redis.RedisCache.set","title":"<code>set(key, value, ttl=None)</code>","text":"<p>Set value in Redis cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <code>value</code> <code>dict</code> <p>Value to cache.</p> required <code>ttl</code> <code>int | None</code> <p>Time-to-live for cache entry.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Result of cache set operation.</p> Source code in <code>dynamiq/cache/backends/redis.py</code> <pre><code>def set(self, key: str, value: dict, ttl: int | None = None) -&gt; Any:\n    \"\"\"Set value in Redis cache.\n\n    Args:\n        key (str): Cache key.\n        value (dict): Value to cache.\n        ttl (int | None): Time-to-live for cache entry.\n\n    Returns:\n        Any: Result of cache set operation.\n    \"\"\"\n    if ttl is None:\n        return self.client.set(key, value)\n    return self.client.setex(key, ttl, value)\n</code></pre>"},{"location":"dynamiq/cache/managers/base/","title":"Base","text":""},{"location":"dynamiq/cache/managers/base/#dynamiq.cache.managers.base.CacheManager","title":"<code>CacheManager</code>","text":"<p>Manager for handling cache operations.</p> <p>Attributes:</p> Name Type Description <code>CACHE_BACKENDS_BY_TYPE</code> <code>dict[CacheBackend, BaseCache]</code> <p>Mapping of backends.</p> <code>cache_backend</code> <code>BaseCache</code> <p>Selected cache backend.</p> <code>cache</code> <code>BaseCache</code> <p>Cache instance.</p> <code>serializer</code> <code>Any</code> <p>Serializer instance.</p> <code>codec</code> <code>Any</code> <p>Codec instance.</p> <code>namespace</code> <code>str | None</code> <p>Cache namespace.</p> <code>ttl</code> <code>int | None</code> <p>Time-to-live for cache entries.</p> Source code in <code>dynamiq/cache/managers/base.py</code> <pre><code>class CacheManager:\n    \"\"\"Manager for handling cache operations.\n\n    Attributes:\n        CACHE_BACKENDS_BY_TYPE (dict[CacheBackend, BaseCache]): Mapping of backends.\n        cache_backend (BaseCache): Selected cache backend.\n        cache (BaseCache): Cache instance.\n        serializer (Any): Serializer instance.\n        codec (Any): Codec instance.\n        namespace (str | None): Cache namespace.\n        ttl (int | None): Time-to-live for cache entries.\n    \"\"\"\n    CACHE_BACKENDS_BY_TYPE: dict[CacheBackend, BaseCache] = {\n        CacheBackend.Redis: RedisCache,\n    }\n\n    def __init__(\n        self,\n        config: CacheConfig,\n        serializer: Any | None = None,\n        codec: Any | None = None,\n    ):\n        \"\"\"Initialize CacheManager.\n\n        Args:\n            config (CacheConfig): Cache configuration.\n            serializer (Any | None): Serializer instance.\n            codec (Any | None): Codec instance.\n        \"\"\"\n        self.cache_backend = self.CACHE_BACKENDS_BY_TYPE.get(config.backend)\n        self.cache = self.cache_backend.from_config(config)\n        self.serializer = serializer or JsonSerializer()\n        self.codec = codec or Base64Codec()\n        self.namespace = config.namespace\n        self.ttl = config.ttl\n\n    def get(\n        self,\n        key: str,\n        namespace: str | None = None,\n        loads_func: Callable[[Any], Any] | None = None,\n        decode_func: Callable[[Any], Any] | None = None,\n    ) -&gt; Any:\n        \"\"\"Retrieve value from cache.\n\n        Args:\n            key (str): Cache key.\n            namespace (str | None): Cache namespace.\n            loads_func (Callable[[Any], Any] | None): Function to deserialize.\n            decode_func (Callable[[Any], Any] | None): Function to decode.\n\n        Returns:\n            Any: Cached value.\n        \"\"\"\n        loads = loads_func or self.serializer.loads\n        decode = decode_func or self.codec.decode\n        ns_key = self._get_key(key, namespace=self._get_namespace(namespace))\n\n        if (res := self.cache.get(ns_key)) is not None:\n            res = loads(decode(self.cache.get(key=ns_key)))\n\n        return res\n\n    def set(\n        self,\n        key: str,\n        value: Any,\n        ttl: int | None = None,\n        namespace: str | None = None,\n        dumps_func: Callable[[Any], Any] | None = None,\n        encode_func: Callable[[Any], Any] | None = None,\n    ) -&gt; Any:\n        \"\"\"Set value in cache.\n\n        Args:\n            key (str): Cache key.\n            value (Any): Value to cache.\n            ttl (int | None): Time-to-live for cache entry.\n            namespace (str | None): Cache namespace.\n            dumps_func (Callable[[Any], Any] | None): Function to serialize.\n            encode_func (Callable[[Any], Any] | None): Function to encode.\n\n        Returns:\n            Any: Result of cache set operation.\n        \"\"\"\n        dumps = dumps_func or self.serializer.dumps\n        encode = encode_func or self.codec.encode\n        ns_key = self._get_key(key, namespace=self._get_namespace(namespace))\n        ttl = ttl or self.ttl\n\n        res = self.cache.set(key=ns_key, value=encode(dumps(value)), ttl=ttl)\n\n        return res\n\n    def delete(\n        self,\n        key: str,\n        namespace: str | None = None,\n    ) -&gt; Any:\n        \"\"\"Delete value from cache.\n\n        Args:\n            key (str): Cache key.\n            namespace (str | None): Cache namespace.\n\n        Returns:\n            Any: Result of cache delete operation.\n        \"\"\"\n        ns_key = self._get_key(key, namespace=self._get_namespace(namespace))\n        res = self.cache.delete(ns_key)\n\n        return res\n\n    def _get_namespace(self, namespace: str | None = None) -&gt; str | None:\n        \"\"\"Get effective namespace.\n\n        Args:\n            namespace (str | None): Provided namespace.\n\n        Returns:\n            str | None: Effective namespace.\n        \"\"\"\n        return namespace if namespace is not None else self.namespace\n\n    @staticmethod\n    def _get_key(key: str, namespace: str | None = None) -&gt; str:\n        \"\"\"Construct cache key with namespace.\n\n        Args:\n            key (str): Cache key.\n            namespace (str | None): Cache namespace.\n\n        Returns:\n            str: Namespaced cache key.\n        \"\"\"\n        if namespace is not None:\n            return f\"{namespace}:{key}\"\n        return key\n</code></pre>"},{"location":"dynamiq/cache/managers/base/#dynamiq.cache.managers.base.CacheManager.__init__","title":"<code>__init__(config, serializer=None, codec=None)</code>","text":"<p>Initialize CacheManager.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>CacheConfig</code> <p>Cache configuration.</p> required <code>serializer</code> <code>Any | None</code> <p>Serializer instance.</p> <code>None</code> <code>codec</code> <code>Any | None</code> <p>Codec instance.</p> <code>None</code> Source code in <code>dynamiq/cache/managers/base.py</code> <pre><code>def __init__(\n    self,\n    config: CacheConfig,\n    serializer: Any | None = None,\n    codec: Any | None = None,\n):\n    \"\"\"Initialize CacheManager.\n\n    Args:\n        config (CacheConfig): Cache configuration.\n        serializer (Any | None): Serializer instance.\n        codec (Any | None): Codec instance.\n    \"\"\"\n    self.cache_backend = self.CACHE_BACKENDS_BY_TYPE.get(config.backend)\n    self.cache = self.cache_backend.from_config(config)\n    self.serializer = serializer or JsonSerializer()\n    self.codec = codec or Base64Codec()\n    self.namespace = config.namespace\n    self.ttl = config.ttl\n</code></pre>"},{"location":"dynamiq/cache/managers/base/#dynamiq.cache.managers.base.CacheManager.delete","title":"<code>delete(key, namespace=None)</code>","text":"<p>Delete value from cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <code>namespace</code> <code>str | None</code> <p>Cache namespace.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Result of cache delete operation.</p> Source code in <code>dynamiq/cache/managers/base.py</code> <pre><code>def delete(\n    self,\n    key: str,\n    namespace: str | None = None,\n) -&gt; Any:\n    \"\"\"Delete value from cache.\n\n    Args:\n        key (str): Cache key.\n        namespace (str | None): Cache namespace.\n\n    Returns:\n        Any: Result of cache delete operation.\n    \"\"\"\n    ns_key = self._get_key(key, namespace=self._get_namespace(namespace))\n    res = self.cache.delete(ns_key)\n\n    return res\n</code></pre>"},{"location":"dynamiq/cache/managers/base/#dynamiq.cache.managers.base.CacheManager.get","title":"<code>get(key, namespace=None, loads_func=None, decode_func=None)</code>","text":"<p>Retrieve value from cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <code>namespace</code> <code>str | None</code> <p>Cache namespace.</p> <code>None</code> <code>loads_func</code> <code>Callable[[Any], Any] | None</code> <p>Function to deserialize.</p> <code>None</code> <code>decode_func</code> <code>Callable[[Any], Any] | None</code> <p>Function to decode.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Cached value.</p> Source code in <code>dynamiq/cache/managers/base.py</code> <pre><code>def get(\n    self,\n    key: str,\n    namespace: str | None = None,\n    loads_func: Callable[[Any], Any] | None = None,\n    decode_func: Callable[[Any], Any] | None = None,\n) -&gt; Any:\n    \"\"\"Retrieve value from cache.\n\n    Args:\n        key (str): Cache key.\n        namespace (str | None): Cache namespace.\n        loads_func (Callable[[Any], Any] | None): Function to deserialize.\n        decode_func (Callable[[Any], Any] | None): Function to decode.\n\n    Returns:\n        Any: Cached value.\n    \"\"\"\n    loads = loads_func or self.serializer.loads\n    decode = decode_func or self.codec.decode\n    ns_key = self._get_key(key, namespace=self._get_namespace(namespace))\n\n    if (res := self.cache.get(ns_key)) is not None:\n        res = loads(decode(self.cache.get(key=ns_key)))\n\n    return res\n</code></pre>"},{"location":"dynamiq/cache/managers/base/#dynamiq.cache.managers.base.CacheManager.set","title":"<code>set(key, value, ttl=None, namespace=None, dumps_func=None, encode_func=None)</code>","text":"<p>Set value in cache.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Cache key.</p> required <code>value</code> <code>Any</code> <p>Value to cache.</p> required <code>ttl</code> <code>int | None</code> <p>Time-to-live for cache entry.</p> <code>None</code> <code>namespace</code> <code>str | None</code> <p>Cache namespace.</p> <code>None</code> <code>dumps_func</code> <code>Callable[[Any], Any] | None</code> <p>Function to serialize.</p> <code>None</code> <code>encode_func</code> <code>Callable[[Any], Any] | None</code> <p>Function to encode.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Result of cache set operation.</p> Source code in <code>dynamiq/cache/managers/base.py</code> <pre><code>def set(\n    self,\n    key: str,\n    value: Any,\n    ttl: int | None = None,\n    namespace: str | None = None,\n    dumps_func: Callable[[Any], Any] | None = None,\n    encode_func: Callable[[Any], Any] | None = None,\n) -&gt; Any:\n    \"\"\"Set value in cache.\n\n    Args:\n        key (str): Cache key.\n        value (Any): Value to cache.\n        ttl (int | None): Time-to-live for cache entry.\n        namespace (str | None): Cache namespace.\n        dumps_func (Callable[[Any], Any] | None): Function to serialize.\n        encode_func (Callable[[Any], Any] | None): Function to encode.\n\n    Returns:\n        Any: Result of cache set operation.\n    \"\"\"\n    dumps = dumps_func or self.serializer.dumps\n    encode = encode_func or self.codec.encode\n    ns_key = self._get_key(key, namespace=self._get_namespace(namespace))\n    ttl = ttl or self.ttl\n\n    res = self.cache.set(key=ns_key, value=encode(dumps(value)), ttl=ttl)\n\n    return res\n</code></pre>"},{"location":"dynamiq/cache/managers/workflow/","title":"Workflow","text":""},{"location":"dynamiq/cache/managers/workflow/#dynamiq.cache.managers.workflow.WorkflowCacheManager","title":"<code>WorkflowCacheManager</code>","text":"<p>               Bases: <code>CacheManager</code></p> <p>Manager for caching workflow entity outputs.</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>CacheConfig</code> <p>Cache configuration.</p> <code>serializer</code> <code>Any</code> <p>Serializer instance.</p> Source code in <code>dynamiq/cache/managers/workflow.py</code> <pre><code>class WorkflowCacheManager(CacheManager):\n    \"\"\"Manager for caching workflow entity outputs.\n\n    Attributes:\n        config (CacheConfig): Cache configuration.\n        serializer (Any): Serializer instance.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: CacheConfig,\n        serializer: Any | None = None,\n    ):\n        \"\"\"Initialize WorkflowCacheManager.\n\n        Args:\n            config (CacheConfig): Cache configuration.\n            serializer (Any | None): Serializer instance.\n        \"\"\"\n        super().__init__(\n            config=config,\n            serializer=serializer,\n        )\n\n    def get_entity_output(self, entity_id: str, input_data: dict, **kwargs) -&gt; Any:\n        \"\"\"Retrieve cached entity output.\n\n        Args:\n            entity_id (str): Entity identifier.\n            input_data (dict): Input data for the entity.\n            kwargs (Any): Additional keyword arguments.\n\n        Returns:\n            Any: Cached output data.\n        \"\"\"\n        key = self.get_key(entity_id=entity_id, input_data=input_data, **kwargs)\n        return super().get(key=key)\n\n    def set_entity_output(self, entity_id: str, input_data: dict, output_data: Any, **kwargs) -&gt; Any:\n        \"\"\"Cache entity output.\n\n        Args:\n            entity_id (str): Entity identifier.\n            input_data (dict): Input data for the entity.\n            output_data (Any): Output data to cache.\n            kwargs (Any): Additional keyword arguments.\n\n        Returns:\n            Any: Result of cache set operation.\n        \"\"\"\n        key = self.get_key(entity_id=entity_id, input_data=input_data, **kwargs)\n        return super().set(key=key, value=output_data)\n\n    def delete_entity_output(self, entity_id: str, input_data: dict, **kwargs) -&gt; Any:\n        \"\"\"Delete cached entity output.\n\n        Args:\n            entity_id (str): Entity identifier.\n            input_data (dict): Input data for the entity.\n            kwargs (Any): Additional keyword arguments.\n\n        Returns:\n            Any: Result of cache delete operation.\n        \"\"\"\n        key = self.get_key(entity_id=entity_id, input_data=input_data, **kwargs)\n        return super().delete(key=key)\n\n    def get_key(self, entity_id: str, input_data: dict, **kwargs) -&gt; str:\n        \"\"\"Generate cache key for entity.\n\n        Args:\n            entity_id (str): Entity identifier.\n            input_data (dict): Input data for the entity.\n            kwargs (Any): Additional keyword arguments.\n\n        Returns:\n            str: Generated cache key.\n        \"\"\"\n        input_data_formatted = format_value(self._sort_dict(input_data))\n        input_data_hash = self.hash(self.serializer.dumps(input_data_formatted))\n        kwargs_formatted = format_value(self._sort_dict(kwargs))\n        kwargs_hash = self.hash(self.serializer.dumps(kwargs_formatted))\n        return f\"{entity_id}:{input_data_hash}:{kwargs_hash}\"\n\n    @staticmethod\n    def hash(data: str) -&gt; str:\n        \"\"\"Generate SHA-256 hash of data.\n\n        Args:\n            data (str): Data to hash.\n\n        Returns:\n            str: SHA-256 hash.\n        \"\"\"\n        return hashlib.sha256(data.encode()).hexdigest()\n\n    def _sort_dict(self, d: dict) -&gt; dict:\n        \"\"\"Recursively sort dictionary keys, including nested dictionaries.\n\n        Args:\n            d (dict): Dictionary to sort.\n\n        Returns:\n            dict: Sorted dictionary.\n        \"\"\"\n        return {k: self._sort_dict(v) if isinstance(v, dict) else v for k, v in sorted(d.items())}\n</code></pre>"},{"location":"dynamiq/cache/managers/workflow/#dynamiq.cache.managers.workflow.WorkflowCacheManager.__init__","title":"<code>__init__(config, serializer=None)</code>","text":"<p>Initialize WorkflowCacheManager.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>CacheConfig</code> <p>Cache configuration.</p> required <code>serializer</code> <code>Any | None</code> <p>Serializer instance.</p> <code>None</code> Source code in <code>dynamiq/cache/managers/workflow.py</code> <pre><code>def __init__(\n    self,\n    config: CacheConfig,\n    serializer: Any | None = None,\n):\n    \"\"\"Initialize WorkflowCacheManager.\n\n    Args:\n        config (CacheConfig): Cache configuration.\n        serializer (Any | None): Serializer instance.\n    \"\"\"\n    super().__init__(\n        config=config,\n        serializer=serializer,\n    )\n</code></pre>"},{"location":"dynamiq/cache/managers/workflow/#dynamiq.cache.managers.workflow.WorkflowCacheManager.delete_entity_output","title":"<code>delete_entity_output(entity_id, input_data, **kwargs)</code>","text":"<p>Delete cached entity output.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity identifier.</p> required <code>input_data</code> <code>dict</code> <p>Input data for the entity.</p> required <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Result of cache delete operation.</p> Source code in <code>dynamiq/cache/managers/workflow.py</code> <pre><code>def delete_entity_output(self, entity_id: str, input_data: dict, **kwargs) -&gt; Any:\n    \"\"\"Delete cached entity output.\n\n    Args:\n        entity_id (str): Entity identifier.\n        input_data (dict): Input data for the entity.\n        kwargs (Any): Additional keyword arguments.\n\n    Returns:\n        Any: Result of cache delete operation.\n    \"\"\"\n    key = self.get_key(entity_id=entity_id, input_data=input_data, **kwargs)\n    return super().delete(key=key)\n</code></pre>"},{"location":"dynamiq/cache/managers/workflow/#dynamiq.cache.managers.workflow.WorkflowCacheManager.get_entity_output","title":"<code>get_entity_output(entity_id, input_data, **kwargs)</code>","text":"<p>Retrieve cached entity output.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity identifier.</p> required <code>input_data</code> <code>dict</code> <p>Input data for the entity.</p> required <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Cached output data.</p> Source code in <code>dynamiq/cache/managers/workflow.py</code> <pre><code>def get_entity_output(self, entity_id: str, input_data: dict, **kwargs) -&gt; Any:\n    \"\"\"Retrieve cached entity output.\n\n    Args:\n        entity_id (str): Entity identifier.\n        input_data (dict): Input data for the entity.\n        kwargs (Any): Additional keyword arguments.\n\n    Returns:\n        Any: Cached output data.\n    \"\"\"\n    key = self.get_key(entity_id=entity_id, input_data=input_data, **kwargs)\n    return super().get(key=key)\n</code></pre>"},{"location":"dynamiq/cache/managers/workflow/#dynamiq.cache.managers.workflow.WorkflowCacheManager.get_key","title":"<code>get_key(entity_id, input_data, **kwargs)</code>","text":"<p>Generate cache key for entity.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity identifier.</p> required <code>input_data</code> <code>dict</code> <p>Input data for the entity.</p> required <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Generated cache key.</p> Source code in <code>dynamiq/cache/managers/workflow.py</code> <pre><code>def get_key(self, entity_id: str, input_data: dict, **kwargs) -&gt; str:\n    \"\"\"Generate cache key for entity.\n\n    Args:\n        entity_id (str): Entity identifier.\n        input_data (dict): Input data for the entity.\n        kwargs (Any): Additional keyword arguments.\n\n    Returns:\n        str: Generated cache key.\n    \"\"\"\n    input_data_formatted = format_value(self._sort_dict(input_data))\n    input_data_hash = self.hash(self.serializer.dumps(input_data_formatted))\n    kwargs_formatted = format_value(self._sort_dict(kwargs))\n    kwargs_hash = self.hash(self.serializer.dumps(kwargs_formatted))\n    return f\"{entity_id}:{input_data_hash}:{kwargs_hash}\"\n</code></pre>"},{"location":"dynamiq/cache/managers/workflow/#dynamiq.cache.managers.workflow.WorkflowCacheManager.hash","title":"<code>hash(data)</code>  <code>staticmethod</code>","text":"<p>Generate SHA-256 hash of data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>Data to hash.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>SHA-256 hash.</p> Source code in <code>dynamiq/cache/managers/workflow.py</code> <pre><code>@staticmethod\ndef hash(data: str) -&gt; str:\n    \"\"\"Generate SHA-256 hash of data.\n\n    Args:\n        data (str): Data to hash.\n\n    Returns:\n        str: SHA-256 hash.\n    \"\"\"\n    return hashlib.sha256(data.encode()).hexdigest()\n</code></pre>"},{"location":"dynamiq/cache/managers/workflow/#dynamiq.cache.managers.workflow.WorkflowCacheManager.set_entity_output","title":"<code>set_entity_output(entity_id, input_data, output_data, **kwargs)</code>","text":"<p>Cache entity output.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>Entity identifier.</p> required <code>input_data</code> <code>dict</code> <p>Input data for the entity.</p> required <code>output_data</code> <code>Any</code> <p>Output data to cache.</p> required <code>kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Result of cache set operation.</p> Source code in <code>dynamiq/cache/managers/workflow.py</code> <pre><code>def set_entity_output(self, entity_id: str, input_data: dict, output_data: Any, **kwargs) -&gt; Any:\n    \"\"\"Cache entity output.\n\n    Args:\n        entity_id (str): Entity identifier.\n        input_data (dict): Input data for the entity.\n        output_data (Any): Output data to cache.\n        kwargs (Any): Additional keyword arguments.\n\n    Returns:\n        Any: Result of cache set operation.\n    \"\"\"\n    key = self.get_key(entity_id=entity_id, input_data=input_data, **kwargs)\n    return super().set(key=key, value=output_data)\n</code></pre>"},{"location":"dynamiq/callbacks/base/","title":"Base","text":""},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.BaseCallbackHandler","title":"<code>BaseCallbackHandler</code>","text":"<p>               Bases: <code>NodeCallbackHandler</code>, <code>ABC</code></p> <p>Abstract base class for general callback handlers.</p> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>class BaseCallbackHandler(NodeCallbackHandler, ABC):\n    \"\"\"Abstract base class for general callback handlers.\"\"\"\n\n    def on_workflow_start(\n        self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the workflow starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            input_data (dict[str, Any]): Input data for the workflow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_workflow_end(\n        self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the workflow ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            output_data (dict[str, Any]): Output data from the workflow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_workflow_error(\n        self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n    ):\n        \"\"\"Called when the workflow errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_flow_start(\n        self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the flow starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized flow data.\n            input_data (dict[str, Any]): Input data for the flow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_flow_end(\n        self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the flow ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized flow data.\n            output_data (dict[str, Any]): Output data from the flow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_flow_error(\n        self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n    ):\n        \"\"\"Called when the flow errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized flow data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.BaseCallbackHandler.on_flow_end","title":"<code>on_flow_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the flow ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized flow data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the flow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_flow_end(\n    self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the flow ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized flow data.\n        output_data (dict[str, Any]): Output data from the flow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.BaseCallbackHandler.on_flow_error","title":"<code>on_flow_error(serialized, error, **kwargs)</code>","text":"<p>Called when the flow errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized flow data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_flow_error(\n    self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n):\n    \"\"\"Called when the flow errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized flow data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.BaseCallbackHandler.on_flow_start","title":"<code>on_flow_start(serialized, input_data, **kwargs)</code>","text":"<p>Called when the flow starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized flow data.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the flow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_flow_start(\n    self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the flow starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized flow data.\n        input_data (dict[str, Any]): Input data for the flow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.BaseCallbackHandler.on_workflow_end","title":"<code>on_workflow_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the workflow ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the workflow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_workflow_end(\n    self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the workflow ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        output_data (dict[str, Any]): Output data from the workflow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.BaseCallbackHandler.on_workflow_error","title":"<code>on_workflow_error(serialized, error, **kwargs)</code>","text":"<p>Called when the workflow errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_workflow_error(\n    self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n):\n    \"\"\"Called when the workflow errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.BaseCallbackHandler.on_workflow_start","title":"<code>on_workflow_start(serialized, input_data, **kwargs)</code>","text":"<p>Called when the workflow starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the workflow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_workflow_start(\n    self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the workflow starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        input_data (dict[str, Any]): Input data for the workflow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler","title":"<code>NodeCallbackHandler</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract class for node callback handlers.</p> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>class NodeCallbackHandler(ABC):\n    \"\"\"Abstract class for node callback handlers.\"\"\"\n\n    def on_node_start(self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any):\n        \"\"\"Called when the node starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_node_end(self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any):\n        \"\"\"Called when the node ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            output_data (dict[str, Any]): Output data from the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_node_error(self, serialized: dict[str, Any], error: BaseException, **kwargs: Any):\n        \"\"\"Called when the node errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_node_execute_start(self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any):\n        \"\"\"Called when the node execute starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_node_execute_end(self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any):\n        \"\"\"Called when the node execute ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            output_data (dict[str, Any]): Output data from the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_node_execute_error(self, serialized: dict[str, Any], error: BaseException, **kwargs: Any):\n        \"\"\"Called when the node execute errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_node_execute_run(self, serialized: dict[str, Any], **kwargs: Any):\n        \"\"\"Called when the node execute runs.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_node_execute_stream(self, serialized: dict[str, Any], chunk: dict[str, Any] | None = None, **kwargs: Any):\n        \"\"\"Called when the node execute streams.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            chunk (dict[str, Any] | None): Stream chunk data.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n\n    def on_node_skip(\n        self, serialized: dict[str, Any], skip_data: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the node skips.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            skip_data (dict[str, Any]): Data related to the skip.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_end","title":"<code>on_node_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the node ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_end(self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any):\n    \"\"\"Called when the node ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        output_data (dict[str, Any]): Output data from the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_error","title":"<code>on_node_error(serialized, error, **kwargs)</code>","text":"<p>Called when the node errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_error(self, serialized: dict[str, Any], error: BaseException, **kwargs: Any):\n    \"\"\"Called when the node errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_execute_end","title":"<code>on_node_execute_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the node execute ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_execute_end(self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any):\n    \"\"\"Called when the node execute ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        output_data (dict[str, Any]): Output data from the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_execute_error","title":"<code>on_node_execute_error(serialized, error, **kwargs)</code>","text":"<p>Called when the node execute errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_execute_error(self, serialized: dict[str, Any], error: BaseException, **kwargs: Any):\n    \"\"\"Called when the node execute errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_execute_run","title":"<code>on_node_execute_run(serialized, **kwargs)</code>","text":"<p>Called when the node execute runs.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_execute_run(self, serialized: dict[str, Any], **kwargs: Any):\n    \"\"\"Called when the node execute runs.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_execute_start","title":"<code>on_node_execute_start(serialized, input_data, **kwargs)</code>","text":"<p>Called when the node execute starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_execute_start(self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any):\n    \"\"\"Called when the node execute starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_execute_stream","title":"<code>on_node_execute_stream(serialized, chunk=None, **kwargs)</code>","text":"<p>Called when the node execute streams.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>chunk</code> <code>dict[str, Any] | None</code> <p>Stream chunk data.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_execute_stream(self, serialized: dict[str, Any], chunk: dict[str, Any] | None = None, **kwargs: Any):\n    \"\"\"Called when the node execute streams.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        chunk (dict[str, Any] | None): Stream chunk data.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_skip","title":"<code>on_node_skip(serialized, skip_data, input_data, **kwargs)</code>","text":"<p>Called when the node skips.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>skip_data</code> <code>dict[str, Any]</code> <p>Data related to the skip.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_skip(\n    self, serialized: dict[str, Any], skip_data: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the node skips.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        skip_data (dict[str, Any]): Data related to the skip.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.NodeCallbackHandler.on_node_start","title":"<code>on_node_start(serialized, input_data, **kwargs)</code>","text":"<p>Called when the node starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def on_node_start(self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any):\n    \"\"\"Called when the node starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.get_entity_id","title":"<code>get_entity_id(entity_name, kwargs)</code>","text":"<p>Retrieve entity ID from kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>entity_name</code> <code>str</code> <p>Name of the entity.</p> required <code>kwargs</code> <code>dict</code> <p>Keyword arguments.</p> required <p>Returns:</p> Name Type Description <code>UUID</code> <code>UUID</code> <p>Entity ID.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If entity ID is not found or invalid.</p> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def get_entity_id(entity_name: str, kwargs: dict) -&gt; UUID:\n    \"\"\"Retrieve entity ID from kwargs.\n\n    Args:\n        entity_name (str): Name of the entity.\n        kwargs (dict): Keyword arguments.\n\n    Returns:\n        UUID: Entity ID.\n\n    Raises:\n        ValueError: If entity ID is not found or invalid.\n    \"\"\"\n    entity_id = kwargs.get(entity_name)\n    if entity_name == \"parent_run_id\" and not entity_id:\n        return entity_id\n    if not entity_id:\n        raise ValueError(f\"{entity_name} not found\")\n\n    if isinstance(entity_id, UUID):\n        return entity_id\n    elif isinstance(entity_id, str):\n        return UUID(entity_id)\n\n    raise ValueError(f\"{entity_name} is not UUID or str\")\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.get_execution_run_id","title":"<code>get_execution_run_id(kwargs)</code>","text":"<p>Retrieve execution run ID from kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>Keyword arguments.</p> required <p>Returns:</p> Name Type Description <code>UUID</code> <code>UUID</code> <p>Execution run ID.</p> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def get_execution_run_id(kwargs: dict) -&gt; UUID:\n    \"\"\"Retrieve execution run ID from kwargs.\n\n    Args:\n        kwargs (dict): Keyword arguments.\n\n    Returns:\n        UUID: Execution run ID.\n    \"\"\"\n    return get_entity_id(\"execution_run_id\", kwargs)\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.get_parent_run_id","title":"<code>get_parent_run_id(kwargs)</code>","text":"<p>Retrieve parent run ID from kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>Keyword arguments.</p> required <p>Returns:</p> Name Type Description <code>UUID</code> <code>UUID</code> <p>Parent run ID.</p> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def get_parent_run_id(kwargs: dict) -&gt; UUID:\n    \"\"\"Retrieve parent run ID from kwargs.\n\n    Args:\n        kwargs (dict): Keyword arguments.\n\n    Returns:\n        UUID: Parent run ID.\n    \"\"\"\n    return get_entity_id(\"parent_run_id\", kwargs)\n</code></pre>"},{"location":"dynamiq/callbacks/base/#dynamiq.callbacks.base.get_run_id","title":"<code>get_run_id(kwargs)</code>","text":"<p>Retrieve run ID from kwargs.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>Keyword arguments.</p> required <p>Returns:</p> Name Type Description <code>UUID</code> <code>UUID</code> <p>Run ID.</p> Source code in <code>dynamiq/callbacks/base.py</code> <pre><code>def get_run_id(kwargs: dict) -&gt; UUID:\n    \"\"\"Retrieve run ID from kwargs.\n\n    Args:\n        kwargs (dict): Keyword arguments.\n\n    Returns:\n        UUID: Run ID.\n    \"\"\"\n    return get_entity_id(\"run_id\", kwargs)\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/","title":"Streaming","text":""},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.AgentStreamingParserCallback","title":"<code>AgentStreamingParserCallback</code>","text":"<p>               Bases: <code>BaseStreamingCallbackHandler</code></p> <p>Agent callback that parses LLM streaming output in real time and streams structured chunks.</p> <p>This callback attaches to the underlying LLM node (group == 'llms'), incrementally parses the provider streaming chunks to detect logical sections like reasoning and final answer based on the selected inference mode, and forwards the relevant segments via the <code>stream_content()</code> API with appropriate <code>step</code> labels (reasoning/answer) included.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class AgentStreamingParserCallback(BaseStreamingCallbackHandler):\n    \"\"\"Agent callback that parses LLM streaming output in real time and streams structured chunks.\n\n    This callback attaches to the underlying LLM node (group == 'llms'), incrementally parses the\n    provider streaming chunks to detect logical sections like reasoning and final answer based on\n    the selected inference mode, and forwards the relevant segments via the `stream_content()` API\n    with appropriate `step` labels (reasoning/answer) included.\n    \"\"\"\n\n    def __init__(self, agent: \"Agent\", config, loop_num: int, **kwargs):\n        self.agent = agent\n        self.config = config\n        self.loop_num = loop_num\n        self.kwargs = kwargs\n\n        # Aggregate streamed text from the LLM in the current loop for proper tracing inside the agent\n        self.accumulated_content: str = \"\"\n\n        self._buffer: str = \"\"\n        self._current_state: str | None = None\n        self._state_start_index: int = 0\n        self._state_last_emit_index: int = 0\n        self._answer_started: bool = False\n        self._state_has_emitted: dict[str, bool] = {\n            StreamingState.REASONING: False,\n            StreamingState.ANSWER: False,\n        }\n\n        # Set a tail guard to avoid streaming parts of the next tag that may arrive in next chunk\n        self._tail_guard: int = TAIL_GUARD_SIZE\n\n        self.mode_name = getattr(self.agent.inference_mode, \"name\", str(self.agent.inference_mode)).upper()\n\n    def on_node_execute_stream(self, serialized: dict[str, Any], chunk: dict[str, Any] | None = None, **kwargs: Any):\n        if not chunk or not self.agent.streaming.enabled:\n            return\n\n        # Only process the chunks from the LLM node\n        if serialized.get(\"group\") != \"llms\":\n            return\n\n        agent_run_id = kwargs.get(\"run_id\") or kwargs.get(\"parent_run_id\")\n        if agent_run_id and serialized.get(\"id\") != getattr(self.agent, \"llm\", object()).id:\n            return\n\n        if self.mode_name == InferenceMode.FUNCTION_CALLING.value:\n            text_delta, function_name = self._extract_function_calling_text(chunk)\n\n            if function_name and function_name == FINAL_ANSWER_FUNCTION_NAME:\n                self._answer_started = True\n        else:\n            text_delta = self._extract_text_delta(chunk)\n\n        if not text_delta:\n            return\n\n        self.accumulated_content += text_delta\n        self._buffer += text_delta\n\n        final_answer_only = self.agent.streaming.mode == StreamingMode.FINAL\n\n        if self.mode_name == InferenceMode.DEFAULT.value:\n            self._process_default_mode(final_answer_only)\n        elif self.mode_name == InferenceMode.XML.value:\n            self._process_xml_mode(final_answer_only)\n        elif self.mode_name == InferenceMode.STRUCTURED_OUTPUT.value:\n            self._process_structured_output_mode(final_answer_only)\n        elif self.mode_name == InferenceMode.FUNCTION_CALLING.value:\n            self._process_function_calling_mode(final_answer_only)\n\n        self._trim_buffer()\n\n    def on_node_execute_end(self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any):\n        # Clear the remaining buffer content when the LLM streaming ends\n        if serialized.get(\"group\") != \"llms\":\n            return\n\n        if not self.agent.streaming.enabled:\n            return\n\n        self._flush_buffer()\n        self._trim_buffer(force=True)\n\n    def _flush_buffer(self) -&gt; None:\n        \"\"\"Flush the remaining buffer content by streaming it as one chunk.\"\"\"\n        if not self._buffer or len(self._buffer) &lt;= self._state_last_emit_index:\n            return\n\n        if self._current_state in (StreamingState.REASONING, StreamingState.ANSWER):\n            remaining_content = self._buffer[self._state_last_emit_index :]\n            if remaining_content.strip():\n                self._emit(remaining_content, step=self._current_state)\n                self._state_last_emit_index = len(self._buffer)\n\n    def _extract_text_delta(self, chunk: dict[str, Any]) -&gt; str:\n        \"\"\"Extract textual content from streaming chunk received from the LLM.\n\n        Returns:\n            str: The extracted content.\n        \"\"\"\n        extracted_content = \"\"\n\n        choices = chunk.get(\"choices\") or []\n        if choices:\n            delta = choices[0].get(\"delta\", {})\n            content = delta.get(\"content\")\n            if isinstance(content, str):\n                extracted_content = content\n\n        if not extracted_content and isinstance(chunk.get(\"content\"), str):\n            extracted_content = chunk.get(\"content\")\n\n        return extracted_content\n\n    def _extract_function_calling_text(self, chunk: dict[str, Any]) -&gt; tuple[str, str | None]:\n        \"\"\"\n        Extract incremental JSON values (arguments) and function name\n        from the LLM streaming chunks in FUNCTION_CALLING inference mode.\n\n        Returns:\n            tuple[str, str | None]: (arguments_text, function_name)\n        \"\"\"\n        arguments_text = \"\"\n        function_name = None\n\n        choices = chunk.get(\"choices\") or []\n        if choices:\n            delta = choices[0].get(\"delta\", {})\n            tool_calls = delta.get(\"tool_calls\")\n\n            if tool_calls and len(tool_calls) &gt; 0:\n                tool_call = tool_calls[0]\n                if tool_call.get(\"type\") == \"function\" and \"function\" in tool_call:\n                    function_data = tool_call[\"function\"]\n\n                    if function_data.get(\"name\"):\n                        function_name = function_data[\"name\"]\n\n                    if function_data.get(\"arguments\"):\n                        arguments_text = function_data[\"arguments\"]\n\n        return arguments_text, function_name\n\n    def _emit(self, content: str, step: str) -&gt; None:\n        \"\"\"Emit the parsed content using the agent's stream_content method.\n\n        Args:\n            content (str): The content to stream.\n            step (str): The step to stream the content to.\n        \"\"\"\n        if not content:\n            return\n\n        # Skip streaming if in FINAL mode and not in answer step\n        if self.agent.streaming.mode == StreamingMode.FINAL and step != StreamingState.ANSWER:\n            return\n\n        if step in self._state_has_emitted:\n            if not self._state_has_emitted[step]:\n                trimmed = content.lstrip(\"\\r\\n \")\n                if not trimmed:\n                    return\n                content = trimmed\n\n        # Format content based on the step type\n        if step == StreamingState.REASONING:\n            thought_model = StreamingThought(thought=content, loop_num=self.loop_num)\n            content_to_stream = thought_model.to_dict()\n        elif step == StreamingState.ANSWER:\n            content_to_stream = content\n\n        self.agent.stream_content(\n            content=content_to_stream,\n            source=self.agent.name,\n            step=step,\n            config=self.config,\n            **(self.kwargs | {\"loop_num\": self.loop_num}),\n        )\n        if step in self._state_has_emitted:\n            self._state_has_emitted[step] = True\n\n    def _process_default_mode(self, final_answer_only: bool) -&gt; None:\n        if self._current_state is None:\n            start = self._state_last_emit_index\n            idx_thought = self._buffer.find(DefaultModeTag.THOUGHT, start) if not final_answer_only else -1\n            idx_answer = self._buffer.find(DefaultModeTag.ANSWER, start)\n\n            if not final_answer_only and idx_thought != -1 and (idx_answer == -1 or idx_thought &lt; idx_answer):\n                self._current_state = StreamingState.REASONING\n                self._state_start_index = idx_thought + len(DefaultModeTag.THOUGHT)\n                self._state_last_emit_index = self._state_start_index\n            elif idx_answer != -1:\n                self._current_state = StreamingState.ANSWER\n                self._answer_started = True\n                self._state_start_index = idx_answer + len(DefaultModeTag.ANSWER)\n                self._state_last_emit_index = self._state_start_index\n\n        # If the state was not detected, nothing to emit yet\n        if self._current_state is None:\n            return\n\n        search_start = self._state_last_emit_index\n\n        if self._current_state == StreamingState.REASONING:\n            # Check if there is a transition to Action or Answer\n            next_tag_pos = -1\n            next_tag_name = None\n            for tag_text, name in ((DefaultModeTag.ACTION, \"action\"), (DefaultModeTag.ANSWER, \"answer\")):\n                pos = self._buffer.find(tag_text, search_start)\n                if pos != -1 and (next_tag_pos == -1 or pos &lt; next_tag_pos):\n                    next_tag_pos, next_tag_name = pos, name\n\n            if next_tag_pos != -1:\n                # If a complete next tag is found, emit everything up to it\n                if next_tag_pos &gt; self._state_last_emit_index:\n                    self._emit(self._buffer[self._state_last_emit_index : next_tag_pos], step=StreamingState.REASONING)\n                if next_tag_name == \"answer\":\n                    self._current_state = StreamingState.ANSWER\n                    self._answer_started = True\n                    self._state_start_index = next_tag_pos + len(DefaultModeTag.ANSWER)\n                    self._state_last_emit_index = self._state_start_index\n                else:\n                    # Wait for the next state after `action`\n                    self._current_state = None\n                    self._state_last_emit_index = next_tag_pos + len(DefaultModeTag.ACTION)\n                return\n\n            # If there is no next tag yet, emit incrementally using a tail guard\n            safe_end = max(self._state_last_emit_index, len(self._buffer) - self._tail_guard)\n            if safe_end &gt; self._state_last_emit_index:\n                self._emit(self._buffer[self._state_last_emit_index : safe_end], step=StreamingState.REASONING)\n                self._state_last_emit_index = safe_end\n            return\n\n        # If the current state is 'answer', stream up to the end\n        safe_end = max(self._state_last_emit_index, len(self._buffer) - self._tail_guard)\n        if safe_end &gt; self._state_last_emit_index:\n            self._emit(self._buffer[self._state_last_emit_index : safe_end], step=StreamingState.ANSWER)\n            self._state_last_emit_index = safe_end\n\n    def _process_xml_mode(self, final_answer_only: bool) -&gt; None:\n        if self._current_state is None:\n            start = self._state_last_emit_index\n            idx_thought = self._buffer.find(XMLModeTag.OPEN_THOUGHT, start) if not final_answer_only else -1\n            idx_answer = self._buffer.find(XMLModeTag.OPEN_ANSWER, start)\n\n            if not final_answer_only and idx_thought != -1 and (idx_answer == -1 or idx_thought &lt; idx_answer):\n                self._current_state = StreamingState.REASONING\n                self._state_start_index = idx_thought + len(XMLModeTag.OPEN_THOUGHT)\n                self._state_last_emit_index = self._state_start_index\n            elif idx_answer != -1:\n                self._current_state = StreamingState.ANSWER\n                self._answer_started = True\n                self._state_start_index = idx_answer + len(XMLModeTag.OPEN_ANSWER)\n                self._state_last_emit_index = self._state_start_index\n\n        if self._current_state is None:\n            return\n\n        search_start = self._state_last_emit_index\n\n        if self._current_state == StreamingState.REASONING:\n            # Check for the next boundary: either &lt;/thought&gt;, &lt;action&gt;, or &lt;answer&gt;\n            next_pos = -1\n            next_tag = None\n            for tag in (XMLModeTag.CLOSE_THOUGHT, XMLModeTag.OPEN_ACTION, XMLModeTag.OPEN_ANSWER):\n                pos = self._buffer.find(tag, search_start)\n                if pos != -1 and (next_pos == -1 or pos &lt; next_pos):\n                    next_pos, next_tag = pos, tag\n\n            if next_pos != -1:\n                # Emit everything up to the next tag\n                if next_pos &gt; self._state_last_emit_index:\n                    self._emit(self._buffer[self._state_last_emit_index : next_pos], step=StreamingState.REASONING)\n\n                if next_tag == XMLModeTag.OPEN_ANSWER:\n                    self._current_state = StreamingState.ANSWER\n                    self._answer_started = True\n                    self._state_start_index = next_pos + len(XMLModeTag.OPEN_ANSWER)\n                    self._state_last_emit_index = self._state_start_index\n                else:\n                    # Stop reasoning stream due to either &lt;/thought&gt; or &lt;action&gt;\n                    self._current_state = None\n                    self._state_last_emit_index = next_pos + len(next_tag)\n                return\n\n            # If there is no next tag yet, emit incrementally using a tail guard\n            safe_end = max(self._state_last_emit_index, len(self._buffer) - self._tail_guard)\n            if safe_end &gt; self._state_last_emit_index:\n                self._emit(self._buffer[self._state_last_emit_index : safe_end], step=StreamingState.REASONING)\n                self._state_last_emit_index = safe_end\n            return\n\n        # If the current state is 'answer', stream up to the &lt;/answer&gt; tag\n        end_pos = self._buffer.find(XMLModeTag.CLOSE_ANSWER, search_start)\n        if end_pos != -1:\n            if end_pos &gt; self._state_last_emit_index:\n                self._emit(self._buffer[self._state_last_emit_index : end_pos], step=StreamingState.ANSWER)\n            # Close the answer\n            self._current_state = None\n            self._state_last_emit_index = end_pos + len(XMLModeTag.CLOSE_ANSWER)\n            return\n\n        safe_end = max(self._state_last_emit_index, len(self._buffer) - self._tail_guard)\n        if safe_end &gt; self._state_last_emit_index:\n            self._emit(self._buffer[self._state_last_emit_index : safe_end], step=StreamingState.ANSWER)\n            self._state_last_emit_index = safe_end\n\n    def _process_structured_output_mode(self, final_answer_only: bool) -&gt; None:\n        \"\"\"Process structured output mode.\"\"\"\n        self._process_json_mode(final_answer_only, is_function_calling=False)\n\n    def _process_function_calling_mode(self, final_answer_only: bool) -&gt; None:\n        \"\"\"Process function calling mode.\"\"\"\n        self._process_json_mode(final_answer_only, is_function_calling=True)\n\n    def _find_unescaped_quote_end(self, input_string: str, start_quote_index: int) -&gt; int:\n        \"\"\"\n        Return index of the next unescaped '\"' after start_quote_index, or -1 if not complete yet.\n\n        Args:\n            input_string (str): The string to search in.\n            start_quote_index (int): The index of the starting quote.\n\n        Returns:\n            int: The index of the next unescaped quote, or -1 if not found.\n        \"\"\"\n        current_index = start_quote_index + 1\n        while current_index &lt; len(input_string):\n            if input_string[current_index] == '\"':\n                # Count preceding backslashes\n                backslash_count = 0\n                previous_index = current_index - 1\n                while previous_index &gt;= 0 and input_string[previous_index] == \"\\\\\":\n                    backslash_count += 1\n                    previous_index -= 1\n                if backslash_count % 2 == 0:\n                    return current_index\n            current_index += 1\n        return -1\n\n    def _find_field_string_value_start(self, input_string: str, field_name: str, start_index: int = 0) -&gt; int:\n        \"\"\"\n        Find the index of the first character inside the opening quote of a string field value.\n        Returns -1 if field or opening quote is not fully present yet.\n\n        Args:\n            input_string (str): The string to search in.\n            field_name (str): The name of the field to search for.\n            start_index (int): The index to start searching from.\n\n        Returns:\n            int: The index of the first character inside the opening quote of the string field value,\n                 or -1 if not found.\n        \"\"\"\n        key = f'\"{field_name}\"'\n        position = input_string.find(key, start_index)\n        if position == -1:\n            return -1\n\n        colon_index = input_string.find(\":\", position + len(key))\n        if colon_index == -1:\n            return -1\n\n        # Skip the whitespace after the colon\n        index = colon_index + 1\n        while index &lt; len(input_string) and input_string[index] in WHITESPACE_PATTERNS:\n            index += 1\n        if index &gt;= len(input_string) or input_string[index] != '\"':\n            return -1\n        return index + 1\n\n    def _initialize_json_field_state(\n        self, buf: str, field_name: str, state: str, final_answer_only: bool = False\n    ) -&gt; bool:\n        \"\"\"\n        Initialize streaming state for a JSON field if not already set.\n\n        Args:\n            buf: Buffer containing JSON content\n            field_name: Name of the JSON field to look for\n            state: State to set if field is found (\"reasoning\" or \"answer\")\n            final_answer_only: Whether we're in final answer only mode\n\n        Returns:\n            bool: True if state was initialized, False otherwise\n        \"\"\"\n        if self._current_state is not None:\n            return False\n\n        # Skip reasoning fields in final answer only mode\n        if final_answer_only and state == StreamingState.REASONING:\n            return False\n\n        field_start = self._find_field_string_value_start(\n            buf, field_name, max(0, self._state_last_emit_index - FIND_JSON_FIELD_MAX_OFFSET)\n        )\n\n        # If the field is found, set the state and indices\n        if field_start != -1:\n            self._current_state = state\n            self._state_start_index = field_start\n            self._state_last_emit_index = max(self._state_last_emit_index, field_start)\n            return True\n        return False\n\n    def _process_json_mode(self, final_answer_only: bool, is_function_calling: bool = False) -&gt; None:\n        \"\"\"\n        Unified processing for JSON-like modes (structured output and function calling).\n\n        Args:\n            final_answer_only: Whether to stream only final answers\n            is_function_calling: Whether this is function calling mode (vs structured output)\n        \"\"\"\n        buf = self._buffer\n\n        if not is_function_calling and not self._answer_started:\n            # If there is a \"finish\" action, enable answer streaming\n            action_key_pos = buf.find(\n                f'\"{JSONStreamingField.ACTION.value}\"', max(0, self._state_last_emit_index - FIND_JSON_FIELD_MAX_OFFSET)\n            )\n            if action_key_pos != -1:\n                colon_pos = buf.find(\":\", action_key_pos)\n                if colon_pos != -1:\n                    v_start = self._skip_whitespace(buf, colon_pos + 1)\n                    if v_start &lt; len(buf) and buf[v_start] == '\"':\n                        end_quote = self._find_unescaped_quote_end(buf, v_start)\n                        if end_quote != -1:\n                            action_value = buf[v_start + 1 : end_quote]\n                            if action_value.strip().lower() == \"finish\":\n                                self._answer_started = True\n                                # Try to find the action_input field\n                                action_input_start = self._find_field_string_value_start(\n                                    buf, JSONStreamingField.ACTION_INPUT.value, end_quote + 1\n                                )\n                                if action_input_start != -1:\n                                    self._current_state = StreamingState.ANSWER\n                                    self._state_start_index = action_input_start\n                                    self._state_last_emit_index = max(self._state_last_emit_index, action_input_start)\n\n        self._initialize_json_field_state(\n            buf, JSONStreamingField.THOUGHT.value, StreamingState.REASONING, final_answer_only\n        )\n\n        if self._answer_started:\n            answer_field = (\n                JSONStreamingField.ANSWER.value if is_function_calling else JSONStreamingField.ACTION_INPUT.value\n            )\n            self._initialize_json_field_state(buf, answer_field, StreamingState.ANSWER)\n\n        if self._current_state == StreamingState.REASONING:\n            self._emit_json_field_content(buf, StreamingState.REASONING)\n        elif self._current_state == StreamingState.ANSWER:\n            self._emit_json_field_content(buf, StreamingState.ANSWER)\n\n    def _skip_whitespace(self, text: str, start: int) -&gt; int:\n        \"\"\"Skip whitespace characters starting from the given position.\"\"\"\n        while start &lt; len(text) and text[start] in WHITESPACE_PATTERNS:\n            start += 1\n        return start\n\n    def _emit_json_field_content(self, buf: str, step: str) -&gt; bool:\n        \"\"\"\n        Emit JSON field content in segments, handling complete and partial values.\n\n        Args:\n            buf: Buffer containing the JSON content\n            step: The streaming step (\"reasoning\" or \"answer\")\n\n        Returns:\n            bool: True if field is complete and state should be reset, False otherwise\n        \"\"\"\n        # Find the closing quote of the current JSON field\n        end_quote = self._find_unescaped_quote_end(buf, self._state_start_index - 1)\n        if end_quote != -1:\n            # If the field is complete, emit it\n            if end_quote &gt; self._state_last_emit_index:\n                segment_start = self._state_last_emit_index\n                while segment_start &lt; end_quote:\n                    segment_end = min(end_quote, segment_start + STREAMING_SEGMENT_SIZE)\n                    self._emit(buf[segment_start:segment_end], step=step)\n                    segment_start = segment_end\n                self._state_last_emit_index = end_quote\n            # Reset the state\n            self._current_state = None\n            return True\n\n        # Emit incrementally if the field is not complete\n        if len(buf) &gt; self._state_last_emit_index:\n            segment_start = self._state_last_emit_index\n            segment_end_target = len(buf)\n            while segment_start &lt; segment_end_target:\n                segment_end = min(segment_end_target, segment_start + STREAMING_SEGMENT_SIZE)\n                self._emit(buf[segment_start:segment_end], step=step)\n                segment_start = segment_end\n            self._state_last_emit_index = segment_end_target\n        return False\n\n    def _trim_buffer(self, force: bool = False) -&gt; None:\n        \"\"\"Trim already-emitted prefix of buffer to prevent re-detection.\"\"\"\n        if not self._buffer:\n            return\n\n        if self.mode_name == InferenceMode.STRUCTURED_OUTPUT.value:\n            return\n\n        if force:\n            keep_from = self._state_last_emit_index\n        else:\n            if (\n                self._current_state in (StreamingState.REASONING, StreamingState.ANSWER)\n                and self._state_start_index != -1\n            ):\n                keep_from = max(0, min(self._state_last_emit_index - self._tail_guard, self._state_start_index - 1))\n            else:\n                keep_from = max(0, self._state_last_emit_index - self._tail_guard)\n        if keep_from &lt;= 0:\n            return\n        self._buffer = self._buffer[keep_from:]\n\n        # Rebase the indices\n        self._state_start_index = max(0, self._state_start_index - keep_from)\n        self._state_last_emit_index = max(0, self._state_last_emit_index - keep_from)\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.AsyncStreamingIteratorCallbackHandler","title":"<code>AsyncStreamingIteratorCallbackHandler</code>","text":"<p>               Bases: <code>StreamingQueueCallbackHandler</code></p> <p>Callback handler for streaming events using an async iterator.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class AsyncStreamingIteratorCallbackHandler(StreamingQueueCallbackHandler):\n    \"\"\"Callback handler for streaming events using an async iterator.\"\"\"\n\n    def __init__(\n        self,\n        queue: asyncio.Queue | None = None,\n        done_event: asyncio.Event | None = None,\n        loop: asyncio.AbstractEventLoop | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize AsyncStreamingIteratorCallbackHandler.\n\n        Args:\n            queue (asyncio.Queue | None): Queue for streaming events.\n            done_event (asyncio.Event | None): Event to signal completion.\n            loop (asyncio.AbstractEventLoop | None): Event loop.\n        \"\"\"\n        if queue is None:\n            queue = asyncio.Queue()\n        if done_event is None:\n            done_event = asyncio.Event()\n        super().__init__(queue, done_event)\n        self._iterator = self._iter_queue_events()\n        self.loop = loop or asyncio.get_event_loop()\n\n    def send_to_queue(self, event: StreamingEventMessage):\n        \"\"\"Send the event to the queue.\"\"\"\n        asyncio.run_coroutine_threadsafe(self.queue.put(event), self.loop)\n\n    async def _iter_queue_events(self) -&gt; AsyncIterator[StreamingEventMessage]:\n        \"\"\"Async iterate over queue events.\n\n        Returns:\n            AsyncIterator[StreamingEventMessage]: Async iterator for streaming events.\n        \"\"\"\n        try:\n            while not self.queue.empty() or not self.done_event.is_set():\n                event = await self.queue.get()\n                yield event\n        except Exception as e:\n            logger.error(f\"Event streaming failed. Error: {e}\")\n\n    async def __anext__(self) -&gt; StreamingEventMessage:\n        \"\"\"Get the next async streaming event.\n\n        Returns:\n            StreamingEventMessage: Next async streaming event.\n        \"\"\"\n        return await self._iterator.__anext__()\n\n    async def __aiter__(self) -&gt; AsyncIterator[StreamingEventMessage]:\n        \"\"\"Get the async iterator for streaming events.\n\n        Returns:\n            AsyncIterator[StreamingEventMessage]: Async iterator for streaming events.\n        \"\"\"\n        async for item in self._iterator:\n            yield item\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.AsyncStreamingIteratorCallbackHandler.__aiter__","title":"<code>__aiter__()</code>  <code>async</code>","text":"<p>Get the async iterator for streaming events.</p> <p>Returns:</p> Type Description <code>AsyncIterator[StreamingEventMessage]</code> <p>AsyncIterator[StreamingEventMessage]: Async iterator for streaming events.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>async def __aiter__(self) -&gt; AsyncIterator[StreamingEventMessage]:\n    \"\"\"Get the async iterator for streaming events.\n\n    Returns:\n        AsyncIterator[StreamingEventMessage]: Async iterator for streaming events.\n    \"\"\"\n    async for item in self._iterator:\n        yield item\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.AsyncStreamingIteratorCallbackHandler.__anext__","title":"<code>__anext__()</code>  <code>async</code>","text":"<p>Get the next async streaming event.</p> <p>Returns:</p> Name Type Description <code>StreamingEventMessage</code> <code>StreamingEventMessage</code> <p>Next async streaming event.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>async def __anext__(self) -&gt; StreamingEventMessage:\n    \"\"\"Get the next async streaming event.\n\n    Returns:\n        StreamingEventMessage: Next async streaming event.\n    \"\"\"\n    return await self._iterator.__anext__()\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.AsyncStreamingIteratorCallbackHandler.__init__","title":"<code>__init__(queue=None, done_event=None, loop=None)</code>","text":"<p>Initialize AsyncStreamingIteratorCallbackHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue | None</code> <p>Queue for streaming events.</p> <code>None</code> <code>done_event</code> <code>Event | None</code> <p>Event to signal completion.</p> <code>None</code> <code>loop</code> <code>AbstractEventLoop | None</code> <p>Event loop.</p> <code>None</code> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def __init__(\n    self,\n    queue: asyncio.Queue | None = None,\n    done_event: asyncio.Event | None = None,\n    loop: asyncio.AbstractEventLoop | None = None,\n) -&gt; None:\n    \"\"\"Initialize AsyncStreamingIteratorCallbackHandler.\n\n    Args:\n        queue (asyncio.Queue | None): Queue for streaming events.\n        done_event (asyncio.Event | None): Event to signal completion.\n        loop (asyncio.AbstractEventLoop | None): Event loop.\n    \"\"\"\n    if queue is None:\n        queue = asyncio.Queue()\n    if done_event is None:\n        done_event = asyncio.Event()\n    super().__init__(queue, done_event)\n    self._iterator = self._iter_queue_events()\n    self.loop = loop or asyncio.get_event_loop()\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.AsyncStreamingIteratorCallbackHandler.send_to_queue","title":"<code>send_to_queue(event)</code>","text":"<p>Send the event to the queue.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def send_to_queue(self, event: StreamingEventMessage):\n    \"\"\"Send the event to the queue.\"\"\"\n    asyncio.run_coroutine_threadsafe(self.queue.put(event), self.loop)\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.BaseStreamingCallbackHandler","title":"<code>BaseStreamingCallbackHandler</code>","text":"<p>               Bases: <code>BaseCallbackHandler</code></p> <p>Base callback handler for streaming events.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class BaseStreamingCallbackHandler(BaseCallbackHandler):\n    \"\"\"Base callback handler for streaming events.\"\"\"\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.DefaultModeTag","title":"<code>DefaultModeTag</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of default mode tags.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class DefaultModeTag(str, Enum):\n    \"\"\"\n    Enumeration of default mode tags.\n    \"\"\"\n\n    THOUGHT = \"Thought:\"\n    ACTION = \"Action:\"\n    ANSWER = \"Answer:\"\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.InferenceMode","title":"<code>InferenceMode</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of inference types.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class InferenceMode(str, Enum):\n    \"\"\"\n    Enumeration of inference types.\n    \"\"\"\n\n    DEFAULT = \"DEFAULT\"\n    XML = \"XML\"\n    FUNCTION_CALLING = \"FUNCTION_CALLING\"\n    STRUCTURED_OUTPUT = \"STRUCTURED_OUTPUT\"\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.JSONStreamingField","title":"<code>JSONStreamingField</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of JSON streaming fields in FUNCTION_CALLING mode.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class JSONStreamingField(str, Enum):\n    \"\"\"\n    Enumeration of JSON streaming fields in FUNCTION_CALLING mode.\n    \"\"\"\n\n    THOUGHT = \"thought\"\n    ACTION = \"action\"\n    ACTION_INPUT = \"action_input\"\n    ANSWER = \"answer\"\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingIteratorCallbackHandler","title":"<code>StreamingIteratorCallbackHandler</code>","text":"<p>               Bases: <code>StreamingQueueCallbackHandler</code></p> <p>Callback handler for streaming events using an iterator.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class StreamingIteratorCallbackHandler(StreamingQueueCallbackHandler):\n    \"\"\"Callback handler for streaming events using an iterator.\"\"\"\n\n    def __init__(\n        self,\n        queue: Queue | None = None,\n        done_event: threading.Event | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize StreamingIteratorCallbackHandler.\n\n        Args:\n            queue (Queue | None): Queue for streaming events.\n            done_event (threading.Event | None): Event to signal completion.\n        \"\"\"\n        if queue is None:\n            queue = Queue()\n        if done_event is None:\n            done_event = threading.Event()\n        super().__init__(queue, done_event)\n        self._iterator = self._iter_queue_events()\n\n    def _iter_queue_events(self) -&gt; Iterator[StreamingEventMessage]:\n        \"\"\"Iterate over queue events.\n\n        Returns:\n            Iterator[StreamingEventMessage]: Iterator for streaming events.\n        \"\"\"\n        try:\n            while not self.queue.empty() or not self.done_event.is_set():\n                event = self.queue.get()\n                yield event\n        except Exception as e:\n            logger.error(f\"Event streaming failed. Error: {e}\")\n\n    def __next__(self) -&gt; StreamingEventMessage:\n        \"\"\"Get the next streaming event.\n\n        Returns:\n            StreamingEventMessage: Next streaming event.\n        \"\"\"\n        return self._iterator.__next__()\n\n    def __iter__(self) -&gt; Iterator[StreamingEventMessage]:\n        \"\"\"Get the iterator for streaming events.\n\n        Returns:\n            Iterator[StreamingEventMessage]: Iterator for streaming events.\n        \"\"\"\n        yield from self._iterator\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingIteratorCallbackHandler.__init__","title":"<code>__init__(queue=None, done_event=None)</code>","text":"<p>Initialize StreamingIteratorCallbackHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue | None</code> <p>Queue for streaming events.</p> <code>None</code> <code>done_event</code> <code>Event | None</code> <p>Event to signal completion.</p> <code>None</code> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def __init__(\n    self,\n    queue: Queue | None = None,\n    done_event: threading.Event | None = None,\n) -&gt; None:\n    \"\"\"Initialize StreamingIteratorCallbackHandler.\n\n    Args:\n        queue (Queue | None): Queue for streaming events.\n        done_event (threading.Event | None): Event to signal completion.\n    \"\"\"\n    if queue is None:\n        queue = Queue()\n    if done_event is None:\n        done_event = threading.Event()\n    super().__init__(queue, done_event)\n    self._iterator = self._iter_queue_events()\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingIteratorCallbackHandler.__iter__","title":"<code>__iter__()</code>","text":"<p>Get the iterator for streaming events.</p> <p>Returns:</p> Type Description <code>Iterator[StreamingEventMessage]</code> <p>Iterator[StreamingEventMessage]: Iterator for streaming events.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def __iter__(self) -&gt; Iterator[StreamingEventMessage]:\n    \"\"\"Get the iterator for streaming events.\n\n    Returns:\n        Iterator[StreamingEventMessage]: Iterator for streaming events.\n    \"\"\"\n    yield from self._iterator\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingIteratorCallbackHandler.__next__","title":"<code>__next__()</code>","text":"<p>Get the next streaming event.</p> <p>Returns:</p> Name Type Description <code>StreamingEventMessage</code> <code>StreamingEventMessage</code> <p>Next streaming event.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def __next__(self) -&gt; StreamingEventMessage:\n    \"\"\"Get the next streaming event.\n\n    Returns:\n        StreamingEventMessage: Next streaming event.\n    \"\"\"\n    return self._iterator.__next__()\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingQueueCallbackHandler","title":"<code>StreamingQueueCallbackHandler</code>","text":"<p>               Bases: <code>BaseStreamingCallbackHandler</code></p> <p>Callback handler for streaming events to a queue.</p> <p>Attributes:</p> Name Type Description <code>queue</code> <code>Queue | Queue | None</code> <p>Queue for streaming events.</p> <code>done_event</code> <code>Event | Event | None</code> <p>Event to signal completion.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class StreamingQueueCallbackHandler(BaseStreamingCallbackHandler):\n    \"\"\"Callback handler for streaming events to a queue.\n\n    Attributes:\n        queue (asyncio.Queue | Queue | None): Queue for streaming events.\n        done_event (asyncio.Event | threading.Event | None): Event to signal completion.\n    \"\"\"\n\n    def __init__(\n        self,\n        queue: asyncio.Queue | Queue | None = None,\n        done_event: asyncio.Event | threading.Event | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize StreamingQueueCallbackHandler.\n\n        Args:\n            queue (asyncio.Queue | Queue | None): Queue for streaming events.\n            done_event (asyncio.Event | threading.Event | None): Event to signal completion.\n        \"\"\"\n        self.queue = queue\n        self.done_event = done_event\n\n    def on_workflow_start(\n        self, serialized: dict[str, Any], prompts: list[str], **kwargs: Any\n    ) -&gt; None:\n        \"\"\"Called when the workflow starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            prompts (list[str]): List of prompts.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        self.done_event.clear()\n\n    def on_node_execute_stream(\n        self, serialized: dict[str, Any], chunk: dict[str, Any] | None = None, **kwargs: Any\n    ) -&gt; None:\n        \"\"\"Called when the node execute streams.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            chunk (dict[str, Any] | None): Stream chunk data.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        event = kwargs.get(\"event\") or StreamingEventMessage(\n            run_id=str(get_run_id(kwargs)),\n            wf_run_id=kwargs.get(\"wf_run_id\"),\n            entity_id=serialized.get(\"id\"),\n            data=format_value(chunk),\n            event=serialized.get(\"streaming\", {}).get(\"event\"),\n            source=StreamingEntitySource(\n                name=serialized.get(\"name\", None),\n                group=serialized.get(\"group\", None),\n                type=serialized.get(\"type\", None),\n            ),\n        )\n        self.send_to_queue(event)\n\n    def on_workflow_end(\n        self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n    ) -&gt; None:\n        \"\"\"Called when the workflow ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            output_data (dict[str, Any]): Output data from the workflow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        event = StreamingEventMessage(\n            run_id=str(get_run_id(kwargs)),\n            wf_run_id=kwargs.get(\"wf_run_id\"),\n            entity_id=serialized.get(\"id\"),\n            data=format_value(output_data),\n            event=serialized.get(\"streaming\", {}).get(\"event\"),\n            source=StreamingEntitySource(\n                name=serialized.get(\"name\", None),\n                group=serialized.get(\"group\", None),\n                type=serialized.get(\"type\", None),\n            ),\n        )\n        self.send_to_queue(event)\n        self.done_event.set()\n\n    def on_workflow_error(\n        self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n    ) -&gt; None:\n        \"\"\"Called when the workflow errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        self.done_event.set()\n\n    def send_to_queue(self, event: StreamingEventMessage):\n        \"\"\"Send the event to the queue.\"\"\"\n        self.queue.put_nowait(event)\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingQueueCallbackHandler.__init__","title":"<code>__init__(queue=None, done_event=None)</code>","text":"<p>Initialize StreamingQueueCallbackHandler.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue | Queue | None</code> <p>Queue for streaming events.</p> <code>None</code> <code>done_event</code> <code>Event | Event | None</code> <p>Event to signal completion.</p> <code>None</code> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def __init__(\n    self,\n    queue: asyncio.Queue | Queue | None = None,\n    done_event: asyncio.Event | threading.Event | None = None,\n) -&gt; None:\n    \"\"\"Initialize StreamingQueueCallbackHandler.\n\n    Args:\n        queue (asyncio.Queue | Queue | None): Queue for streaming events.\n        done_event (asyncio.Event | threading.Event | None): Event to signal completion.\n    \"\"\"\n    self.queue = queue\n    self.done_event = done_event\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingQueueCallbackHandler.on_node_execute_stream","title":"<code>on_node_execute_stream(serialized, chunk=None, **kwargs)</code>","text":"<p>Called when the node execute streams.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>chunk</code> <code>dict[str, Any] | None</code> <p>Stream chunk data.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def on_node_execute_stream(\n    self, serialized: dict[str, Any], chunk: dict[str, Any] | None = None, **kwargs: Any\n) -&gt; None:\n    \"\"\"Called when the node execute streams.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        chunk (dict[str, Any] | None): Stream chunk data.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    event = kwargs.get(\"event\") or StreamingEventMessage(\n        run_id=str(get_run_id(kwargs)),\n        wf_run_id=kwargs.get(\"wf_run_id\"),\n        entity_id=serialized.get(\"id\"),\n        data=format_value(chunk),\n        event=serialized.get(\"streaming\", {}).get(\"event\"),\n        source=StreamingEntitySource(\n            name=serialized.get(\"name\", None),\n            group=serialized.get(\"group\", None),\n            type=serialized.get(\"type\", None),\n        ),\n    )\n    self.send_to_queue(event)\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingQueueCallbackHandler.on_workflow_end","title":"<code>on_workflow_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the workflow ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the workflow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def on_workflow_end(\n    self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n) -&gt; None:\n    \"\"\"Called when the workflow ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        output_data (dict[str, Any]): Output data from the workflow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    event = StreamingEventMessage(\n        run_id=str(get_run_id(kwargs)),\n        wf_run_id=kwargs.get(\"wf_run_id\"),\n        entity_id=serialized.get(\"id\"),\n        data=format_value(output_data),\n        event=serialized.get(\"streaming\", {}).get(\"event\"),\n        source=StreamingEntitySource(\n            name=serialized.get(\"name\", None),\n            group=serialized.get(\"group\", None),\n            type=serialized.get(\"type\", None),\n        ),\n    )\n    self.send_to_queue(event)\n    self.done_event.set()\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingQueueCallbackHandler.on_workflow_error","title":"<code>on_workflow_error(serialized, error, **kwargs)</code>","text":"<p>Called when the workflow errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def on_workflow_error(\n    self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n) -&gt; None:\n    \"\"\"Called when the workflow errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    self.done_event.set()\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingQueueCallbackHandler.on_workflow_start","title":"<code>on_workflow_start(serialized, prompts, **kwargs)</code>","text":"<p>Called when the workflow starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>prompts</code> <code>list[str]</code> <p>List of prompts.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def on_workflow_start(\n    self, serialized: dict[str, Any], prompts: list[str], **kwargs: Any\n) -&gt; None:\n    \"\"\"Called when the workflow starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        prompts (list[str]): List of prompts.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    self.done_event.clear()\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingQueueCallbackHandler.send_to_queue","title":"<code>send_to_queue(event)</code>","text":"<p>Send the event to the queue.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>def send_to_queue(self, event: StreamingEventMessage):\n    \"\"\"Send the event to the queue.\"\"\"\n    self.queue.put_nowait(event)\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.StreamingState","title":"<code>StreamingState</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of streaming states.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class StreamingState(str, Enum):\n    \"\"\"\n    Enumeration of streaming states.\n    \"\"\"\n\n    REASONING = \"reasoning\"\n    ANSWER = \"answer\"\n</code></pre>"},{"location":"dynamiq/callbacks/streaming/#dynamiq.callbacks.streaming.XMLModeTag","title":"<code>XMLModeTag</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of XML mode tags.</p> Source code in <code>dynamiq/callbacks/streaming.py</code> <pre><code>class XMLModeTag(str, Enum):\n    \"\"\"\n    Enumeration of XML mode tags.\n    \"\"\"\n\n    OPEN_THOUGHT = \"&lt;thought&gt;\"\n    CLOSE_THOUGHT = \"&lt;/thought&gt;\"\n    OPEN_ACTION = \"&lt;action&gt;\"\n    OPEN_ANSWER = \"&lt;answer&gt;\"\n    CLOSE_ANSWER = \"&lt;/answer&gt;\"\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/","title":"Tracing","text":""},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.ExecutionRun","title":"<code>ExecutionRun</code>  <code>dataclass</code>","text":"<p>Data class for execution run details.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>UUID</code> <p>Execution run ID.</p> <code>start_time</code> <code>datetime</code> <p>Start time of the execution.</p> <code>end_time</code> <code>datetime | None</code> <p>End time of the execution.</p> <code>status</code> <code>RunStatus | None</code> <p>Status of the execution.</p> <code>input</code> <code>Any | None</code> <p>Input data for the execution.</p> <code>output</code> <code>Any | None</code> <p>Output data from the execution.</p> <code>error</code> <code>Any | None</code> <p>Error details if any.</p> <code>metadata</code> <code>dict</code> <p>Additional metadata.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>@dataclass\nclass ExecutionRun:\n    \"\"\"Data class for execution run details.\n\n    Attributes:\n        id (UUID): Execution run ID.\n        start_time (datetime): Start time of the execution.\n        end_time (datetime | None): End time of the execution.\n        status (RunStatus | None): Status of the execution.\n        input (Any | None): Input data for the execution.\n        output (Any | None): Output data from the execution.\n        error (Any | None): Error details if any.\n        metadata (dict): Additional metadata.\n    \"\"\"\n    id: UUID\n    start_time: datetime\n    end_time: datetime | None = None\n    status: RunStatus | None = None\n    input: Any | None = None\n    output: Any | None = None\n    error: Any | None = None\n    metadata: dict = field(default_factory=dict)\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert ExecutionRun to dictionary.\n\n        Returns:\n            dict: Dictionary representation of ExecutionRun.\n        \"\"\"\n        return asdict(self)\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.ExecutionRun.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert ExecutionRun to dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary representation of ExecutionRun.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert ExecutionRun to dictionary.\n\n    Returns:\n        dict: Dictionary representation of ExecutionRun.\n    \"\"\"\n    return asdict(self)\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.Run","title":"<code>Run</code>  <code>dataclass</code>","text":"<p>Data class for run details.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>UUID</code> <p>Run ID.</p> <code>name</code> <code>str</code> <p>Name of the run.</p> <code>type</code> <code>RunType</code> <p>Type of the run.</p> <code>trace_id</code> <code>UUID | str</code> <p>Trace ID.</p> <code>source_id</code> <code>UUID | str</code> <p>Source ID.</p> <code>session_id</code> <code>UUID | str</code> <p>Session ID.</p> <code>start_time</code> <code>datetime</code> <p>Start time of the run.</p> <code>end_time</code> <code>datetime</code> <p>End time of the run.</p> <code>parent_run_id</code> <code>UUID</code> <p>Parent run ID.</p> <code>status</code> <code>RunStatus</code> <p>Status of the run.</p> <code>input</code> <code>Any</code> <p>Input data for the run.</p> <code>output</code> <code>Any</code> <p>Output data from the run.</p> <code>metadata</code> <code>Any</code> <p>Additional metadata.</p> <code>error</code> <code>Any</code> <p>Error details if any.</p> <code>executions</code> <code>list[ExecutionRun]</code> <p>List of execution runs.</p> <code>tags</code> <code>list[str]</code> <p>List of tags.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>@dataclass\nclass Run:\n    \"\"\"Data class for run details.\n\n    Attributes:\n        id (UUID): Run ID.\n        name (str): Name of the run.\n        type (RunType): Type of the run.\n        trace_id (UUID | str): Trace ID.\n        source_id (UUID | str): Source ID.\n        session_id (UUID | str): Session ID.\n        start_time (datetime): Start time of the run.\n        end_time (datetime): End time of the run.\n        parent_run_id (UUID): Parent run ID.\n        status (RunStatus): Status of the run.\n        input (Any): Input data for the run.\n        output (Any): Output data from the run.\n        metadata (Any): Additional metadata.\n        error (Any): Error details if any.\n        executions (list[ExecutionRun]): List of execution runs.\n        tags (list[str]): List of tags.\n    \"\"\"\n    id: UUID\n    name: str\n    type: RunType\n    trace_id: UUID | str\n    source_id: UUID | str\n    session_id: UUID | str\n    start_time: datetime\n    end_time: datetime = None\n    parent_run_id: UUID = None\n    status: RunStatus = None\n    input: Any = None\n    output: Any = None\n    metadata: Any = None\n    error: Any = None\n    executions: list[ExecutionRun] = field(default_factory=list)\n    tags: list[str] = field(default_factory=list)\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert Run to dictionary.\n\n        Returns:\n            dict: Dictionary representation of Run.\n        \"\"\"\n        return asdict(self)\n\n    def to_json(self) -&gt; str:\n        \"\"\"Convert Run to JSON string.\n\n        Returns:\n            str: JSON string representation of Run.\n        \"\"\"\n        return json.dumps(self.to_dict(), cls=JsonWorkflowEncoder)\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.Run.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert Run to dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary representation of Run.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert Run to dictionary.\n\n    Returns:\n        dict: Dictionary representation of Run.\n    \"\"\"\n    return asdict(self)\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.Run.to_json","title":"<code>to_json()</code>","text":"<p>Convert Run to JSON string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>JSON string representation of Run.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert Run to JSON string.\n\n    Returns:\n        str: JSON string representation of Run.\n    \"\"\"\n    return json.dumps(self.to_dict(), cls=JsonWorkflowEncoder)\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.RunStatus","title":"<code>RunStatus</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration for run statuses.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>class RunStatus(str, Enum):\n    \"\"\"Enumeration for run statuses.\"\"\"\n    SUCCEEDED = \"succeeded\"\n    FAILED = \"failed\"\n    SKIPPED = \"skipped\"\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.RunType","title":"<code>RunType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration for run types.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>class RunType(str, Enum):\n    \"\"\"Enumeration for run types.\"\"\"\n    WORKFLOW = \"workflow\"\n    FLOW = \"flow\"\n    NODE = \"node\"\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler","title":"<code>TracingCallbackHandler</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>BaseCallbackHandler</code></p> <p>Callback handler for tracing workflow events.</p> <p>Attributes:</p> Name Type Description <code>source_id</code> <code>str | None</code> <p>Source ID.</p> <code>trace_id</code> <code>str | None</code> <p>Trace ID.</p> <code>session_id</code> <code>str | None</code> <p>Session ID.</p> <code>client</code> <code>BaseTracingClient | None</code> <p>Tracing client.</p> <code>runs</code> <code>dict[UUID, Run]</code> <p>Dictionary of runs.</p> <code>tags</code> <code>list[str]</code> <p>List of tags.</p> <code>installed_pkgs</code> <code>list[str]</code> <p>List of installed packages.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>class TracingCallbackHandler(BaseModel, BaseCallbackHandler):\n    \"\"\"Callback handler for tracing workflow events.\n\n    Attributes:\n        source_id (str | None): Source ID.\n        trace_id (str | None): Trace ID.\n        session_id (str | None): Session ID.\n        client (BaseTracingClient | None): Tracing client.\n        runs (dict[UUID, Run]): Dictionary of runs.\n        tags (list[str]): List of tags.\n        installed_pkgs (list[str]): List of installed packages.\n    \"\"\"\n    source_id: str | None = Field(default_factory=generate_uuid)\n    trace_id: str | None = Field(default_factory=generate_uuid)\n    session_id: str | None = Field(default_factory=generate_uuid)\n    client: BaseTracingClient | None = None\n    runs: dict[UUID, Run] = {}\n    tags: list[str] = []\n    metadata: dict = {}\n\n    installed_pkgs: list[str] = Field(\n        [\"dynamiq\"],\n        description=\"List of installed packages to include in the host information.\",\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @cached_property\n    def host(self) -&gt; dict:\n        \"\"\"Get host information.\n\n        Returns:\n            dict: Host information including installed packages.\n        \"\"\"\n        return {\n            \"installed_pkgs\": [\n                {\"name\": dist.metadata[\"Name\"], \"version\": dist.version}\n                for dist in distributions()\n                if dist.metadata.get(\"Name\") in self.installed_pkgs\n            ],\n        }\n\n    def _get_node_base_run(self, serialized: dict[str, Any], **kwargs: Any) -&gt; Run:\n        \"\"\"Get base run details for a node.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            **kwargs (Any): Additional arguments.\n\n        Returns:\n            Run: Base run details for the node.\n        \"\"\"\n        run_id = get_run_id(kwargs)\n        parent_run_id = get_parent_run_id(kwargs)\n\n        from dynamiq.nodes import NodeGroup\n\n        # Handle runtime LLM prompt override\n        if serialized.get(\"group\") == NodeGroup.LLMS:\n            prompt = kwargs.get(\"prompt\") or serialized.get(\"prompt\")\n            if isinstance(prompt, BaseModel):\n                prompt = prompt.model_dump()\n            serialized[\"prompt\"] = prompt\n\n        run = Run(\n            id=run_id,\n            name=serialized.get(\"name\"),\n            type=RunType.NODE,\n            trace_id=self.trace_id,\n            source_id=self.source_id,\n            session_id=self.session_id,\n            start_time=datetime.now(UTC),\n            parent_run_id=parent_run_id,\n            metadata={\n                \"node\": serialized,\n                \"run_depends\": kwargs.get(\"run_depends\", []),\n                **self.metadata,\n            },\n            tags=self.tags,\n            input=format_value(kwargs.get(\"input_data\"), for_tracing=True),\n        )\n        return run\n\n    def on_workflow_start(\n        self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the workflow starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            input_data (dict[str, Any]): Input data for the workflow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run_id = get_run_id(kwargs)\n\n        self.runs[run_id] = Run(\n            id=run_id,\n            name=\"Workflow\",\n            type=RunType.WORKFLOW,\n            trace_id=self.trace_id,\n            source_id=self.source_id,\n            session_id=self.session_id,\n            start_time=datetime.now(UTC),\n            input=format_value(input_data, for_tracing=True),\n            metadata={\n                \"workflow\": {\"id\": serialized.get(\"id\"), \"version\": serialized.get(\"version\")},\n                **self.metadata,\n            },\n            tags=self.tags,\n        )\n\n    def on_workflow_end(\n        self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the workflow ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            output_data (dict[str, Any]): Output data from the workflow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        run.end_time = datetime.now(UTC)\n        run.output = format_value(output_data, for_tracing=True)\n        run.status = RunStatus.SUCCEEDED\n\n        self.flush()\n\n    def on_workflow_error(\n        self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n    ):\n        \"\"\"Called when the workflow errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized workflow data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        run.end_time = datetime.now(UTC)\n        run.status = RunStatus.FAILED\n        run.error = {\n            \"message\": str(error),\n            \"traceback\": traceback.format_exc(),\n        }\n\n    def on_flow_start(\n        self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the flow starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized flow data.\n            input_data (dict[str, Any]): Input data for the flow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run_id = get_run_id(kwargs)\n        parent_run_id = get_parent_run_id(kwargs)\n\n        self.runs[run_id] = Run(\n            id=run_id,\n            name=\"Flow\",\n            type=RunType.FLOW,\n            trace_id=self.trace_id,\n            source_id=self.source_id,\n            session_id=self.session_id,\n            start_time=datetime.now(UTC),\n            parent_run_id=parent_run_id,\n            input=format_value(input_data, for_tracing=True),\n            metadata={\"flow\": {\"id\": serialized.get(\"id\")}, **self.metadata},\n            tags=self.tags,\n        )\n\n    def on_flow_end(\n        self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the flow ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized flow data.\n            output_data (dict[str, Any]): Output data from the flow.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        run.end_time = datetime.now(UTC)\n        run.output = format_value(output_data, for_tracing=True)\n        run.status = RunStatus.SUCCEEDED\n        # If parent_run_id is None, the run is the highest in the execution tree\n        if run.parent_run_id is None:\n            self.flush()\n\n    def on_flow_error(\n        self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n    ):\n        \"\"\"Called when the flow errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized flow data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        run.end_time = datetime.now(UTC)\n        run.status = RunStatus.FAILED\n        run.error = {\n            \"message\": str(error),\n            \"traceback\": traceback.format_exc(),\n        }\n\n    def on_node_start(\n        self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the node starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run_id = get_run_id(kwargs)\n        run = self._get_node_base_run(serialized, **kwargs)\n        run.input = format_value(input_data, for_tracing=True)\n        self.runs[run_id] = run\n\n    def on_node_end(\n        self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the node ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            output_data (dict[str, Any]): Output data from the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        run.end_time = datetime.now(UTC)\n        run.output = format_value(output_data, for_tracing=True)\n        run.status = RunStatus.SUCCEEDED\n        run.metadata[\"is_output_from_cache\"] = kwargs.get(\"is_output_from_cache\", False)\n        # If parent_run_id is None, the run is the highest in the execution tree\n        if run.parent_run_id is None:\n            self.flush()\n\n    def on_node_error(\n        self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n    ):\n        \"\"\"Called when the node errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run_id = get_run_id(kwargs)\n        if (run := self.runs.get(run_id)) is None:\n            run = self._get_node_base_run(serialized, **kwargs)\n            self.runs[run_id] = run\n\n        run.end_time = datetime.now(UTC)\n        run.status = RunStatus.FAILED\n        run.error = {\n            \"message\": str(error),\n            \"traceback\": traceback.format_exc(),\n        }\n\n    def on_node_skip(\n        self,\n        serialized: dict[str, Any],\n        skip_data: dict[str, Any],\n        input_data: dict[str, Any],\n        **kwargs: Any,\n    ):\n        \"\"\"Called when the node skips.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            skip_data (dict[str, Any]): Data related to the skip.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run_id = get_run_id(kwargs)\n        if (run := self.runs.get(run_id)) is None:\n            run = self._get_node_base_run(serialized, **kwargs)\n            self.runs[run_id] = run\n\n        run.input = format_value(input_data, for_tracing=True)\n        run.end_time = run.start_time\n        run.status = RunStatus.SKIPPED\n        run.metadata[\"skip\"] = format_value(skip_data)\n\n    def on_node_execute_start(\n        self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the node execute starts.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        execution_run_id = get_execution_run_id(kwargs)\n        execution = ExecutionRun(\n            id=execution_run_id,\n            start_time=datetime.now(UTC),\n            metadata={},\n        )\n        run.executions.append(execution)\n\n    def on_node_execute_end(\n        self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n    ):\n        \"\"\"Called when the node execute ends.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            output_data (dict[str, Any]): Output data from the node.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        execution = ensure_execution_run(get_execution_run_id(kwargs), run.executions)\n        execution.end_time = datetime.now(UTC)\n        execution.status = RunStatus.SUCCEEDED\n\n    def on_node_execute_error(\n        self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n    ):\n        \"\"\"Called when the node execute errors.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            error (BaseException): Error encountered.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        execution = ensure_execution_run(get_execution_run_id(kwargs), run.executions)\n        execution.end_time = datetime.now(UTC)\n        execution.status = RunStatus.FAILED\n        execution.error = {\n            \"message\": str(error),\n            \"traceback\": traceback.format_exc(),\n        }\n\n    def on_node_execute_run(self, serialized: dict[str, Any], **kwargs: Any):\n        \"\"\"Called when the node execute runs.\n\n        Args:\n            serialized (dict[str, Any]): Serialized node data.\n            **kwargs (Any): Additional arguments.\n        \"\"\"\n        run = ensure_run(get_run_id(kwargs), self.runs)\n        if usage := kwargs.get(\"usage_data\"):\n            run.metadata[\"usage\"] = usage\n\n        if prompt_messages := kwargs.get(\"prompt_messages\"):\n            run.metadata[\"node\"][\"prompt\"][\"messages\"] = prompt_messages\n\n        if tool_data := kwargs.get(\"tool_data\"):\n            run.metadata[\"tool_data\"] = tool_data\n\n    def flush(self):\n        \"\"\"Flush the runs to the tracing client.\"\"\"\n        if self.client:\n            self.client.trace([run for run in self.runs.values()])\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.host","title":"<code>host: dict</code>  <code>cached</code> <code>property</code>","text":"<p>Get host information.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Host information including installed packages.</p>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.flush","title":"<code>flush()</code>","text":"<p>Flush the runs to the tracing client.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def flush(self):\n    \"\"\"Flush the runs to the tracing client.\"\"\"\n    if self.client:\n        self.client.trace([run for run in self.runs.values()])\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_flow_end","title":"<code>on_flow_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the flow ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized flow data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the flow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_flow_end(\n    self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the flow ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized flow data.\n        output_data (dict[str, Any]): Output data from the flow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    run.end_time = datetime.now(UTC)\n    run.output = format_value(output_data, for_tracing=True)\n    run.status = RunStatus.SUCCEEDED\n    # If parent_run_id is None, the run is the highest in the execution tree\n    if run.parent_run_id is None:\n        self.flush()\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_flow_error","title":"<code>on_flow_error(serialized, error, **kwargs)</code>","text":"<p>Called when the flow errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized flow data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_flow_error(\n    self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n):\n    \"\"\"Called when the flow errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized flow data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    run.end_time = datetime.now(UTC)\n    run.status = RunStatus.FAILED\n    run.error = {\n        \"message\": str(error),\n        \"traceback\": traceback.format_exc(),\n    }\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_flow_start","title":"<code>on_flow_start(serialized, input_data, **kwargs)</code>","text":"<p>Called when the flow starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized flow data.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the flow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_flow_start(\n    self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the flow starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized flow data.\n        input_data (dict[str, Any]): Input data for the flow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run_id = get_run_id(kwargs)\n    parent_run_id = get_parent_run_id(kwargs)\n\n    self.runs[run_id] = Run(\n        id=run_id,\n        name=\"Flow\",\n        type=RunType.FLOW,\n        trace_id=self.trace_id,\n        source_id=self.source_id,\n        session_id=self.session_id,\n        start_time=datetime.now(UTC),\n        parent_run_id=parent_run_id,\n        input=format_value(input_data, for_tracing=True),\n        metadata={\"flow\": {\"id\": serialized.get(\"id\")}, **self.metadata},\n        tags=self.tags,\n    )\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_node_end","title":"<code>on_node_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the node ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_node_end(\n    self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the node ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        output_data (dict[str, Any]): Output data from the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    run.end_time = datetime.now(UTC)\n    run.output = format_value(output_data, for_tracing=True)\n    run.status = RunStatus.SUCCEEDED\n    run.metadata[\"is_output_from_cache\"] = kwargs.get(\"is_output_from_cache\", False)\n    # If parent_run_id is None, the run is the highest in the execution tree\n    if run.parent_run_id is None:\n        self.flush()\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_node_error","title":"<code>on_node_error(serialized, error, **kwargs)</code>","text":"<p>Called when the node errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_node_error(\n    self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n):\n    \"\"\"Called when the node errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run_id = get_run_id(kwargs)\n    if (run := self.runs.get(run_id)) is None:\n        run = self._get_node_base_run(serialized, **kwargs)\n        self.runs[run_id] = run\n\n    run.end_time = datetime.now(UTC)\n    run.status = RunStatus.FAILED\n    run.error = {\n        \"message\": str(error),\n        \"traceback\": traceback.format_exc(),\n    }\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_node_execute_end","title":"<code>on_node_execute_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the node execute ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_node_execute_end(\n    self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the node execute ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        output_data (dict[str, Any]): Output data from the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    execution = ensure_execution_run(get_execution_run_id(kwargs), run.executions)\n    execution.end_time = datetime.now(UTC)\n    execution.status = RunStatus.SUCCEEDED\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_node_execute_error","title":"<code>on_node_execute_error(serialized, error, **kwargs)</code>","text":"<p>Called when the node execute errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_node_execute_error(\n    self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n):\n    \"\"\"Called when the node execute errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    execution = ensure_execution_run(get_execution_run_id(kwargs), run.executions)\n    execution.end_time = datetime.now(UTC)\n    execution.status = RunStatus.FAILED\n    execution.error = {\n        \"message\": str(error),\n        \"traceback\": traceback.format_exc(),\n    }\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_node_execute_run","title":"<code>on_node_execute_run(serialized, **kwargs)</code>","text":"<p>Called when the node execute runs.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_node_execute_run(self, serialized: dict[str, Any], **kwargs: Any):\n    \"\"\"Called when the node execute runs.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    if usage := kwargs.get(\"usage_data\"):\n        run.metadata[\"usage\"] = usage\n\n    if prompt_messages := kwargs.get(\"prompt_messages\"):\n        run.metadata[\"node\"][\"prompt\"][\"messages\"] = prompt_messages\n\n    if tool_data := kwargs.get(\"tool_data\"):\n        run.metadata[\"tool_data\"] = tool_data\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_node_execute_start","title":"<code>on_node_execute_start(serialized, input_data, **kwargs)</code>","text":"<p>Called when the node execute starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_node_execute_start(\n    self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the node execute starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    execution_run_id = get_execution_run_id(kwargs)\n    execution = ExecutionRun(\n        id=execution_run_id,\n        start_time=datetime.now(UTC),\n        metadata={},\n    )\n    run.executions.append(execution)\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_node_skip","title":"<code>on_node_skip(serialized, skip_data, input_data, **kwargs)</code>","text":"<p>Called when the node skips.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>skip_data</code> <code>dict[str, Any]</code> <p>Data related to the skip.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_node_skip(\n    self,\n    serialized: dict[str, Any],\n    skip_data: dict[str, Any],\n    input_data: dict[str, Any],\n    **kwargs: Any,\n):\n    \"\"\"Called when the node skips.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        skip_data (dict[str, Any]): Data related to the skip.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run_id = get_run_id(kwargs)\n    if (run := self.runs.get(run_id)) is None:\n        run = self._get_node_base_run(serialized, **kwargs)\n        self.runs[run_id] = run\n\n    run.input = format_value(input_data, for_tracing=True)\n    run.end_time = run.start_time\n    run.status = RunStatus.SKIPPED\n    run.metadata[\"skip\"] = format_value(skip_data)\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_node_start","title":"<code>on_node_start(serialized, input_data, **kwargs)</code>","text":"<p>Called when the node starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized node data.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_node_start(\n    self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the node starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized node data.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run_id = get_run_id(kwargs)\n    run = self._get_node_base_run(serialized, **kwargs)\n    run.input = format_value(input_data, for_tracing=True)\n    self.runs[run_id] = run\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_workflow_end","title":"<code>on_workflow_end(serialized, output_data, **kwargs)</code>","text":"<p>Called when the workflow ends.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the workflow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_workflow_end(\n    self, serialized: dict[str, Any], output_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the workflow ends.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        output_data (dict[str, Any]): Output data from the workflow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    run.end_time = datetime.now(UTC)\n    run.output = format_value(output_data, for_tracing=True)\n    run.status = RunStatus.SUCCEEDED\n\n    self.flush()\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_workflow_error","title":"<code>on_workflow_error(serialized, error, **kwargs)</code>","text":"<p>Called when the workflow errors.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>error</code> <code>BaseException</code> <p>Error encountered.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_workflow_error(\n    self, serialized: dict[str, Any], error: BaseException, **kwargs: Any\n):\n    \"\"\"Called when the workflow errors.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        error (BaseException): Error encountered.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run = ensure_run(get_run_id(kwargs), self.runs)\n    run.end_time = datetime.now(UTC)\n    run.status = RunStatus.FAILED\n    run.error = {\n        \"message\": str(error),\n        \"traceback\": traceback.format_exc(),\n    }\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.TracingCallbackHandler.on_workflow_start","title":"<code>on_workflow_start(serialized, input_data, **kwargs)</code>","text":"<p>Called when the workflow starts.</p> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>dict[str, Any]</code> <p>Serialized workflow data.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the workflow.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def on_workflow_start(\n    self, serialized: dict[str, Any], input_data: dict[str, Any], **kwargs: Any\n):\n    \"\"\"Called when the workflow starts.\n\n    Args:\n        serialized (dict[str, Any]): Serialized workflow data.\n        input_data (dict[str, Any]): Input data for the workflow.\n        **kwargs (Any): Additional arguments.\n    \"\"\"\n    run_id = get_run_id(kwargs)\n\n    self.runs[run_id] = Run(\n        id=run_id,\n        name=\"Workflow\",\n        type=RunType.WORKFLOW,\n        trace_id=self.trace_id,\n        source_id=self.source_id,\n        session_id=self.session_id,\n        start_time=datetime.now(UTC),\n        input=format_value(input_data, for_tracing=True),\n        metadata={\n            \"workflow\": {\"id\": serialized.get(\"id\"), \"version\": serialized.get(\"version\")},\n            **self.metadata,\n        },\n        tags=self.tags,\n    )\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.ensure_execution_run","title":"<code>ensure_execution_run(execution_run_id, executions)</code>","text":"<p>Ensure the execution run exists in the executions list.</p> <p>Parameters:</p> Name Type Description Default <code>execution_run_id</code> <code>UUID</code> <p>Execution run ID.</p> required <code>executions</code> <code>list[ExecutionRun]</code> <p>List of execution runs.</p> required <p>Returns:</p> Name Type Description <code>ExecutionRun</code> <code>ExecutionRun</code> <p>The execution run corresponding to the execution run ID.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the execution run is not found.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def ensure_execution_run(execution_run_id: UUID, executions: list[ExecutionRun]) -&gt; ExecutionRun:\n    \"\"\"Ensure the execution run exists in the executions list.\n\n    Args:\n        execution_run_id (UUID): Execution run ID.\n        executions (list[ExecutionRun]): List of execution runs.\n\n    Returns:\n        ExecutionRun: The execution run corresponding to the execution run ID.\n\n    Raises:\n        ValueError: If the execution run is not found.\n    \"\"\"\n    for execution in executions:\n        if execution.id == execution_run_id:\n            return execution\n\n    raise ValueError(f\"execution run {execution_run_id} not found\")\n</code></pre>"},{"location":"dynamiq/callbacks/tracing/#dynamiq.callbacks.tracing.ensure_run","title":"<code>ensure_run(run_id, runs)</code>","text":"<p>Ensure the run exists in the runs dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>UUID</code> <p>Run ID.</p> required <code>runs</code> <code>dict[UUID, Run]</code> <p>Dictionary of runs.</p> required <p>Returns:</p> Name Type Description <code>Run</code> <code>Run</code> <p>The run corresponding to the run ID.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the run is not found.</p> Source code in <code>dynamiq/callbacks/tracing.py</code> <pre><code>def ensure_run(run_id: UUID, runs: dict[UUID, Run]) -&gt; Run:\n    \"\"\"Ensure the run exists in the runs dictionary.\n\n    Args:\n        run_id (UUID): Run ID.\n        runs (dict[UUID, Run]): Dictionary of runs.\n\n    Returns:\n        Run: The run corresponding to the run ID.\n\n    Raises:\n        ValueError: If the run is not found.\n    \"\"\"\n    run = runs.get(run_id)\n    if not run:\n        raise ValueError(f\"run {run_id} not found\")\n\n    return runs[run_id]\n</code></pre>"},{"location":"dynamiq/cli/client/","title":"Client","text":""},{"location":"dynamiq/cli/client/#dynamiq.cli.client.HTTPError","title":"<code>HTTPError</code>","text":"<p>               Bases: <code>RuntimeError</code></p> <p>Raised for non-2xx responses after retries.</p> Source code in <code>dynamiq/cli/client.py</code> <pre><code>class HTTPError(RuntimeError):\n    \"\"\"Raised for non-2xx responses after retries.\"\"\"\n</code></pre>"},{"location":"dynamiq/cli/config/","title":"Config","text":""},{"location":"dynamiq/cli/config/#dynamiq.cli.config.Settings","title":"<code>Settings</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/cli/config.py</code> <pre><code>class Settings(BaseModel):\n    org_id: str | None = Field(default=None)\n    project_id: str | None = Field(default=None)\n\n    api_host: str | None = Field(default=DYNAMIQ_BASE_URL)\n    api_key: str | None = Field(default=None)\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    @property\n    def base_url(self) -&gt; str:\n        return self.api_host.rstrip(\"/\")\n\n    def __str__(self) -&gt; str:\n        return f\"Settings(org={self.org_id}, project={self.project_id}, host={self.api_host})\"\n\n    @classmethod\n    def _from_env(cls) -&gt; dict[str, Any]:\n        \"\"\"Pick just the env-vars we care about.\"\"\"\n        return {\n            k: v\n            for k, v in {\n                \"api_host\": os.getenv(\"DYNAMIQ_API_HOST\"),\n                \"api_key\": os.getenv(\"DYNAMIQ_API_KEY\"),\n            }.items()\n            if v is not None\n        }\n\n    @classmethod\n    def load_settings(cls):\n        disk: dict[str, Any] = {}\n        env: dict = cls._from_env()\n        if _CONFIG_FILE_PATH.exists():\n            try:\n                disk = json.loads(_CONFIG_FILE_PATH.read_text())\n            except json.JSONDecodeError as exc:\n                raise SystemExit(f\"\u274c Corrupted config file at {_CONFIG_FILE_PATH}: {exc}\") from exc\n        if _CREDS_FILE_PATH.exists():\n            try:\n                env = json.loads(_CREDS_FILE_PATH.read_text())\n            except json.JSONDecodeError as exc:\n                raise SystemExit(f\"\u274c Corrupted credentials file at {_CREDS_FILE_PATH}: {exc}\") from exc\n\n        merged = {**disk, **env}\n        try:\n            return cls.model_validate(merged)\n        except ValidationError as exc:\n            raise SystemExit(f\"\u274c Invalid configuration: {exc}\") from exc\n\n    def save_settings(self) -&gt; None:\n        _CONFIG_FILE_PATH.parent.mkdir(parents=True, exist_ok=True)\n        payload = self.model_dump(include={\"org_id\", \"project_id\"})\n        _CONFIG_FILE_PATH.write_text(json.dumps(payload, indent=2))\n\n        _CREDS_FILE_PATH.parent.mkdir(parents=True, exist_ok=True)\n        payload = self.model_dump(include={\"api_key\", \"api_host\"})\n        _CREDS_FILE_PATH.write_text(json.dumps(payload, indent=2))\n</code></pre>"},{"location":"dynamiq/cli/commands/config/","title":"Config","text":""},{"location":"dynamiq/cli/commands/context/","title":"Context","text":""},{"location":"dynamiq/cli/commands/context/#dynamiq.cli.commands.context.with_api_and_settings","title":"<code>with_api_and_settings(fn)</code>","text":"<p>Decorator to inject <code>api</code> kwarg after verifying settings.</p> Source code in <code>dynamiq/cli/commands/context.py</code> <pre><code>def with_api_and_settings(fn):\n    \"\"\"Decorator to inject `api` kwarg after verifying settings.\"\"\"\n\n    @pass_dctx\n    def _wrapper(dctx: DynamiqCtx, *args, **kwargs):\n        if dctx.settings is None:\n            dctx.settings = Settings.load_settings()\n            dctx.api = ApiClient(dctx.settings)\n        return fn(*args, api=dctx.api, settings=dctx.settings, **kwargs)\n\n    return _wrapper\n</code></pre>"},{"location":"dynamiq/cli/commands/org/","title":"Org","text":""},{"location":"dynamiq/cli/commands/project/","title":"Project","text":""},{"location":"dynamiq/cli/commands/service/","title":"Service","text":""},{"location":"dynamiq/cli/commands/utils/","title":"Utils","text":""},{"location":"dynamiq/clients/base/","title":"Base","text":""},{"location":"dynamiq/clients/base/#dynamiq.clients.base.BaseTracingClient","title":"<code>BaseTracingClient</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for tracing clients.</p> Source code in <code>dynamiq/clients/base.py</code> <pre><code>class BaseTracingClient(abc.ABC):\n    \"\"\"Abstract base class for tracing clients.\"\"\"\n\n    @abc.abstractmethod\n    def trace(self, runs: list[\"Run\"]) -&gt; None:\n        \"\"\"Trace the given runs.\n\n        Args:\n            runs (list[\"Run\"]): List of runs to trace.\n\n        Raises:\n            NotImplementedError: If not implemented.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/clients/base/#dynamiq.clients.base.BaseTracingClient.trace","title":"<code>trace(runs)</code>  <code>abstractmethod</code>","text":"<p>Trace the given runs.</p> <p>Parameters:</p> Name Type Description Default <code>runs</code> <code>list[Run]</code> <p>List of runs to trace.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented.</p> Source code in <code>dynamiq/clients/base.py</code> <pre><code>@abc.abstractmethod\ndef trace(self, runs: list[\"Run\"]) -&gt; None:\n    \"\"\"Trace the given runs.\n\n    Args:\n        runs (list[\"Run\"]): List of runs to trace.\n\n    Raises:\n        NotImplementedError: If not implemented.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/clients/dynamiq/","title":"Dynamiq","text":""},{"location":"dynamiq/clients/dynamiq/#dynamiq.clients.dynamiq.DynamiqTracingClient","title":"<code>DynamiqTracingClient</code>","text":"<p>               Bases: <code>BaseTracingClient</code></p> Source code in <code>dynamiq/clients/dynamiq.py</code> <pre><code>class DynamiqTracingClient(BaseTracingClient):\n\n    def __init__(self, base_url: str | None = None, access_key: str | None = None, timeout: float = 60.0):\n        self.base_url = base_url or DYNAMIQ_BASE_URL\n        self.access_key = access_key or get_env_var(\"DYNAMIQ_ACCESS_KEY\") or get_env_var(\"DYNAMIQ_SERVICE_TOKEN\")\n        if self.access_key is None:\n            raise ValueError(\"No API key provided\")\n        self.timeout = timeout\n\n    def _send_traces_sync(self, runs: list[\"Run\"]) -&gt; None:\n        \"\"\"Synchronous method to send traces using requests\"\"\"\n        try:\n            trace_data = orjson.dumps(\n                {\"runs\": [run.to_dict() for run in runs]},\n                default=orjson_encode,\n                option=orjson.OPT_NON_STR_KEYS,\n            )\n            response = requests.post(  # nosec\n                urljoin(self.base_url, \"/v1/traces\"),\n                data=trace_data,\n                headers={\n                    \"Content-Type\": \"application/json\",\n                    \"Authorization\": f\"Bearer {self.access_key}\",\n                },\n                timeout=self.timeout,\n            )\n            response.raise_for_status()\n        except Exception as e:\n            logger.error(f\"Failed to send traces (sync). Error: {e}\")\n\n    async def request(self, method: str, url_path: URLTypes, **kwargs: Any) -&gt; Response:\n        logger.debug(f'[{self.__class__.__name__}] REQ \"{method} {url_path}\". Kwargs: {kwargs}')\n        url = f\"{self.base_url}/{str(url_path).lstrip('/')}\" if self.base_url else str(url_path).lstrip(\"/\")\n        try:\n            async with httpx.AsyncClient() as client:  # nosec B113\n                response = await client.request(method, url=url, timeout=self.timeout, **kwargs)\n        except (httpx.TimeoutException, httpx.NetworkError) as e:\n            raise HttpConnectionError(e) from e\n\n        try:\n            response.raise_for_status()\n        except httpx.HTTPError as e:\n            if httpx.codes.is_client_error(response.status_code):\n                raise HttpClientError(e, response) from e\n            else:\n                raise HttpServerError(e, response) from e\n\n        return response\n\n    async def _send_traces_async(self, runs: list[\"Run\"]) -&gt; None:\n        \"\"\"Async method to send traces using httpx\"\"\"\n        try:\n            trace_data = orjson.dumps(\n                {\"runs\": [run.to_dict() for run in runs]},\n                default=orjson_encode,\n                option=orjson.OPT_NON_STR_KEYS,\n            )\n            await self.request(\n                method=\"POST\",\n                url_path=\"/v1/traces\",\n                content=trace_data,\n                headers={\n                    \"Content-Type\": \"application/json\",\n                    \"Authorization\": f\"Bearer {self.access_key}\",\n                },\n            )\n        except Exception as e:\n            logger.error(f\"Failed to send traces (async). Error: {e}\")\n\n    def trace(self, runs: list[\"Run\"]) -&gt; None:\n        \"\"\"Sync method required by BaseTracingClient interface\"\"\"\n        if not runs:\n            return\n\n        try:\n            if is_called_from_async_context():\n                loop = asyncio.get_running_loop()\n                loop.create_task(self._send_traces_async(runs))\n            else:\n                self._send_traces_sync(runs)\n        except Exception as e:\n            logger.error(f\"Failed to send traces. Error: {e}\")\n</code></pre>"},{"location":"dynamiq/clients/dynamiq/#dynamiq.clients.dynamiq.DynamiqTracingClient.trace","title":"<code>trace(runs)</code>","text":"<p>Sync method required by BaseTracingClient interface</p> Source code in <code>dynamiq/clients/dynamiq.py</code> <pre><code>def trace(self, runs: list[\"Run\"]) -&gt; None:\n    \"\"\"Sync method required by BaseTracingClient interface\"\"\"\n    if not runs:\n        return\n\n    try:\n        if is_called_from_async_context():\n            loop = asyncio.get_running_loop()\n            loop.create_task(self._send_traces_async(runs))\n        else:\n            self._send_traces_sync(runs)\n    except Exception as e:\n        logger.error(f\"Failed to send traces. Error: {e}\")\n</code></pre>"},{"location":"dynamiq/components/serializers/","title":"Serializers","text":""},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.BaseSerializer","title":"<code>BaseSerializer</code>","text":"<p>Base class for serializers providing interface for dumps and loads methods.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>class BaseSerializer:\n    \"\"\"\n    Base class for serializers providing interface for dumps and loads methods.\n    \"\"\"\n\n    def dumps(self, value: Any) -&gt; str:\n        \"\"\"\n        Serialize the given value to a string.\n\n        Args:\n            value (Any): The value to be serialized.\n\n        Returns:\n            str: The serialized string representation of the value.\n\n        Raises:\n            NotImplementedError: This method should be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError\n\n    def loads(self, value: Any) -&gt; Any:\n        \"\"\"\n        Deserialize the given value from a string.\n\n        Args:\n            value (Any): The serialized string to be deserialized.\n\n        Returns:\n            Any: The deserialized value.\n\n        Raises:\n            NotImplementedError: This method should be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.BaseSerializer.dumps","title":"<code>dumps(value)</code>","text":"<p>Serialize the given value to a string.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to be serialized.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The serialized string representation of the value.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method should be implemented by subclasses.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>def dumps(self, value: Any) -&gt; str:\n    \"\"\"\n    Serialize the given value to a string.\n\n    Args:\n        value (Any): The value to be serialized.\n\n    Returns:\n        str: The serialized string representation of the value.\n\n    Raises:\n        NotImplementedError: This method should be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.BaseSerializer.loads","title":"<code>loads(value)</code>","text":"<p>Deserialize the given value from a string.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The serialized string to be deserialized.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The deserialized value.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method should be implemented by subclasses.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>def loads(self, value: Any) -&gt; Any:\n    \"\"\"\n    Deserialize the given value from a string.\n\n    Args:\n        value (Any): The serialized string to be deserialized.\n\n    Returns:\n        Any: The deserialized value.\n\n    Raises:\n        NotImplementedError: This method should be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.JsonPickleSerializer","title":"<code>JsonPickleSerializer</code>","text":"<p>               Bases: <code>BaseSerializer</code></p> <p>Serializer that uses jsonpickle to convert complex Python objects to and from JSON format.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>class JsonPickleSerializer(BaseSerializer):\n    \"\"\"\n    Serializer that uses jsonpickle to convert complex Python objects to and from JSON format.\n    \"\"\"\n\n    def dumps(self, value: Any) -&gt; str:\n        \"\"\"\n        Serialize the given value to a JSON string using jsonpickle.\n\n        Args:\n            value (Any): The value to be serialized.\n\n        Returns:\n            str: The JSON string representation of the value.\n        \"\"\"\n        import jsonpickle\n\n        return jsonpickle.encode(value)\n\n    def loads(self, value: str) -&gt; Any:\n        \"\"\"\n        Deserialize the given JSON string to a Python object using jsonpickle.\n\n        Args:\n            value (str): The JSON string to be deserialized.\n\n        Returns:\n            Any: The deserialized Python object.\n        \"\"\"\n        import jsonpickle\n\n        return jsonpickle.decode(value)  # nosec\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.JsonPickleSerializer.dumps","title":"<code>dumps(value)</code>","text":"<p>Serialize the given value to a JSON string using jsonpickle.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to be serialized.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The JSON string representation of the value.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>def dumps(self, value: Any) -&gt; str:\n    \"\"\"\n    Serialize the given value to a JSON string using jsonpickle.\n\n    Args:\n        value (Any): The value to be serialized.\n\n    Returns:\n        str: The JSON string representation of the value.\n    \"\"\"\n    import jsonpickle\n\n    return jsonpickle.encode(value)\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.JsonPickleSerializer.loads","title":"<code>loads(value)</code>","text":"<p>Deserialize the given JSON string to a Python object using jsonpickle.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The JSON string to be deserialized.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The deserialized Python object.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>def loads(self, value: str) -&gt; Any:\n    \"\"\"\n    Deserialize the given JSON string to a Python object using jsonpickle.\n\n    Args:\n        value (str): The JSON string to be deserialized.\n\n    Returns:\n        Any: The deserialized Python object.\n    \"\"\"\n    import jsonpickle\n\n    return jsonpickle.decode(value)  # nosec\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.JsonSerializer","title":"<code>JsonSerializer</code>","text":"<p>               Bases: <code>BaseSerializer</code></p> <p>Serializer that converts values to and from JSON format.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>class JsonSerializer(BaseSerializer):\n    \"\"\"\n    Serializer that converts values to and from JSON format.\n    \"\"\"\n\n    def dumps(self, value: Any) -&gt; str:\n        \"\"\"\n        Serialize the given value to a JSON string.\n\n        Args:\n            value (Any): The value to be serialized to JSON.\n\n        Returns:\n            str: The JSON string representation of the value.\n        \"\"\"\n        return json.dumps(value, cls=JsonWorkflowEncoder)\n\n    def loads(self, value: str | None) -&gt; Any:\n        \"\"\"\n        Deserialize the given JSON string to a Python object.\n\n        Args:\n            value (str | None): The JSON string to be deserialized, or None.\n\n        Returns:\n            Any: The deserialized Python object, or None if the input is None.\n        \"\"\"\n        if value is None:\n            return None\n        return json.loads(value)\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.JsonSerializer.dumps","title":"<code>dumps(value)</code>","text":"<p>Serialize the given value to a JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to be serialized to JSON.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The JSON string representation of the value.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>def dumps(self, value: Any) -&gt; str:\n    \"\"\"\n    Serialize the given value to a JSON string.\n\n    Args:\n        value (Any): The value to be serialized to JSON.\n\n    Returns:\n        str: The JSON string representation of the value.\n    \"\"\"\n    return json.dumps(value, cls=JsonWorkflowEncoder)\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.JsonSerializer.loads","title":"<code>loads(value)</code>","text":"<p>Deserialize the given JSON string to a Python object.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str | None</code> <p>The JSON string to be deserialized, or None.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The deserialized Python object, or None if the input is None.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>def loads(self, value: str | None) -&gt; Any:\n    \"\"\"\n    Deserialize the given JSON string to a Python object.\n\n    Args:\n        value (str | None): The JSON string to be deserialized, or None.\n\n    Returns:\n        Any: The deserialized Python object, or None if the input is None.\n    \"\"\"\n    if value is None:\n        return None\n    return json.loads(value)\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.StringSerializer","title":"<code>StringSerializer</code>","text":"<p>               Bases: <code>BaseSerializer</code></p> <p>Serializer that converts values to and from strings.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>class StringSerializer(BaseSerializer):\n    \"\"\"\n    Serializer that converts values to and from strings.\n    \"\"\"\n\n    def dumps(self, value: Any) -&gt; str:\n        \"\"\"\n        Convert the given value to a string.\n\n        Args:\n            value (Any): The value to be converted to a string.\n\n        Returns:\n            str: The string representation of the value.\n        \"\"\"\n        return str(value)\n\n    def loads(self, value: Any) -&gt; Any:\n        \"\"\"\n        Return the input value as is, since it's already a string.\n\n        Args:\n            value (Any): The value to be deserialized (expected to be a string).\n\n        Returns:\n            Any: The input value, unchanged.\n        \"\"\"\n        return value\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.StringSerializer.dumps","title":"<code>dumps(value)</code>","text":"<p>Convert the given value to a string.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to be converted to a string.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The string representation of the value.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>def dumps(self, value: Any) -&gt; str:\n    \"\"\"\n    Convert the given value to a string.\n\n    Args:\n        value (Any): The value to be converted to a string.\n\n    Returns:\n        str: The string representation of the value.\n    \"\"\"\n    return str(value)\n</code></pre>"},{"location":"dynamiq/components/serializers/#dynamiq.components.serializers.StringSerializer.loads","title":"<code>loads(value)</code>","text":"<p>Return the input value as is, since it's already a string.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to be deserialized (expected to be a string).</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The input value, unchanged.</p> Source code in <code>dynamiq/components/serializers.py</code> <pre><code>def loads(self, value: Any) -&gt; Any:\n    \"\"\"\n    Return the input value as is, since it's already a string.\n\n    Args:\n        value (Any): The value to be deserialized (expected to be a string).\n\n    Returns:\n        Any: The input value, unchanged.\n    \"\"\"\n    return value\n</code></pre>"},{"location":"dynamiq/components/converters/base/","title":"Base","text":""},{"location":"dynamiq/components/converters/base/#dynamiq.components.converters.base.BaseConverter","title":"<code>BaseConverter</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/components/converters/base.py</code> <pre><code>class BaseConverter(BaseModel):\n    document_creation_mode: DocumentCreationMode = DocumentCreationMode.ONE_DOC_PER_FILE\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(**kwargs)\n\n    def run(\n        self,\n        file_paths: list[str] | list[os.PathLike] | None = None,\n        files: list[BytesIO] | None = None,\n        metadata: dict[str, Any] | list[dict[str, Any]] | None = None,\n    ) -&gt; dict[str, list[Any]]:\n        \"\"\"\n        Converts files to Documents.\n\n        Processes file paths or BytesIO objects into Documents. Handles directories and files.\n\n        Args:\n            file_paths: List of file or directory paths to convert.\n            files: List of BytesIO objects to convert.\n            metadata: Metadata for documents. Can be a dict for all or a list of dicts for each.\n\n        Returns:\n            Dict with 'documents' key containing a list of created Documents.\n\n        Raises:\n            ValueError: If neither paths nor files provided, or if metadata is a list with\n                directory paths, or if files cannot be processed properly.\n            FileNotFoundError: If any file path does not exist.\n            IOError: If any file cannot be read.\n            Exception: Any other exception that may occur during processing.\n        \"\"\"\n        if file_paths is None and files is None:\n            raise ValueError(\"No input provided. Please provide either file_paths or files.\")\n\n        documents = []\n\n        if file_paths is not None:\n            paths_obj = [Path(path) for path in file_paths]\n            filepaths = [path for path in paths_obj if path.is_file()]\n            filepaths_in_directories = [\n                filepath for path in paths_obj if path.is_dir() for filepath in path.glob(\"*.*\") if filepath.is_file()\n            ]\n            if filepaths_in_directories and isinstance(metadata, list):\n                raise ValueError(\n                    \"If providing directories in the `paths` parameter, \"\n                    \"`metadata` can only be a dictionary (metadata applied to every file), \"\n                    \"and not a list. To specify different metadata for each file, \"\n                    \"provide an explicit list of direct paths instead.\"\n                )\n\n            all_filepaths = set(filepaths + filepaths_in_directories)\n\n            if not all_filepaths:\n                raise FileNotFoundError(f\"No files found in the provided paths: {file_paths}\")\n\n            meta_list = self._normalize_metadata(metadata, len(all_filepaths))\n\n            for filepath, meta in zip(all_filepaths, meta_list):\n                documents.extend(self._process_file(filepath, meta))\n\n        if files is not None:\n            meta_list = self._normalize_metadata(metadata, len(files))\n            for file, meta in zip(files, meta_list):\n                documents.extend(self._process_file(file, meta))\n\n        if len(documents) == 0 and (file_paths is not None or files is not None):\n            raise ValueError(\n                \"No documents were created from the provided inputs. Please check your files and try again.\"\n            )\n\n        return {\"documents\": documents}\n\n    @staticmethod\n    def _normalize_metadata(\n        metadata: dict[str, Any] | list[dict[str, Any]] | None, sources_count: int\n    ) -&gt; list[dict[str, Any]]:\n        \"\"\"Normalizes metadata input for a converter.\n\n        Given all possible values of the metadata input for a converter (None, dictionary, or list of\n        dicts), ensures to return a list of dictionaries of the correct length for the converter to use.\n\n        Args:\n            metadata: The meta input of the converter, as-is. Can be None, a dictionary, or a list of\n                dictionaries.\n            sources_count: The number of sources the converter received.\n\n        Returns:\n            A list of dictionaries of the same length as the sources list.\n\n        Raises:\n            ValueError: If metadata is not None, a dictionary, or a list of dictionaries, or if the length\n                of the metadata list doesn't match the number of sources.\n        \"\"\"\n        if metadata is None:\n            return [{} for _ in range(sources_count)]\n        if isinstance(metadata, dict):\n            return [copy.deepcopy(metadata) for _ in range(sources_count)]\n        if isinstance(metadata, list):\n            metadata_count = len(metadata)\n            if sources_count != metadata_count:\n                raise ValueError(\n                    f\"The length of the metadata list [{metadata_count}] \"\n                    f\"must match the number of sources [{sources_count}].\"\n                )\n            return metadata\n        raise ValueError(\"metadata must be either None, a dictionary or a list of dictionaries.\")\n\n    @abstractmethod\n    def _create_documents(\n        self,\n        filepath: str,\n        elements: Any,\n        document_creation_mode: DocumentCreationMode,\n        metadata: dict[str, Any],\n        **kwargs,\n    ) -&gt; list[Document]:\n        pass\n\n    @abstractmethod\n    def _process_file(self, file: Path | BytesIO, metadata: dict[str, Any]) -&gt; list[Any]:\n        pass\n</code></pre>"},{"location":"dynamiq/components/converters/base/#dynamiq.components.converters.base.BaseConverter.run","title":"<code>run(file_paths=None, files=None, metadata=None)</code>","text":"<p>Converts files to Documents.</p> <p>Processes file paths or BytesIO objects into Documents. Handles directories and files.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>list[str] | list[PathLike] | None</code> <p>List of file or directory paths to convert.</p> <code>None</code> <code>files</code> <code>list[BytesIO] | None</code> <p>List of BytesIO objects to convert.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | list[dict[str, Any]] | None</code> <p>Metadata for documents. Can be a dict for all or a list of dicts for each.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, list[Any]]</code> <p>Dict with 'documents' key containing a list of created Documents.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither paths nor files provided, or if metadata is a list with directory paths, or if files cannot be processed properly.</p> <code>FileNotFoundError</code> <p>If any file path does not exist.</p> <code>IOError</code> <p>If any file cannot be read.</p> <code>Exception</code> <p>Any other exception that may occur during processing.</p> Source code in <code>dynamiq/components/converters/base.py</code> <pre><code>def run(\n    self,\n    file_paths: list[str] | list[os.PathLike] | None = None,\n    files: list[BytesIO] | None = None,\n    metadata: dict[str, Any] | list[dict[str, Any]] | None = None,\n) -&gt; dict[str, list[Any]]:\n    \"\"\"\n    Converts files to Documents.\n\n    Processes file paths or BytesIO objects into Documents. Handles directories and files.\n\n    Args:\n        file_paths: List of file or directory paths to convert.\n        files: List of BytesIO objects to convert.\n        metadata: Metadata for documents. Can be a dict for all or a list of dicts for each.\n\n    Returns:\n        Dict with 'documents' key containing a list of created Documents.\n\n    Raises:\n        ValueError: If neither paths nor files provided, or if metadata is a list with\n            directory paths, or if files cannot be processed properly.\n        FileNotFoundError: If any file path does not exist.\n        IOError: If any file cannot be read.\n        Exception: Any other exception that may occur during processing.\n    \"\"\"\n    if file_paths is None and files is None:\n        raise ValueError(\"No input provided. Please provide either file_paths or files.\")\n\n    documents = []\n\n    if file_paths is not None:\n        paths_obj = [Path(path) for path in file_paths]\n        filepaths = [path for path in paths_obj if path.is_file()]\n        filepaths_in_directories = [\n            filepath for path in paths_obj if path.is_dir() for filepath in path.glob(\"*.*\") if filepath.is_file()\n        ]\n        if filepaths_in_directories and isinstance(metadata, list):\n            raise ValueError(\n                \"If providing directories in the `paths` parameter, \"\n                \"`metadata` can only be a dictionary (metadata applied to every file), \"\n                \"and not a list. To specify different metadata for each file, \"\n                \"provide an explicit list of direct paths instead.\"\n            )\n\n        all_filepaths = set(filepaths + filepaths_in_directories)\n\n        if not all_filepaths:\n            raise FileNotFoundError(f\"No files found in the provided paths: {file_paths}\")\n\n        meta_list = self._normalize_metadata(metadata, len(all_filepaths))\n\n        for filepath, meta in zip(all_filepaths, meta_list):\n            documents.extend(self._process_file(filepath, meta))\n\n    if files is not None:\n        meta_list = self._normalize_metadata(metadata, len(files))\n        for file, meta in zip(files, meta_list):\n            documents.extend(self._process_file(file, meta))\n\n    if len(documents) == 0 and (file_paths is not None or files is not None):\n        raise ValueError(\n            \"No documents were created from the provided inputs. Please check your files and try again.\"\n        )\n\n    return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/components/converters/docx/","title":"Docx","text":""},{"location":"dynamiq/components/converters/docx/#dynamiq.components.converters.docx.DOCXConverter","title":"<code>DOCXConverter</code>","text":"<p>               Bases: <code>BaseConverter</code></p> <p>A component for converting DOCX files to Documents using the python-docx library.</p> <p>Initializes the object with the configuration for converting documents using python-docx.</p> <p>Parameters:</p> Name Type Description Default <code>document_creation_mode</code> <code>Literal['one-doc-per-file', 'one-doc-per-page']</code> <p>Determines how to create Documents from the elements of the Word document. Options are: - <code>\"one-doc-per-file\"</code>: Creates one Document per file.     All elements are concatenated into one text field. - <code>\"one-doc-per-page\"</code>: Creates one Document per page.     All elements on a page are concatenated into one text field. Defaults to <code>\"one-doc-per-file\"</code>.</p> required Usage example <pre><code>from dynamiq.components.converters.docx import DOCXConverter\n\nconverter = DOCXConverter()\ndocuments = converter.run(paths=[\"a/file/path.docx\", \"a/directory/path\"])[\"documents\"]\n</code></pre> Source code in <code>dynamiq/components/converters/docx.py</code> <pre><code>class DOCXConverter(BaseConverter):\n    \"\"\"\n    A component for converting DOCX files to Documents using the python-docx library.\n\n    Initializes the object with the configuration for converting documents using\n    python-docx.\n\n    Args:\n        document_creation_mode (Literal[\"one-doc-per-file\", \"one-doc-per-page\"], optional):\n            Determines how to create Documents from the elements of the Word document. Options are:\n            - `\"one-doc-per-file\"`: Creates one Document per file.\n                All elements are concatenated into one text field.\n            - `\"one-doc-per-page\"`: Creates one Document per page.\n                All elements on a page are concatenated into one text field.\n            Defaults to `\"one-doc-per-file\"`.\n\n    Usage example:\n        ```python\n        from dynamiq.components.converters.docx import DOCXConverter\n\n        converter = DOCXConverter()\n        documents = converter.run(paths=[\"a/file/path.docx\", \"a/directory/path\"])[\"documents\"]\n        ```\n    \"\"\"\n\n    document_creation_mode: Literal[DocumentCreationMode.ONE_DOC_PER_FILE, DocumentCreationMode.ONE_DOC_PER_PAGE] = (\n        DocumentCreationMode.ONE_DOC_PER_FILE\n    )\n\n    xml_key: str = \"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\"\n    xml_namespaces: dict[str, str] = {\n        \"w\": \"http://schemas.microsoft.com/office/word/2003/wordml\",\n        \"a\": \"http://schemas.openxmlformats.org/drawingml/2006/main\",\n        \"r\": \"http://schemas.openxmlformats.org/officeDocument/2006/relationships\",\n    }\n    image_placeholder: str = \"&lt;!-- image --&gt;\"\n    blip_tag: str = \"{http://schemas.openxmlformats.org/drawingml/2006/main}blip\"\n\n    def _process_file(self, file: Path | BytesIO, metadata: dict[str, Any]) -&gt; list[Any]:\n        \"\"\"\n        Process a single Word document and create documents.\n\n        Args:\n            file (Union[Path, BytesIO]): The file to process.\n            metadata (Dict[str, Any]): Metadata to attach to the documents.\n\n        Returns:\n            List[Any]: A list of created documents.\n\n        Raises:\n            TypeError: If the file argument is neither a Path nor a BytesIO object.\n        \"\"\"\n        if isinstance(file, Path):\n            with open(file, \"rb\") as upload_file:\n                file_content = BytesIO(upload_file.read())\n                file_path = upload_file.name\n        elif isinstance(file, BytesIO):\n            file_path = get_filename_for_bytesio(file)\n            file_content = file\n        else:\n            raise TypeError(\"Expected a Path object or a BytesIO object.\")\n\n        file_content.seek(0)\n        elements = DocxDocument(file_content)\n        return self._create_documents(\n            filepath=file_path,\n            elements=elements,\n            document_creation_mode=self.document_creation_mode,\n            metadata=metadata,\n        )\n\n    def _create_documents(\n        self,\n        filepath: str,\n        elements: DocxDocument,\n        document_creation_mode: DocumentCreationMode,\n        metadata: dict[str, Any],\n        **kwargs,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Create Documents from the elements of the Word document.\n        \"\"\"\n        docs = []\n        if document_creation_mode == DocumentCreationMode.ONE_DOC_PER_FILE:\n            text_content = []\n\n            for element in elements.element.body:\n                tag_name = element.tag.split(\"}\", 1)[-1] if \"}\" in element.tag else element.tag\n\n                # Check for inline images\n                contains_blip = any(child.tag == self.blip_tag for child in element.iter())\n\n                if element.tag.endswith(\"p\"):\n                    text = self._process_paragraph(element, elements)\n                    if text.strip():\n                        text_content.append(text)\n                elif element.tag.endswith(\"tbl\"):\n                    text = self._process_table(element, elements)\n                    if text.strip():\n                        text_content.append(text)\n                elif contains_blip:\n                    text_content.append(self.image_placeholder)\n                elif tag_name in [\"sdt\"]:\n                    sdt_content = element.find(\".//w:sdtContent\", namespaces=self.xml_namespaces)\n                    if sdt_content is not None:\n                        paragraphs = sdt_content.findall(\".//w:p\", namespaces=self.xml_namespaces)\n                        for p in paragraphs:\n                            text = self._process_paragraph(p, elements)\n                            if text.strip():\n                                text_content.append(text)\n\n            full_text = \"\\n\\n\".join(text_content)\n\n            metadata = copy.deepcopy(metadata)\n            metadata[\"file_path\"] = filepath\n            docs = [Document(content=full_text, metadata=metadata)]\n\n        elif document_creation_mode == DocumentCreationMode.ONE_DOC_PER_PAGE:\n            sections = self._split_into_sections(elements)\n            metadata = copy.deepcopy(metadata)\n            metadata[\"file_path\"] = filepath\n\n            for idx, section_content in enumerate(sections, start=1):\n                section_metadata = copy.deepcopy(metadata)\n                section_metadata[\"page_number\"] = idx\n                docs.append(Document(content=section_content, metadata=section_metadata))\n\n        return docs\n\n    def _process_paragraph(self, paragraph_element, docx_obj) -&gt; str:\n        \"\"\"\n        Process a paragraph element with formatting and hyperlinks.\n        \"\"\"\n        paragraph = Paragraph(paragraph_element, docx_obj)\n        text = paragraph.text\n\n        paragraph_elements = self._get_paragraph_elements(paragraph)\n        is_list_item, list_marker, list_level = self._check_for_list_item(paragraph)\n        is_header, header_level = self._check_for_header(paragraph)\n\n        formatted_text = \"\"\n\n        if is_header:\n            header_prefix = \"#\" * header_level\n            formatted_text = f\"{header_prefix} {text}\"\n        elif is_list_item:\n            indent = \"  \" * (list_level - 1) if list_level &gt; 1 else \"\"\n            formatted_text = f\"{indent}{list_marker} {text}\"\n        else:\n            formatted_parts = []\n            for txt, format_info, hyperlink in paragraph_elements:\n                if not txt.strip():\n                    continue\n\n                if format_info:\n                    if format_info.get(\"bold\", False):\n                        txt = f\"**{txt}**\"\n                    if format_info.get(\"italic\", False):\n                        txt = f\"*{txt}*\"\n                    if format_info.get(\"underline\", False):\n                        txt = f\"_{txt}_\"\n\n                if hyperlink:\n                    txt = f\"[{txt}]({hyperlink})\"\n\n                formatted_parts.append(txt)\n\n            formatted_text = \" \".join(formatted_parts)\n\n        return formatted_text\n\n    def _process_table(self, table_element, docx_obj) -&gt; str:\n        \"\"\"\n        Process a table element with enhanced features like cell spanning and formatting.\n        \"\"\"\n        table = Table(table_element, docx_obj)\n\n        # Check for single-cell tables\n        if len(table.rows) == 1 and len(table.columns) == 1:\n            cell_text = table.rows[0].cells[0].text\n            if cell_text.strip():\n                return cell_text\n\n        table_rows = []\n\n        if table.rows:\n            header_cells = []\n            for cell in table.rows[0].cells:\n                header_cells.append(cell.text.strip() or \"\")\n            table_rows.append(\"| \" + \" | \".join(header_cells) + \" |\")\n            table_rows.append(\"| \" + \" | \".join([\"---\"] * len(header_cells)) + \" |\")\n\n        cell_set = set()\n        for row_idx, row in enumerate(table.rows):\n            # Skip the header row\n            if row_idx == 0:\n                continue\n\n            row_cells = []\n            for cell in row.cells:\n                if cell._tc in cell_set:\n                    continue\n                cell_set.add(cell._tc)\n\n                cell_text = cell.text.strip() or \"\"\n                row_cells.append(cell_text)\n\n            if row_cells:\n                table_rows.append(\"| \" + \" | \".join(row_cells) + \" |\")\n\n        return \"\\n\".join(table_rows)\n\n    def _get_paragraph_elements(self, paragraph):\n        \"\"\"\n        Extract paragraph elements (with the formatting and hyperlinks).\n        \"\"\"\n        if paragraph.text.strip() == \"\":\n            return [(\"\", None, None)]\n\n        paragraph_elements = []\n\n        for content in paragraph.iter_inner_content():\n            if isinstance(content, Hyperlink):\n                text = content.text\n                hyperlink = content.address if hasattr(content, \"address\") else None\n                format_info = self._get_format_from_run(content.runs[0] if content.runs else None)\n                if text.strip():\n                    paragraph_elements.append((text, format_info, hyperlink))\n            elif isinstance(content, Run):\n                text = content.text\n                format_info = self._get_format_from_run(content)\n                if text.strip():\n                    paragraph_elements.append((text, format_info, None))\n\n        if not paragraph_elements and paragraph.text.strip():\n            paragraph_elements.append((paragraph.text.strip(), None, None))\n\n        return paragraph_elements\n\n    def _get_format_from_run(self, run):\n        \"\"\"\n        Extract formatting information from a run.\n        \"\"\"\n        if not run:\n            return None\n\n        format_info = {}\n        if hasattr(run, \"bold\") and run.bold:\n            format_info[\"bold\"] = True\n        if hasattr(run, \"italic\") and run.italic:\n            format_info[\"italic\"] = True\n        if hasattr(run, \"underline\") and run.underline:\n            format_info[\"underline\"] = True\n\n        return format_info if format_info else None\n\n    def _check_for_list_item(self, paragraph):\n        \"\"\"\n        Check if a paragraph is a list item and return relevant information.\n        \"\"\"\n        numbering_properties = paragraph._element.find(\".//w:numPr\", namespaces=paragraph._element.nsmap)\n        if numbering_properties is not None:\n            numbering_id_elem = numbering_properties.find(\"w:numId\", namespaces=paragraph._element.nsmap)\n            indexing_level_elem = numbering_properties.find(\"w:ilvl\", namespaces=paragraph._element.nsmap)\n\n            numbering_id = numbering_id_elem.get(self.xml_key) if numbering_id_elem is not None else None\n            indexing_level = indexing_level_elem.get(self.xml_key) if indexing_level_elem is not None else None\n\n            if numbering_id and numbering_id != \"0\":\n                level = int(indexing_level) + 1 if indexing_level else 1\n                # Check if the paragraph is a numbered list item or a bullet list item\n                is_numbered = \"Number\" in paragraph.style.name if paragraph.style and paragraph.style.name else False\n                marker = f\"{level}.\" if is_numbered else \"\u2022\"\n                return True, marker, level\n\n        return False, \"\", 0\n\n    def _check_for_header(self, paragraph):\n        \"\"\"\n        Check if a paragraph is a header and return the level.\n        \"\"\"\n        if not paragraph.style:\n            return False, 0\n\n        style_id = paragraph.style.name.lower() if paragraph.style.name else \"\"\n\n        heading_string = \"heading\"\n        heading_pattern = r\"heading\\s*(\\d+)\"\n\n        if heading_string in style_id:\n            match = re.search(heading_pattern, style_id)\n            if match:\n                level = int(match.group(1))\n                return True, level\n\n        return False, 0\n\n    def _split_into_sections(self, doc: DocxDocument) -&gt; list[str]:\n        \"\"\"\n        Split the document into sections based on section breaks.\n        \"\"\"\n        sections = []\n        current_section = []\n\n        for element in doc.element.body:\n            if element.tag.endswith(\"sectPr\"):\n                if current_section:\n                    sections.append(\"\\n\\n\".join(current_section))\n                    current_section = []\n            elif element.tag.endswith(\"p\"):\n                text = self._process_paragraph(element, doc)\n                if text.strip():\n                    current_section.append(text)\n            elif element.tag.endswith(\"tbl\"):\n                text = self._process_table(element, doc)\n                if text.strip():\n                    current_section.append(text)\n\n        if current_section:\n            sections.append(\"\\n\\n\".join(current_section))\n        if not sections:\n            return [\"\"]\n\n        return sections\n</code></pre>"},{"location":"dynamiq/components/converters/html/","title":"Html","text":""},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.HTMLConverter","title":"<code>HTMLConverter</code>","text":"<p>               Bases: <code>BaseConverter</code></p> <p>A component for converting HTML files to Documents using lxml.</p> <p>Initializes the object with the configuration for converting documents using lxml HTML parser.</p> <p>Parameters:</p> Name Type Description Default <code>document_creation_mode</code> <code>Literal['one-doc-per-file']</code> <p>Determines how to create Documents from the HTML content. Currently only supports: - <code>\"one-doc-per-file\"</code>: Creates one Document per file.     All content is converted to markdown format. Defaults to <code>\"one-doc-per-file\"</code>.</p> required Usage example <pre><code>from dynamiq.components.converters.html import HTMLConverter\n\nconverter = HTMLConverter()\ndocuments = converter.run(paths=[\"a/file/path.html\", \"a/directory/path\"])[\"documents\"]\n</code></pre> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>class HTMLConverter(BaseConverter):\n    \"\"\"\n    A component for converting HTML files to Documents using lxml.\n\n    Initializes the object with the configuration for converting documents using\n    lxml HTML parser.\n\n    Args:\n        document_creation_mode (Literal[\"one-doc-per-file\"], optional):\n            Determines how to create Documents from the HTML content. Currently only supports:\n            - `\"one-doc-per-file\"`: Creates one Document per file.\n                All content is converted to markdown format.\n            Defaults to `\"one-doc-per-file\"`.\n\n    Usage example:\n        ```python\n        from dynamiq.components.converters.html import HTMLConverter\n\n        converter = HTMLConverter()\n        documents = converter.run(paths=[\"a/file/path.html\", \"a/directory/path\"])[\"documents\"]\n        ```\n    \"\"\"\n\n    document_creation_mode: Literal[DocumentCreationMode.ONE_DOC_PER_FILE] = DocumentCreationMode.ONE_DOC_PER_FILE\n\n    def _process_file(self, file: Path | BytesIO, metadata: dict[str, Any]) -&gt; list[Any]:\n        \"\"\"\n        Process a file and return a list of Documents.\n\n        Args:\n            file: Path to a file or BytesIO object\n            metadata: Metadata to attach to the documents\n\n        Returns:\n            List of Documents\n        \"\"\"\n        # Get the file path or name for BytesIO\n        if isinstance(file, BytesIO):\n            filepath = get_filename_for_bytesio(file)\n        else:\n            filepath = str(file)\n\n        # Read the file content\n        if isinstance(file, BytesIO):\n            file.seek(0)\n            html_content = file.read().decode(\"utf-8\")\n        else:\n            with open(file, encoding=\"utf-8\") as f:\n                html_content = f.read()\n\n        # Parse the HTML content\n        elements = self._parse_html_content(html_content)\n\n        # Create documents from the HTML elements\n        return self._create_documents(\n            filepath=filepath,\n            elements=elements,\n            document_creation_mode=self.document_creation_mode,\n            metadata=metadata,\n        )\n\n    def _parse_html_content(self, html_content: str) -&gt; lxml_html.HtmlElement:\n        \"\"\"\n        Parse HTML content using lxml.\n\n        Args:\n            html_content: HTML content to parse\n\n        Returns:\n            lxml HTML element\n        \"\"\"\n        try:\n            return lxml_html.fromstring(html_content)\n        except etree.ParserError:\n            # Handle malformed HTML by cleaning it first\n            html_content = self._clean_html(html_content)\n            return lxml_html.fromstring(html_content)\n\n    @staticmethod\n    def _clean_html(html_content: str) -&gt; str:\n        \"\"\"\n        Clean malformed HTML.\n\n        Args:\n            html_content: HTML content to clean\n\n        Returns:\n            Cleaned HTML content\n        \"\"\"\n        parser = html.parser.HTMLParser()\n        try:\n            return parser.unescape(html_content)\n        except AttributeError:\n            # For Python 3.9+, HTMLParser.unescape is deprecated\n            return html_module.unescape(html_content)\n\n    def _create_documents(\n        self,\n        filepath: str,\n        elements: lxml_html.HtmlElement,\n        document_creation_mode: DocumentCreationMode,\n        metadata: dict[str, Any],\n        **kwargs,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Create Documents from the HTML elements.\n        \"\"\"\n        if document_creation_mode != DocumentCreationMode.ONE_DOC_PER_FILE:\n            raise ValueError(\"HTMLConverter only supports one-doc-per-file mode\")\n\n        markdown_content = self._convert_to_markdown(elements)\n\n        # Clean up excessive newlines\n        markdown_content = re.sub(r\"\\n{4,}\", \"\\n\\n\", markdown_content)\n        markdown_content = markdown_content.strip()\n\n        metadata = copy.deepcopy(metadata)\n        metadata[\"file_path\"] = filepath\n\n        return [Document(content=markdown_content, metadata=metadata)]\n\n    def _convert_to_markdown(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"\n        Convert HTML element to Markdown.\n\n        Args:\n            element: lxml HTML element\n\n        Returns:\n            Markdown string\n        \"\"\"\n        markdown = MarkdownConverter()\n        return markdown.convert_element(element)\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter","title":"<code>MarkdownConverter</code>","text":"<p>Helper class to convert HTML elements to Markdown format</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>class MarkdownConverter:\n    \"\"\"Helper class to convert HTML elements to Markdown format\"\"\"\n\n    def __init__(self):\n        self.tag_handlers = {\n            \"h1\": self.handle_heading,\n            \"h2\": self.handle_heading,\n            \"h3\": self.handle_heading,\n            \"h4\": self.handle_heading,\n            \"h5\": self.handle_heading,\n            \"h6\": self.handle_heading,\n            \"p\": self.handle_paragraph,\n            \"a\": self.handle_link,\n            \"img\": self.handle_image,\n            \"strong\": self.handle_strong,\n            \"b\": self.handle_strong,\n            \"em\": self.handle_emphasis,\n            \"i\": self.handle_emphasis,\n            \"code\": self.handle_code,\n            \"pre\": self.handle_preformatted,\n            \"ul\": self.handle_unordered_list,\n            \"ol\": self.handle_ordered_list,\n            \"li\": self.handle_list_item,\n            \"br\": self.handle_linebreak,\n            \"hr\": self.handle_horizontal_rule,\n            \"table\": self.handle_table,\n            \"tr\": self.handle_table_row,\n            \"th\": self.handle_table_cell,\n            \"td\": self.handle_table_cell,\n            \"blockquote\": self.handle_blockquote,\n            \"div\": self.handle_block,\n            \"span\": self.handle_inline,\n        }\n\n        self.list_state = []\n        self.in_table = False\n        self.table_headers = []\n        self.table_rows = []\n        self.current_row = []\n\n    def convert_element(self, element: lxml_html.HtmlElement | str, parent_tag=None) -&gt; str:\n        \"\"\"Convert an HTML element to Markdown recursively\"\"\"\n        if element is None:\n            return \"\"\n\n        if isinstance(element, str) or element.tag == \"text\":\n            text = element if isinstance(element, str) else element.text_content().strip()\n            if text and parent_tag not in [\"pre\", \"code\"]:\n                text = \" \".join(text.split())\n            return text\n\n        tag = element.tag\n\n        if tag is etree.Comment or tag in [\"script\", \"style\"]:\n            return \"\"\n\n        if tag == \"html\" or tag == \"body\" or tag == \"document\":\n            return self.handle_document(element)\n\n        if tag in self.tag_handlers:\n            return self.tag_handlers[tag](element)\n\n        return self.process_children(element)\n\n    def process_children(self, element: lxml_html.HtmlElement, add_linebreaks=False) -&gt; str:\n        \"\"\"Process all children of an element and join their markdown\"\"\"\n        result = []\n\n        if element.text and element.text.strip():\n            result.append(element.text)\n\n        for child in element:\n            child_md = self.convert_element(child)\n            if child_md:\n                result.append(child_md)\n            if child.tail and child.tail.strip():\n                result.append(child.tail)\n\n        separator = \"\\n\" if add_linebreaks else \"\"\n        return separator.join([r for r in result if r and r.strip()])\n\n    def handle_document(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle document element (html or body)\"\"\"\n        return self.process_children(element, True)\n\n    def handle_heading(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle heading elements (h1-h6)\"\"\"\n        level = int(element.tag[1])\n        content = element.text_content().strip()\n        return f\"\\n\\n{'#' * level} {content}\\n\\n\"\n\n    def handle_paragraph(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle paragraph elements\"\"\"\n        content = element.text or \"\"\n\n        for child in element:\n            if child.tag in self.tag_handlers:\n                content += self.tag_handlers[child.tag](child)\n            else:\n                content += self.process_children(child)\n\n            if child.tail:\n                content += child.tail\n\n        if not content.strip():\n            return \"\"\n\n        return f\"\\n\\n{content}\\n\\n\"\n\n    def handle_link(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle anchor elements\"\"\"\n        href = element.get(\"href\", \"\")\n        content = element.text_content() or href\n\n        if href.startswith(\"#\"):\n            anchor = href[1:]\n            return f\"[{content}](#{anchor})\"\n\n        return f\"[{content}]({href})\"\n\n    def handle_image(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle image elements\"\"\"\n        src = element.get(\"src\", \"\")\n        alt = element.get(\"alt\", \"\")\n        title = element.get(\"title\", \"\")\n        if title:\n            return f'![{alt}]({src} \"{title}\")'\n        return f\"![{alt}]({src})\"\n\n    def handle_strong(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle strong/bold elements\"\"\"\n        content = element.text_content().strip()\n        return f\"**{content}**\"\n\n    def handle_emphasis(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle emphasis/italic elements\"\"\"\n        content = element.text_content().strip()\n        return f\"*{content}*\"\n\n    def handle_code(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle inline code elements\"\"\"\n        if element.getparent() is not None and element.getparent().tag == \"pre\":\n            return element.text_content()\n\n        content = element.text_content()\n        return f\"`{content}`\"\n\n    def handle_preformatted(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle preformatted code blocks\"\"\"\n        code_element = element.find(\"code\")\n        if code_element is not None:\n            content = code_element.text_content()\n            language = \"\"\n            for cls in code_element.get(\"class\", \"\").split():\n                if cls.startswith(\"language-\"):\n                    language = cls[9:]\n                    break\n            return f\"\\n```{language}\\n{content}\\n```\\n\"\n\n        content = element.text_content()\n        return f\"\\n```\\n{content}\\n```\\n\"\n\n    def handle_unordered_list(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle unordered list elements\"\"\"\n        self.list_state.append({\"type\": \"ul\", \"index\": 0})\n        content = self.process_children(element, True)\n        self.list_state.pop()\n        return f\"\\n{content}\\n\"\n\n    def handle_ordered_list(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle ordered list elements\"\"\"\n        start = element.get(\"start\", \"1\")\n        try:\n            start = int(start)\n        except ValueError:\n            start = 1\n\n        self.list_state.append({\"type\": \"ol\", \"index\": start - 1})\n        content = self.process_children(element, True)\n        self.list_state.pop()\n        return f\"\\n{content}\\n\"\n\n    def handle_list_item(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle list item elements\"\"\"\n        if self.list_state and self.list_state[-1][\"type\"] == \"ol\":\n            self.list_state[-1][\"index\"] += 1\n\n        indent = \"  \" * (len(self.list_state) - 1)\n        if self.list_state and self.list_state[-1][\"type\"] == \"ul\":\n            bullet = \"*\"\n        else:\n            bullet = f\"{self.list_state[-1]['index']}.\"\n\n        content = element.text or \"\"\n\n        for child in element:\n            if child.tag in self.tag_handlers:\n                content += self.tag_handlers[child.tag](child)\n            else:\n                content += self.process_children(child)\n\n            if child.tail:\n                content += child.tail\n\n        return f\"{indent}{bullet} {content}\"\n\n    def handle_linebreak(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle line break elements\"\"\"\n        return \"\\n\"\n\n    def handle_horizontal_rule(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle horizontal rule elements\"\"\"\n        return \"\\n\\n---\\n\\n\"\n\n    def handle_table(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle table elements\"\"\"\n        self.in_table = True\n        self.table_headers = []\n        self.table_rows = []\n\n        self.process_children(element)\n\n        if not self.table_headers and self.table_rows:\n            self.table_headers = self.table_rows[0]\n            self.table_rows = self.table_rows[1:]\n\n        if not self.table_headers:\n            self.in_table = False\n            return \"\"\n\n        result = []\n        result.append(\"| \" + \" | \".join(self.table_headers) + \" |\")\n        result.append(\"| \" + \" | \".join([\"---\"] * len(self.table_headers)) + \" |\")\n\n        for row in self.table_rows:\n            padded_row = row + [\"\"] * (len(self.table_headers) - len(row))\n            result.append(\"| \" + \" | \".join(padded_row) + \" |\")\n\n        self.in_table = False\n        return \"\\n\\n\" + \"\\n\".join(result) + \"\\n\\n\"\n\n    def handle_table_row(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle table row elements\"\"\"\n        if not self.in_table:\n            return \"\"\n\n        self.current_row = []\n        self.process_children(element)\n\n        if element.findall(\"th\"):\n            self.table_headers = self.current_row\n        else:\n            self.table_rows.append(self.current_row)\n\n        return \"\"\n\n    def handle_table_cell(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle table cell elements\"\"\"\n        if not self.in_table:\n            return \"\"\n\n        content = element.text_content()\n        self.current_row.append(content.strip())\n        return \"\"\n\n    def handle_blockquote(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle blockquote elements\"\"\"\n        content = element.text_content()\n        lines = content.split(\"\\n\")\n        quoted_lines = [f\"&gt; {line}\" if line.strip() else \"&gt;\" for line in lines]\n        return \"\\n\\n\" + \"\\n\".join(quoted_lines) + \"\\n\\n\"\n\n    def handle_block(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle block-level elements like div\"\"\"\n        content = self.process_children(element)\n        return f\"\\n\\n{content}\\n\\n\"\n\n    def handle_inline(self, element: lxml_html.HtmlElement) -&gt; str:\n        \"\"\"Handle inline elements like span\"\"\"\n        return self.process_children(element)\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.convert_element","title":"<code>convert_element(element, parent_tag=None)</code>","text":"<p>Convert an HTML element to Markdown recursively</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def convert_element(self, element: lxml_html.HtmlElement | str, parent_tag=None) -&gt; str:\n    \"\"\"Convert an HTML element to Markdown recursively\"\"\"\n    if element is None:\n        return \"\"\n\n    if isinstance(element, str) or element.tag == \"text\":\n        text = element if isinstance(element, str) else element.text_content().strip()\n        if text and parent_tag not in [\"pre\", \"code\"]:\n            text = \" \".join(text.split())\n        return text\n\n    tag = element.tag\n\n    if tag is etree.Comment or tag in [\"script\", \"style\"]:\n        return \"\"\n\n    if tag == \"html\" or tag == \"body\" or tag == \"document\":\n        return self.handle_document(element)\n\n    if tag in self.tag_handlers:\n        return self.tag_handlers[tag](element)\n\n    return self.process_children(element)\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_block","title":"<code>handle_block(element)</code>","text":"<p>Handle block-level elements like div</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_block(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle block-level elements like div\"\"\"\n    content = self.process_children(element)\n    return f\"\\n\\n{content}\\n\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_blockquote","title":"<code>handle_blockquote(element)</code>","text":"<p>Handle blockquote elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_blockquote(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle blockquote elements\"\"\"\n    content = element.text_content()\n    lines = content.split(\"\\n\")\n    quoted_lines = [f\"&gt; {line}\" if line.strip() else \"&gt;\" for line in lines]\n    return \"\\n\\n\" + \"\\n\".join(quoted_lines) + \"\\n\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_code","title":"<code>handle_code(element)</code>","text":"<p>Handle inline code elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_code(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle inline code elements\"\"\"\n    if element.getparent() is not None and element.getparent().tag == \"pre\":\n        return element.text_content()\n\n    content = element.text_content()\n    return f\"`{content}`\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_document","title":"<code>handle_document(element)</code>","text":"<p>Handle document element (html or body)</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_document(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle document element (html or body)\"\"\"\n    return self.process_children(element, True)\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_emphasis","title":"<code>handle_emphasis(element)</code>","text":"<p>Handle emphasis/italic elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_emphasis(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle emphasis/italic elements\"\"\"\n    content = element.text_content().strip()\n    return f\"*{content}*\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_heading","title":"<code>handle_heading(element)</code>","text":"<p>Handle heading elements (h1-h6)</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_heading(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle heading elements (h1-h6)\"\"\"\n    level = int(element.tag[1])\n    content = element.text_content().strip()\n    return f\"\\n\\n{'#' * level} {content}\\n\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_horizontal_rule","title":"<code>handle_horizontal_rule(element)</code>","text":"<p>Handle horizontal rule elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_horizontal_rule(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle horizontal rule elements\"\"\"\n    return \"\\n\\n---\\n\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_image","title":"<code>handle_image(element)</code>","text":"<p>Handle image elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_image(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle image elements\"\"\"\n    src = element.get(\"src\", \"\")\n    alt = element.get(\"alt\", \"\")\n    title = element.get(\"title\", \"\")\n    if title:\n        return f'![{alt}]({src} \"{title}\")'\n    return f\"![{alt}]({src})\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_inline","title":"<code>handle_inline(element)</code>","text":"<p>Handle inline elements like span</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_inline(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle inline elements like span\"\"\"\n    return self.process_children(element)\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_linebreak","title":"<code>handle_linebreak(element)</code>","text":"<p>Handle line break elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_linebreak(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle line break elements\"\"\"\n    return \"\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_link","title":"<code>handle_link(element)</code>","text":"<p>Handle anchor elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_link(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle anchor elements\"\"\"\n    href = element.get(\"href\", \"\")\n    content = element.text_content() or href\n\n    if href.startswith(\"#\"):\n        anchor = href[1:]\n        return f\"[{content}](#{anchor})\"\n\n    return f\"[{content}]({href})\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_list_item","title":"<code>handle_list_item(element)</code>","text":"<p>Handle list item elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_list_item(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle list item elements\"\"\"\n    if self.list_state and self.list_state[-1][\"type\"] == \"ol\":\n        self.list_state[-1][\"index\"] += 1\n\n    indent = \"  \" * (len(self.list_state) - 1)\n    if self.list_state and self.list_state[-1][\"type\"] == \"ul\":\n        bullet = \"*\"\n    else:\n        bullet = f\"{self.list_state[-1]['index']}.\"\n\n    content = element.text or \"\"\n\n    for child in element:\n        if child.tag in self.tag_handlers:\n            content += self.tag_handlers[child.tag](child)\n        else:\n            content += self.process_children(child)\n\n        if child.tail:\n            content += child.tail\n\n    return f\"{indent}{bullet} {content}\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_ordered_list","title":"<code>handle_ordered_list(element)</code>","text":"<p>Handle ordered list elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_ordered_list(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle ordered list elements\"\"\"\n    start = element.get(\"start\", \"1\")\n    try:\n        start = int(start)\n    except ValueError:\n        start = 1\n\n    self.list_state.append({\"type\": \"ol\", \"index\": start - 1})\n    content = self.process_children(element, True)\n    self.list_state.pop()\n    return f\"\\n{content}\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_paragraph","title":"<code>handle_paragraph(element)</code>","text":"<p>Handle paragraph elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_paragraph(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle paragraph elements\"\"\"\n    content = element.text or \"\"\n\n    for child in element:\n        if child.tag in self.tag_handlers:\n            content += self.tag_handlers[child.tag](child)\n        else:\n            content += self.process_children(child)\n\n        if child.tail:\n            content += child.tail\n\n    if not content.strip():\n        return \"\"\n\n    return f\"\\n\\n{content}\\n\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_preformatted","title":"<code>handle_preformatted(element)</code>","text":"<p>Handle preformatted code blocks</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_preformatted(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle preformatted code blocks\"\"\"\n    code_element = element.find(\"code\")\n    if code_element is not None:\n        content = code_element.text_content()\n        language = \"\"\n        for cls in code_element.get(\"class\", \"\").split():\n            if cls.startswith(\"language-\"):\n                language = cls[9:]\n                break\n        return f\"\\n```{language}\\n{content}\\n```\\n\"\n\n    content = element.text_content()\n    return f\"\\n```\\n{content}\\n```\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_strong","title":"<code>handle_strong(element)</code>","text":"<p>Handle strong/bold elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_strong(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle strong/bold elements\"\"\"\n    content = element.text_content().strip()\n    return f\"**{content}**\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_table","title":"<code>handle_table(element)</code>","text":"<p>Handle table elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_table(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle table elements\"\"\"\n    self.in_table = True\n    self.table_headers = []\n    self.table_rows = []\n\n    self.process_children(element)\n\n    if not self.table_headers and self.table_rows:\n        self.table_headers = self.table_rows[0]\n        self.table_rows = self.table_rows[1:]\n\n    if not self.table_headers:\n        self.in_table = False\n        return \"\"\n\n    result = []\n    result.append(\"| \" + \" | \".join(self.table_headers) + \" |\")\n    result.append(\"| \" + \" | \".join([\"---\"] * len(self.table_headers)) + \" |\")\n\n    for row in self.table_rows:\n        padded_row = row + [\"\"] * (len(self.table_headers) - len(row))\n        result.append(\"| \" + \" | \".join(padded_row) + \" |\")\n\n    self.in_table = False\n    return \"\\n\\n\" + \"\\n\".join(result) + \"\\n\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_table_cell","title":"<code>handle_table_cell(element)</code>","text":"<p>Handle table cell elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_table_cell(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle table cell elements\"\"\"\n    if not self.in_table:\n        return \"\"\n\n    content = element.text_content()\n    self.current_row.append(content.strip())\n    return \"\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_table_row","title":"<code>handle_table_row(element)</code>","text":"<p>Handle table row elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_table_row(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle table row elements\"\"\"\n    if not self.in_table:\n        return \"\"\n\n    self.current_row = []\n    self.process_children(element)\n\n    if element.findall(\"th\"):\n        self.table_headers = self.current_row\n    else:\n        self.table_rows.append(self.current_row)\n\n    return \"\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.handle_unordered_list","title":"<code>handle_unordered_list(element)</code>","text":"<p>Handle unordered list elements</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def handle_unordered_list(self, element: lxml_html.HtmlElement) -&gt; str:\n    \"\"\"Handle unordered list elements\"\"\"\n    self.list_state.append({\"type\": \"ul\", \"index\": 0})\n    content = self.process_children(element, True)\n    self.list_state.pop()\n    return f\"\\n{content}\\n\"\n</code></pre>"},{"location":"dynamiq/components/converters/html/#dynamiq.components.converters.html.MarkdownConverter.process_children","title":"<code>process_children(element, add_linebreaks=False)</code>","text":"<p>Process all children of an element and join their markdown</p> Source code in <code>dynamiq/components/converters/html.py</code> <pre><code>def process_children(self, element: lxml_html.HtmlElement, add_linebreaks=False) -&gt; str:\n    \"\"\"Process all children of an element and join their markdown\"\"\"\n    result = []\n\n    if element.text and element.text.strip():\n        result.append(element.text)\n\n    for child in element:\n        child_md = self.convert_element(child)\n        if child_md:\n            result.append(child_md)\n        if child.tail and child.tail.strip():\n            result.append(child.tail)\n\n    separator = \"\\n\" if add_linebreaks else \"\"\n    return separator.join([r for r in result if r and r.strip()])\n</code></pre>"},{"location":"dynamiq/components/converters/pptx/","title":"Pptx","text":""},{"location":"dynamiq/components/converters/pptx/#dynamiq.components.converters.pptx.PPTXConverter","title":"<code>PPTXConverter</code>","text":"<p>               Bases: <code>BaseConverter</code></p> <p>A component for converting files to Documents using the pptx library.</p> <pre><code>  Initializes the object with the configuration for converting documents using\n  the python-pptx.\n\n  Args:\n  document_creation_mode (Literal[\"one-doc-per-file\", \"one-doc-per-page\", \"one-doc-per-element\"], optional):\n      Determines how to create Documents from the elements of presentation. Options are:\n      - `\"one-doc-per-file\"`: Creates one Document per file.\n          All elements are concatenated into one text field.\n      - `\"one-doc-per-page\"`: Creates one Document per page.\n          All elements on a page are concatenated into one text field.\n      Defaults to `\"one-doc-per-file\"`.\n  extraction_mode(ExtractionMode): Type of text extraction format.\n\nUsage example:\n    ```python\n    from dynamiq.components.converters.pptx import PPTXConverter\n\n    converter = PPTXConverter()\n    documents = converter.run(paths=[\"a/file/path.pptx\", \"a/directory/path\"])[\"documents\"]\n    ```\n</code></pre> Source code in <code>dynamiq/components/converters/pptx.py</code> <pre><code>class PPTXConverter(BaseConverter):\n    \"\"\"\n    A component for converting files to Documents using the pptx library.\n\n          Initializes the object with the configuration for converting documents using\n          the python-pptx.\n\n          Args:\n          document_creation_mode (Literal[\"one-doc-per-file\", \"one-doc-per-page\", \"one-doc-per-element\"], optional):\n              Determines how to create Documents from the elements of presentation. Options are:\n              - `\"one-doc-per-file\"`: Creates one Document per file.\n                  All elements are concatenated into one text field.\n              - `\"one-doc-per-page\"`: Creates one Document per page.\n                  All elements on a page are concatenated into one text field.\n              Defaults to `\"one-doc-per-file\"`.\n          extraction_mode(ExtractionMode): Type of text extraction format.\n\n        Usage example:\n            ```python\n            from dynamiq.components.converters.pptx import PPTXConverter\n\n            converter = PPTXConverter()\n            documents = converter.run(paths=[\"a/file/path.pptx\", \"a/directory/path\"])[\"documents\"]\n            ```\n    \"\"\"\n\n    document_creation_mode: Literal[DocumentCreationMode.ONE_DOC_PER_FILE, DocumentCreationMode.ONE_DOC_PER_PAGE] = (\n        DocumentCreationMode.ONE_DOC_PER_FILE\n    )\n\n    def _process_file(self, file: Path | BytesIO, metadata: dict[str, Any]) -&gt; list[Any]:\n        \"\"\"\n        Process a single presentation and create documents.\n\n        Args:\n            file (Union[Path, BytesIO]): The file to process.\n            metadata (Dict[str, Any]): Metadata to attach to the documents.\n\n        Returns:\n            List[Any]: A list of created documents.\n\n        Raises:\n            ValueError: If the file object doesn't have a name and its extension can't be guessed.\n            TypeError: If the file argument is neither a Path nor a BytesIO object.\n        \"\"\"\n        if isinstance(file, Path):\n            with open(file, \"rb\") as upload_file:\n                file_content = BytesIO(upload_file.read())\n                file_path = upload_file.name\n        elif isinstance(file, BytesIO):\n            file_path = get_filename_for_bytesio(file)\n            file_content = file\n        else:\n            raise TypeError(\"Expected a Path object or a BytesIO object.\")\n        elements = Presentation(file_content)\n        return self._create_documents(\n            filepath=file_path,\n            elements=elements,\n            document_creation_mode=self.document_creation_mode,\n            metadata=metadata,\n        )\n\n    def _create_documents(\n        self,\n        filepath: str,\n        elements: Any,\n        document_creation_mode: DocumentCreationMode,\n        metadata: dict[str, Any],\n        **kwargs\n    ) -&gt; list[Document]:\n        \"\"\"\n        Create Documents from the elements of the presentation.\n        \"\"\"\n        docs = []\n        if document_creation_mode == DocumentCreationMode.ONE_DOC_PER_FILE:\n            text_all_slides = \"\\n\".join(\n                \"\\n\".join(shape.text for shape in slide.shapes if hasattr(shape, \"text\") and shape.text)\n                for slide in elements.slides\n            )\n            metadata = copy.deepcopy(metadata)\n            metadata[\"file_path\"] = filepath\n            docs = [Document(content=text_all_slides, metadata=metadata)]\n\n        elif document_creation_mode == DocumentCreationMode.ONE_DOC_PER_PAGE:\n            texts_per_page = [\n                \"\\n\".join(shape.text for shape in slide.shapes if hasattr(shape, \"text\") and shape.text)\n                for slide in elements.slides\n            ]\n            metadata = copy.deepcopy(metadata)\n            metadata[\"file_path\"] = filepath\n\n            docs = [Document(content=text, metadata=metadata) for text in texts_per_page]\n\n        return docs\n</code></pre>"},{"location":"dynamiq/components/converters/pypdf/","title":"Pypdf","text":"<p>pdf</p>"},{"location":"dynamiq/components/converters/text/","title":"Text","text":""},{"location":"dynamiq/components/converters/text/#dynamiq.components.converters.text.TextFileConverter","title":"<code>TextFileConverter</code>","text":"<p>               Bases: <code>BaseConverter</code></p> <p>A component for converting text files to Documents using the text file converter.</p> <p>Initializes the object with the configuration for converting documents using the text file converter.</p> <p>Parameters:</p> Name Type Description Default <code>document_creation_mode</code> <code>Literal['one-doc-per-file']</code> <p>Determines how to create Documents from the text file content. Currently only supports: - <code>\"one-doc-per-file\"</code>: Creates one Document per file.     All content is converted to markdown format. Defaults to <code>\"one-doc-per-file\"</code>.</p> required Usage example <pre><code>from dynamiq.components.converters.txt import TextFileConverter\n\nconverter = TextFileConverter()\ndocuments = converter.run(paths=[\"a/file/path.txt\", \"a/directory/path\"])[\"documents\"]\n</code></pre> Source code in <code>dynamiq/components/converters/text.py</code> <pre><code>class TextFileConverter(BaseConverter):\n    \"\"\"\n    A component for converting text files to Documents using the text file converter.\n\n    Initializes the object with the configuration for converting documents using\n    the text file converter.\n\n    Args:\n        document_creation_mode (Literal[\"one-doc-per-file\"], optional):\n            Determines how to create Documents from the text file content. Currently only supports:\n            - `\"one-doc-per-file\"`: Creates one Document per file.\n                All content is converted to markdown format.\n            Defaults to `\"one-doc-per-file\"`.\n\n    Usage example:\n        ```python\n        from dynamiq.components.converters.txt import TextFileConverter\n\n        converter = TextFileConverter()\n        documents = converter.run(paths=[\"a/file/path.txt\", \"a/directory/path\"])[\"documents\"]\n        ```\n    \"\"\"\n\n    document_creation_mode: Literal[DocumentCreationMode.ONE_DOC_PER_FILE] = DocumentCreationMode.ONE_DOC_PER_FILE\n\n    def _process_file(self, file: Path | BytesIO, metadata: dict[str, Any]) -&gt; list[Any]:\n        \"\"\"\n        Process a file and return a list of Documents.\n\n        Args:\n            file: Path to a file or BytesIO object\n            metadata: Metadata to attach to the documents\n\n        Returns:\n            List of Documents\n        \"\"\"\n\n        if isinstance(file, BytesIO):\n            filepath = get_filename_for_bytesio(file)\n            file.seek(0)\n            data = file.read()\n        else:\n            filepath = str(file)\n            with open(file, \"rb\") as f:\n                data = f.read()\n\n        encoding = self._detect_encoding(data)\n        content = data.decode(encoding, errors=\"replace\")\n\n        # Create documents from the text file content\n        return self._create_documents(\n            filepath=filepath,\n            content=content,\n            document_creation_mode=self.document_creation_mode,\n            metadata=metadata,\n        )\n\n    def _create_documents(\n        self,\n        filepath: str,\n        content: str,\n        document_creation_mode: DocumentCreationMode,\n        metadata: dict[str, Any],\n        **kwargs,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Create Documents from the text content.\n        \"\"\"\n        if document_creation_mode != DocumentCreationMode.ONE_DOC_PER_FILE:\n            raise ValueError(\"TextFileConverter only supports one-doc-per-file mode\")\n\n        content = content.strip()\n\n        metadata = copy.deepcopy(metadata)\n        metadata[\"file_path\"] = filepath\n\n        docs = [Document(content=content, metadata=metadata)]\n        return docs\n\n    def _detect_encoding(self, data: bytes) -&gt; str:\n        \"\"\"\n        Detect the encoding of the data using charset_normalizer.\n        If detection fails, fallback to \"utf-8\".\n        \"\"\"\n        try:\n            result = from_bytes(data)\n            best = result.best()\n\n            if best and best.encoding:\n                encoding = best.encoding\n\n                try:\n                    data.decode(encoding)\n                    return encoding\n                except UnicodeDecodeError:\n                    logger.debug(f\"Detected encoding '{encoding}' failed to decode. Falling back...\")\n\n            else:\n                logger.debug(\"Encoding detection returned None. Falling back...\")\n\n        except Exception as e:\n            logger.debug(f\"Encoding detection error: {e}. Falling back...\")\n\n        return \"utf-8\"\n</code></pre>"},{"location":"dynamiq/components/converters/unstructured/","title":"Unstructured","text":""},{"location":"dynamiq/components/converters/unstructured/#dynamiq.components.converters.unstructured.UnstructuredFileConverter","title":"<code>UnstructuredFileConverter</code>","text":"<p>               Bases: <code>BaseConverter</code></p> <p>A component for converting files to Documents using the Unstructured API (hosted or running locally).</p> <p>For the supported file types and the specific API parameters, see Unstructured docs.</p> <p>Usage example: <pre><code>from dynamiq.components.converters.unstructured.file_converter import UnstructuredFileConverter\n\n# make sure to either set the environment variable UNSTRUCTURED_API_KEY\n# or run the Unstructured API locally:\n# docker run -p 8000:8000 -d --rm --name unstructured-api quay.io/unstructured-io/unstructured-api:latest\n# --port 8000 --host 0.0.0.0\n\nconverter = UnstructuredFileConverter()\ndocuments = converter.run(paths=[\"a/file/path.pdf\", \"a/directory/path\"])[\"documents\"]\n</code></pre></p> Source code in <code>dynamiq/components/converters/unstructured.py</code> <pre><code>class UnstructuredFileConverter(BaseConverter):\n    \"\"\"\n    A component for converting files to Documents using the Unstructured API (hosted or running locally).\n\n    For the supported file types and the specific API parameters, see\n    [Unstructured docs](https://unstructured-io.github.io/unstructured/api.html).\n\n    Usage example:\n    ```python\n    from dynamiq.components.converters.unstructured.file_converter import UnstructuredFileConverter\n\n    # make sure to either set the environment variable UNSTRUCTURED_API_KEY\n    # or run the Unstructured API locally:\n    # docker run -p 8000:8000 -d --rm --name unstructured-api quay.io/unstructured-io/unstructured-api:latest\n    # --port 8000 --host 0.0.0.0\n\n    converter = UnstructuredFileConverter()\n    documents = converter.run(paths=[\"a/file/path.pdf\", \"a/directory/path\"])[\"documents\"]\n    ```\n    \"\"\"\n\n    connection: UnstructuredConnection = None\n    document_creation_mode: DocumentCreationMode = DocumentCreationMode.ONE_DOC_PER_FILE\n    separator: str = \"\\n\\n\"\n    strategy: ConvertStrategy = ConvertStrategy.AUTO\n    unstructured_kwargs: dict[str, Any] | None = None\n\n    def __init__(self, *args, **kwargs):\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = UnstructuredConnection()\n        super().__init__(**kwargs)\n        \"\"\"\n        Initializes the object with the configuration for converting documents using\n        the Unstructured API.\n\n        Args:\n        connection (UnstructuredConnection, optional): The connection to use for the Unstructured API.\n            Defaults to None, which will initialize a new UnstructuredConnection.\n        document_creation_mode (Literal[\"one-doc-per-file\", \"one-doc-per-page\", \"one-doc-per-element\"], optional):\n            Determines how to create Documents from the elements returned by Unstructured. Options are:\n            - `\"one-doc-per-file\"`: Creates one Document per file.\n                All elements are concatenated into one text field.\n            - `\"one-doc-per-page\"`: Creates one Document per page.\n                All elements on a page are concatenated into one text field.\n            - `\"one-doc-per-element\"`: Creates one Document per element.\n                Each element is converted to a separate Document.\n            Defaults to `\"one-doc-per-file\"`.\n        separator (str, optional): The separator to use between elements when concatenating them into one text field.\n            Defaults to \"\\n\\n\".\n        strategy (Literal[\"auto\", \"fast\", \"hi_res\", \"ocr_only\"], optional): The strategy to use for document processing.\n            Defaults to \"auto\".\n        unstructured_kwargs (Optional[dict[str, Any]], optional): Additional parameters to pass to the Unstructured API.\n            See [Unstructured API docs](https://unstructured-io.github.io/unstructured/apis/api_parameters.html)\n                for available parameters.\n            Defaults to None.\n        progress_bar (bool, optional): Whether to show a progress bar during the conversion process.\n            Defaults to True.\n\n        Returns:\n        None\n        \"\"\"\n\n    def _process_file(self, file: Path | str | BytesIO, metadata: dict[str, Any]) -&gt; list[Any]:\n        \"\"\"\n        Process a single file and create documents.\n\n        Args:\n            file (Union[Path, str, BytesIO]): The file to process.\n            metadata (Dict[str, Any]): Metadata to attach to the documents.\n\n        Returns:\n            List[Any]: A list of created documents.\n\n        Raises:\n            ValueError: If the file object doesn't have a name and its extension can't be guessed.\n            TypeError: If the file argument is neither a Path, string, nor a BytesIO object.\n        \"\"\"\n        if isinstance(file, (Path, str)):\n            file_name = str(file)\n            elements = self._partition_file_into_elements_by_filepath(file_name)\n        elif isinstance(file, BytesIO):\n            file_name = get_filename_for_bytesio(file)\n            elements = self._partition_file_into_elements_by_file(file, file_name)\n        else:\n            raise TypeError(\"Expected a Path object, a string path, or a BytesIO object.\")\n        return self._create_documents(\n            filepath=file_name,\n            elements=elements,\n            document_creation_mode=self.document_creation_mode,\n            metadata=metadata,\n        )\n\n    def _partition_file_into_elements_by_filepath(self, filepath: Path | str) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        Partition a file into elements using the Unstructured API.\n\n        Args:\n            filepath (Path | str): The path to the file to partition.\n\n        Returns:\n            List[Dict[str, Any]]: A list of elements extracted from the file.\n\n        Raises:\n            FileNotFoundError: If the file doesn't exist\n            ValueError: If the file is empty or cannot be processed\n            Exception: Any other exception that occurs during processing\n        \"\"\"\n        if isinstance(filepath, str):\n            filepath = Path(filepath)\n\n        if not filepath.exists():\n            raise FileNotFoundError(f\"File not found: {filepath}\")\n\n        if filepath.stat().st_size == 0:\n            raise ValueError(f\"Empty file cannot be processed: {filepath}\")\n\n        return partition_via_api(\n            filename=str(filepath),\n            api_url=self.connection.url,\n            api_key=self.connection.api_key,\n            strategy=self.strategy,\n            **self.unstructured_kwargs or {},\n        )\n\n    def _partition_file_into_elements_by_file(\n        self,\n        file: BytesIO,\n        metadata_filename: str,\n    ) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        Partition a file into elements using the Unstructured API.\n\n        Args:\n            file (BytesIO): The file object to partition.\n            metadata_filename (str): The filename to store in element metadata.\n\n        Returns:\n            List[Dict[str, Any]]: A list of elements extracted from the file.\n\n        Raises:\n            ValueError: If the file is empty or cannot be processed\n            Exception: Any other exception that occurs during processing\n        \"\"\"\n        return partition_via_api(\n            filename=None,\n            file=file,\n            metadata_filename=metadata_filename,\n            api_url=self.connection.url,\n            api_key=self.connection.api_key,\n            strategy=self.strategy,\n            **self.unstructured_kwargs or {},\n        )\n\n    def _create_documents(\n        self,\n        filepath: str,\n        elements: list[dict],\n        document_creation_mode: DocumentCreationMode,\n        metadata: dict[str, Any],\n        **kwargs,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Create Documents from the elements returned by Unstructured.\n        \"\"\"\n        separator = self.separator\n        docs = []\n        if document_creation_mode == DocumentCreationMode.ONE_DOC_PER_FILE:\n            element_texts = []\n            for el in elements:\n                text = str(el.get(\"text\", \"\"))\n                if el.get(\"category\") == \"Title\":\n                    element_texts.append(\"# \" + text)\n                else:\n                    element_texts.append(text)\n\n            text = separator.join(element_texts)\n            metadata = copy.deepcopy(metadata)\n            metadata[\"file_path\"] = str(filepath)\n            docs = [Document(content=text, metadata=metadata)]\n\n        elif document_creation_mode == DocumentCreationMode.ONE_DOC_PER_PAGE:\n            texts_per_page: defaultdict[int, str] = defaultdict(str)\n            meta_per_page: defaultdict[int, dict] = defaultdict(dict)\n            for el in elements:\n                text = str(el.get(\"text\", \"\"))\n                metadata = copy.deepcopy(metadata)\n                metadata[\"file_path\"] = str(filepath)\n                element_medata = el.get(\"metadata\")\n                if element_medata:\n                    metadata.update(element_medata)\n                page_number = int(metadata.get(\"page_number\", 1))\n\n                texts_per_page[page_number] += text + separator\n                meta_per_page[page_number].update(metadata)\n\n            docs = [\n                Document(content=texts_per_page[page], metadata=meta_per_page[page])\n                for page in texts_per_page.keys()\n            ]\n\n        elif document_creation_mode == DocumentCreationMode.ONE_DOC_PER_ELEMENT:\n            for index, el in enumerate(elements):\n                text = str(el.get(\"text\", \"\"))\n                metadata = copy.deepcopy(metadata)\n                metadata[\"file_path\"] = str(filepath)\n                metadata[\"element_index\"] = index\n                element_medata = el.get(\"metadata\")\n                if element_medata:\n                    metadata.update(element_medata)\n                element_category = el.get(\"category\")\n                if element_category:\n                    metadata[\"category\"] = element_category\n                doc = Document(content=str(el), metadata=metadata)\n                docs.append(doc)\n        return docs\n</code></pre>"},{"location":"dynamiq/components/converters/unstructured/#dynamiq.components.converters.unstructured.partition_via_api","title":"<code>partition_via_api(filename=None, content_type=None, file=None, file_filename=None, api_url='https://api.unstructured.io/', api_key='', metadata_filename=None, **request_kwargs)</code>","text":"<p>Partitions a document using the Unstructured REST API. This is equivalent to running the document through partition.</p> <p>See https://api.unstructured.io/general/docs for the hosted API documentation or https://github.com/Unstructured-IO/unstructured-api for instructions on how to run the API locally as a container.</p>"},{"location":"dynamiq/components/converters/unstructured/#dynamiq.components.converters.unstructured.partition_via_api--parameters","title":"Parameters","text":"<p>filename     A string defining the target filename path. content_type     A string defining the file content in MIME type file     A file-like object using \"rb\" mode --&gt; open(filename, \"rb\"). metadata_filename     When file is not None, the filename (string) to store in element metadata. E.g. \"foo.txt\" api_url     The URL for the Unstructured API. Defaults to the hosted Unstructured API. api_key     The API key to pass to the Unstructured API. request_kwargs     Additional parameters to pass to the data field of the request to the Unstructured API.     For example the <code>strategy</code> parameter.</p> Source code in <code>dynamiq/components/converters/unstructured.py</code> <pre><code>def partition_via_api(\n    filename: str | None = None,\n    content_type: str | None = None,\n    file: IO[bytes] | None = None,\n    file_filename: str | None = None,\n    api_url: str = \"https://api.unstructured.io/\",\n    api_key: str = \"\",\n    metadata_filename: str | None = None,\n    **request_kwargs,\n) -&gt; list[dict]:\n    \"\"\"Partitions a document using the Unstructured REST API. This is equivalent to\n    running the document through partition.\n\n    See https://api.unstructured.io/general/docs for the hosted API documentation or\n    https://github.com/Unstructured-IO/unstructured-api for instructions on how to run\n    the API locally as a container.\n\n    Parameters\n    ----------\n    filename\n        A string defining the target filename path.\n    content_type\n        A string defining the file content in MIME type\n    file\n        A file-like object using \"rb\" mode --&gt; open(filename, \"rb\").\n    metadata_filename\n        When file is not None, the filename (string) to store in element metadata. E.g. \"foo.txt\"\n    api_url\n        The URL for the Unstructured API. Defaults to the hosted Unstructured API.\n    api_key\n        The API key to pass to the Unstructured API.\n    request_kwargs\n        Additional parameters to pass to the data field of the request to the Unstructured API.\n        For example the `strategy` parameter.\n    \"\"\"\n\n    if metadata_filename and file_filename:\n        raise ValueError(\n            \"Only one of metadata_filename and file_filename is specified. \"\n            \"metadata_filename is preferred. file_filename is marked for deprecation.\",\n        )\n\n    if file_filename is not None:\n        metadata_filename = file_filename\n        logger.warn(\n            \"The file_filename kwarg will be deprecated in a future version of unstructured. \"\n            \"Please use metadata_filename instead.\",\n        )\n\n    # Note(austin) - the sdk takes the base url, but we have the full api_url\n    # For consistency, just strip off the path when it's given\n    base_url = api_url[:-19] if \"/general/v0/general\" in api_url else api_url\n    sdk = UnstructuredClient(api_key_auth=api_key, server_url=base_url)\n\n    files = None\n    if filename is not None:\n        with open(filename, \"rb\") as f:\n            files = shared.Files(\n                content=f.read(),\n                file_name=filename,\n            )\n\n    elif file is not None:\n        if metadata_filename is None:\n            raise ValueError(\n                \"If file is specified in partition_via_api, \"\n                \"metadata_filename must be specified as well.\",\n            )\n        files = shared.Files(\n            content=file,\n            file_name=metadata_filename,\n        )\n\n    req = shared.PartitionParameters(\n        files=files,\n        **request_kwargs,\n    )\n    response = sdk.general.partition(req)\n\n    if response.status_code == 200:\n        element_dict = json.loads(response.raw_response.text)\n        return element_dict\n    else:\n        raise ValueError(\n            f\"Receive unexpected status code {response.status_code} from the API.\",\n        )\n</code></pre>"},{"location":"dynamiq/components/converters/utils/","title":"Utils","text":""},{"location":"dynamiq/components/converters/utils/#dynamiq.components.converters.utils.get_filename_for_bytesio","title":"<code>get_filename_for_bytesio(file)</code>","text":"<p>Get a filepath for a BytesIO object.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BytesIO</code> <p>The BytesIO object.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A filename for the BytesIO object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file extension couldn't be guessed.</p> Source code in <code>dynamiq/components/converters/utils.py</code> <pre><code>def get_filename_for_bytesio(file: BytesIO) -&gt; str:\n    \"\"\"\n    Get a filepath for a BytesIO object.\n\n    Args:\n        file (BytesIO): The BytesIO object.\n\n    Returns:\n        str: A filename for the BytesIO object.\n\n    Raises:\n        ValueError: If the file extension couldn't be guessed.\n    \"\"\"\n    filename = getattr(file, \"name\", None)\n    if filename is None:\n        file_extension = filetype.guess_extension(file)\n        if file_extension:\n            filename = f\"{generate_uuid()}.{file_extension}\"\n        else:\n            raise ValueError(\n                \"Unable to determine file extension. BytesIO object lacks name and \"\n                \"extension couldn't be guessed.\"\n            )\n    return filename\n</code></pre>"},{"location":"dynamiq/components/embedders/base/","title":"Base","text":""},{"location":"dynamiq/components/embedders/base/#dynamiq.components.embedders.base.BaseEmbedder","title":"<code>BaseEmbedder</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Initializes the Embedder component with given configuration.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Optional[BaseConnection]</code> <p>The connection to the  API. A new connection is created if none is provided.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding.</p> <code>prefix</code> <code>str</code> <p>A prefix string to prepend to each document text before embedding.</p> <code>suffix</code> <code>str</code> <p>A suffix string to append to each document text after embedding.</p> <code>batch_size</code> <code>int</code> <p>The number of documents to encode in a single batch.</p> <code>meta_fields_to_embed</code> <code>Optional[list[str]]</code> <p>A list of document meta fields to embed alongside the document text.</p> <code>embedding_separator</code> <code>str</code> <p>The separator string used to join document text with meta fields for embedding.</p> <code>truncate(str)</code> <code>str</code> <p>truncate embeddings that are too long from start or end, (\"NONE\"|\"START\"|\"END\"). Passing \"START\" will discard the start of the input. \"END\" will discard the end of the input. In both cases, input is discarded until the remaining input is exactly the maximum input token length for the model. If \"NONE\" is selected, when the input exceeds the maximum input token length an error will be returned.</p> <code>input_type(str)</code> <code>str</code> <p>specifies the type of input you're giving to the model. Supported values are \"search_document\", \"search_query\", \"classification\" and \"clustering\".</p> <code>dimensions(int)</code> <code>str</code> <p>he number of dimensions the resulting output embeddings should have. Only supported in OpenAI/Azure text-embedding-3 and later models.</p> <code>truncation_enabled(bool)</code> <code>str</code> <p>Whether to enable automatic text truncation for long inputs that exceed the embedding model's token limits. Defaults to True.</p> <code>max_input_tokens(int)</code> <code>str</code> <p>Maximum number of tokens allowed for input text. If text exceeds this limit and truncation_enabled is True, the text will be truncated. Defaults to 8192.</p> <code>truncation_method(TruncationMethod)</code> <code>str</code> <p>Method to use for truncation when text exceeds max_input_tokens. Options: TruncationMethod.START, TruncationMethod.END, TruncationMethod.MIDDLE. Defaults to TruncationMethod.MIDDLE.</p> Source code in <code>dynamiq/components/embedders/base.py</code> <pre><code>class BaseEmbedder(BaseModel):\n    \"\"\"\n    Initializes the Embedder component with given configuration.\n\n    Attributes:\n        connection (Optional[BaseConnection]): The connection to the  API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding.\n        prefix (str): A prefix string to prepend to each document text before embedding.\n        suffix (str): A suffix string to append to each document text after embedding.\n        batch_size (int): The number of documents to encode in a single batch.\n        meta_fields_to_embed (Optional[list[str]]): A list of document meta fields to embed alongside\n            the document text.\n        embedding_separator (str): The separator string used to join document text with meta fields\n            for embedding.\n        truncate(str): truncate embeddings that are too long from start or end, (\"NONE\"|\"START\"|\"END\").\n            Passing \"START\" will discard the start of the input. \"END\" will discard the end of the input. In both\n            cases, input is discarded until the remaining input is exactly the maximum input token length\n            for the model. If \"NONE\" is selected, when the input exceeds the maximum input token length\n            an error will be returned.\n        input_type(str):specifies the type of input you're giving to the model. Supported values are\n            \"search_document\", \"search_query\", \"classification\" and \"clustering\".\n        dimensions(int):he number of dimensions the resulting output embeddings should have.\n            Only supported in OpenAI/Azure text-embedding-3 and later models.\n        truncation_enabled(bool): Whether to enable automatic text truncation for long inputs that exceed\n            the embedding model's token limits. Defaults to True.\n        max_input_tokens(int): Maximum number of tokens allowed for input text. If text exceeds this limit\n            and truncation_enabled is True, the text will be truncated. Defaults to 8192.\n        truncation_method(TruncationMethod): Method to use for truncation when text exceeds max_input_tokens.\n            Options: TruncationMethod.START, TruncationMethod.END, TruncationMethod.MIDDLE.\n            Defaults to TruncationMethod.MIDDLE.\n\n    \"\"\"\n\n    @staticmethod\n    def validate_embedding(embedding: Any) -&gt; None:\n        \"\"\"\n        Validates that an embedding is valid.\n\n        Args:\n            embedding: The embedding vector to validate\n\n        Raises:\n            InvalidEmbeddingError: If the embedding is None, empty, or malformed\n        \"\"\"\n        try:\n            if embedding is None:\n                raise InvalidEmbeddingError(\"Embedding is None\")\n\n            if len(embedding) == 0:\n                raise InvalidEmbeddingError(\"Embedding is empty (zero length)\")\n        except (TypeError, AttributeError):\n            raise InvalidEmbeddingError(\"Embedding has no length attribute or is not iterable\")\n\n    @staticmethod\n    def validate_document_embeddings(documents: Any) -&gt; None:\n        \"\"\"\n        Validates embeddings for a list of documents.\n\n        Args:\n            documents: List of documents with embeddings\n\n        Raises:\n            DocumentEmbeddingValidationError: If any document embedding is invalid\n        \"\"\"\n        if not documents:\n            return\n\n        try:\n            for i, doc in enumerate(documents):\n                if not hasattr(doc, \"embedding\") or doc.embedding is None:\n                    raise DocumentEmbeddingValidationError(f\"Document at index {i} has no embedding\")\n\n                try:\n                    BaseEmbedder.validate_embedding(doc.embedding)\n                except InvalidEmbeddingError as e:\n                    raise DocumentEmbeddingValidationError(f\"Document at index {i}: {str(e)}\")\n        except (TypeError, AttributeError):\n            raise DocumentEmbeddingValidationError(\"Documents is not iterable or has incorrect structure\")\n    model: str\n    connection: BaseConnection\n    prefix: str = \"\"\n    suffix: str = \"\"\n    batch_size: int = 32\n    meta_fields_to_embed: list[str] | None = []\n    embedding_separator: str = \"\\n\"\n    truncate: str | None = None\n    input_type: str | None = None\n    dimensions: int | None = None\n    truncation_enabled: bool = True\n    max_input_tokens: int = 8192\n    truncation_method: TruncationMethod = TruncationMethod.MIDDLE\n    client: Any | None = None\n\n    _embedding: Callable = PrivateAttr()\n\n    def __init__(self, *args, **kwargs):\n        # Import in runtime to save memory\n        super().__init__(**kwargs)\n        from litellm import embedding\n\n        self._embedding = embedding\n\n    @property\n    def embed_params(self) -&gt; dict:\n        params = self.connection.conn_params\n        if self.client:\n            params = {\"client\": self.client}\n        return params\n\n    def _apply_text_truncation(self, text: str) -&gt; str:\n        \"\"\"\n        Apply text truncation if enabled and text exceeds max_input_tokens.\n\n        Args:\n            text: The text to potentially truncate\n\n        Returns:\n            Original or truncated text\n        \"\"\"\n        if not self.truncation_enabled or not text:\n            return text\n\n        return truncate_text_for_embedding(\n            text=text, max_tokens=self.max_input_tokens, truncation_method=self.truncation_method\n        )\n\n    def embed_text(self, text: str) -&gt; dict:\n        \"\"\"\n        Embeds a single string using the Embedder model specified during the initialization of the component.\n\n        Args:\n            text (str): The text string to be embedded.\n\n        Returns:\n            dict: A dictionary containing:\n                - 'embedding': A list representing the embedding vector of the input text.\n                - 'meta': A dictionary with metadata information about the model usage.\n\n        Raises:\n            TypeError: If input is not a string\n            ValueError: If the embedding response is invalid\n        \"\"\"\n        if not isinstance(text, str):\n            msg = (\n                \"TextEmbedder expects a string as input.\"\n                \"In case you want to embed a list of Documents, please use the DocumentEmbedder.\"\n            )\n            raise TypeError(msg)\n\n        text_to_embed = self.prefix + text + self.suffix\n        text_to_embed = text_to_embed.replace(\"\\n\", \" \")\n        text_to_embed = self._apply_text_truncation(text_to_embed)\n\n        response = self._embedding(model=self.model, input=[text_to_embed], **self.embed_params)\n\n        meta = {\"model\": response.model, \"usage\": dict(response.usage)}\n        embedding = response.data[0][\"embedding\"]\n\n        try:\n            self.validate_embedding(embedding)\n        except InvalidEmbeddingError as e:\n            logger.error(f\"Invalid embedding returned by model {self.model}: {str(e)}\")\n            raise ValueError(f\"Invalid embedding returned by the model: {str(e)}\")\n\n        return {\"embedding\": embedding, \"meta\": meta}\n\n    def _prepare_documents_to_embed(self, documents: list[Document]) -&gt; list[str]:\n        \"\"\"\n        Prepare the texts to embed by concatenating the Document text with the metadata fields to embed.\n\n        Args:\n            documents (list[Document]): A list of Document objects to prepare for embedding.\n\n        Returns:\n            list[str]: A list of concatenated strings ready for embedding.\n        \"\"\"\n        texts_to_embed: list[str] = []\n        for doc in documents:\n            meta_values_to_embed = [\n                str(doc.meta[key])\n                for key in self.meta_fields_to_embed\n                if doc.meta.get(key) is not None\n            ]\n\n            text_to_embed = self.embedding_separator.join(\n                meta_values_to_embed + [doc.content or \"\"]\n            )\n            text_to_embed = self._apply_text_truncation(text_to_embed)\n            texts_to_embed.append(text_to_embed)\n        return texts_to_embed\n\n    def _embed_texts_batch(\n        self, texts_to_embed: list[str], batch_size: int\n    ) -&gt; tuple[list[list[float]], dict[str, Any]]:\n        \"\"\"\n        Embed a list of texts in batches.\n        \"\"\"\n        all_embeddings = []\n        meta: dict[str, Any] = {}\n        embed_params = self.embed_params\n        for i in range(0, len(texts_to_embed), batch_size):\n            batch = texts_to_embed[i : i + batch_size]\n            response = self._embedding(model=self.model, input=batch, **embed_params)\n            embeddings = [el[\"embedding\"] for el in response.data]\n            all_embeddings.extend(embeddings)\n\n            if \"model\" not in meta:\n                meta[\"model\"] = response.model\n            if \"usage\" not in meta:\n                meta[\"usage\"] = dict(response.usage)\n            else:\n                meta[\"usage\"][\"prompt_tokens\"] += response.usage.prompt_tokens\n                meta[\"usage\"][\"total_tokens\"] += response.usage.total_tokens\n\n        return all_embeddings, meta\n\n    def embed_documents(self, documents: list[Document]) -&gt; dict:\n        \"\"\"\n        Embeds a list of documents and returns the embedded documents along with meta information.\n\n        Args:\n            documents (list[Document]): The documents to be embedded.\n\n        Returns:\n            dict: A dictionary containing:\n                - 'documents' (list[Document]): The input documents with their embeddings populated.\n                - 'meta' (dict): Metadata information about the embedding process.\n\n        Raises:\n            TypeError: If input is not a list of Documents\n            ValueError: If the embedding response is invalid\n        \"\"\"\n        if (\n            not isinstance(documents, list)\n            or documents\n            and not isinstance(documents[0], Document)\n        ):\n            msg = (\n                \"DocumentEmbedder expects a list of Documents as input.\"\n                \"In case you want to embed a string, please use the embed_text.\"\n            )\n            raise TypeError(msg)\n\n        if not documents:\n            # return early if we were passed an empty list\n            return {\"documents\": [], \"meta\": {}}\n\n        texts_to_embed = self._prepare_documents_to_embed(documents=documents)\n\n        embeddings, meta = self._embed_texts_batch(\n            texts_to_embed=texts_to_embed, batch_size=self.batch_size\n        )\n\n        for doc, emb in zip(documents, embeddings):\n            doc.embedding = emb\n\n        try:\n            self.validate_document_embeddings(documents)\n        except DocumentEmbeddingValidationError as e:\n            logger.error(f\"Invalid document embeddings returned by model {self.model}: {str(e)}\")\n            raise ValueError(f\"Invalid document embeddings: {str(e)}\")\n\n        return {\"documents\": documents, \"meta\": meta}\n</code></pre>"},{"location":"dynamiq/components/embedders/base/#dynamiq.components.embedders.base.BaseEmbedder.embed_documents","title":"<code>embed_documents(documents)</code>","text":"<p>Embeds a list of documents and returns the embedded documents along with meta information.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>The documents to be embedded.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing: - 'documents' (list[Document]): The input documents with their embeddings populated. - 'meta' (dict): Metadata information about the embedding process.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If input is not a list of Documents</p> <code>ValueError</code> <p>If the embedding response is invalid</p> Source code in <code>dynamiq/components/embedders/base.py</code> <pre><code>def embed_documents(self, documents: list[Document]) -&gt; dict:\n    \"\"\"\n    Embeds a list of documents and returns the embedded documents along with meta information.\n\n    Args:\n        documents (list[Document]): The documents to be embedded.\n\n    Returns:\n        dict: A dictionary containing:\n            - 'documents' (list[Document]): The input documents with their embeddings populated.\n            - 'meta' (dict): Metadata information about the embedding process.\n\n    Raises:\n        TypeError: If input is not a list of Documents\n        ValueError: If the embedding response is invalid\n    \"\"\"\n    if (\n        not isinstance(documents, list)\n        or documents\n        and not isinstance(documents[0], Document)\n    ):\n        msg = (\n            \"DocumentEmbedder expects a list of Documents as input.\"\n            \"In case you want to embed a string, please use the embed_text.\"\n        )\n        raise TypeError(msg)\n\n    if not documents:\n        # return early if we were passed an empty list\n        return {\"documents\": [], \"meta\": {}}\n\n    texts_to_embed = self._prepare_documents_to_embed(documents=documents)\n\n    embeddings, meta = self._embed_texts_batch(\n        texts_to_embed=texts_to_embed, batch_size=self.batch_size\n    )\n\n    for doc, emb in zip(documents, embeddings):\n        doc.embedding = emb\n\n    try:\n        self.validate_document_embeddings(documents)\n    except DocumentEmbeddingValidationError as e:\n        logger.error(f\"Invalid document embeddings returned by model {self.model}: {str(e)}\")\n        raise ValueError(f\"Invalid document embeddings: {str(e)}\")\n\n    return {\"documents\": documents, \"meta\": meta}\n</code></pre>"},{"location":"dynamiq/components/embedders/base/#dynamiq.components.embedders.base.BaseEmbedder.embed_text","title":"<code>embed_text(text)</code>","text":"<p>Embeds a single string using the Embedder model specified during the initialization of the component.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text string to be embedded.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing: - 'embedding': A list representing the embedding vector of the input text. - 'meta': A dictionary with metadata information about the model usage.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If input is not a string</p> <code>ValueError</code> <p>If the embedding response is invalid</p> Source code in <code>dynamiq/components/embedders/base.py</code> <pre><code>def embed_text(self, text: str) -&gt; dict:\n    \"\"\"\n    Embeds a single string using the Embedder model specified during the initialization of the component.\n\n    Args:\n        text (str): The text string to be embedded.\n\n    Returns:\n        dict: A dictionary containing:\n            - 'embedding': A list representing the embedding vector of the input text.\n            - 'meta': A dictionary with metadata information about the model usage.\n\n    Raises:\n        TypeError: If input is not a string\n        ValueError: If the embedding response is invalid\n    \"\"\"\n    if not isinstance(text, str):\n        msg = (\n            \"TextEmbedder expects a string as input.\"\n            \"In case you want to embed a list of Documents, please use the DocumentEmbedder.\"\n        )\n        raise TypeError(msg)\n\n    text_to_embed = self.prefix + text + self.suffix\n    text_to_embed = text_to_embed.replace(\"\\n\", \" \")\n    text_to_embed = self._apply_text_truncation(text_to_embed)\n\n    response = self._embedding(model=self.model, input=[text_to_embed], **self.embed_params)\n\n    meta = {\"model\": response.model, \"usage\": dict(response.usage)}\n    embedding = response.data[0][\"embedding\"]\n\n    try:\n        self.validate_embedding(embedding)\n    except InvalidEmbeddingError as e:\n        logger.error(f\"Invalid embedding returned by model {self.model}: {str(e)}\")\n        raise ValueError(f\"Invalid embedding returned by the model: {str(e)}\")\n\n    return {\"embedding\": embedding, \"meta\": meta}\n</code></pre>"},{"location":"dynamiq/components/embedders/base/#dynamiq.components.embedders.base.BaseEmbedder.validate_document_embeddings","title":"<code>validate_document_embeddings(documents)</code>  <code>staticmethod</code>","text":"<p>Validates embeddings for a list of documents.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>Any</code> <p>List of documents with embeddings</p> required <p>Raises:</p> Type Description <code>DocumentEmbeddingValidationError</code> <p>If any document embedding is invalid</p> Source code in <code>dynamiq/components/embedders/base.py</code> <pre><code>@staticmethod\ndef validate_document_embeddings(documents: Any) -&gt; None:\n    \"\"\"\n    Validates embeddings for a list of documents.\n\n    Args:\n        documents: List of documents with embeddings\n\n    Raises:\n        DocumentEmbeddingValidationError: If any document embedding is invalid\n    \"\"\"\n    if not documents:\n        return\n\n    try:\n        for i, doc in enumerate(documents):\n            if not hasattr(doc, \"embedding\") or doc.embedding is None:\n                raise DocumentEmbeddingValidationError(f\"Document at index {i} has no embedding\")\n\n            try:\n                BaseEmbedder.validate_embedding(doc.embedding)\n            except InvalidEmbeddingError as e:\n                raise DocumentEmbeddingValidationError(f\"Document at index {i}: {str(e)}\")\n    except (TypeError, AttributeError):\n        raise DocumentEmbeddingValidationError(\"Documents is not iterable or has incorrect structure\")\n</code></pre>"},{"location":"dynamiq/components/embedders/base/#dynamiq.components.embedders.base.BaseEmbedder.validate_embedding","title":"<code>validate_embedding(embedding)</code>  <code>staticmethod</code>","text":"<p>Validates that an embedding is valid.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>Any</code> <p>The embedding vector to validate</p> required <p>Raises:</p> Type Description <code>InvalidEmbeddingError</code> <p>If the embedding is None, empty, or malformed</p> Source code in <code>dynamiq/components/embedders/base.py</code> <pre><code>@staticmethod\ndef validate_embedding(embedding: Any) -&gt; None:\n    \"\"\"\n    Validates that an embedding is valid.\n\n    Args:\n        embedding: The embedding vector to validate\n\n    Raises:\n        InvalidEmbeddingError: If the embedding is None, empty, or malformed\n    \"\"\"\n    try:\n        if embedding is None:\n            raise InvalidEmbeddingError(\"Embedding is None\")\n\n        if len(embedding) == 0:\n            raise InvalidEmbeddingError(\"Embedding is empty (zero length)\")\n    except (TypeError, AttributeError):\n        raise InvalidEmbeddingError(\"Embedding has no length attribute or is not iterable\")\n</code></pre>"},{"location":"dynamiq/components/embedders/base/#dynamiq.components.embedders.base.DocumentEmbeddingValidationError","title":"<code>DocumentEmbeddingValidationError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Error raised when document embeddings validation fails.</p> Source code in <code>dynamiq/components/embedders/base.py</code> <pre><code>class DocumentEmbeddingValidationError(ValueError):\n    \"\"\"Error raised when document embeddings validation fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/components/embedders/base/#dynamiq.components.embedders.base.InvalidEmbeddingError","title":"<code>InvalidEmbeddingError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Error raised when an embedding is invalid, including empty, null, or malformed embeddings.</p> Source code in <code>dynamiq/components/embedders/base.py</code> <pre><code>class InvalidEmbeddingError(ValueError):\n    \"\"\"Error raised when an embedding is invalid, including empty, null, or malformed embeddings.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/components/embedders/bedrock/","title":"Bedrock","text":""},{"location":"dynamiq/components/embedders/bedrock/#dynamiq.components.embedders.bedrock.BedrockEmbedder","title":"<code>BedrockEmbedder</code>","text":"<p>               Bases: <code>BaseEmbedder</code></p> <p>Initializes the BedrockEmbedder component with given configuration.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>AWS</code> <p>The connection to the  Bedrock API. A new connection is created if none is provided.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to \"amazon.titan-embed-text-v1\".</p> Source code in <code>dynamiq/components/embedders/bedrock.py</code> <pre><code>class BedrockEmbedder(BaseEmbedder):\n    \"\"\"\n    Initializes the BedrockEmbedder component with given configuration.\n\n    Attributes:\n        connection (BedrockConnection): The connection to the  Bedrock API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to \"amazon.titan-embed-text-v1\".\n    \"\"\"\n    connection: BedrockConnection\n    model: str = \"amazon.titan-embed-text-v1\"\n\n    def __init__(self, **kwargs):\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = BedrockConnection()\n        super().__init__(**kwargs)\n\n    @property\n    def embed_params(self) -&gt; dict:\n        params = super().embed_params\n        if \"cohere\" in self.model:\n            params[\"input_type\"] = self.input_type\n            if self.truncate:\n                params[\"truncate\"] = self.truncate\n\n        return params\n</code></pre>"},{"location":"dynamiq/components/embedders/cohere/","title":"Cohere","text":""},{"location":"dynamiq/components/embedders/cohere/#dynamiq.components.embedders.cohere.CohereEmbedder","title":"<code>CohereEmbedder</code>","text":"<p>               Bases: <code>BaseEmbedder</code></p> <p>Initializes the CohereEmbedder component with given configuration.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Cohere</code> <p>The connection to the  Cohere API. A new connection is created if none is provided.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to \"cohere/embed-english-v2.0\"</p> <code>input_type</code> <code>str</code> <p>Specifies the type of input you're giving to the model. Defaults to \"search_query\"</p> Source code in <code>dynamiq/components/embedders/cohere.py</code> <pre><code>class CohereEmbedder(BaseEmbedder):\n    \"\"\"\n    Initializes the CohereEmbedder component with given configuration.\n\n    Attributes:\n        connection (CohereConnection): The connection to the  Cohere API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to \"cohere/embed-english-v2.0\"\n        input_type (str): Specifies the type of input you're giving to the model. Defaults to \"search_query\"\n    \"\"\"\n    connection: CohereConnection\n    model: str = \"cohere/embed-english-v2.0\"\n    input_type: str = \"search_query\"\n\n    def __init__(self, **kwargs):\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = CohereConnection()\n        super().__init__(**kwargs)\n\n    @property\n    def embed_params(self) -&gt; dict:\n        params = super().embed_params\n        params[\"input_type\"] = self.input_type\n        if self.truncate:\n            params[\"truncate\"] = self.truncate\n\n        return params\n</code></pre>"},{"location":"dynamiq/components/embedders/gemini/","title":"Gemini","text":""},{"location":"dynamiq/components/embedders/gemini/#dynamiq.components.embedders.gemini.GeminiEmbedder","title":"<code>GeminiEmbedder</code>","text":"<p>               Bases: <code>BaseEmbedder</code></p> <p>Initializes the GeminiEmbedder component with given configuration.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Gemini</code> <p>The connection to the Gemini API. A new connection is created if none is provided.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to \"gemini/gemini-embedding-exp-03-07\"</p> <code>input_type</code> <code>str</code> <p>Specifies the type of embedding task. Defaults to \"search_query\"</p> Source code in <code>dynamiq/components/embedders/gemini.py</code> <pre><code>class GeminiEmbedder(BaseEmbedder):\n    \"\"\"\n    Initializes the GeminiEmbedder component with given configuration.\n\n    Attributes:\n        connection (GeminiConnection): The connection to the Gemini API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to \"gemini/gemini-embedding-exp-03-07\"\n        input_type (str): Specifies the type of embedding task. Defaults to \"search_query\"\n    \"\"\"\n\n    connection: GeminiConnection\n    model: str = \"gemini/gemini-embedding-exp-03-07\"\n    input_type: str = \"search_query\"\n\n    def __init__(self, **kwargs):\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = GeminiConnection()\n        super().__init__(**kwargs)\n\n    @property\n    def embed_params(self) -&gt; dict:\n        \"\"\"\n        Returns the embedding parameters for the Gemini API.\n\n        Returns:\n            dict: A dictionary containing the parameters for the embedding call.\n        \"\"\"\n        params = super().embed_params\n\n        input_to_task_mapping = {\n            \"search_document\": \"RETRIEVAL_DOCUMENT\",\n            \"search_query\": \"RETRIEVAL_QUERY\",\n            \"classification\": \"CLASSIFICATION\",\n            \"clustering\": \"CLUSTERING\",\n        }\n        params[\"task_type\"] = input_to_task_mapping.get(self.input_type)\n\n        if self.truncate:\n            params[\"truncate\"] = self.truncate\n\n        if self.dimensions:\n            params[\"dimensions\"] = self.dimensions\n\n        return params\n</code></pre>"},{"location":"dynamiq/components/embedders/gemini/#dynamiq.components.embedders.gemini.GeminiEmbedder.embed_params","title":"<code>embed_params: dict</code>  <code>property</code>","text":"<p>Returns the embedding parameters for the Gemini API.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the parameters for the embedding call.</p>"},{"location":"dynamiq/components/embedders/huggingface/","title":"Huggingface","text":""},{"location":"dynamiq/components/embedders/huggingface/#dynamiq.components.embedders.huggingface.HuggingFaceEmbedder","title":"<code>HuggingFaceEmbedder</code>","text":"<p>               Bases: <code>BaseEmbedder</code></p> <p>Initializes the HuggingFaceEmbedder component with given configuration.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>HuggingFace</code> <p>The connection to the  HuggingFace API. A new connection is created if none is provided.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to \"huggingface/BAAI/bge-large-zh\"</p> Source code in <code>dynamiq/components/embedders/huggingface.py</code> <pre><code>class HuggingFaceEmbedder(BaseEmbedder):\n    \"\"\"\n    Initializes the HuggingFaceEmbedder component with given configuration.\n\n    Attributes:\n        connection (HuggingFaceConnection): The connection to the  HuggingFace API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to \"huggingface/BAAI/bge-large-zh\"\n    \"\"\"\n\n    API_BASE_URL: ClassVar[str] = \"https://api-inference.huggingface.co/models\"\n    connection: HuggingFaceConnection\n    model: str = \"huggingface/BAAI/bge-large-zh\"\n\n    def __init__(self, **kwargs):\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = HuggingFaceConnection()\n        super().__init__(**kwargs)\n\n    @property\n    def embed_params(self) -&gt; dict:\n        params = super().embed_params\n\n        if self.model.startswith(\"huggingface/\"):\n            model_id = self.model[len(\"huggingface/\") :]\n        else:\n            model_id = self.model\n\n        params[\"api_base\"] = f\"{self.API_BASE_URL}/{model_id}\"\n\n        return params\n\n    def embed_text(self, text: str) -&gt; dict:\n        \"\"\"\n        Embeds a single string using the Embedder model specified during the initialization of the component.\n\n        Args:\n            text (str): The text string to be embedded.\n\n        Returns:\n            dict: A dictionary containing:\n                - 'embedding': A list representing the embedding vector of the input text.\n                - 'meta': A dictionary with metadata information about the model usage.\n\n        Raises:\n            TypeError: If input is not a string\n            ValueError: If the embedding response is invalid\n        \"\"\"\n        if not isinstance(text, str):\n            msg = (\n                \"TextEmbedder expects a string as input.\"\n                \"In case you want to embed a list of Documents, please use the DocumentEmbedder.\"\n            )\n            raise TypeError(msg)\n\n        text_to_embed = f\"{self.prefix}{text}{self.suffix}\"\n        text_to_embed = text_to_embed.replace(\"\\n\", \" \")\n\n        response = self._embedding(model=self.model, input=text_to_embed, **self.embed_params)\n\n        meta = {\"model\": response.model, \"usage\": dict(response.usage)}\n        embedding = response.data[0][\"embedding\"]\n\n        try:\n            self.validate_embedding(embedding)\n        except InvalidEmbeddingError as e:\n            logger.error(f\"Invalid embedding returned by model {self.model}: {str(e)}\")\n            raise ValueError(f\"Invalid embedding returned by the model: {str(e)}\")\n\n        return {\"embedding\": embedding, \"meta\": meta}\n\n    def _embed_texts_batch(\n        self, texts_to_embed: list[str], batch_size: int\n    ) -&gt; tuple[list[list[float]], dict[str, Any]]:\n        \"\"\"\n        Embed a list of texts one by one (non-batched API).\n        \"\"\"\n        all_embeddings = []\n        meta: dict[str, Any] = {}\n        embed_params = self.embed_params\n\n        for i in range(0, len(texts_to_embed), batch_size):\n            batch = texts_to_embed[i : i + batch_size]\n\n            for text in batch:\n                response = self._embedding(model=self.model, input=text, **embed_params)\n\n                embedding = response.data[0][\"embedding\"]\n                all_embeddings.append(embedding)\n\n                if \"model\" not in meta:\n                    meta[\"model\"] = response.model\n\n                if \"usage\" not in meta:\n                    meta[\"usage\"] = dict(response.usage)\n                else:\n                    meta[\"usage\"][\"prompt_tokens\"] += response.usage.prompt_tokens\n                    meta[\"usage\"][\"total_tokens\"] += response.usage.total_tokens\n\n        return all_embeddings, meta\n</code></pre>"},{"location":"dynamiq/components/embedders/huggingface/#dynamiq.components.embedders.huggingface.HuggingFaceEmbedder.embed_text","title":"<code>embed_text(text)</code>","text":"<p>Embeds a single string using the Embedder model specified during the initialization of the component.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text string to be embedded.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing: - 'embedding': A list representing the embedding vector of the input text. - 'meta': A dictionary with metadata information about the model usage.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If input is not a string</p> <code>ValueError</code> <p>If the embedding response is invalid</p> Source code in <code>dynamiq/components/embedders/huggingface.py</code> <pre><code>def embed_text(self, text: str) -&gt; dict:\n    \"\"\"\n    Embeds a single string using the Embedder model specified during the initialization of the component.\n\n    Args:\n        text (str): The text string to be embedded.\n\n    Returns:\n        dict: A dictionary containing:\n            - 'embedding': A list representing the embedding vector of the input text.\n            - 'meta': A dictionary with metadata information about the model usage.\n\n    Raises:\n        TypeError: If input is not a string\n        ValueError: If the embedding response is invalid\n    \"\"\"\n    if not isinstance(text, str):\n        msg = (\n            \"TextEmbedder expects a string as input.\"\n            \"In case you want to embed a list of Documents, please use the DocumentEmbedder.\"\n        )\n        raise TypeError(msg)\n\n    text_to_embed = f\"{self.prefix}{text}{self.suffix}\"\n    text_to_embed = text_to_embed.replace(\"\\n\", \" \")\n\n    response = self._embedding(model=self.model, input=text_to_embed, **self.embed_params)\n\n    meta = {\"model\": response.model, \"usage\": dict(response.usage)}\n    embedding = response.data[0][\"embedding\"]\n\n    try:\n        self.validate_embedding(embedding)\n    except InvalidEmbeddingError as e:\n        logger.error(f\"Invalid embedding returned by model {self.model}: {str(e)}\")\n        raise ValueError(f\"Invalid embedding returned by the model: {str(e)}\")\n\n    return {\"embedding\": embedding, \"meta\": meta}\n</code></pre>"},{"location":"dynamiq/components/embedders/mistral/","title":"Mistral","text":""},{"location":"dynamiq/components/embedders/mistral/#dynamiq.components.embedders.mistral.MistralEmbedder","title":"<code>MistralEmbedder</code>","text":"<p>               Bases: <code>BaseEmbedder</code></p> <p>Initializes the MistralEmbedder component with given configuration.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Mistral</code> <p>The connection to the  Mistral API. A new connection is created if none is provided.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to \"mistral/mistral-embed\"</p> Source code in <code>dynamiq/components/embedders/mistral.py</code> <pre><code>class MistralEmbedder(BaseEmbedder):\n    \"\"\"\n    Initializes the MistralEmbedder component with given configuration.\n\n    Attributes:\n        connection (MistralConnection): The connection to the  Mistral API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to \"mistral/mistral-embed\"\n    \"\"\"\n    connection: MistralConnection\n    model: str = \"mistral/mistral-embed\"\n\n    def __init__(self, **kwargs):\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = MistralConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/components/embedders/openai/","title":"Openai","text":""},{"location":"dynamiq/components/embedders/openai/#dynamiq.components.embedders.openai.OpenAIEmbedder","title":"<code>OpenAIEmbedder</code>","text":"<p>               Bases: <code>BaseEmbedder</code></p> <p>Provides functionality to compute embeddings for documents using OpenAI's models.</p> <p>This class leverages the OpenAI API to generate embeddings for given text documents. It's designed to work with instances of the Document class from the dynamiq package. The embeddings generated can be used for tasks such as similarity search, clustering, and more.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>OpenAI</code> <p>The connection to the  OpenAI API. A new connection is created if none is provided.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to \"text-embedding-3-small\"</p> Example <p>from dynamiq.types import Document from dynamiq.components.embedders.openai import OpenAIEmbedder</p> <p>doc = Document(content=\"I love pizza!\")</p> <p>document_embedder = OpenAIEmbedder()</p> <p>result = document_embedder.run([doc]) print(result\"documents\".embedding) [0.017020374536514282, -0.023255806416273117, ...]</p> Note <p>An OpenAI API key must be provided either via environment variables or when creating an instance of OpenAIDocumentEmbedder through the OpenAIConnection.</p> Source code in <code>dynamiq/components/embedders/openai.py</code> <pre><code>class OpenAIEmbedder(BaseEmbedder):\n    \"\"\"\n    Provides functionality to compute embeddings for documents using OpenAI's models.\n\n    This class leverages the OpenAI API to generate embeddings for given text documents. It's designed to work\n    with instances of the Document class from the dynamiq package. The embeddings generated can be used for tasks\n    such as similarity search, clustering, and more.\n\n    Attributes:\n        connection (OpenAIConnection): The connection to the  OpenAI API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to \"text-embedding-3-small\"\n\n\n    Example:\n        &gt;&gt;&gt; from dynamiq.types import Document\n        &gt;&gt;&gt; from dynamiq.components.embedders.openai import OpenAIEmbedder\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; doc = Document(content=\"I love pizza!\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; document_embedder = OpenAIEmbedder()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; result = document_embedder.run([doc])\n        &gt;&gt;&gt; print(result[\"documents\"][0].embedding)\n        [0.017020374536514282, -0.023255806416273117, ...]\n\n    Note:\n        An OpenAI API key must be provided either via environment variables or when creating an instance of\n        OpenAIDocumentEmbedder through the OpenAIConnection.\n    \"\"\"\n\n    connection: OpenAIConnection | None = None\n    model: str = \"text-embedding-3-small\"\n\n    def __init__(self, **kwargs):\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = OpenAIConnection()\n        super().__init__(**kwargs)\n\n    @property\n    def embed_params(self) -&gt; dict:\n        params = super().embed_params\n        if self.dimensions:\n            params[\"dimensions\"] = self.dimensions\n\n        return params\n</code></pre>"},{"location":"dynamiq/components/embedders/vertexai/","title":"Vertexai","text":""},{"location":"dynamiq/components/embedders/vertexai/#dynamiq.components.embedders.vertexai.VertexAIEmbedder","title":"<code>VertexAIEmbedder</code>","text":"<p>               Bases: <code>BaseEmbedder</code></p> <p>An embedder for generating embeddings using Vertex AI.</p> <p>This component manages a connection to Vertex AI and provides methods to generate embeddings for text or documents.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>VertexAI</code> <p>The Vertex AI connection instance. If not provided, a new connection is created.</p> <code>model</code> <code>str</code> <p>The Vertex AI embedding model name. Defaults to \"vertex_ai/text-embedding-005\".</p> <code>input_type</code> <code>str</code> <p>Specifies the embedding task type. Can be \"search_query\", \"search_document\", \"classification\", or \"clustering\".</p> Source code in <code>dynamiq/components/embedders/vertexai.py</code> <pre><code>class VertexAIEmbedder(BaseEmbedder):\n    \"\"\"\n    An embedder for generating embeddings using Vertex AI.\n\n    This component manages a connection to Vertex AI and provides\n    methods to generate embeddings for text or documents.\n\n    Attributes:\n        connection (VertexAIConnection): The Vertex AI connection instance.\n            If not provided, a new connection is created.\n        model (str): The Vertex AI embedding model name.\n            Defaults to \"vertex_ai/text-embedding-005\".\n        input_type (str): Specifies the embedding task type.\n            Can be \"search_query\", \"search_document\", \"classification\", or \"clustering\".\n    \"\"\"\n\n    connection: VertexAIConnection\n    model: str = \"vertex_ai/text-embedding-005\"\n    input_type: str = \"search_query\"\n\n    def __init__(\n        self,\n        *,\n        connection: VertexAIConnection | None = None,\n        model: str | None = None,\n        input_type: str | None = None,\n        **kwargs: Any\n    ):\n        \"\"\"\n        Initialize the VertexAIEmbedder.\n\n        Args:\n            connection: An existing Vertex AI connection.\n            model: Override the default embedding model.\n            input_type: Override the default embedding task type.\n            **kwargs: Additional BaseEmbedder keyword arguments.\n        \"\"\"\n        if connection is None:\n            connection = VertexAIConnection()\n        super().__init__(connection=connection, **kwargs)\n\n        if model:\n            self.model = model\n        if input_type:\n            self.input_type = input_type\n\n    @property\n    def embed_params(self) -&gt; dict:\n        \"\"\"\n        Build the parameters for the embedding request.\n\n        Returns:\n            A dictionary of parameters including task type,\n            truncate length, and embedding dimensions.\n        \"\"\"\n        # Copy base parameters to avoid side effects\n        params = super().embed_params.copy()\n\n        # Map our input types to Vertex AI task enums\n        task_mapping = {\n            \"search_query\": \"RETRIEVAL_QUERY\",\n            \"search_document\": \"RETRIEVAL_DOCUMENT\",\n            \"classification\": \"CLASSIFICATION\",\n            \"clustering\": \"CLUSTERING\",\n        }\n        params[\"task_type\"] = task_mapping.get(self.input_type, self.input_type)\n\n        if self.truncate is not None:\n            params[\"truncate\"] = self.truncate\n        if self.dimensions is not None:\n            params[\"dimensions\"] = self.dimensions\n\n        return params\n</code></pre>"},{"location":"dynamiq/components/embedders/vertexai/#dynamiq.components.embedders.vertexai.VertexAIEmbedder.embed_params","title":"<code>embed_params: dict</code>  <code>property</code>","text":"<p>Build the parameters for the embedding request.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of parameters including task type,</p> <code>dict</code> <p>truncate length, and embedding dimensions.</p>"},{"location":"dynamiq/components/embedders/vertexai/#dynamiq.components.embedders.vertexai.VertexAIEmbedder.__init__","title":"<code>__init__(*, connection=None, model=None, input_type=None, **kwargs)</code>","text":"<p>Initialize the VertexAIEmbedder.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>VertexAI | None</code> <p>An existing Vertex AI connection.</p> <code>None</code> <code>model</code> <code>str | None</code> <p>Override the default embedding model.</p> <code>None</code> <code>input_type</code> <code>str | None</code> <p>Override the default embedding task type.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional BaseEmbedder keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/components/embedders/vertexai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    connection: VertexAIConnection | None = None,\n    model: str | None = None,\n    input_type: str | None = None,\n    **kwargs: Any\n):\n    \"\"\"\n    Initialize the VertexAIEmbedder.\n\n    Args:\n        connection: An existing Vertex AI connection.\n        model: Override the default embedding model.\n        input_type: Override the default embedding task type.\n        **kwargs: Additional BaseEmbedder keyword arguments.\n    \"\"\"\n    if connection is None:\n        connection = VertexAIConnection()\n    super().__init__(connection=connection, **kwargs)\n\n    if model:\n        self.model = model\n    if input_type:\n        self.input_type = input_type\n</code></pre>"},{"location":"dynamiq/components/embedders/watsonx/","title":"Watsonx","text":""},{"location":"dynamiq/components/embedders/watsonx/#dynamiq.components.embedders.watsonx.WatsonXEmbedder","title":"<code>WatsonXEmbedder</code>","text":"<p>               Bases: <code>BaseEmbedder</code></p> <p>Initializes the WatsonXEmbedder component with given configuration.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>WatsonX</code> <p>The connection to the  WatsonX API. A new connection is created if none is provided.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to \"watsonx/ibm/slate-30m-english-rtrvr\"</p> Source code in <code>dynamiq/components/embedders/watsonx.py</code> <pre><code>class WatsonXEmbedder(BaseEmbedder):\n    \"\"\"\n    Initializes the WatsonXEmbedder component with given configuration.\n\n    Attributes:\n        connection (WatsonXConnection): The connection to the  WatsonX API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to \"watsonx/ibm/slate-30m-english-rtrvr\"\n    \"\"\"\n    connection: WatsonXConnection\n    model: str = \"watsonx/ibm/slate-30m-english-rtrvr\"\n\n    def __init__(self, **kwargs):\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = WatsonXConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/components/retrievers/chroma/","title":"Chroma","text":""},{"location":"dynamiq/components/retrievers/chroma/#dynamiq.components.retrievers.chroma.ChromaDocumentRetriever","title":"<code>ChromaDocumentRetriever</code>","text":"<p>Document Retriever using Chroma.</p> Source code in <code>dynamiq/components/retrievers/chroma.py</code> <pre><code>class ChromaDocumentRetriever:\n    \"\"\"\n    Document Retriever using Chroma.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        vector_store: ChromaVectorStore,\n        filters: dict[str, Any] | None = None,\n        top_k: int = 10,\n        similarity_threshold: float | None = None,\n    ):\n        \"\"\"\n        Initializes a component for retrieving documents from a Chroma vector store with optional filtering.\n\n        Args:\n            vector_store (ChromaVectorStore): An instance of ChromaVectorStore to interface with Chroma vectors.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            top_k (int): The maximum number of documents to return. Defaults to 10.\n\n        Raises:\n            ValueError: If the `vector_store` is not an instance of `ChromaVectorStore`.\n\n        This initializer checks if the `vector_store` provided is an instance of the expected `ChromaVectorStore`\n        class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n        \"\"\"\n        if not isinstance(vector_store, ChromaVectorStore):\n            msg = \"document_store must be an instance of ChromaVectorStore\"\n            raise ValueError(msg)\n\n        self.vector_store = vector_store\n        self.filters = filters or {}\n        self.top_k = top_k\n        self.similarity_threshold = similarity_threshold\n\n    def run(\n        self,\n        query_embedding: list[float],\n        exclude_document_embeddings: bool = True,\n        top_k: int | None = None,\n        filters: dict[str, Any] | None = None,\n        similarity_threshold: float | None = None,\n    ) -&gt; dict[str, list[Document]]:\n        \"\"\"\n        Retrieves documents from the ChromaVectorStore that are similar to the provided query embedding.\n\n        Args:\n            query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n            retrieved.\n            exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n            documents from the output.\n            top_k (int, optional): The maximum number of documents to return. Defaults to None.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n\n        Returns:\n            List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n        \"\"\"\n        query_embeddings = [query_embedding]\n        top_k = top_k or self.top_k\n        filters = filters or self.filters\n\n        docs = self.vector_store.search_embeddings(\n            query_embeddings=query_embeddings,\n            filters=filters,\n            top_k=top_k,\n        )[0]\n\n        threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n        docs = filter_documents_by_threshold(docs, threshold, higher_is_better=False)\n\n        if exclude_document_embeddings:\n            for doc in docs:\n                doc.embedding = None\n        return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/chroma/#dynamiq.components.retrievers.chroma.ChromaDocumentRetriever.__init__","title":"<code>__init__(*, vector_store, filters=None, top_k=10, similarity_threshold=None)</code>","text":"<p>Initializes a component for retrieving documents from a Chroma vector store with optional filtering.</p> <p>Parameters:</p> Name Type Description Default <code>vector_store</code> <code>ChromaVectorStore</code> <p>An instance of ChromaVectorStore to interface with Chroma vectors.</p> required <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to 10.</p> <code>10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>vector_store</code> is not an instance of <code>ChromaVectorStore</code>.</p> <p>This initializer checks if the <code>vector_store</code> provided is an instance of the expected <code>ChromaVectorStore</code> class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.</p> Source code in <code>dynamiq/components/retrievers/chroma.py</code> <pre><code>def __init__(\n    self,\n    *,\n    vector_store: ChromaVectorStore,\n    filters: dict[str, Any] | None = None,\n    top_k: int = 10,\n    similarity_threshold: float | None = None,\n):\n    \"\"\"\n    Initializes a component for retrieving documents from a Chroma vector store with optional filtering.\n\n    Args:\n        vector_store (ChromaVectorStore): An instance of ChromaVectorStore to interface with Chroma vectors.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        top_k (int): The maximum number of documents to return. Defaults to 10.\n\n    Raises:\n        ValueError: If the `vector_store` is not an instance of `ChromaVectorStore`.\n\n    This initializer checks if the `vector_store` provided is an instance of the expected `ChromaVectorStore`\n    class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n    \"\"\"\n    if not isinstance(vector_store, ChromaVectorStore):\n        msg = \"document_store must be an instance of ChromaVectorStore\"\n        raise ValueError(msg)\n\n    self.vector_store = vector_store\n    self.filters = filters or {}\n    self.top_k = top_k\n    self.similarity_threshold = similarity_threshold\n</code></pre>"},{"location":"dynamiq/components/retrievers/chroma/#dynamiq.components.retrievers.chroma.ChromaDocumentRetriever.run","title":"<code>run(query_embedding, exclude_document_embeddings=True, top_k=None, filters=None, similarity_threshold=None)</code>","text":"<p>Retrieves documents from the ChromaVectorStore that are similar to the provided query embedding.</p> <p>Parameters:</p> Name Type Description Default <code>query_embedding</code> <code>List[float]</code> <p>The embedding vector of the query for which similar documents are to be</p> required <code>exclude_document_embeddings</code> <code>bool</code> <p>Specifies whether to exclude the embeddings of the retrieved</p> <code>True</code> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to None.</p> <code>None</code> <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, list[Document]]</code> <p>List[Document]: A list of Document instances sorted by their relevance to the query_embedding.</p> Source code in <code>dynamiq/components/retrievers/chroma.py</code> <pre><code>def run(\n    self,\n    query_embedding: list[float],\n    exclude_document_embeddings: bool = True,\n    top_k: int | None = None,\n    filters: dict[str, Any] | None = None,\n    similarity_threshold: float | None = None,\n) -&gt; dict[str, list[Document]]:\n    \"\"\"\n    Retrieves documents from the ChromaVectorStore that are similar to the provided query embedding.\n\n    Args:\n        query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n        retrieved.\n        exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n        documents from the output.\n        top_k (int, optional): The maximum number of documents to return. Defaults to None.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n\n    Returns:\n        List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n    \"\"\"\n    query_embeddings = [query_embedding]\n    top_k = top_k or self.top_k\n    filters = filters or self.filters\n\n    docs = self.vector_store.search_embeddings(\n        query_embeddings=query_embeddings,\n        filters=filters,\n        top_k=top_k,\n    )[0]\n\n    threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n    docs = filter_documents_by_threshold(docs, threshold, higher_is_better=False)\n\n    if exclude_document_embeddings:\n        for doc in docs:\n            doc.embedding = None\n    return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/elasticsearch/","title":"Elasticsearch","text":""},{"location":"dynamiq/components/retrievers/elasticsearch/#dynamiq.components.retrievers.elasticsearch.ElasticsearchDocumentRetriever","title":"<code>ElasticsearchDocumentRetriever</code>","text":"<p>Document Retriever using Elasticsearch.</p> Source code in <code>dynamiq/components/retrievers/elasticsearch.py</code> <pre><code>class ElasticsearchDocumentRetriever:\n    \"\"\"Document Retriever using Elasticsearch.\"\"\"\n\n    def __init__(\n        self,\n        *,\n        vector_store: ElasticsearchVectorStore,\n        filters: dict[str, Any] | None = None,\n        top_k: int = 10,\n        similarity_threshold: float | None = None,\n    ):\n        \"\"\"\n        Initialize ElasticsearchDocumentRetriever.\n\n        Args:\n            vector_store (ElasticsearchVectorStore): An instance of ElasticsearchVectorStore.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            top_k (int): Maximum number of documents to return. Defaults to 10.\n\n        Raises:\n            ValueError: If `vector_store` is not an instance of ElasticsearchVectorStore.\n        \"\"\"\n        if not isinstance(vector_store, ElasticsearchVectorStore):\n            raise ValueError(\"vector_store must be an instance of ElasticsearchVectorStore\")\n\n        self.vector_store = vector_store\n        self.filters = filters or {}\n        self.top_k = top_k\n        self.similarity_threshold = similarity_threshold\n\n    def _higher_is_better(self) -&gt; bool:\n        return self.vector_store.similarity != ElasticsearchSimilarityMetric.L2\n\n    def run(\n        self,\n        query_embedding: list[float],\n        exclude_document_embeddings: bool = True,\n        top_k: int | None = None,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n        scale_scores: bool = False,\n        similarity_threshold: float | None = None,\n    ) -&gt; dict[str, list[Document]]:\n        \"\"\"\n        Retrieve documents from ElasticsearchVectorStore.\n\n        Args:\n            query_embedding (list[float]): Vector query for similarity search.\n            exclude_document_embeddings (bool): Whether to exclude embeddings in results. Defaults to True.\n            top_k (Optional[int]): Maximum number of documents to return. Defaults to None.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            content_key (Optional[str]): Field used to store content. Defaults to None.\n            embedding_key (Optional[str]): Field used to store vector. Defaults to None.\n            scale_scores (bool): Whether to scale scores to the 0-1 range. Defaults to False.\n\n        Returns:\n            dict[str, list[Document]]: A dictionary containing a list of retrieved documents.\n\n        Raises:\n            ValueError: If the query format is invalid.\n        \"\"\"\n        top_k = top_k or self.top_k\n        filters = filters or self.filters\n\n        docs = self.vector_store._embedding_retrieval(\n            query_embedding=query_embedding,\n            filters=filters,\n            top_k=top_k,\n            exclude_document_embeddings=exclude_document_embeddings,\n            scale_scores=scale_scores,\n            content_key=content_key,\n            embedding_key=embedding_key,\n        )\n\n        threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n        docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n        logger.debug(f\"Retrieved {len(docs)} documents from Elasticsearch Vector Store\")\n        return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/elasticsearch/#dynamiq.components.retrievers.elasticsearch.ElasticsearchDocumentRetriever.__init__","title":"<code>__init__(*, vector_store, filters=None, top_k=10, similarity_threshold=None)</code>","text":"<p>Initialize ElasticsearchDocumentRetriever.</p> <p>Parameters:</p> Name Type Description Default <code>vector_store</code> <code>ElasticsearchVectorStore</code> <p>An instance of ElasticsearchVectorStore.</p> required <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>top_k</code> <code>int</code> <p>Maximum number of documents to return. Defaults to 10.</p> <code>10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>vector_store</code> is not an instance of ElasticsearchVectorStore.</p> Source code in <code>dynamiq/components/retrievers/elasticsearch.py</code> <pre><code>def __init__(\n    self,\n    *,\n    vector_store: ElasticsearchVectorStore,\n    filters: dict[str, Any] | None = None,\n    top_k: int = 10,\n    similarity_threshold: float | None = None,\n):\n    \"\"\"\n    Initialize ElasticsearchDocumentRetriever.\n\n    Args:\n        vector_store (ElasticsearchVectorStore): An instance of ElasticsearchVectorStore.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        top_k (int): Maximum number of documents to return. Defaults to 10.\n\n    Raises:\n        ValueError: If `vector_store` is not an instance of ElasticsearchVectorStore.\n    \"\"\"\n    if not isinstance(vector_store, ElasticsearchVectorStore):\n        raise ValueError(\"vector_store must be an instance of ElasticsearchVectorStore\")\n\n    self.vector_store = vector_store\n    self.filters = filters or {}\n    self.top_k = top_k\n    self.similarity_threshold = similarity_threshold\n</code></pre>"},{"location":"dynamiq/components/retrievers/elasticsearch/#dynamiq.components.retrievers.elasticsearch.ElasticsearchDocumentRetriever.run","title":"<code>run(query_embedding, exclude_document_embeddings=True, top_k=None, filters=None, content_key=None, embedding_key=None, scale_scores=False, similarity_threshold=None)</code>","text":"<p>Retrieve documents from ElasticsearchVectorStore.</p> <p>Parameters:</p> Name Type Description Default <code>query_embedding</code> <code>list[float]</code> <p>Vector query for similarity search.</p> required <code>exclude_document_embeddings</code> <code>bool</code> <p>Whether to exclude embeddings in results. Defaults to True.</p> <code>True</code> <code>top_k</code> <code>Optional[int]</code> <p>Maximum number of documents to return. Defaults to None.</p> <code>None</code> <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>Field used to store content. Defaults to None.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>Field used to store vector. Defaults to None.</p> <code>None</code> <code>scale_scores</code> <code>bool</code> <p>Whether to scale scores to the 0-1 range. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, list[Document]]</code> <p>dict[str, list[Document]]: A dictionary containing a list of retrieved documents.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the query format is invalid.</p> Source code in <code>dynamiq/components/retrievers/elasticsearch.py</code> <pre><code>def run(\n    self,\n    query_embedding: list[float],\n    exclude_document_embeddings: bool = True,\n    top_k: int | None = None,\n    filters: dict[str, Any] | None = None,\n    content_key: str | None = None,\n    embedding_key: str | None = None,\n    scale_scores: bool = False,\n    similarity_threshold: float | None = None,\n) -&gt; dict[str, list[Document]]:\n    \"\"\"\n    Retrieve documents from ElasticsearchVectorStore.\n\n    Args:\n        query_embedding (list[float]): Vector query for similarity search.\n        exclude_document_embeddings (bool): Whether to exclude embeddings in results. Defaults to True.\n        top_k (Optional[int]): Maximum number of documents to return. Defaults to None.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        content_key (Optional[str]): Field used to store content. Defaults to None.\n        embedding_key (Optional[str]): Field used to store vector. Defaults to None.\n        scale_scores (bool): Whether to scale scores to the 0-1 range. Defaults to False.\n\n    Returns:\n        dict[str, list[Document]]: A dictionary containing a list of retrieved documents.\n\n    Raises:\n        ValueError: If the query format is invalid.\n    \"\"\"\n    top_k = top_k or self.top_k\n    filters = filters or self.filters\n\n    docs = self.vector_store._embedding_retrieval(\n        query_embedding=query_embedding,\n        filters=filters,\n        top_k=top_k,\n        exclude_document_embeddings=exclude_document_embeddings,\n        scale_scores=scale_scores,\n        content_key=content_key,\n        embedding_key=embedding_key,\n    )\n\n    threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n    docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n    logger.debug(f\"Retrieved {len(docs)} documents from Elasticsearch Vector Store\")\n    return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/milvus/","title":"Milvus","text":""},{"location":"dynamiq/components/retrievers/milvus/#dynamiq.components.retrievers.milvus.MilvusDocumentRetriever","title":"<code>MilvusDocumentRetriever</code>","text":"<p>Document Retriever using Milvus.</p> Source code in <code>dynamiq/components/retrievers/milvus.py</code> <pre><code>class MilvusDocumentRetriever:\n    \"\"\"\n    Document Retriever using Milvus.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        vector_store: MilvusVectorStore,\n        filters: dict[str, Any] | None = None,\n        top_k: int = 10,\n        similarity_threshold: float | None = None,\n    ):\n        \"\"\"\n        Initializes a component for retrieving documents from a Milvus vector store with optional filtering.\n\n        Args:\n            vector_store (MilvusVectorStore): An instance of MilvusVectorStore to interface with Milvus vectors.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            top_k (int): The maximum number of documents to return. Defaults to 10.\n\n        Raises:\n            ValueError: If the `vector_store` is not an instance of `MilvusVectorStore`.\n        \"\"\"\n        if not isinstance(vector_store, MilvusVectorStore):\n            raise ValueError(\"vector_store must be an instance of MilvusVectorStore\")\n\n        self.vector_store = vector_store\n        self.filters = filters or {}\n        self.top_k = top_k\n        self.similarity_threshold = similarity_threshold\n\n    def _higher_is_better(self) -&gt; bool:\n        metric = (self.vector_store.metric_type or \"\").upper()\n        return metric not in {\"L2\", \"EUCLIDEAN\"}\n\n    def run(\n        self,\n        query_embedding: list[float],\n        query: str | None = None,\n        exclude_document_embeddings: bool = True,\n        top_k: int | None = None,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n        similarity_threshold: float | None = None,\n    ) -&gt; dict[str, list[Document]]:\n        \"\"\"\n        Retrieves documents from the MilvusVectorStore that are similar to the provided query embedding.\n\n        Args:\n            query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n            retrieved.\n            query(Optional[str]): The query string to search for (when using hybrid search). Defaults to None.\n            exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n            documents from the output.\n            top_k (int, optional): The maximum number of documents to return. Defaults to None.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store vector in the storage.\n\n        Returns:\n            Dict[str, List[Document]]: A dictionary containing a list of Document instances sorted by their relevance\n            to the query_embedding.\n        \"\"\"\n        query_embeddings = [query_embedding]\n        top_k = top_k or self.top_k\n        filters = filters or self.filters\n\n        if query is not None:\n            docs = self.vector_store._hybrid_retrieval(\n                query=query,\n                query_embeddings=query_embeddings,\n                top_k=top_k,\n                content_key=content_key,\n                embedding_key=embedding_key,\n                return_embeddings=not exclude_document_embeddings,\n            )\n        else:\n            docs = self.vector_store._embedding_retrieval(\n                query_embeddings=query_embeddings,\n                filters=filters,\n                top_k=top_k,\n                content_key=content_key,\n                embedding_key=embedding_key,\n                return_embeddings=not exclude_document_embeddings,\n            )\n\n        threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n        docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n        return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/milvus/#dynamiq.components.retrievers.milvus.MilvusDocumentRetriever.__init__","title":"<code>__init__(*, vector_store, filters=None, top_k=10, similarity_threshold=None)</code>","text":"<p>Initializes a component for retrieving documents from a Milvus vector store with optional filtering.</p> <p>Parameters:</p> Name Type Description Default <code>vector_store</code> <code>MilvusVectorStore</code> <p>An instance of MilvusVectorStore to interface with Milvus vectors.</p> required <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to 10.</p> <code>10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>vector_store</code> is not an instance of <code>MilvusVectorStore</code>.</p> Source code in <code>dynamiq/components/retrievers/milvus.py</code> <pre><code>def __init__(\n    self,\n    *,\n    vector_store: MilvusVectorStore,\n    filters: dict[str, Any] | None = None,\n    top_k: int = 10,\n    similarity_threshold: float | None = None,\n):\n    \"\"\"\n    Initializes a component for retrieving documents from a Milvus vector store with optional filtering.\n\n    Args:\n        vector_store (MilvusVectorStore): An instance of MilvusVectorStore to interface with Milvus vectors.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        top_k (int): The maximum number of documents to return. Defaults to 10.\n\n    Raises:\n        ValueError: If the `vector_store` is not an instance of `MilvusVectorStore`.\n    \"\"\"\n    if not isinstance(vector_store, MilvusVectorStore):\n        raise ValueError(\"vector_store must be an instance of MilvusVectorStore\")\n\n    self.vector_store = vector_store\n    self.filters = filters or {}\n    self.top_k = top_k\n    self.similarity_threshold = similarity_threshold\n</code></pre>"},{"location":"dynamiq/components/retrievers/milvus/#dynamiq.components.retrievers.milvus.MilvusDocumentRetriever.run","title":"<code>run(query_embedding, query=None, exclude_document_embeddings=True, top_k=None, filters=None, content_key=None, embedding_key=None, similarity_threshold=None)</code>","text":"<p>Retrieves documents from the MilvusVectorStore that are similar to the provided query embedding.</p> <p>Parameters:</p> Name Type Description Default <code>query_embedding</code> <code>List[float]</code> <p>The embedding vector of the query for which similar documents are to be</p> required <code>query(Optional[str])</code> <p>The query string to search for (when using hybrid search). Defaults to None.</p> required <code>exclude_document_embeddings</code> <code>bool</code> <p>Specifies whether to exclude the embeddings of the retrieved</p> <code>True</code> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to None.</p> <code>None</code> <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store vector in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, list[Document]]</code> <p>Dict[str, List[Document]]: A dictionary containing a list of Document instances sorted by their relevance</p> <code>dict[str, list[Document]]</code> <p>to the query_embedding.</p> Source code in <code>dynamiq/components/retrievers/milvus.py</code> <pre><code>def run(\n    self,\n    query_embedding: list[float],\n    query: str | None = None,\n    exclude_document_embeddings: bool = True,\n    top_k: int | None = None,\n    filters: dict[str, Any] | None = None,\n    content_key: str | None = None,\n    embedding_key: str | None = None,\n    similarity_threshold: float | None = None,\n) -&gt; dict[str, list[Document]]:\n    \"\"\"\n    Retrieves documents from the MilvusVectorStore that are similar to the provided query embedding.\n\n    Args:\n        query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n        retrieved.\n        query(Optional[str]): The query string to search for (when using hybrid search). Defaults to None.\n        exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n        documents from the output.\n        top_k (int, optional): The maximum number of documents to return. Defaults to None.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        content_key (Optional[str]): The field used to store content in the storage.\n        embedding_key (Optional[str]): The field used to store vector in the storage.\n\n    Returns:\n        Dict[str, List[Document]]: A dictionary containing a list of Document instances sorted by their relevance\n        to the query_embedding.\n    \"\"\"\n    query_embeddings = [query_embedding]\n    top_k = top_k or self.top_k\n    filters = filters or self.filters\n\n    if query is not None:\n        docs = self.vector_store._hybrid_retrieval(\n            query=query,\n            query_embeddings=query_embeddings,\n            top_k=top_k,\n            content_key=content_key,\n            embedding_key=embedding_key,\n            return_embeddings=not exclude_document_embeddings,\n        )\n    else:\n        docs = self.vector_store._embedding_retrieval(\n            query_embeddings=query_embeddings,\n            filters=filters,\n            top_k=top_k,\n            content_key=content_key,\n            embedding_key=embedding_key,\n            return_embeddings=not exclude_document_embeddings,\n        )\n\n    threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n    docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n    return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/pgvector/","title":"Pgvector","text":""},{"location":"dynamiq/components/retrievers/pgvector/#dynamiq.components.retrievers.pgvector.PGVectorDocumentRetriever","title":"<code>PGVectorDocumentRetriever</code>","text":"<p>Document Retriever using PGVector.</p> Source code in <code>dynamiq/components/retrievers/pgvector.py</code> <pre><code>class PGVectorDocumentRetriever:\n    \"\"\"\n    Document Retriever using PGVector.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        vector_store: PGVectorStore,\n        filters: dict[str, Any] | None = None,\n        top_k: int = 10,\n        similarity_threshold: float | None = None,\n    ):\n        \"\"\"\n        Initializes a component for retrieving documents from a PGVector vector store with optional filtering.\n\n        Args:\n            vector_store (PGVectorStore): An instance of PGVectorStore to interface with PGVector vectors.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            top_k (int): The maximum number of documents to return. Defaults to 10.\n\n        Raises:\n            ValueError: If the `vector_store` is not an instance of `PGVectorStore`.\n\n        This initializer checks if the `vector_store` provided is an instance of the expected `PGVectorStore`\n        class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n        \"\"\"\n        if not isinstance(vector_store, PGVectorStore):\n            msg = \"document_store must be an instance of PGVectorStore\"\n            raise ValueError(msg)\n\n        self.vector_store = vector_store\n        self.filters = filters or {}\n        self.top_k = top_k\n        self.similarity_threshold = similarity_threshold\n\n    def _higher_is_better(self) -&gt; bool:\n        distance_metrics = {\n            PGVectorVectorFunction.L1_DISTANCE,\n            PGVectorVectorFunction.L2_DISTANCE,\n        }\n        return self.vector_store.vector_function not in distance_metrics\n\n    def run(\n        self,\n        query_embedding: list[float],\n        exclude_document_embeddings: bool = True,\n        top_k: int | None = None,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n        query: str | None = None,\n        alpha: float | None = 0.5,\n        similarity_threshold: float | None = None,\n    ):\n        \"\"\"\n        Retrieves documents from the PGVectorStore that are similar to the provided query embedding.\n\n        Args:\n            query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n            retrieved.\n            exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n            documents from the output.\n            top_k (int, optional): The maximum number of documents to return. Defaults to None.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            content_key (Optional[str]): The field used to store content in the storage. Defaults to None.\n            embedding_key (Optional[str]): The field used to store vector in the storage. Defaults to None.\n            query(Optional[str]): The query string to search for (when using keyword search). Defaults to None.\n            alpha (Optional[float]): The alpha value for hybrid retrieval. Defaults to 0.5.\n\n            When using hybrid retrieval, the alpha value determines the weight of the keyword search score in the\n            final ranking. A value of 0.0 means only keyword search score will be used, and a value of 1.0 means only\n            vector similarity score will be considered.\n\n        Returns:\n            List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n        \"\"\"\n\n        top_k = top_k or self.top_k\n        filters = filters or self.filters\n\n        if query:\n            docs = self.vector_store._hybrid_retrieval(\n                query_embedding=query_embedding,\n                query=query,\n                filters=filters,\n                top_k=top_k,\n                exclude_document_embeddings=exclude_document_embeddings,\n                content_key=content_key,\n                embedding_key=embedding_key,\n                alpha=alpha,\n            )\n        else:\n            docs = self.vector_store._embedding_retrieval(\n                query_embedding=query_embedding,\n                filters=filters,\n                top_k=top_k,\n                exclude_document_embeddings=exclude_document_embeddings,\n                content_key=content_key,\n                embedding_key=embedding_key,\n            )\n\n        threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n        docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n        logger.debug(f\"Retrieved {len(docs)} documents from pgvector Vector Store.\")\n\n        return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/pgvector/#dynamiq.components.retrievers.pgvector.PGVectorDocumentRetriever.__init__","title":"<code>__init__(*, vector_store, filters=None, top_k=10, similarity_threshold=None)</code>","text":"<p>Initializes a component for retrieving documents from a PGVector vector store with optional filtering.</p> <p>Parameters:</p> Name Type Description Default <code>vector_store</code> <code>PGVectorStore</code> <p>An instance of PGVectorStore to interface with PGVector vectors.</p> required <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to 10.</p> <code>10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>vector_store</code> is not an instance of <code>PGVectorStore</code>.</p> <p>This initializer checks if the <code>vector_store</code> provided is an instance of the expected <code>PGVectorStore</code> class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.</p> Source code in <code>dynamiq/components/retrievers/pgvector.py</code> <pre><code>def __init__(\n    self,\n    *,\n    vector_store: PGVectorStore,\n    filters: dict[str, Any] | None = None,\n    top_k: int = 10,\n    similarity_threshold: float | None = None,\n):\n    \"\"\"\n    Initializes a component for retrieving documents from a PGVector vector store with optional filtering.\n\n    Args:\n        vector_store (PGVectorStore): An instance of PGVectorStore to interface with PGVector vectors.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        top_k (int): The maximum number of documents to return. Defaults to 10.\n\n    Raises:\n        ValueError: If the `vector_store` is not an instance of `PGVectorStore`.\n\n    This initializer checks if the `vector_store` provided is an instance of the expected `PGVectorStore`\n    class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n    \"\"\"\n    if not isinstance(vector_store, PGVectorStore):\n        msg = \"document_store must be an instance of PGVectorStore\"\n        raise ValueError(msg)\n\n    self.vector_store = vector_store\n    self.filters = filters or {}\n    self.top_k = top_k\n    self.similarity_threshold = similarity_threshold\n</code></pre>"},{"location":"dynamiq/components/retrievers/pgvector/#dynamiq.components.retrievers.pgvector.PGVectorDocumentRetriever.run","title":"<code>run(query_embedding, exclude_document_embeddings=True, top_k=None, filters=None, content_key=None, embedding_key=None, query=None, alpha=0.5, similarity_threshold=None)</code>","text":"<p>Retrieves documents from the PGVectorStore that are similar to the provided query embedding.</p> <p>Parameters:</p> Name Type Description Default <code>query_embedding</code> <code>List[float]</code> <p>The embedding vector of the query for which similar documents are to be</p> required <code>exclude_document_embeddings</code> <code>bool</code> <p>Specifies whether to exclude the embeddings of the retrieved</p> <code>True</code> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to None.</p> <code>None</code> <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage. Defaults to None.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store vector in the storage. Defaults to None.</p> <code>None</code> <code>query(Optional[str])</code> <p>The query string to search for (when using keyword search). Defaults to None.</p> required <code>alpha</code> <code>Optional[float]</code> <p>The alpha value for hybrid retrieval. Defaults to 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <p>List[Document]: A list of Document instances sorted by their relevance to the query_embedding.</p> Source code in <code>dynamiq/components/retrievers/pgvector.py</code> <pre><code>def run(\n    self,\n    query_embedding: list[float],\n    exclude_document_embeddings: bool = True,\n    top_k: int | None = None,\n    filters: dict[str, Any] | None = None,\n    content_key: str | None = None,\n    embedding_key: str | None = None,\n    query: str | None = None,\n    alpha: float | None = 0.5,\n    similarity_threshold: float | None = None,\n):\n    \"\"\"\n    Retrieves documents from the PGVectorStore that are similar to the provided query embedding.\n\n    Args:\n        query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n        retrieved.\n        exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n        documents from the output.\n        top_k (int, optional): The maximum number of documents to return. Defaults to None.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        content_key (Optional[str]): The field used to store content in the storage. Defaults to None.\n        embedding_key (Optional[str]): The field used to store vector in the storage. Defaults to None.\n        query(Optional[str]): The query string to search for (when using keyword search). Defaults to None.\n        alpha (Optional[float]): The alpha value for hybrid retrieval. Defaults to 0.5.\n\n        When using hybrid retrieval, the alpha value determines the weight of the keyword search score in the\n        final ranking. A value of 0.0 means only keyword search score will be used, and a value of 1.0 means only\n        vector similarity score will be considered.\n\n    Returns:\n        List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n    \"\"\"\n\n    top_k = top_k or self.top_k\n    filters = filters or self.filters\n\n    if query:\n        docs = self.vector_store._hybrid_retrieval(\n            query_embedding=query_embedding,\n            query=query,\n            filters=filters,\n            top_k=top_k,\n            exclude_document_embeddings=exclude_document_embeddings,\n            content_key=content_key,\n            embedding_key=embedding_key,\n            alpha=alpha,\n        )\n    else:\n        docs = self.vector_store._embedding_retrieval(\n            query_embedding=query_embedding,\n            filters=filters,\n            top_k=top_k,\n            exclude_document_embeddings=exclude_document_embeddings,\n            content_key=content_key,\n            embedding_key=embedding_key,\n        )\n\n    threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n    docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n    logger.debug(f\"Retrieved {len(docs)} documents from pgvector Vector Store.\")\n\n    return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/pinecone/","title":"Pinecone","text":""},{"location":"dynamiq/components/retrievers/pinecone/#dynamiq.components.retrievers.pinecone.PineconeDocumentRetriever","title":"<code>PineconeDocumentRetriever</code>","text":"<p>Document Retriever using Pinecone.</p> Source code in <code>dynamiq/components/retrievers/pinecone.py</code> <pre><code>class PineconeDocumentRetriever:\n    \"\"\"\n    Document Retriever using Pinecone.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        vector_store: PineconeVectorStore,\n        filters: dict[str, Any] | None = None,\n        top_k: int = 10,\n        similarity_threshold: float | None = None,\n    ):\n        \"\"\"\n        Initializes a component for retrieving documents from a Pinecone vector store with optional filtering.\n\n        Args:\n            vector_store (PineconeVectorStore): An instance of PineconeVectorStore to interface with Pinecone vectors.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            top_k (int): The maximum number of documents to return. Defaults to 10.\n\n        Raises:\n            ValueError: If the `vector_store` is not an instance of `PineconeVectorStore`.\n\n        This initializer checks if the `vector_store` provided is an instance of the expected `PineconeVectorStore`\n        class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n        \"\"\"\n        if not isinstance(vector_store, PineconeVectorStore):\n            msg = \"document_store must be an instance of PineconeVectorStore\"\n            raise ValueError(msg)\n\n        self.vector_store = vector_store\n        self.filters = filters or {}\n        self.top_k = top_k\n        self.similarity_threshold = similarity_threshold\n\n    def _higher_is_better(self) -&gt; bool:\n        metric = self.vector_store.metric\n        return metric != PineconeSimilarityMetric.EUCLIDEAN\n\n    def run(\n        self,\n        query_embedding: list[float],\n        exclude_document_embeddings: bool = True,\n        top_k: int | None = None,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        similarity_threshold: float | None = None,\n    ) -&gt; dict[str, list[Document]]:\n        \"\"\"\n        Retrieves documents from the PineconeDocumentStore that are similar to the provided query embedding.\n\n        Args:\n            query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n            retrieved.\n            exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n            documents from the output.\n            top_k (int, optional): The maximum number of documents to return. Defaults to None.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n        \"\"\"\n        top_k = top_k or self.top_k\n        filters = filters or self.filters\n\n        docs = self.vector_store._embedding_retrieval(\n            query_embedding=query_embedding,\n            filters=filters,\n            top_k=top_k,\n            exclude_document_embeddings=exclude_document_embeddings,\n            content_key=content_key,\n        )\n        logger.debug(f\"Retrieved {len(docs)} documents from Pinecone Vector Store.\")\n\n        threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n        docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n        return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/pinecone/#dynamiq.components.retrievers.pinecone.PineconeDocumentRetriever.__init__","title":"<code>__init__(*, vector_store, filters=None, top_k=10, similarity_threshold=None)</code>","text":"<p>Initializes a component for retrieving documents from a Pinecone vector store with optional filtering.</p> <p>Parameters:</p> Name Type Description Default <code>vector_store</code> <code>PineconeVectorStore</code> <p>An instance of PineconeVectorStore to interface with Pinecone vectors.</p> required <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to 10.</p> <code>10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>vector_store</code> is not an instance of <code>PineconeVectorStore</code>.</p> <p>This initializer checks if the <code>vector_store</code> provided is an instance of the expected <code>PineconeVectorStore</code> class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.</p> Source code in <code>dynamiq/components/retrievers/pinecone.py</code> <pre><code>def __init__(\n    self,\n    *,\n    vector_store: PineconeVectorStore,\n    filters: dict[str, Any] | None = None,\n    top_k: int = 10,\n    similarity_threshold: float | None = None,\n):\n    \"\"\"\n    Initializes a component for retrieving documents from a Pinecone vector store with optional filtering.\n\n    Args:\n        vector_store (PineconeVectorStore): An instance of PineconeVectorStore to interface with Pinecone vectors.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        top_k (int): The maximum number of documents to return. Defaults to 10.\n\n    Raises:\n        ValueError: If the `vector_store` is not an instance of `PineconeVectorStore`.\n\n    This initializer checks if the `vector_store` provided is an instance of the expected `PineconeVectorStore`\n    class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n    \"\"\"\n    if not isinstance(vector_store, PineconeVectorStore):\n        msg = \"document_store must be an instance of PineconeVectorStore\"\n        raise ValueError(msg)\n\n    self.vector_store = vector_store\n    self.filters = filters or {}\n    self.top_k = top_k\n    self.similarity_threshold = similarity_threshold\n</code></pre>"},{"location":"dynamiq/components/retrievers/pinecone/#dynamiq.components.retrievers.pinecone.PineconeDocumentRetriever.run","title":"<code>run(query_embedding, exclude_document_embeddings=True, top_k=None, filters=None, content_key=None, similarity_threshold=None)</code>","text":"<p>Retrieves documents from the PineconeDocumentStore that are similar to the provided query embedding.</p> <p>Parameters:</p> Name Type Description Default <code>query_embedding</code> <code>List[float]</code> <p>The embedding vector of the query for which similar documents are to be</p> required <code>exclude_document_embeddings</code> <code>bool</code> <p>Specifies whether to exclude the embeddings of the retrieved</p> <code>True</code> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to None.</p> <code>None</code> <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, list[Document]]</code> <p>List[Document]: A list of Document instances sorted by their relevance to the query_embedding.</p> Source code in <code>dynamiq/components/retrievers/pinecone.py</code> <pre><code>def run(\n    self,\n    query_embedding: list[float],\n    exclude_document_embeddings: bool = True,\n    top_k: int | None = None,\n    filters: dict[str, Any] | None = None,\n    content_key: str | None = None,\n    similarity_threshold: float | None = None,\n) -&gt; dict[str, list[Document]]:\n    \"\"\"\n    Retrieves documents from the PineconeDocumentStore that are similar to the provided query embedding.\n\n    Args:\n        query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n        retrieved.\n        exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n        documents from the output.\n        top_k (int, optional): The maximum number of documents to return. Defaults to None.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n    \"\"\"\n    top_k = top_k or self.top_k\n    filters = filters or self.filters\n\n    docs = self.vector_store._embedding_retrieval(\n        query_embedding=query_embedding,\n        filters=filters,\n        top_k=top_k,\n        exclude_document_embeddings=exclude_document_embeddings,\n        content_key=content_key,\n    )\n    logger.debug(f\"Retrieved {len(docs)} documents from Pinecone Vector Store.\")\n\n    threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n    docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n    return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/qdrant/","title":"Qdrant","text":""},{"location":"dynamiq/components/retrievers/qdrant/#dynamiq.components.retrievers.qdrant.QdrantDocumentRetriever","title":"<code>QdrantDocumentRetriever</code>","text":"<p>Document Retriever using Qdrant</p> Source code in <code>dynamiq/components/retrievers/qdrant.py</code> <pre><code>class QdrantDocumentRetriever:\n    \"\"\"\n    Document Retriever using Qdrant\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        vector_store: QdrantVectorStore,\n        filters: dict[str, Any] | None = None,\n        top_k: int = 10,\n        similarity_threshold: float | None = None,\n    ):\n        \"\"\"\n        Initializes a component for retrieving documents from a Qdrant vector store with optional filtering.\n        Args:\n            vector_store (QdrantVectorStore): An instance of QdrantVectorStore to interface with Qdrant vectors.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            top_k (int): The maximum number of documents to return. Defaults to 10.\n        Raises:\n            ValueError: If the `vector_store` is not an instance of `QdrantVectorStore`.\n        This initializer checks if the `vector_store` provided is an instance of the expected `QdrantVectorStore`\n        class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n        \"\"\"\n        if not isinstance(vector_store, QdrantVectorStore):\n            msg = \"document_store must be an instance of QdrantVectorStore\"\n            raise ValueError(msg)\n\n        self.vector_store = vector_store\n        self.filters = filters or {}\n        self.top_k = top_k\n        self.similarity_threshold = similarity_threshold\n\n    def _higher_is_better(self) -&gt; bool:\n        return self.vector_store.metric != QdrantSimilarityMetric.L2\n\n    def run(\n        self,\n        query_embedding: list[float],\n        exclude_document_embeddings: bool = True,\n        top_k: int | None = None,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        similarity_threshold: float | None = None,\n    ) -&gt; dict[str, list[Document]]:\n        \"\"\"\n        Retrieves documents from the QdrantDocumentStore that are similar to the provided query embedding.\n        Args:\n            query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n            retrieved.\n            exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n            documents from the output.\n            top_k (Optional[int], optional): The maximum number of documents to return. Defaults to None.\n            filters (Optional[dict[str, Any]], optional): Filters to apply\n                for retrieving specific documents. Defaults to None.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n        \"\"\"\n        top_k = top_k or self.top_k\n        filters = filters or self.filters\n\n        threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n\n        docs = self.vector_store._query_by_embedding(\n            query_embedding=query_embedding,\n            filters=filters,\n            top_k=top_k,\n            return_embedding=not exclude_document_embeddings,\n            score_threshold=threshold,\n            content_key=content_key,\n        )\n        logger.debug(f\"Retrieved {len(docs)} documents from Qdrant Vector Store.\")\n\n        docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n        return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/qdrant/#dynamiq.components.retrievers.qdrant.QdrantDocumentRetriever.__init__","title":"<code>__init__(*, vector_store, filters=None, top_k=10, similarity_threshold=None)</code>","text":"<p>Initializes a component for retrieving documents from a Qdrant vector store with optional filtering. Args:     vector_store (QdrantVectorStore): An instance of QdrantVectorStore to interface with Qdrant vectors.     filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.     top_k (int): The maximum number of documents to return. Defaults to 10. Raises:     ValueError: If the <code>vector_store</code> is not an instance of <code>QdrantVectorStore</code>. This initializer checks if the <code>vector_store</code> provided is an instance of the expected <code>QdrantVectorStore</code> class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.</p> Source code in <code>dynamiq/components/retrievers/qdrant.py</code> <pre><code>def __init__(\n    self,\n    *,\n    vector_store: QdrantVectorStore,\n    filters: dict[str, Any] | None = None,\n    top_k: int = 10,\n    similarity_threshold: float | None = None,\n):\n    \"\"\"\n    Initializes a component for retrieving documents from a Qdrant vector store with optional filtering.\n    Args:\n        vector_store (QdrantVectorStore): An instance of QdrantVectorStore to interface with Qdrant vectors.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        top_k (int): The maximum number of documents to return. Defaults to 10.\n    Raises:\n        ValueError: If the `vector_store` is not an instance of `QdrantVectorStore`.\n    This initializer checks if the `vector_store` provided is an instance of the expected `QdrantVectorStore`\n    class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n    \"\"\"\n    if not isinstance(vector_store, QdrantVectorStore):\n        msg = \"document_store must be an instance of QdrantVectorStore\"\n        raise ValueError(msg)\n\n    self.vector_store = vector_store\n    self.filters = filters or {}\n    self.top_k = top_k\n    self.similarity_threshold = similarity_threshold\n</code></pre>"},{"location":"dynamiq/components/retrievers/qdrant/#dynamiq.components.retrievers.qdrant.QdrantDocumentRetriever.run","title":"<code>run(query_embedding, exclude_document_embeddings=True, top_k=None, filters=None, content_key=None, similarity_threshold=None)</code>","text":"<p>Retrieves documents from the QdrantDocumentStore that are similar to the provided query embedding. Args:     query_embedding (List[float]): The embedding vector of the query for which similar documents are to be     retrieved.     exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved     documents from the output.     top_k (Optional[int], optional): The maximum number of documents to return. Defaults to None.     filters (Optional[dict[str, Any]], optional): Filters to apply         for retrieving specific documents. Defaults to None.     content_key (Optional[str]): The field used to store content in the storage.</p> <p>Returns:</p> Type Description <code>dict[str, list[Document]]</code> <p>List[Document]: A list of Document instances sorted by their relevance to the query_embedding.</p> Source code in <code>dynamiq/components/retrievers/qdrant.py</code> <pre><code>def run(\n    self,\n    query_embedding: list[float],\n    exclude_document_embeddings: bool = True,\n    top_k: int | None = None,\n    filters: dict[str, Any] | None = None,\n    content_key: str | None = None,\n    similarity_threshold: float | None = None,\n) -&gt; dict[str, list[Document]]:\n    \"\"\"\n    Retrieves documents from the QdrantDocumentStore that are similar to the provided query embedding.\n    Args:\n        query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n        retrieved.\n        exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n        documents from the output.\n        top_k (Optional[int], optional): The maximum number of documents to return. Defaults to None.\n        filters (Optional[dict[str, Any]], optional): Filters to apply\n            for retrieving specific documents. Defaults to None.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n    \"\"\"\n    top_k = top_k or self.top_k\n    filters = filters or self.filters\n\n    threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n\n    docs = self.vector_store._query_by_embedding(\n        query_embedding=query_embedding,\n        filters=filters,\n        top_k=top_k,\n        return_embedding=not exclude_document_embeddings,\n        score_threshold=threshold,\n        content_key=content_key,\n    )\n    logger.debug(f\"Retrieved {len(docs)} documents from Qdrant Vector Store.\")\n\n    docs = filter_documents_by_threshold(docs, threshold, higher_is_better=self._higher_is_better())\n\n    return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/retrievers/utils/","title":"Utils","text":""},{"location":"dynamiq/components/retrievers/utils/#dynamiq.components.retrievers.utils.filter_documents_by_threshold","title":"<code>filter_documents_by_threshold(documents, threshold, *, higher_is_better)</code>","text":"<p>Filter documents by score threshold while preserving order.</p> Source code in <code>dynamiq/components/retrievers/utils.py</code> <pre><code>def filter_documents_by_threshold(\n    documents: Iterable[Document],\n    threshold: float | None,\n    *,\n    higher_is_better: bool,\n) -&gt; list[Document]:\n    \"\"\"Filter documents by score threshold while preserving order.\"\"\"\n    if threshold is None:\n        return list(documents)\n\n    filtered: list[Document] = []\n    for document in documents:\n        score = document.score\n        if score is None:\n            filtered.append(document)\n            continue\n\n        if higher_is_better:\n            if score &gt;= threshold:\n                filtered.append(document)\n        elif score &lt;= threshold:\n            filtered.append(document)\n\n    return filtered\n</code></pre>"},{"location":"dynamiq/components/retrievers/weaviate/","title":"Weaviate","text":""},{"location":"dynamiq/components/retrievers/weaviate/#dynamiq.components.retrievers.weaviate.WeaviateDocumentRetriever","title":"<code>WeaviateDocumentRetriever</code>","text":"<p>Document Retriever using Weaviate</p> Source code in <code>dynamiq/components/retrievers/weaviate.py</code> <pre><code>class WeaviateDocumentRetriever:\n    \"\"\"\n    Document Retriever using Weaviate\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        vector_store: WeaviateVectorStore,\n        filters: dict[str, Any] | None = None,\n        top_k: int = 10,\n        similarity_threshold: float | None = None,\n    ):\n        \"\"\"\n        Initializes a component for retrieving documents from a Weaviate vector store with optional filtering.\n        Args:\n            vector_store (WeaviateVectorStore): An instance of WeaviateVectorStore to interface with Weaviate vectors.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            top_k (int): The maximum number of documents to return. Defaults to 10.\n        Raises:\n            ValueError: If the `vector_store` is not an instance of `WeaviateVectorStore`.\n        This initializer checks if the `vector_store` provided is an instance of the expected `WeaviateVectorStore`\n        class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n        \"\"\"\n        if not isinstance(vector_store, WeaviateVectorStore):\n            msg = \"document_store must be an instance of WeaviateVectorStore\"\n            raise ValueError(msg)\n\n        self.vector_store = vector_store\n        self.filters = filters or {}\n        self.top_k = top_k\n        self.similarity_threshold = similarity_threshold\n\n    def run(\n        self,\n        query_embedding: list[float],\n        exclude_document_embeddings: bool = True,\n        top_k: int | None = None,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        query: str | None = None,\n        alpha: float | None = 0.5,\n        similarity_threshold: float | None = None,\n    ) -&gt; dict[str, list[Document]]:\n        \"\"\"\n        Retrieves documents from the WeaviateDocumentStore that are similar to the provided query embedding.\n        Args:\n            query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n            retrieved.\n            exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n            documents from the output.\n            top_k (int, optional): The maximum number of documents to return. Defaults to None.\n            filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n            content_key (Optional[str]): The field used to store content in the storage.\n            query(Optional[str]): The query string to search for (when using keyword search). Defaults to None.\n            alpha (Optional[float]): The alpha value for hybrid retrieval. Defaults to 0.5.\n\n            When using hybrid retrieval, the alpha value determines the weight of the keyword search score in the\n            final ranking. A value of 0.0 means only keyword search score will be used, and a value of 1.0 means only\n            vector similarity score will be considered.\n\n        Returns:\n            List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n        \"\"\"\n        top_k = top_k or self.top_k\n        filters = filters or self.filters\n\n        threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n\n        if query:\n            docs = self.vector_store._hybrid_retrieval(\n                query_embedding=query_embedding,\n                query=query,\n                filters=filters,\n                top_k=top_k,\n                exclude_document_embeddings=exclude_document_embeddings,\n                content_key=content_key,\n                alpha=alpha,\n            )\n            docs = filter_documents_by_threshold(docs, threshold, higher_is_better=True)\n\n        else:\n            distance = None\n            certainty = None\n            higher_is_better = True\n            if threshold is not None:\n                if threshold &lt;= 1:\n                    certainty = threshold\n                    higher_is_better = True\n                else:\n                    distance = threshold\n                    higher_is_better = False\n\n            docs = self.vector_store._embedding_retrieval(\n                query_embedding=query_embedding,\n                filters=filters,\n                top_k=top_k,\n                exclude_document_embeddings=exclude_document_embeddings,\n                distance=distance,\n                certainty=certainty,\n                content_key=content_key,\n            )\n            docs = filter_documents_by_threshold(docs, threshold, higher_is_better=higher_is_better)\n\n        logger.debug(f\"Retrieved {len(docs)} documents from Weaviate Vector Store.\")\n\n        return {\"documents\": docs}\n\n    def close(self):\n        \"\"\"\n        Closes the WeaviateDocumentRetriever component.\n        \"\"\"\n        self.vector_store.close()\n</code></pre>"},{"location":"dynamiq/components/retrievers/weaviate/#dynamiq.components.retrievers.weaviate.WeaviateDocumentRetriever.__init__","title":"<code>__init__(*, vector_store, filters=None, top_k=10, similarity_threshold=None)</code>","text":"<p>Initializes a component for retrieving documents from a Weaviate vector store with optional filtering. Args:     vector_store (WeaviateVectorStore): An instance of WeaviateVectorStore to interface with Weaviate vectors.     filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.     top_k (int): The maximum number of documents to return. Defaults to 10. Raises:     ValueError: If the <code>vector_store</code> is not an instance of <code>WeaviateVectorStore</code>. This initializer checks if the <code>vector_store</code> provided is an instance of the expected <code>WeaviateVectorStore</code> class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.</p> Source code in <code>dynamiq/components/retrievers/weaviate.py</code> <pre><code>def __init__(\n    self,\n    *,\n    vector_store: WeaviateVectorStore,\n    filters: dict[str, Any] | None = None,\n    top_k: int = 10,\n    similarity_threshold: float | None = None,\n):\n    \"\"\"\n    Initializes a component for retrieving documents from a Weaviate vector store with optional filtering.\n    Args:\n        vector_store (WeaviateVectorStore): An instance of WeaviateVectorStore to interface with Weaviate vectors.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        top_k (int): The maximum number of documents to return. Defaults to 10.\n    Raises:\n        ValueError: If the `vector_store` is not an instance of `WeaviateVectorStore`.\n    This initializer checks if the `vector_store` provided is an instance of the expected `WeaviateVectorStore`\n    class, sets up filtering conditions if any, and defines how many top results to retrieve in document queries.\n    \"\"\"\n    if not isinstance(vector_store, WeaviateVectorStore):\n        msg = \"document_store must be an instance of WeaviateVectorStore\"\n        raise ValueError(msg)\n\n    self.vector_store = vector_store\n    self.filters = filters or {}\n    self.top_k = top_k\n    self.similarity_threshold = similarity_threshold\n</code></pre>"},{"location":"dynamiq/components/retrievers/weaviate/#dynamiq.components.retrievers.weaviate.WeaviateDocumentRetriever.close","title":"<code>close()</code>","text":"<p>Closes the WeaviateDocumentRetriever component.</p> Source code in <code>dynamiq/components/retrievers/weaviate.py</code> <pre><code>def close(self):\n    \"\"\"\n    Closes the WeaviateDocumentRetriever component.\n    \"\"\"\n    self.vector_store.close()\n</code></pre>"},{"location":"dynamiq/components/retrievers/weaviate/#dynamiq.components.retrievers.weaviate.WeaviateDocumentRetriever.run","title":"<code>run(query_embedding, exclude_document_embeddings=True, top_k=None, filters=None, content_key=None, query=None, alpha=0.5, similarity_threshold=None)</code>","text":"<p>Retrieves documents from the WeaviateDocumentStore that are similar to the provided query embedding. Args:     query_embedding (List[float]): The embedding vector of the query for which similar documents are to be     retrieved.     exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved     documents from the output.     top_k (int, optional): The maximum number of documents to return. Defaults to None.     filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.     content_key (Optional[str]): The field used to store content in the storage.     query(Optional[str]): The query string to search for (when using keyword search). Defaults to None.     alpha (Optional[float]): The alpha value for hybrid retrieval. Defaults to 0.5.</p> <pre><code>When using hybrid retrieval, the alpha value determines the weight of the keyword search score in the\nfinal ranking. A value of 0.0 means only keyword search score will be used, and a value of 1.0 means only\nvector similarity score will be considered.\n</code></pre> <p>Returns:</p> Type Description <code>dict[str, list[Document]]</code> <p>List[Document]: A list of Document instances sorted by their relevance to the query_embedding.</p> Source code in <code>dynamiq/components/retrievers/weaviate.py</code> <pre><code>def run(\n    self,\n    query_embedding: list[float],\n    exclude_document_embeddings: bool = True,\n    top_k: int | None = None,\n    filters: dict[str, Any] | None = None,\n    content_key: str | None = None,\n    query: str | None = None,\n    alpha: float | None = 0.5,\n    similarity_threshold: float | None = None,\n) -&gt; dict[str, list[Document]]:\n    \"\"\"\n    Retrieves documents from the WeaviateDocumentStore that are similar to the provided query embedding.\n    Args:\n        query_embedding (List[float]): The embedding vector of the query for which similar documents are to be\n        retrieved.\n        exclude_document_embeddings (bool, optional): Specifies whether to exclude the embeddings of the retrieved\n        documents from the output.\n        top_k (int, optional): The maximum number of documents to return. Defaults to None.\n        filters (Optional[dict[str, Any]]): Filters to apply for retrieving specific documents. Defaults to None.\n        content_key (Optional[str]): The field used to store content in the storage.\n        query(Optional[str]): The query string to search for (when using keyword search). Defaults to None.\n        alpha (Optional[float]): The alpha value for hybrid retrieval. Defaults to 0.5.\n\n        When using hybrid retrieval, the alpha value determines the weight of the keyword search score in the\n        final ranking. A value of 0.0 means only keyword search score will be used, and a value of 1.0 means only\n        vector similarity score will be considered.\n\n    Returns:\n        List[Document]: A list of Document instances sorted by their relevance to the query_embedding.\n    \"\"\"\n    top_k = top_k or self.top_k\n    filters = filters or self.filters\n\n    threshold = similarity_threshold if similarity_threshold is not None else self.similarity_threshold\n\n    if query:\n        docs = self.vector_store._hybrid_retrieval(\n            query_embedding=query_embedding,\n            query=query,\n            filters=filters,\n            top_k=top_k,\n            exclude_document_embeddings=exclude_document_embeddings,\n            content_key=content_key,\n            alpha=alpha,\n        )\n        docs = filter_documents_by_threshold(docs, threshold, higher_is_better=True)\n\n    else:\n        distance = None\n        certainty = None\n        higher_is_better = True\n        if threshold is not None:\n            if threshold &lt;= 1:\n                certainty = threshold\n                higher_is_better = True\n            else:\n                distance = threshold\n                higher_is_better = False\n\n        docs = self.vector_store._embedding_retrieval(\n            query_embedding=query_embedding,\n            filters=filters,\n            top_k=top_k,\n            exclude_document_embeddings=exclude_document_embeddings,\n            distance=distance,\n            certainty=certainty,\n            content_key=content_key,\n        )\n        docs = filter_documents_by_threshold(docs, threshold, higher_is_better=higher_is_better)\n\n    logger.debug(f\"Retrieved {len(docs)} documents from Weaviate Vector Store.\")\n\n    return {\"documents\": docs}\n</code></pre>"},{"location":"dynamiq/components/splitters/document/","title":"Document","text":""},{"location":"dynamiq/components/splitters/document/#dynamiq.components.splitters.document.DocumentSplitBy","title":"<code>DocumentSplitBy</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum class for document splitting methods.</p> Source code in <code>dynamiq/components/splitters/document.py</code> <pre><code>class DocumentSplitBy(str, enum.Enum):\n    \"\"\"Enum class for document splitting methods.\"\"\"\n\n    WORD = \"word\"\n    SENTENCE = \"sentence\"\n    PAGE = \"page\"\n    PASSAGE = \"passage\"\n    TITLE = \"title\"\n    CHARACTER = \"character\"\n</code></pre>"},{"location":"dynamiq/components/splitters/document/#dynamiq.components.splitters.document.DocumentSplitter","title":"<code>DocumentSplitter</code>","text":"<p>Splits a list of text documents into a list of text documents with shorter texts.</p> <p>Splitting documents with long texts is a common preprocessing step during indexing. This allows Embedders to create significant semantic representations and avoids exceeding the maximum context length of language models.</p> Source code in <code>dynamiq/components/splitters/document.py</code> <pre><code>class DocumentSplitter:\n    \"\"\"\n    Splits a list of text documents into a list of text documents with shorter texts.\n\n    Splitting documents with long texts is a common preprocessing step during indexing.\n    This allows Embedders to create significant semantic representations\n    and avoids exceeding the maximum context length of language models.\n    \"\"\"\n\n    def __init__(\n        self,\n        split_by: DocumentSplitBy = DocumentSplitBy.PASSAGE,\n        split_length: int = 10,\n        split_overlap: int = 0,\n    ):\n        \"\"\"\n        Initializes an object for splitting documents into smaller parts based on specified criteria.\n\n        Args:\n            split_by (DocumentSplitBy): Determines the unit by which the document should be split.\n                Defaults to DocumentSplitBy.PASSAGE.\n            split_length (int): Specifies the maximum number of units to include in each split.\n                Defaults to 10.\n            split_overlap (int): Specifies the number of units that should overlap between consecutive\n                splits. Defaults to 0.\n\n        Raises:\n            ValueError: If split_length is less than or equal to 0.\n            ValueError: If split_overlap is less than 0.\n        \"\"\"\n        self.split_by = split_by\n        if split_length &lt;= 0:\n            raise ValueError(\"split_length must be greater than 0.\")\n        self.split_length = split_length\n        if split_overlap &lt; 0:\n            raise ValueError(\"split_overlap must be greater than or equal to 0.\")\n        self.split_overlap = split_overlap\n\n    def run(self, documents: list[Document]) -&gt; dict:\n        \"\"\"\n        Splits the provided documents into smaller parts based on the specified configuration.\n\n        Args:\n            documents (list[Document]): The list of documents to be split.\n\n        Returns:\n            dict: A dictionary containing one key, 'documents', which is a list of the split Documents.\n\n        Raises:\n            TypeError: If the input is not a list of Document instances.\n            ValueError: If the content of any document is None.\n        \"\"\"\n        if not isinstance(documents, list) or (\n            documents and not isinstance(documents[0], Document)\n        ):\n            raise TypeError(\"DocumentSplitter expects a List of Documents as input.\")\n\n        split_docs = []\n        for doc in documents:\n            if doc.content is None:\n                raise ValueError(\n                    f\"DocumentSplitter only works with text documents but document.content for document \"\n                    f\"ID {doc.id} is None.\"\n                )\n            units = self._split_into_units(doc.content, self.split_by)\n            text_splits = self._concatenate_units(\n                units, self.split_length, self.split_overlap\n            )\n            if doc.metadata is None:\n                doc.metadata = {}\n            metadata = deepcopy(doc.metadata)\n            metadata[\"source_id\"] = doc.id\n            split_docs += [\n                Document(content=txt, metadata=metadata) for txt in text_splits\n            ]\n        return {\"documents\": split_docs}\n\n    def _split_into_units(self, text: str, split_by: DocumentSplitBy) -&gt; list[str]:\n        \"\"\"\n        Splits the input text into units based on the specified split_by method.\n\n        Args:\n            text (str): The input text to be split.\n            split_by (DocumentSplitBy): The method to use for splitting the text.\n\n        Returns:\n            list[str]: A list of text units after splitting.\n        \"\"\"\n        split_at = SPLIT_STR_BY_SPLIT_TYPE[split_by]\n        if split_by == DocumentSplitBy.CHARACTER:\n            return [char for char in text]\n        else:\n            units = text.split(split_at)\n        # Add the delimiter back to all units except the last one\n        for i in range(len(units) - 1):\n            if split_at == \"\\n#\":\n                units[i] = \"\\n# \" + units[i]\n            else:\n                units[i] += split_at\n        return units\n\n    def _concatenate_units(\n        self, elements: list[str], split_length: int, split_overlap: int\n    ) -&gt; list[str]:\n        \"\"\"\n        Concatenates the elements into parts of split_length units.\n\n        Args:\n            elements (list[str]): The list of text units to be concatenated.\n            split_length (int): The maximum number of units in each split.\n            split_overlap (int): The number of overlapping units between splits.\n\n        Returns:\n            list[str]: A list of concatenated text splits.\n        \"\"\"\n        text_splits = []\n        segments = windowed(elements, n=split_length, step=split_length - split_overlap)\n        for seg in segments:\n            current_units = [unit for unit in seg if unit is not None]\n            txt = \"\".join(current_units)\n            if len(txt) &gt; 0:\n                text_splits.append(txt)\n        return text_splits\n</code></pre>"},{"location":"dynamiq/components/splitters/document/#dynamiq.components.splitters.document.DocumentSplitter.__init__","title":"<code>__init__(split_by=DocumentSplitBy.PASSAGE, split_length=10, split_overlap=0)</code>","text":"<p>Initializes an object for splitting documents into smaller parts based on specified criteria.</p> <p>Parameters:</p> Name Type Description Default <code>split_by</code> <code>DocumentSplitBy</code> <p>Determines the unit by which the document should be split. Defaults to DocumentSplitBy.PASSAGE.</p> <code>PASSAGE</code> <code>split_length</code> <code>int</code> <p>Specifies the maximum number of units to include in each split. Defaults to 10.</p> <code>10</code> <code>split_overlap</code> <code>int</code> <p>Specifies the number of units that should overlap between consecutive splits. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If split_length is less than or equal to 0.</p> <code>ValueError</code> <p>If split_overlap is less than 0.</p> Source code in <code>dynamiq/components/splitters/document.py</code> <pre><code>def __init__(\n    self,\n    split_by: DocumentSplitBy = DocumentSplitBy.PASSAGE,\n    split_length: int = 10,\n    split_overlap: int = 0,\n):\n    \"\"\"\n    Initializes an object for splitting documents into smaller parts based on specified criteria.\n\n    Args:\n        split_by (DocumentSplitBy): Determines the unit by which the document should be split.\n            Defaults to DocumentSplitBy.PASSAGE.\n        split_length (int): Specifies the maximum number of units to include in each split.\n            Defaults to 10.\n        split_overlap (int): Specifies the number of units that should overlap between consecutive\n            splits. Defaults to 0.\n\n    Raises:\n        ValueError: If split_length is less than or equal to 0.\n        ValueError: If split_overlap is less than 0.\n    \"\"\"\n    self.split_by = split_by\n    if split_length &lt;= 0:\n        raise ValueError(\"split_length must be greater than 0.\")\n    self.split_length = split_length\n    if split_overlap &lt; 0:\n        raise ValueError(\"split_overlap must be greater than or equal to 0.\")\n    self.split_overlap = split_overlap\n</code></pre>"},{"location":"dynamiq/components/splitters/document/#dynamiq.components.splitters.document.DocumentSplitter.run","title":"<code>run(documents)</code>","text":"<p>Splits the provided documents into smaller parts based on the specified configuration.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>The list of documents to be split.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing one key, 'documents', which is a list of the split Documents.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input is not a list of Document instances.</p> <code>ValueError</code> <p>If the content of any document is None.</p> Source code in <code>dynamiq/components/splitters/document.py</code> <pre><code>def run(self, documents: list[Document]) -&gt; dict:\n    \"\"\"\n    Splits the provided documents into smaller parts based on the specified configuration.\n\n    Args:\n        documents (list[Document]): The list of documents to be split.\n\n    Returns:\n        dict: A dictionary containing one key, 'documents', which is a list of the split Documents.\n\n    Raises:\n        TypeError: If the input is not a list of Document instances.\n        ValueError: If the content of any document is None.\n    \"\"\"\n    if not isinstance(documents, list) or (\n        documents and not isinstance(documents[0], Document)\n    ):\n        raise TypeError(\"DocumentSplitter expects a List of Documents as input.\")\n\n    split_docs = []\n    for doc in documents:\n        if doc.content is None:\n            raise ValueError(\n                f\"DocumentSplitter only works with text documents but document.content for document \"\n                f\"ID {doc.id} is None.\"\n            )\n        units = self._split_into_units(doc.content, self.split_by)\n        text_splits = self._concatenate_units(\n            units, self.split_length, self.split_overlap\n        )\n        if doc.metadata is None:\n            doc.metadata = {}\n        metadata = deepcopy(doc.metadata)\n        metadata[\"source_id\"] = doc.id\n        split_docs += [\n            Document(content=txt, metadata=metadata) for txt in text_splits\n        ]\n    return {\"documents\": split_docs}\n</code></pre>"},{"location":"dynamiq/connections/connections/","title":"Connections","text":""},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.AWS","title":"<code>AWS</code>","text":"<p>               Bases: <code>BaseConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class AWS(BaseConnection):\n    access_key_id: str | None = Field(\n        default_factory=partial(get_env_var, \"AWS_ACCESS_KEY_ID\")\n    )\n    secret_access_key: str | None = Field(\n        default_factory=partial(get_env_var, \"AWS_SECRET_ACCESS_KEY\")\n    )\n    region: str = Field(default_factory=partial(get_env_var, \"AWS_DEFAULT_REGION\"))\n    profile: str | None = Field(default_factory=partial(get_env_var, \"AWS_DEFAULT_PROFILE\"))\n\n    def connect(self):\n        pass\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"Return parameters with aws_ prefix for compatibility with other systems\"\"\"\n        params = {}\n        if self.profile:\n            params[\"aws_profile_name\"] = self.profile\n            params[\"aws_region_name\"] = self.region\n        else:\n            params[\"aws_access_key_id\"] = self.access_key_id\n            params[\"aws_secret_access_key\"] = self.secret_access_key\n            params[\"aws_region_name\"] = self.region\n        return params\n\n    def get_boto3_session(self):\n        \"\"\"Create and return a boto3.Session with properly formatted parameters\"\"\"\n        import boto3\n        params = {}\n        if self.profile:\n            params[\"profile_name\"] = self.profile\n        elif self.access_key_id and self.secret_access_key:\n            params[\"aws_access_key_id\"] = self.access_key_id\n            params[\"aws_secret_access_key\"] = self.secret_access_key\n        if self.region:\n            params[\"region_name\"] = self.region\n        return boto3.Session(**params)\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.AWS.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Return parameters with aws_ prefix for compatibility with other systems</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.AWS.get_boto3_session","title":"<code>get_boto3_session()</code>","text":"<p>Create and return a boto3.Session with properly formatted parameters</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def get_boto3_session(self):\n    \"\"\"Create and return a boto3.Session with properly formatted parameters\"\"\"\n    import boto3\n    params = {}\n    if self.profile:\n        params[\"profile_name\"] = self.profile\n    elif self.access_key_id and self.secret_access_key:\n        params[\"aws_access_key_id\"] = self.access_key_id\n        params[\"aws_secret_access_key\"] = self.secret_access_key\n    if self.region:\n        params[\"region_name\"] = self.region\n    return boto3.Session(**params)\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.AzureAI","title":"<code>AzureAI</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class AzureAI(BaseApiKeyConnection):\n    api_key: str = Field(default_factory=partial(get_env_var, \"AZURE_API_KEY\"))\n    url: str = Field(default_factory=partial(get_env_var, \"AZURE_URL\"))\n    api_version: str = Field(default_factory=partial(get_env_var, \"AZURE_API_VERSION\"))\n\n    def connect(self):\n        pass\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"\n        Returns the parameters required for connection.\n\n        Returns:\n            dict: A dictionary containing\n\n                -the API key with the key 'api_key'.\n\n                -the base url with the key 'api_base'.\n\n                -the API version with the key 'api_version'.\n        \"\"\"\n        return {\n            \"api_base\": self.url,\n            \"api_key\": self.api_key,\n            \"api_version\": self.api_version,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.AzureAI.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing</p> <p>-the API key with the key 'api_key'.</p> <p>-the base url with the key 'api_base'.</p> <p>-the API version with the key 'api_version'.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.BaseApiKeyConnection","title":"<code>BaseApiKeyConnection</code>","text":"<p>               Bases: <code>BaseConnection</code></p> <p>Represents a base connection class that uses an API key for authentication.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>str</code> <p>The API key used for authentication.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class BaseApiKeyConnection(BaseConnection):\n    \"\"\"\n    Represents a base connection class that uses an API key for authentication.\n\n    Attributes:\n        api_key (str): The API key used for authentication.\n    \"\"\"\n    api_key: str\n\n    @abstractmethod\n    def connect(self):\n        \"\"\"\n        Connects to the service.\n\n        This method should be implemented by subclasses to establish a connection to the service using\n        the provided API key.\n\n        Raises:\n            NotImplementedError: If the method is not implemented by a subclass.\n        \"\"\"\n        raise NotImplementedError\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"\n        Returns the parameters required for connection.\n\n        Returns:\n            dict: A dictionary containing the API key with the key 'api_key'.\n        \"\"\"\n        return {\"api_key\": self.api_key}\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.BaseApiKeyConnection.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the API key with the key 'api_key'.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.BaseApiKeyConnection.connect","title":"<code>connect()</code>  <code>abstractmethod</code>","text":"<p>Connects to the service.</p> <p>This method should be implemented by subclasses to establish a connection to the service using the provided API key.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the method is not implemented by a subclass.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@abstractmethod\ndef connect(self):\n    \"\"\"\n    Connects to the service.\n\n    This method should be implemented by subclasses to establish a connection to the service using\n    the provided API key.\n\n    Raises:\n        NotImplementedError: If the method is not implemented by a subclass.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.BaseConnection","title":"<code>BaseConnection</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Represents a base connection class.</p> <p>This class should be subclassed to provide specific implementations for different types of connections.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>A unique identifier for the connection, generated using <code>generate_uuid</code>.</p> <code>type</code> <code>ConnectionType</code> <p>The type of connection.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class BaseConnection(BaseModel, ABC):\n    \"\"\"Represents a base connection class.\n\n    This class should be subclassed to provide specific implementations for different types of\n    connections.\n\n    Attributes:\n        id (str): A unique identifier for the connection, generated using `generate_uuid`.\n        type (ConnectionType): The type of connection.\n    \"\"\"\n    id: str = Field(default_factory=generate_uuid)\n\n    @computed_field\n    @cached_property\n    def type(self) -&gt; str:\n        return f\"{self.__module__.rsplit('.', 1)[0]}.{self.__class__.__name__}\"\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"\n        Returns the parameters required for connection.\n\n        Returns:\n            dict: An empty dictionary.\n        \"\"\"\n        return {}\n\n    def to_dict(self, for_tracing: bool = False, **kwargs) -&gt; dict:\n        \"\"\"Converts the connection instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the connection instance.\n        \"\"\"\n        if for_tracing:\n            return {\"id\": self.id, \"type\": self.type}\n        else:\n            return self.model_dump(**kwargs)\n\n    @abstractmethod\n    def connect(self):\n        \"\"\"Connects to the service.\n\n        This method should be implemented by subclasses to establish a connection to the service.\n\n        Raises:\n            NotImplementedError: If the method is not implemented by a subclass.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.BaseConnection.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>An empty dictionary.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.BaseConnection.connect","title":"<code>connect()</code>  <code>abstractmethod</code>","text":"<p>Connects to the service.</p> <p>This method should be implemented by subclasses to establish a connection to the service.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the method is not implemented by a subclass.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@abstractmethod\ndef connect(self):\n    \"\"\"Connects to the service.\n\n    This method should be implemented by subclasses to establish a connection to the service.\n\n    Raises:\n        NotImplementedError: If the method is not implemented by a subclass.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.BaseConnection.to_dict","title":"<code>to_dict(for_tracing=False, **kwargs)</code>","text":"<p>Converts the connection instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the connection instance.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def to_dict(self, for_tracing: bool = False, **kwargs) -&gt; dict:\n    \"\"\"Converts the connection instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the connection instance.\n    \"\"\"\n    if for_tracing:\n        return {\"id\": self.id, \"type\": self.type}\n    else:\n        return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Chroma","title":"<code>Chroma</code>","text":"<p>               Bases: <code>BaseConnection</code></p> <p>Represents a connection to the Chroma service.</p> <p>Attributes:</p> Name Type Description <code>host</code> <code>str</code> <p>The host address of the Chroma service, fetched from the environment variable 'CHROMA_HOST'.</p> <code>port</code> <code>int</code> <p>The port number of the Chroma service, fetched from the environment variable 'CHROMA_PORT'.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Chroma(BaseConnection):\n    \"\"\"\n    Represents a connection to the Chroma service.\n\n    Attributes:\n        host (str): The host address of the Chroma service, fetched from the environment variable 'CHROMA_HOST'.\n        port (int): The port number of the Chroma service, fetched from the environment variable 'CHROMA_PORT'.\n    \"\"\"\n\n    host: str = Field(default_factory=partial(get_env_var, \"CHROMA_HOST\"))\n    port: int = Field(default_factory=partial(get_env_var, \"CHROMA_PORT\"))\n\n    @property\n    def vector_store_cls(self):\n        \"\"\"\n        Returns the ChromaVectorStore class.\n\n        This property dynamically imports and returns the ChromaVectorStore class\n        from the 'dynamiq.storages.vector' module.\n\n        Returns:\n            type: The ChromaVectorStore class.\n        \"\"\"\n        from dynamiq.storages.vector import ChromaVectorStore\n\n        return ChromaVectorStore\n\n    def connect(self) -&gt; \"ChromaClient\":\n        \"\"\"\n        Connects to the Chroma service.\n\n        This method establishes a connection to the Chroma service using the provided host and port.\n\n        Returns:\n            ChromaClient: An instance of the ChromaClient connected to the specified host and port.\n        \"\"\"\n        # Import in runtime to save memory\n        from chromadb import HttpClient\n\n        chroma_client = HttpClient(host=self.host, port=self.port)\n        logger.debug(f\"Connected to Chroma with host={self.host} and port={str(self.port)}\")\n        return chroma_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Chroma.vector_store_cls","title":"<code>vector_store_cls</code>  <code>property</code>","text":"<p>Returns the ChromaVectorStore class.</p> <p>This property dynamically imports and returns the ChromaVectorStore class from the 'dynamiq.storages.vector' module.</p> <p>Returns:</p> Name Type Description <code>type</code> <p>The ChromaVectorStore class.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Chroma.connect","title":"<code>connect()</code>","text":"<p>Connects to the Chroma service.</p> <p>This method establishes a connection to the Chroma service using the provided host and port.</p> <p>Returns:</p> Name Type Description <code>ChromaClient</code> <code>ClientAPI</code> <p>An instance of the ChromaClient connected to the specified host and port.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self) -&gt; \"ChromaClient\":\n    \"\"\"\n    Connects to the Chroma service.\n\n    This method establishes a connection to the Chroma service using the provided host and port.\n\n    Returns:\n        ChromaClient: An instance of the ChromaClient connected to the specified host and port.\n    \"\"\"\n    # Import in runtime to save memory\n    from chromadb import HttpClient\n\n    chroma_client = HttpClient(host=self.host, port=self.port)\n    logger.debug(f\"Connected to Chroma with host={self.host} and port={str(self.port)}\")\n    return chroma_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Databricks","title":"<code>Databricks</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Databricks(BaseApiKeyConnection):\n    url: str = Field(default_factory=partial(get_env_var, \"DATABRICKS_API_BASE\"))\n    api_key: str = Field(default_factory=partial(get_env_var, \"DATABRICKS_API_KEY\"))\n\n    def connect(self):\n        pass\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"\n        Returns the parameters required for connection.\n        \"\"\"\n        return {\n            \"api_base\": self.url,\n            \"api_key\": self.api_key,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Databricks.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Elasticsearch","title":"<code>Elasticsearch</code>","text":"<p>               Bases: <code>BaseConnection</code></p> <p>Represents a connection to the Elasticsearch service.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the Elasticsearch service</p> <code>api_key</code> <code>str</code> <p>API key for authentication</p> <code>username</code> <code>str</code> <p>Username for basic authentication</p> <code>password</code> <code>str</code> <p>Password for basic authentication</p> <code>cloud_id</code> <code>str</code> <p>Cloud ID for Elastic Cloud deployment</p> <code>ca_path</code> <code>str</code> <p>Path to CA certificate for SSL verification</p> <code>verify_certs</code> <code>bool</code> <p>Whether to verify SSL certificates</p> <code>use_ssl</code> <code>bool</code> <p>Whether to use SSL for connection</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Elasticsearch(BaseConnection):\n    \"\"\"\n    Represents a connection to the Elasticsearch service.\n\n    Attributes:\n        url (str): The URL of the Elasticsearch service\n        api_key (str): API key for authentication\n        username (str): Username for basic authentication\n        password (str): Password for basic authentication\n        cloud_id (str): Cloud ID for Elastic Cloud deployment\n        ca_path (str): Path to CA certificate for SSL verification\n        verify_certs (bool): Whether to verify SSL certificates\n        use_ssl (bool): Whether to use SSL for connection\n    \"\"\"\n\n    url: str = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_URL\", None))\n    api_key_id: str | None = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_API_KEY_ID\", None))\n    api_key: str | None = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_API_KEY\", None))\n    username: str | None = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_USERNAME\", None))\n    password: str | None = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_PASSWORD\", None))\n    cloud_id: str | None = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_CLOUD_ID\", None))\n    ca_path: str | None = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_CA_PATH\", None))\n    verify_certs: bool = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_VERIFY_CERTS\", False))\n    use_ssl: bool = Field(default_factory=partial(get_env_var, \"ELASTICSEARCH_USE_SSL\", True))\n\n    def connect(self):\n        \"\"\"\n        Connects to the Elasticsearch service.\n\n        Returns:\n            elasticsearch.Elasticsearch: An instance of the Elasticsearch client.\n\n        Raises:\n            ImportError: If elasticsearch package is not installed\n            ConnectionError: If connection fails\n            ValueError: If neither API key nor basic auth credentials are provided\n        \"\"\"\n\n        from elasticsearch import Elasticsearch\n        from elasticsearch.exceptions import AuthenticationException\n\n        # Build connection params\n        conn_params = {}\n\n        # Handle authentication\n        if self.api_key is not None:\n            if self.api_key_id is not None:\n                conn_params[\"api_key\"] = (self.api_key_id, self.api_key)\n            else:\n                conn_params[\"api_key\"] = self.api_key\n        elif self.username is not None and self.password is not None:\n            conn_params[\"basic_auth\"] = (self.username, self.password)\n        elif self.cloud_id is None:  # Only require auth for non-cloud deployments\n            raise ValueError(\"Either API key or username/password must be provided\")\n\n        # Handle SSL/TLS\n        if self.use_ssl:\n            if self.ca_path is not None:\n                conn_params[\"ca_certs\"] = self.ca_path\n            conn_params[\"verify_certs\"] = self.verify_certs\n\n        # Handle cloud deployment\n        if self.cloud_id is not None:\n            conn_params[\"cloud_id\"] = self.cloud_id\n        else:\n            conn_params[\"hosts\"] = [self.url]\n\n        # Create client\n        try:\n            es_client = Elasticsearch(**conn_params)\n        except Exception as e:\n            raise ConnectionError(f\"Failed to connect to Elasticsearch: {str(e)}\")\n\n        if not es_client.ping():\n            try:\n                info = es_client.info()\n            except AuthenticationException as e:\n                info = f\"Authentication error: {e}\"\n            raise ConnectionError(f\"Failed to connect to Elasticsearch. {info}\")\n\n        logger.debug(f\"Connected to Elasticsearch at {self.cloud_id or self.url}\")\n        return es_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Elasticsearch.connect","title":"<code>connect()</code>","text":"<p>Connects to the Elasticsearch service.</p> <p>Returns:</p> Type Description <p>elasticsearch.Elasticsearch: An instance of the Elasticsearch client.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If elasticsearch package is not installed</p> <code>ConnectionError</code> <p>If connection fails</p> <code>ValueError</code> <p>If neither API key nor basic auth credentials are provided</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self):\n    \"\"\"\n    Connects to the Elasticsearch service.\n\n    Returns:\n        elasticsearch.Elasticsearch: An instance of the Elasticsearch client.\n\n    Raises:\n        ImportError: If elasticsearch package is not installed\n        ConnectionError: If connection fails\n        ValueError: If neither API key nor basic auth credentials are provided\n    \"\"\"\n\n    from elasticsearch import Elasticsearch\n    from elasticsearch.exceptions import AuthenticationException\n\n    # Build connection params\n    conn_params = {}\n\n    # Handle authentication\n    if self.api_key is not None:\n        if self.api_key_id is not None:\n            conn_params[\"api_key\"] = (self.api_key_id, self.api_key)\n        else:\n            conn_params[\"api_key\"] = self.api_key\n    elif self.username is not None and self.password is not None:\n        conn_params[\"basic_auth\"] = (self.username, self.password)\n    elif self.cloud_id is None:  # Only require auth for non-cloud deployments\n        raise ValueError(\"Either API key or username/password must be provided\")\n\n    # Handle SSL/TLS\n    if self.use_ssl:\n        if self.ca_path is not None:\n            conn_params[\"ca_certs\"] = self.ca_path\n        conn_params[\"verify_certs\"] = self.verify_certs\n\n    # Handle cloud deployment\n    if self.cloud_id is not None:\n        conn_params[\"cloud_id\"] = self.cloud_id\n    else:\n        conn_params[\"hosts\"] = [self.url]\n\n    # Create client\n    try:\n        es_client = Elasticsearch(**conn_params)\n    except Exception as e:\n        raise ConnectionError(f\"Failed to connect to Elasticsearch: {str(e)}\")\n\n    if not es_client.ping():\n        try:\n            info = es_client.info()\n        except AuthenticationException as e:\n            info = f\"Authentication error: {e}\"\n        raise ConnectionError(f\"Failed to connect to Elasticsearch. {info}\")\n\n    logger.debug(f\"Connected to Elasticsearch at {self.cloud_id or self.url}\")\n    return es_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.ElevenLabs","title":"<code>ElevenLabs</code>","text":"<p>               Bases: <code>Http</code></p> <p>Represents a connection to the ElevenLabs API using an HTTP request.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>URL of the ElevenLabs API.</p> <code>method</code> <code>str</code> <p>HTTP method used for the request, defaults to HTTPMethod.POST.</p> <code>api_key</code> <code>str</code> <p>API key for authentication, fetched from the environment variable \"ELEVENLABS_API_KEY\".</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class ElevenLabs(Http):\n    \"\"\"\n    Represents a connection to the ElevenLabs API using an HTTP request.\n\n    Attributes:\n        url (str): URL of the ElevenLabs API.\n        method (str): HTTP method used for the request, defaults to HTTPMethod.POST.\n        api_key (str): API key for authentication, fetched from the environment variable \"ELEVENLABS_API_KEY\".\n    \"\"\"\n\n    url: str = Field(\n        default_factory=partial(\n            get_env_var,\n            \"ELEVENLABS_URL\",\n            \"https://api.elevenlabs.io/v1/\",\n        )\n    )\n    method: str = HTTPMethod.POST\n    api_key: str = Field(default_factory=partial(get_env_var, \"ELEVENLABS_API_KEY\"))\n\n    @model_validator(mode=\"after\")\n    def setup_headers(self):\n        \"\"\"Setup headers after model validation.\"\"\"\n        if self.api_key:\n            self.headers.update({\"xi-api-key\": self.api_key})\n        return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.ElevenLabs.setup_headers","title":"<code>setup_headers()</code>","text":"<p>Setup headers after model validation.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_headers(self):\n    \"\"\"Setup headers after model validation.\"\"\"\n    if self.api_key:\n        self.headers.update({\"xi-api-key\": self.api_key})\n    return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Exa","title":"<code>Exa</code>","text":"<p>               Bases: <code>Http</code></p> <p>Represents a connection to the Exa AI Search API.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the Exa API.</p> <code>method</code> <code>Literal[POST]</code> <p>HTTP method used for the request, defaults to POST.</p> <code>api_key</code> <code>str</code> <p>The API key for authentication, fetched from the environment variable 'EXA_API_KEY'.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Exa(Http):\n    \"\"\"\n    Represents a connection to the Exa AI Search API.\n\n    Attributes:\n        url (str): The URL of the Exa API.\n        method (Literal[HTTPMethod.POST]): HTTP method used for the request, defaults to POST.\n        api_key (str): The API key for authentication, fetched from the environment variable 'EXA_API_KEY'.\n    \"\"\"\n\n    url: Literal[\"https://api.exa.ai\"] = Field(default=\"https://api.exa.ai\")\n    method: Literal[HTTPMethod.POST] = HTTPMethod.POST\n    api_key: str = Field(default_factory=partial(get_env_var, \"EXA_API_KEY\"))\n\n    @model_validator(mode=\"after\")\n    def setup_headers(self):\n        \"\"\"Setup headers after model validation.\"\"\"\n        if self.api_key:\n            self.headers.update({\"x-api-key\": self.api_key, \"Content-Type\": \"application/json\"})\n        return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Exa.setup_headers","title":"<code>setup_headers()</code>","text":"<p>Setup headers after model validation.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_headers(self):\n    \"\"\"Setup headers after model validation.\"\"\"\n    if self.api_key:\n        self.headers.update({\"x-api-key\": self.api_key, \"Content-Type\": \"application/json\"})\n    return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Firecrawl","title":"<code>Firecrawl</code>","text":"<p>               Bases: <code>Http</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Firecrawl(Http):\n    url: str = Field(default=\"https://api.firecrawl.dev/v1/\")\n    api_key: str = Field(default_factory=lambda: get_env_var(\"FIRECRAWL_API_KEY\"))\n    method: Literal[HTTPMethod.POST] = HTTPMethod.POST\n\n    @model_validator(mode=\"after\")\n    def setup_headers(self):\n        \"\"\"Setup authorization headers after model validation.\"\"\"\n        if self.api_key:\n            self.headers.update({\"Authorization\": f\"Bearer {self.api_key}\"})\n        return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Firecrawl.setup_headers","title":"<code>setup_headers()</code>","text":"<p>Setup authorization headers after model validation.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_headers(self):\n    \"\"\"Setup authorization headers after model validation.\"\"\"\n    if self.api_key:\n        self.headers.update({\"Authorization\": f\"Bearer {self.api_key}\"})\n    return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.GoogleCloud","title":"<code>GoogleCloud</code>","text":"<p>               Bases: <code>BaseConnection</code></p> <p>Represents a connection to Google Cloud Platform (GCP) using service account credentials.</p> <p>Attributes:</p> Name Type Description <code>project_id</code> <code>str</code> <p>The GCP project ID.</p> <code>private_key_id</code> <code>str</code> <p>The private key ID used for authentication.</p> <code>private_key</code> <code>str</code> <p>The private key used for secure access.</p> <code>client_email</code> <code>str</code> <p>The service account email address.</p> <code>client_id</code> <code>str</code> <p>The unique client ID for authentication.</p> <code>auth_uri</code> <code>str</code> <p>The URI for Google's authentication endpoint.</p> <code>token_uri</code> <code>str</code> <p>The URI for obtaining OAuth tokens.</p> <code>auth_provider_x509_cert_url</code> <code>str</code> <p>The URL for Google's authentication provider X.509 certificates.</p> <code>client_x509_cert_url</code> <code>str</code> <p>The URL for the client's X.509 certificate.</p> <code>universe_domain</code> <code>str</code> <p>The domain associated with the Google Cloud environment.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class GoogleCloud(BaseConnection):\n    \"\"\"\n    Represents a connection to Google Cloud Platform (GCP) using service account credentials.\n\n    Attributes:\n        project_id (str): The GCP project ID.\n        private_key_id (str): The private key ID used for authentication.\n        private_key (str): The private key used for secure access.\n        client_email (str): The service account email address.\n        client_id (str): The unique client ID for authentication.\n        auth_uri (str): The URI for Google's authentication endpoint.\n        token_uri (str): The URI for obtaining OAuth tokens.\n        auth_provider_x509_cert_url (str): The URL for Google's authentication provider X.509 certificates.\n        client_x509_cert_url (str): The URL for the client's X.509 certificate.\n        universe_domain (str): The domain associated with the Google Cloud environment.\n    \"\"\"\n\n    project_id: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_PROJECT_ID\"))\n    private_key_id: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_PRIVATE_KEY_ID\"))\n    private_key: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_PRIVATE_KEY\"))\n    client_email: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_CLIENT_EMAIL\"))\n    client_id: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_CLIENT_ID\"))\n    auth_uri: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_AUTH_URI\"))\n    token_uri: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_TOKEN_URI\"))\n    auth_provider_x509_cert_url: str = Field(\n        default_factory=partial(get_env_var, \"GOOGLE_CLOUD_AUTH_PROVIDER_X509_CERT_URL\")\n    )\n    client_x509_cert_url: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_CLIENT_X509_CERT_URL\"))\n    universe_domain: str = Field(default_factory=partial(get_env_var, \"GOOGLE_CLOUD_UNIVERSE_DOMAIN\"))\n\n    def connect(self):\n        pass\n\n    @property\n    def conn_params(self):\n        \"\"\"\n        Returns the parameters required for the connection.\n\n        This property returns a dictionary containing Google Cloud service account credentials.\n\n        Returns:\n            dict: A dictionary with the keys 'vertex_project' and 'vertex_location'.\n        \"\"\"\n        return {\n            \"project_id\": self.project_id,\n            \"private_key_id\": self.private_key_id,\n            \"private_key\": self.private_key,\n            \"client_email\": self.client_email,\n            \"client_id\": self.client_id,\n            \"client_x509_cert_url\": self.client_x509_cert_url,\n            \"auth_uri\": self.auth_uri,\n            \"token_uri\": self.token_uri,\n            \"auth_provider_x509_cert_url\": self.auth_provider_x509_cert_url,\n            \"universe_domain\": self.universe_domain,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.GoogleCloud.conn_params","title":"<code>conn_params</code>  <code>property</code>","text":"<p>Returns the parameters required for the connection.</p> <p>This property returns a dictionary containing Google Cloud service account credentials.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary with the keys 'vertex_project' and 'vertex_location'.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.HTTPMethod","title":"<code>HTTPMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>This enum defines various method types for different HTTP requests.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class HTTPMethod(str, enum.Enum):\n    \"\"\"\n    This enum defines various method types for different HTTP requests.\n    \"\"\"\n\n    GET = \"GET\"\n    POST = \"POST\"\n    PUT = \"PUT\"\n    DELETE = \"DELETE\"\n    PATCH = \"PATCH\"\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Http","title":"<code>Http</code>","text":"<p>               Bases: <code>BaseConnection</code></p> <p>Represents a connection to an API.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the API.</p> <code>method</code> <code>str</code> <p>HTTP method used for the request, defaults to HTTPMethod.POST.</p> <code>headers</code> <code>dict[str, Any]</code> <p>Additional headers to include in the request, defaults to an empty dictionary.</p> <code>params</code> <code>Optional[dict[str, Any]]</code> <p>Parameters to include in the request, defaults to an empty dictionary.</p> <code>data</code> <code>Optional[dict[str, Any]]</code> <p>Data to include in the request, defaults to an empty dictionary.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Http(BaseConnection):\n    \"\"\"\n    Represents a connection to an API.\n\n    Attributes:\n        url (str): The URL of the API.\n        method (str): HTTP method used for the request, defaults to HTTPMethod.POST.\n        headers (dict[str, Any]): Additional headers to include in the request, defaults to an empty dictionary.\n        params (Optional[dict[str, Any]]): Parameters to include in the request, defaults to an empty dictionary.\n        data (Optional[dict[str, Any]]): Data to include in the request, defaults to an empty dictionary.\n    \"\"\"\n\n    url: str = \"\"\n    method: HTTPMethod\n    headers: dict[str, Any] = Field(default_factory=dict)\n    params: dict[str, Any] | None = Field(default_factory=dict)\n    data: dict[str, Any] | None = Field(default_factory=dict)\n\n    def connect(self):\n        \"\"\"\n        Connects to the API.\n\n        This method establishes a connection to the API using the provided URL and returns a requests\n        session.\n\n        Returns:\n            requests: A requests module for making HTTP requests to the API.\n        \"\"\"\n        import requests\n\n        return requests\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Http.connect","title":"<code>connect()</code>","text":"<p>Connects to the API.</p> <p>This method establishes a connection to the API using the provided URL and returns a requests session.</p> <p>Returns:</p> Name Type Description <code>requests</code> <p>A requests module for making HTTP requests to the API.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self):\n    \"\"\"\n    Connects to the API.\n\n    This method establishes a connection to the API using the provided URL and returns a requests\n    session.\n\n    Returns:\n        requests: A requests module for making HTTP requests to the API.\n    \"\"\"\n    import requests\n\n    return requests\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.HttpApiKey","title":"<code>HttpApiKey</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> <p>Represents a connection to an API that uses an HTTP API key for authentication.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the API.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class HttpApiKey(BaseApiKeyConnection):\n    \"\"\"\n    Represents a connection to an API that uses an HTTP API key for authentication.\n\n    Attributes:\n        url (str): The URL of the API.\n    \"\"\"\n\n    url: str\n\n    def connect(self):\n        \"\"\"\n        Connects to the API.\n\n        This method establishes a connection to the API using the provided URL and returns a requests\n        session.\n\n        Returns:\n            requests: A requests module for making HTTP requests to the API.\n        \"\"\"\n        import requests\n\n        return requests\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"\n        Returns the parameters required for connection.\n\n        Returns:\n            dict: A dictionary containing the API key with the key 'api_key' and base url with the key 'api_base'.\n        \"\"\"\n        return {\n            \"api_base\": self.url,\n            \"api_key\": self.api_key,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.HttpApiKey.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the API key with the key 'api_key' and base url with the key 'api_base'.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.HttpApiKey.connect","title":"<code>connect()</code>","text":"<p>Connects to the API.</p> <p>This method establishes a connection to the API using the provided URL and returns a requests session.</p> <p>Returns:</p> Name Type Description <code>requests</code> <p>A requests module for making HTTP requests to the API.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self):\n    \"\"\"\n    Connects to the API.\n\n    This method establishes a connection to the API using the provided URL and returns a requests\n    session.\n\n    Returns:\n        requests: A requests module for making HTTP requests to the API.\n    \"\"\"\n    import requests\n\n    return requests\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Jina","title":"<code>Jina</code>","text":"<p>               Bases: <code>Http</code></p> <p>Connection class for Jina Scrape API.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Jina(Http):\n    \"\"\"\n    Connection class for Jina Scrape API.\n    \"\"\"\n\n    api_key: str = Field(default_factory=partial(get_env_var, \"JINA_API_KEY\"))\n    method: Literal[HTTPMethod.GET] = HTTPMethod.GET\n\n    @model_validator(mode=\"after\")\n    def setup_headers(self):\n        \"\"\"Setup headers after model validation.\"\"\"\n        if self.api_key:\n            self.headers.update({\"Authorization\": f\"Bearer {self.api_key}\"})\n        return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Jina.setup_headers","title":"<code>setup_headers()</code>","text":"<p>Setup headers after model validation.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_headers(self):\n    \"\"\"Setup headers after model validation.\"\"\"\n    if self.api_key:\n        self.headers.update({\"Authorization\": f\"Bearer {self.api_key}\"})\n    return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.MCPSse","title":"<code>MCPSse</code>","text":"<p>               Bases: <code>BaseConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class MCPSse(BaseConnection):\n    url: str = Field(..., description=\"The SSE endpoint URL to connect to.\")\n    headers: dict[str, Any] | None = Field(default=None, description=\"Optional headers to include in the SSE request.\")\n    timeout: float = Field(default=5.0, description=\"Timeout in seconds for establishing the initial connection.\")\n    sse_read_timeout: float = Field(default=60 * 5, description=\"Timeout for reading SSE messages (in seconds).\")\n\n    def connect(self):\n        \"\"\"\n        Establishes an SSE connection.\n\n        Returns:\n            Async context manager for the SSE client.\n        \"\"\"\n        from mcp.client.sse import sse_client\n\n        return sse_client(\n            url=self.url,\n            headers=self.headers,\n            timeout=self.timeout,\n            sse_read_timeout=self.sse_read_timeout,\n        )\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.MCPSse.connect","title":"<code>connect()</code>","text":"<p>Establishes an SSE connection.</p> <p>Returns:</p> Type Description <p>Async context manager for the SSE client.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self):\n    \"\"\"\n    Establishes an SSE connection.\n\n    Returns:\n        Async context manager for the SSE client.\n    \"\"\"\n    from mcp.client.sse import sse_client\n\n    return sse_client(\n        url=self.url,\n        headers=self.headers,\n        timeout=self.timeout,\n        sse_read_timeout=self.sse_read_timeout,\n    )\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.MCPStdio","title":"<code>MCPStdio</code>","text":"<p>               Bases: <code>BaseConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class MCPStdio(BaseConnection):\n    command: str = Field(..., description=\"The executable to run to start the server.\")\n    args: list[str] = Field(default_factory=list, description=\"Command-line arguments to pass to the executable.\")\n    env: dict[str, str] | None = Field(None, description=\"Environment variables for the process.\")\n    cwd: str | Path | None = Field(None, description=\"Working directory for the process.\")\n    encoding: str = Field(default=\"utf-8\", description=\"Text encoding for communication.\")\n    encoding_error_handler: MCPEncodingErrorHandler = Field(\n        default=MCPEncodingErrorHandler.STRICT, description=\"Strategy for handling encoding errors.\"\n    )\n\n    def connect(self):\n        \"\"\"\n        Establishes a STDIO connection using a subprocess.\n\n        Returns:\n            Async context manager for the STDIO client.\n        \"\"\"\n        from mcp import StdioServerParameters\n        from mcp.client.stdio import stdio_client\n\n        return stdio_client(\n            StdioServerParameters(\n                command=self.command,\n                args=self.args,\n                env=self.env,\n                cwd=self.cwd,\n                encoding=self.encoding,\n                encoding_error_handler=self.encoding_error_handler.value,\n            )\n        )\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.MCPStdio.connect","title":"<code>connect()</code>","text":"<p>Establishes a STDIO connection using a subprocess.</p> <p>Returns:</p> Type Description <p>Async context manager for the STDIO client.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self):\n    \"\"\"\n    Establishes a STDIO connection using a subprocess.\n\n    Returns:\n        Async context manager for the STDIO client.\n    \"\"\"\n    from mcp import StdioServerParameters\n    from mcp.client.stdio import stdio_client\n\n    return stdio_client(\n        StdioServerParameters(\n            command=self.command,\n            args=self.args,\n            env=self.env,\n            cwd=self.cwd,\n            encoding=self.encoding,\n            encoding_error_handler=self.encoding_error_handler.value,\n        )\n    )\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.MCPStreamableHTTP","title":"<code>MCPStreamableHTTP</code>","text":"<p>               Bases: <code>BaseConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class MCPStreamableHTTP(BaseConnection):\n    url: str = Field(..., description=\"The endpoint URL to connect to.\")\n    headers: dict[str, Any] | None = Field(default=None, description=\"Optional headers to include in the request.\")\n    timeout: float = Field(default=30.0, description=\"Timeout in seconds for establishing the initial connection.\")\n    sse_read_timeout: float = Field(default=60 * 5, description=\"Timeout for reading messages (in seconds).\")\n\n    def connect(self):\n        \"\"\"\n        Establishes a streamable HTTP connection.\n\n        Returns:\n            Async context manager for the streamable HTTP client.\n        \"\"\"\n        from mcp.client.streamable_http import streamablehttp_client\n\n        return streamablehttp_client(\n            url=self.url,\n            headers=self.headers,\n            timeout=timedelta(seconds=self.timeout),\n            sse_read_timeout=timedelta(seconds=self.sse_read_timeout),\n        )\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.MCPStreamableHTTP.connect","title":"<code>connect()</code>","text":"<p>Establishes a streamable HTTP connection.</p> <p>Returns:</p> Type Description <p>Async context manager for the streamable HTTP client.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self):\n    \"\"\"\n    Establishes a streamable HTTP connection.\n\n    Returns:\n        Async context manager for the streamable HTTP client.\n    \"\"\"\n    from mcp.client.streamable_http import streamablehttp_client\n\n    return streamablehttp_client(\n        url=self.url,\n        headers=self.headers,\n        timeout=timedelta(seconds=self.timeout),\n        sse_read_timeout=timedelta(seconds=self.sse_read_timeout),\n    )\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Milvus","title":"<code>Milvus</code>","text":"<p>               Bases: <code>BaseConnection</code></p> <p>Represents a connection to the Milvus service.</p> <p>Attributes:</p> Name Type Description <code>deployment_type</code> <code>MilvusDeploymentType</code> <p>The deployment type of the Milvus service</p> <code>api_key</code> <code>Optional[str]</code> <p>The API key for Milvus</p> <code>uri</code> <code>str</code> <p>The URI for the Milvus instance (file path or host URL).</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Milvus(BaseConnection):\n    \"\"\"\n    Represents a connection to the Milvus service.\n\n    Attributes:\n        deployment_type (MilvusDeploymentType): The deployment type of the Milvus service\n        api_key (Optional[str]): The API key for Milvus\n        uri (str): The URI for the Milvus instance (file path or host URL).\n    \"\"\"\n\n    deployment_type: MilvusDeploymentType = MilvusDeploymentType.HOST\n    uri: str = Field(default_factory=partial(get_env_var, \"MILVUS_URI\", \"http://localhost:19530\"))\n    api_key: str | None = Field(default_factory=partial(get_env_var, \"MILVUS_API_TOKEN\", None))\n\n    @field_validator(\"uri\")\n    @classmethod\n    def validate_uri(cls, uri: str, values: ValidationInfo) -&gt; str:\n        deployment_type = values.data.get(\"deployment_type\")\n\n        if deployment_type == MilvusDeploymentType.FILE and not uri.endswith(\".db\"):\n            raise ValueError(\"For FILE deployment, URI should point to a file ending with '.db'.\")\n\n        return uri\n\n    def connect(self):\n        from pymilvus import MilvusClient\n\n        if self.deployment_type == MilvusDeploymentType.FILE:\n            milvus_client = MilvusClient(uri=self.uri)\n\n        elif self.deployment_type == MilvusDeploymentType.HOST:\n            if self.api_key:\n                milvus_client = MilvusClient(uri=self.uri, token=self.api_key)\n            else:\n                milvus_client = MilvusClient(uri=self.uri)\n\n        else:\n            raise ValueError(\"Invalid deployment type for Milvus connection.\")\n\n        return milvus_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.MilvusDeploymentType","title":"<code>MilvusDeploymentType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Defines general deployment types for Milvus deployments. Attributes:     FILE (str): Represents a file-based deployment, validated with a .db suffix.     HOST (str): Represents a host-based deployment, which could be a cloud, cluster,                 or single machine with or without authentication.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class MilvusDeploymentType(str, enum.Enum):\n    \"\"\"\n    Defines general deployment types for Milvus deployments.\n    Attributes:\n        FILE (str): Represents a file-based deployment, validated with a .db suffix.\n        HOST (str): Represents a host-based deployment, which could be a cloud, cluster,\n                    or single machine with or without authentication.\n    \"\"\"\n\n    FILE = \"file\"\n    HOST = \"host\"\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.NvidiaNIM","title":"<code>NvidiaNIM</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class NvidiaNIM(BaseApiKeyConnection):\n    url: str = Field(default_factory=partial(get_env_var, \"NVIDIA_NIM_URL\"))\n    api_key: str = Field(default_factory=partial(get_env_var, \"NVIDIA_NIM_API_KEY\"))\n\n    def connect(self):\n        pass\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"\n        Returns the parameters required for connection.\n        \"\"\"\n        return {\n            \"api_base\": self.url,\n            \"api_key\": self.api_key,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.NvidiaNIM.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Ollama","title":"<code>Ollama</code>","text":"<p>               Bases: <code>BaseConnection</code></p> <p>Represents a connection to Ollama API.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the Ollama API, defaults to \"http://localhost:11434\".</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Ollama(BaseConnection):\n    \"\"\"Represents a connection to Ollama API.\n\n    Attributes:\n        url (str): The URL of the Ollama API, defaults to \"http://localhost:11434\".\n    \"\"\"\n\n    url: str = Field(default=\"http://localhost:11434\")\n\n    def connect(self):\n        \"\"\"Connects to the Ollama API.\n\n        Returns:\n            requests: A requests module for making HTTP requests to the API.\n        \"\"\"\n        import requests\n\n        return requests\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"Returns the parameters required for connection.\n\n        Returns:\n            dict: A dictionary containing the base url with the key 'api_base'.\n        \"\"\"\n        return {\n            \"api_base\": self.url,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Ollama.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the base url with the key 'api_base'.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Ollama.connect","title":"<code>connect()</code>","text":"<p>Connects to the Ollama API.</p> <p>Returns:</p> Name Type Description <code>requests</code> <p>A requests module for making HTTP requests to the API.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self):\n    \"\"\"Connects to the Ollama API.\n\n    Returns:\n        requests: A requests module for making HTTP requests to the API.\n    \"\"\"\n    import requests\n\n    return requests\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.OpenAI","title":"<code>OpenAI</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> <p>Represents a connection to the OpenAI service.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>str</code> <p>The API key for the OpenAI service, fetched from the environment variable 'OPENAI_API_KEY'.</p> <code>url</code> <code>str</code> <p>The endpoint url for the OpenAI service, fetched from the environment variable 'OPENAI_URL'.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class OpenAI(BaseApiKeyConnection):\n    \"\"\"\n    Represents a connection to the OpenAI service.\n\n    Attributes:\n        api_key (str): The API key for the OpenAI service, fetched from the environment variable 'OPENAI_API_KEY'.\n        url (str): The endpoint url for the OpenAI service, fetched from the environment variable 'OPENAI_URL'.\n    \"\"\"\n    api_key: str = Field(default_factory=partial(get_env_var, \"OPENAI_API_KEY\"))\n    url: str = Field(default_factory=partial(get_env_var, \"OPENAI_URL\", \"https://api.openai.com/v1\"))\n\n    def connect(self) -&gt; \"OpenAIClient\":\n        \"\"\"\n        Connects to the OpenAI service.\n\n        This method establishes a connection to the OpenAI service using the provided API key.\n\n        Returns:\n            OpenAIClient: An instance of the OpenAIClient connected with the specified API key.\n        \"\"\"\n        # Import in runtime to save memory\n        from openai import OpenAI as OpenAIClient\n\n        openai_client = OpenAIClient(api_key=self.api_key, base_url=self.url)\n        logger.debug(\"Connected to OpenAI\")\n        return openai_client\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"\n        Returns the parameters required for connection.\n        \"\"\"\n        return {\n            \"api_base\": self.url,\n            \"api_key\": self.api_key,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.OpenAI.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.OpenAI.connect","title":"<code>connect()</code>","text":"<p>Connects to the OpenAI service.</p> <p>This method establishes a connection to the OpenAI service using the provided API key.</p> <p>Returns:</p> Name Type Description <code>OpenAIClient</code> <code>OpenAI</code> <p>An instance of the OpenAIClient connected with the specified API key.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self) -&gt; \"OpenAIClient\":\n    \"\"\"\n    Connects to the OpenAI service.\n\n    This method establishes a connection to the OpenAI service using the provided API key.\n\n    Returns:\n        OpenAIClient: An instance of the OpenAIClient connected with the specified API key.\n    \"\"\"\n    # Import in runtime to save memory\n    from openai import OpenAI as OpenAIClient\n\n    openai_client = OpenAIClient(api_key=self.api_key, base_url=self.url)\n    logger.debug(\"Connected to OpenAI\")\n    return openai_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Pinecone","title":"<code>Pinecone</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> <p>Represents a connection to the Pinecone service.</p> <p>Attributes:</p> Name Type Description <code>api_key</code> <code>str</code> <p>The API key for the service. Defaults to the environment variable 'PINECONE_API_KEY'.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Pinecone(BaseApiKeyConnection):\n    \"\"\"\n    Represents a connection to the Pinecone service.\n\n    Attributes:\n        api_key (str): The API key for the service.\n            Defaults to the environment variable 'PINECONE_API_KEY'.\n    \"\"\"\n\n    api_key: str = Field(default_factory=partial(get_env_var, \"PINECONE_API_KEY\"))\n\n    def connect(self) -&gt; \"PineconeClient\":\n        \"\"\"\n        Connects to the Pinecone service.\n\n        This method establishes a connection to the Pinecone service using the provided API key.\n\n        Returns:\n            PineconeClient: An instance of the PineconeClient connected to the service.\n        \"\"\"\n        # Import in runtime to save memory\n        from pinecone import Pinecone as PineconeClient\n        pinecone_client = PineconeClient(self.api_key)\n        logger.debug(\"Connected to Pinecone\")\n        return pinecone_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Pinecone.connect","title":"<code>connect()</code>","text":"<p>Connects to the Pinecone service.</p> <p>This method establishes a connection to the Pinecone service using the provided API key.</p> <p>Returns:</p> Name Type Description <code>PineconeClient</code> <code>Pinecone</code> <p>An instance of the PineconeClient connected to the service.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self) -&gt; \"PineconeClient\":\n    \"\"\"\n    Connects to the Pinecone service.\n\n    This method establishes a connection to the Pinecone service using the provided API key.\n\n    Returns:\n        PineconeClient: An instance of the PineconeClient connected to the service.\n    \"\"\"\n    # Import in runtime to save memory\n    from pinecone import Pinecone as PineconeClient\n    pinecone_client = PineconeClient(self.api_key)\n    logger.debug(\"Connected to Pinecone\")\n    return pinecone_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.PostgreSQL","title":"<code>PostgreSQL</code>","text":"<p>               Bases: <code>BaseConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class PostgreSQL(BaseConnection):\n    host: str = Field(default_factory=partial(get_env_var, \"POSTGRESQL_HOST\", \"localhost\"))\n    port: int = Field(default_factory=partial(get_env_var, \"POSTGRESQL_PORT\", 5432))\n    database: str = Field(default_factory=partial(get_env_var, \"POSTGRESQL_DATABASE\", \"db\"))\n    user: str = Field(default_factory=partial(get_env_var, \"POSTGRESQL_USER\", \"postgres\"))\n    password: str = Field(default_factory=partial(get_env_var, \"POSTGRESQL_PASSWORD\", \"password\"))\n\n    def connect(self):\n        try:\n            import psycopg\n\n            conn = psycopg.connect(\n                host=self.host,\n                port=self.port,\n                dbname=self.database,\n                user=self.user,\n                password=self.password,\n                row_factory=psycopg.rows.dict_row,\n            )\n            conn.autocommit = True\n            logger.debug(\n                f\"Connected to PostgreSQL with host={self.host}, \"\n                f\"port={str(self.port)}, user={self.user}, \"\n                f\"database={self.database}.\"\n            )\n            return conn\n        except Exception as e:\n            raise ConnectionError(f\"Failed to connect to PostgreSQL: {str(e)}\")\n\n    @property\n    def conn_params(self) -&gt; str:\n        \"\"\"\n        Returns the parameters required for connection.\n\n        Returns:\n            dict: A string containing the host, the port, the database,\n            the user, and the password for the connection.\n        \"\"\"\n        return f\"postgresql://{self.user}:{self.password}@{self.host}:{self.port}/{self.database}\"\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.PostgreSQL.conn_params","title":"<code>conn_params: str</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>str</code> <p>A string containing the host, the port, the database,</p> <code>str</code> <p>the user, and the password for the connection.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Qdrant","title":"<code>Qdrant</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> <p>Represents a connection to the Qdrant service.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the Qdrant service. Defaults to the environment variable 'QDRANT_URL'.</p> <code>api_key</code> <code>str</code> <p>The API key for the Qdrant service. Defaults to the environment variable 'QDRANT_API_KEY'.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Qdrant(BaseApiKeyConnection):\n    \"\"\"\n    Represents a connection to the Qdrant service.\n\n    Attributes:\n        url (str): The URL of the Qdrant service.\n            Defaults to the environment variable 'QDRANT_URL'.\n        api_key (str): The API key for the Qdrant service.\n            Defaults to the environment variable 'QDRANT_API_KEY'.\n    \"\"\"\n\n    url: str = Field(default_factory=partial(get_env_var, \"QDRANT_URL\"))\n    api_key: str = Field(default_factory=partial(get_env_var, \"QDRANT_API_KEY\"))\n\n    def connect(self) -&gt; \"QdrantClient\":\n        from qdrant_client import QdrantClient\n\n        qdrant_client = QdrantClient(\n            url=self.url,\n            api_key=self.api_key,\n        )\n\n        return qdrant_client\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.ScaleSerp","title":"<code>ScaleSerp</code>","text":"<p>               Bases: <code>Http</code></p> <p>Connection class for Scale SERP Search API.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class ScaleSerp(Http):\n    \"\"\"\n    Connection class for Scale SERP Search API.\n    \"\"\"\n\n    url: str = \"https://api.scaleserp.com\"\n    api_key: str = Field(default_factory=partial(get_env_var, \"SERP_API_KEY\"))\n    method: str = HTTPMethod.GET\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def setup_params(self):\n        \"\"\"Setup params after model validation.\"\"\"\n        if self.api_key:\n            self.params.update({\"api_key\": self.api_key})\n        return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.ScaleSerp.setup_params","title":"<code>setup_params()</code>","text":"<p>Setup params after model validation.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_params(self):\n    \"\"\"Setup params after model validation.\"\"\"\n    if self.api_key:\n        self.params.update({\"api_key\": self.api_key})\n    return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Tavily","title":"<code>Tavily</code>","text":"<p>               Bases: <code>Http</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Tavily(Http):\n    url: str = Field(default=\"https://api.tavily.com\")\n    api_key: str = Field(default_factory=partial(get_env_var, \"TAVILY_API_KEY\"))\n    method: Literal[HTTPMethod.POST] = HTTPMethod.POST\n\n    @model_validator(mode=\"after\")\n    def setup_data(self):\n        \"\"\"Setup data after model validation.\"\"\"\n        if self.api_key:\n            self.data.update({\"api_key\": self.api_key})\n        return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Tavily.setup_data","title":"<code>setup_data()</code>","text":"<p>Setup data after model validation.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_data(self):\n    \"\"\"Setup data after model validation.\"\"\"\n    if self.api_key:\n        self.data.update({\"api_key\": self.api_key})\n    return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Unstructured","title":"<code>Unstructured</code>","text":"<p>               Bases: <code>HttpApiKey</code></p> <p>Represents a connection to the Unstructured API.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the Unstructured API, fetched from the environment variable 'UNSTRUCTURED_API_URL'.</p> <code>api_key</code> <code>str</code> <p>The API key for the Unstructured API, fetched from the environment variable 'UNSTRUCTURED_API_KEY'.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Unstructured(HttpApiKey):\n    \"\"\"\n    Represents a connection to the Unstructured API.\n\n    Attributes:\n        url (str): The URL of the Unstructured API, fetched from the environment variable 'UNSTRUCTURED_API_URL'.\n        api_key (str): The API key for the Unstructured API, fetched from the environment\n            variable 'UNSTRUCTURED_API_KEY'.\n    \"\"\"\n\n    url: str = Field(\n        default_factory=partial(\n            get_env_var,\n            \"UNSTRUCTURED_API_URL\",\n            \"https://api.unstructured.io/\",\n        )\n    )\n    api_key: str = Field(default_factory=partial(get_env_var, \"UNSTRUCTURED_API_KEY\"))\n\n    def connect(self):\n        \"\"\"\n        Connects to the Unstructured API.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Unstructured.connect","title":"<code>connect()</code>","text":"<p>Connects to the Unstructured API.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self):\n    \"\"\"\n    Connects to the Unstructured API.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.VertexAI","title":"<code>VertexAI</code>","text":"<p>               Bases: <code>GoogleCloud</code></p> <p>Represents a connection to the Vertex AI service.</p> <p>This connection requires additional GCP application credentials. The credentials should be provided in the connection fields (related to Google Cloud) or set in the environment variables.</p> <p>Attributes:</p> Name Type Description <code>vertex_project_id</code> <code>str</code> <p>The GCP project ID.</p> <code>vertex_project_location</code> <code>str</code> <p>The location of the GCP project.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class VertexAI(GoogleCloud):\n    \"\"\"\n    Represents a connection to the Vertex AI service.\n\n    This connection requires additional GCP application credentials. The credentials should be provided in the\n    connection fields (related to Google Cloud) or set in the environment variables.\n\n    Attributes:\n        vertex_project_id (str): The GCP project ID.\n        vertex_project_location (str): The location of the GCP project.\n    \"\"\"\n\n    vertex_project_id: str = Field(default_factory=partial(get_env_var, \"VERTEXAI_PROJECT_ID\"))\n    vertex_project_location: str = Field(default_factory=partial(get_env_var, \"VERTEXAI_PROJECT_LOCATION\"))\n\n    def connect(self):\n        pass\n\n    @property\n    def conn_params(self):\n        \"\"\"\n        Returns the parameters required for the connection.\n\n        This property returns a dictionary containing the project ID and project location.\n\n        Returns:\n            dict: A dictionary with the keys 'vertex_project' and 'vertex_location'.\n        \"\"\"\n        vertex_credentials = json.dumps(super().conn_params.copy())\n        return {\n            \"vertex_project\": self.vertex_project_id,\n            \"vertex_location\": self.vertex_project_location,\n            \"vertex_credentials\": vertex_credentials,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.VertexAI.conn_params","title":"<code>conn_params</code>  <code>property</code>","text":"<p>Returns the parameters required for the connection.</p> <p>This property returns a dictionary containing the project ID and project location.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary with the keys 'vertex_project' and 'vertex_location'.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.WatsonX","title":"<code>WatsonX</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class WatsonX(BaseApiKeyConnection):\n    api_key: str = Field(default_factory=partial(get_env_var, \"WATSONX_API_KEY\"))\n    project_id: str = Field(default_factory=partial(get_env_var, \"WATSONX_PROJECT_ID\"))\n    url: str = Field(default_factory=partial(get_env_var, \"WATSONX_URL\"))\n\n    def connect(self):\n        pass\n\n    @property\n    def conn_params(self) -&gt; dict:\n        \"\"\"\n        Returns the parameters required for connection.\n\n        Returns:\n            dict: A dictionary containing\n\n                -the API key with the key 'api_key'.\n\n                -the project ID with the key 'project_id'.\n\n                -the url with the key 'url'.\n        \"\"\"\n        return {\n            \"apikey\": self.api_key,\n            \"project_id\": self.project_id,\n            \"url\": self.url,\n        }\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.WatsonX.conn_params","title":"<code>conn_params: dict</code>  <code>property</code>","text":"<p>Returns the parameters required for connection.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing</p> <p>-the API key with the key 'api_key'.</p> <p>-the project ID with the key 'project_id'.</p> <p>-the url with the key 'url'.</p>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Weaviate","title":"<code>Weaviate</code>","text":"<p>               Bases: <code>BaseApiKeyConnection</code></p> <p>Represents a connection to the Weaviate service.</p> <p>Attributes:</p> Name Type Description <code>deployment_type</code> <code>WeaviateDeploymentType</code> <p>The deployment type of the service.</p> <code>api_key</code> <code>str</code> <p>The API key for the service. Defaults to the environment variable 'WEAVIATE_API_KEY'.</p> <code>url</code> <code>str</code> <p>The URL of the service. Defaults to the environment variable 'WEAVIATE_URL'.</p> <code>http_host</code> <code>str</code> <p>The HTTP host for the service. Defaults to the environment variable 'WEAVIATE_HTTP_HOST'.</p> <code>http_port</code> <code>int</code> <p>The HTTP port for the service. Defaults to the environment variable 'WEAVIATE_HTTP_PORT'.</p> <code>grpc_host</code> <code>str</code> <p>The gRPC host for the service. Defaults to the environment variable 'WEAVIATE_GRPC_HOST'.</p> <code>grpc_port</code> <code>int</code> <p>The gRPC port for the service. Defaults to the environment variable 'WEAVIATE_GRPC_PORT'.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Weaviate(BaseApiKeyConnection):\n    \"\"\"\n    Represents a connection to the Weaviate service.\n\n    Attributes:\n        deployment_type (WeaviateDeploymentType): The deployment type of the service.\n        api_key (str): The API key for the service.\n            Defaults to the environment variable 'WEAVIATE_API_KEY'.\n        url (str): The URL of the service.\n            Defaults to the environment variable 'WEAVIATE_URL'.\n        http_host (str): The HTTP host for the service.\n            Defaults to the environment variable 'WEAVIATE_HTTP_HOST'.\n        http_port (int): The HTTP port for the service.\n            Defaults to the environment variable 'WEAVIATE_HTTP_PORT'.\n        grpc_host (str): The gRPC host for the service.\n            Defaults to the environment variable 'WEAVIATE_GRPC_HOST'.\n        grpc_port (int): The gRPC port for the service.\n            Defaults to the environment variable 'WEAVIATE_GRPC_PORT'.\n    \"\"\"\n\n    deployment_type: WeaviateDeploymentType = WeaviateDeploymentType.WEAVIATE_CLOUD\n    api_key: str = Field(default_factory=partial(get_env_var, \"WEAVIATE_API_KEY\"))\n    url: str = Field(default_factory=partial(get_env_var, \"WEAVIATE_URL\"))\n    http_host: str = Field(default_factory=partial(get_env_var, \"WEAVIATE_HTTP_HOST\"))\n    http_port: int = Field(default_factory=partial(get_env_var, \"WEAVIATE_HTTP_PORT\", 443))\n    grpc_host: str = Field(default_factory=partial(get_env_var, \"WEAVIATE_GRPC_HOST\"))\n    grpc_port: int = Field(default_factory=partial(get_env_var, \"WEAVIATE_GRPC_PORT\", 50051))\n\n    def connect(self) -&gt; \"WeaviateClient\":\n        \"\"\"\n        Connects to the Weaviate service.\n\n        This method establishes a connection to the Weaviate service using the provided URL and API key.\n\n        Returns:\n            WeaviateClient: An instance of the WeaviateClient connected to the specified URL.\n        \"\"\"\n        # Import in runtime to save memory\n        from weaviate import connect_to_custom, connect_to_weaviate_cloud\n        from weaviate.classes.init import AdditionalConfig, Auth, Timeout\n\n        if self.deployment_type == WeaviateDeploymentType.WEAVIATE_CLOUD:\n            weaviate_client = connect_to_weaviate_cloud(\n                cluster_url=self.url,\n                auth_credentials=Auth.api_key(self.api_key),\n            )\n            logger.debug(f\"Connected to Weaviate with url={self.url}\")\n            return weaviate_client\n\n        elif self.deployment_type == WeaviateDeploymentType.CUSTOM:\n            weaviate_client = connect_to_custom(\n                http_host=self.http_host,\n                http_port=self.http_port,\n                http_secure=True,\n                grpc_host=self.grpc_host,\n                grpc_port=self.grpc_port,\n                grpc_secure=True,\n                auth_credentials=Auth.api_key(self.api_key),\n                additional_config=AdditionalConfig(\n                    timeout=Timeout(init=30, query=60, insert=120),  # Values in seconds\n                ),\n                skip_init_checks=False,\n            )\n            logger.debug(f\"Connected to Weaviate with http_host={self.http_host}\")\n            return weaviate_client\n        else:\n            raise ValueError(\"Invalid deployment type\")\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Weaviate.connect","title":"<code>connect()</code>","text":"<p>Connects to the Weaviate service.</p> <p>This method establishes a connection to the Weaviate service using the provided URL and API key.</p> <p>Returns:</p> Name Type Description <code>WeaviateClient</code> <code>WeaviateClient</code> <p>An instance of the WeaviateClient connected to the specified URL.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>def connect(self) -&gt; \"WeaviateClient\":\n    \"\"\"\n    Connects to the Weaviate service.\n\n    This method establishes a connection to the Weaviate service using the provided URL and API key.\n\n    Returns:\n        WeaviateClient: An instance of the WeaviateClient connected to the specified URL.\n    \"\"\"\n    # Import in runtime to save memory\n    from weaviate import connect_to_custom, connect_to_weaviate_cloud\n    from weaviate.classes.init import AdditionalConfig, Auth, Timeout\n\n    if self.deployment_type == WeaviateDeploymentType.WEAVIATE_CLOUD:\n        weaviate_client = connect_to_weaviate_cloud(\n            cluster_url=self.url,\n            auth_credentials=Auth.api_key(self.api_key),\n        )\n        logger.debug(f\"Connected to Weaviate with url={self.url}\")\n        return weaviate_client\n\n    elif self.deployment_type == WeaviateDeploymentType.CUSTOM:\n        weaviate_client = connect_to_custom(\n            http_host=self.http_host,\n            http_port=self.http_port,\n            http_secure=True,\n            grpc_host=self.grpc_host,\n            grpc_port=self.grpc_port,\n            grpc_secure=True,\n            auth_credentials=Auth.api_key(self.api_key),\n            additional_config=AdditionalConfig(\n                timeout=Timeout(init=30, query=60, insert=120),  # Values in seconds\n            ),\n            skip_init_checks=False,\n        )\n        logger.debug(f\"Connected to Weaviate with http_host={self.http_host}\")\n        return weaviate_client\n    else:\n        raise ValueError(\"Invalid deployment type\")\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.WeaviateDeploymentType","title":"<code>WeaviateDeploymentType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Defines various deployment types for different Weaviate deployments.</p> <p>Attributes:</p> Name Type Description <code>WEAVIATE_CLOUD</code> <code>str</code> <p>Represents a deployment on Weaviate Cloud. Value is 'weaviate_cloud'.</p> <code>CUSTOM</code> <code>str</code> <p>Represents a custom deployment. Value is 'custom'.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class WeaviateDeploymentType(str, enum.Enum):\n    \"\"\"\n    Defines various deployment types for different Weaviate deployments.\n\n    Attributes:\n        WEAVIATE_CLOUD (str): Represents a deployment on Weaviate Cloud.\n            Value is 'weaviate_cloud'.\n        CUSTOM (str): Represents a custom deployment.\n            Value is 'custom'.\n    \"\"\"\n\n    WEAVIATE_CLOUD = \"weaviate_cloud\"\n    CUSTOM = \"custom\"\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Whisper","title":"<code>Whisper</code>","text":"<p>               Bases: <code>Http</code></p> <p>Represents a connection to the Whisper API using an HTTP request.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>URL of the Whisper API, fetched from the environment variable \"WHISPER_URL\".</p> <code>method</code> <code>str</code> <p>HTTP method used for the request, defaults to HTTPMethod.POST.</p> <code>api_key</code> <code>str</code> <p>API key for authentication, fetched from the environment variable \"OPENAI_API_KEY\".</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class Whisper(Http):\n    \"\"\"\n    Represents a connection to the Whisper API using an HTTP request.\n\n    Attributes:\n        url (str): URL of the Whisper API, fetched from the environment variable \"WHISPER_URL\".\n        method (str): HTTP method used for the request, defaults to HTTPMethod.POST.\n        api_key (str): API key for authentication, fetched from the environment variable \"OPENAI_API_KEY\".\n    \"\"\"\n    url: str = Field(\n        default_factory=partial(\n            get_env_var, \"WHISPER_URL\", \"https://api.openai.com/v1/\"\n        )\n    )\n    method: str = HTTPMethod.POST\n    api_key: str = Field(default_factory=partial(get_env_var, \"OPENAI_API_KEY\"))\n\n    @model_validator(mode=\"after\")\n    def setup_headers(self):\n        \"\"\"Setup headers after model validation.\"\"\"\n        if self.api_key:\n            self.headers.update({\"Authorization\": f\"Bearer {self.api_key}\"})\n        return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.Whisper.setup_headers","title":"<code>setup_headers()</code>","text":"<p>Setup headers after model validation.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_headers(self):\n    \"\"\"Setup headers after model validation.\"\"\"\n    if self.api_key:\n        self.headers.update({\"Authorization\": f\"Bearer {self.api_key}\"})\n    return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.ZenRows","title":"<code>ZenRows</code>","text":"<p>               Bases: <code>Http</code></p> <p>Connection class for ZenRows Scrape API.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>class ZenRows(Http):\n    \"\"\"\n    Connection class for ZenRows Scrape API.\n    \"\"\"\n\n    url: str = \"https://api.zenrows.com/v1/\"\n    api_key: str = Field(default_factory=partial(get_env_var, \"ZENROWS_API_KEY\"))\n    method: str = HTTPMethod.GET\n\n    @model_validator(mode=\"after\")\n    def setup_params(self):\n        \"\"\"Setup params after model validation.\"\"\"\n        if self.api_key:\n            self.params.update({\"apikey\": self.api_key})\n        return self\n</code></pre>"},{"location":"dynamiq/connections/connections/#dynamiq.connections.connections.ZenRows.setup_params","title":"<code>setup_params()</code>","text":"<p>Setup params after model validation.</p> Source code in <code>dynamiq/connections/connections.py</code> <pre><code>@model_validator(mode=\"after\")\ndef setup_params(self):\n    \"\"\"Setup params after model validation.\"\"\"\n    if self.api_key:\n        self.params.update({\"apikey\": self.api_key})\n    return self\n</code></pre>"},{"location":"dynamiq/connections/managers/","title":"Managers","text":""},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionClientInitType","title":"<code>ConnectionClientInitType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of connection client initialization types.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>class ConnectionClientInitType(str, enum.Enum):\n    \"\"\"Enumeration of connection client initialization types.\"\"\"\n    DEFAULT = \"DEFAULT\"\n    VECTOR_STORE = \"VECTOR_STORE\"\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager","title":"<code>ConnectionManager</code>","text":"<p>Manages connections to various services and databases.</p> <p>This class handles the creation, retrieval, and management of connection clients for different types of services and databases.</p> <p>Attributes:</p> Name Type Description <code>serializer</code> <p>An object used for serializing and deserializing data.</p> <code>connection_clients</code> <code>dict[str, Any]</code> <p>A dictionary storing initialized connection clients.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>class ConnectionManager:\n    \"\"\"\n    Manages connections to various services and databases.\n\n    This class handles the creation, retrieval, and management of connection clients\n    for different types of services and databases.\n\n    Attributes:\n        serializer: An object used for serializing and deserializing data.\n        connection_clients: A dictionary storing initialized connection clients.\n    \"\"\"\n\n    def __init__(self, serializer: Any | None = None):\n        \"\"\"\n        Initializes the ConnectionManager.\n\n        Args:\n            serializer: An optional serializer object. If not provided, JsonPickleSerializer is used.\n        \"\"\"\n        self.serializer = serializer or JsonPickleSerializer()\n        self.connection_clients: dict[str, Any] = {}\n\n    @staticmethod\n    def get_connection_by_type(conn_type: str) -&gt; type[BaseConnection]:\n        \"\"\"\n        Retrieves the connection class based on the given connection type.\n\n        Args:\n            conn_type: The type of connection to retrieve.\n\n        Returns:\n            The connection class corresponding to the given type.\n\n        Raises:\n            ValueError: If the connection type is not found.\n        \"\"\"\n        try:\n            entity_module, entity_name = conn_type.rsplit(\".\", 1)\n            imported_module = importlib.import_module(entity_module)\n            if entity := getattr(imported_module, entity_name, None):\n                return entity\n        except (ModuleNotFoundError, ImportError):\n            raise ValueError(f\"Connection type {conn_type} not found\")\n\n    def get_connection_client(\n        self,\n        connection: BaseConnection,\n        init_type: ConnectionClientInitType = ConnectionClientInitType.DEFAULT,\n    ) -&gt; Any | None:\n        \"\"\"\n        Retrieves or initializes a connection client for the given connection.\n\n        Args:\n            connection: The connection object.\n            init_type: The initialization type for the connection client.\n\n        Returns:\n            The initialized connection client.\n\n        Raises:\n            ConnectionManagerException: If the connection does not support the specified initialization type.\n        \"\"\"\n        logger.debug(\n            f\"Get connection client for '{connection.id}-{connection.type}' \"\n            f\"with '{init_type.value.lower()}' initialization\"\n        )\n        conn_id = self.get_connection_id(connection, init_type)\n        if conn_client := self.connection_clients.get(conn_id):\n            if (conn_client_closed := getattr(conn_client, \"closed\", None)) is None:\n                return conn_client\n\n            if not conn_client_closed:\n                return conn_client\n\n        logger.debug(\n            f\"Init connection client for '{connection.id}-{connection.type}' \"\n            f\"with '{init_type.value.lower()}' initialization\"\n        )\n        conn_method_name = CONNECTION_METHOD_BY_INIT_TYPE[init_type]\n        if not (\n            conn_method := getattr(connection, conn_method_name, None)\n        ) or not callable(conn_method):\n            raise ConnectionManagerException(\n                f\"Connection '{connection.id}-{connection.type}' not support '{init_type.value}' initialization\"\n            )\n\n        conn_client = conn_method()\n        self.connection_clients[conn_id] = conn_client\n\n        return conn_client\n\n    def get_connection_id(\n        self,\n        connection: BaseConnection,\n        init_type: ConnectionClientInitType = ConnectionClientInitType.DEFAULT,\n    ) -&gt; str:\n        \"\"\"\n        Generates a unique connection ID based on the connection and initialization type.\n\n        Args:\n            connection: The connection object.\n            init_type: The initialization type for the connection client.\n\n        Returns:\n            A unique string identifier for the connection.\n        \"\"\"\n        conn_hash = self.hash(connection.model_dump_json())\n        return f\"{connection.type.lower()}:{init_type.lower()}:{conn_hash}\"\n\n    def close(self):\n        \"\"\"\n        Closes all open connection clients and clears the connection_clients dictionary.\n        \"\"\"\n        logger.debug(\"Close connection clients\")\n        for conn_client in self.connection_clients.values():\n            if hasattr(conn_client, \"close\"):\n                conn_client.close()\n        self.connection_clients = {}\n\n    @staticmethod\n    def hash(data: str) -&gt; str:\n        \"\"\"\n        Generates a SHA256 hash of the input string.\n\n        Args:\n            data: The input string to hash.\n\n        Returns:\n            The hexadecimal representation of the SHA256 hash.\n        \"\"\"\n        return hashlib.sha256(data.encode()).hexdigest()\n\n    def dumps(self, data: Any):\n        \"\"\"\n        Serializes the given data using the serializer.\n\n        Args:\n            data: The data to serialize.\n\n        Returns:\n            The serialized data.\n        \"\"\"\n        return self.serializer.dumps(data)\n\n    def loads(self, value: str):\n        \"\"\"\n        Deserializes the given value using the serializer.\n\n        Args:\n            value: The serialized string to deserialize.\n\n        Returns:\n            The deserialized data.\n        \"\"\"\n        return self.serializer.loads(value)\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager.__init__","title":"<code>__init__(serializer=None)</code>","text":"<p>Initializes the ConnectionManager.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>Any | None</code> <p>An optional serializer object. If not provided, JsonPickleSerializer is used.</p> <code>None</code> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>def __init__(self, serializer: Any | None = None):\n    \"\"\"\n    Initializes the ConnectionManager.\n\n    Args:\n        serializer: An optional serializer object. If not provided, JsonPickleSerializer is used.\n    \"\"\"\n    self.serializer = serializer or JsonPickleSerializer()\n    self.connection_clients: dict[str, Any] = {}\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager.close","title":"<code>close()</code>","text":"<p>Closes all open connection clients and clears the connection_clients dictionary.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>def close(self):\n    \"\"\"\n    Closes all open connection clients and clears the connection_clients dictionary.\n    \"\"\"\n    logger.debug(\"Close connection clients\")\n    for conn_client in self.connection_clients.values():\n        if hasattr(conn_client, \"close\"):\n            conn_client.close()\n    self.connection_clients = {}\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager.dumps","title":"<code>dumps(data)</code>","text":"<p>Serializes the given data using the serializer.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to serialize.</p> required <p>Returns:</p> Type Description <p>The serialized data.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>def dumps(self, data: Any):\n    \"\"\"\n    Serializes the given data using the serializer.\n\n    Args:\n        data: The data to serialize.\n\n    Returns:\n        The serialized data.\n    \"\"\"\n    return self.serializer.dumps(data)\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager.get_connection_by_type","title":"<code>get_connection_by_type(conn_type)</code>  <code>staticmethod</code>","text":"<p>Retrieves the connection class based on the given connection type.</p> <p>Parameters:</p> Name Type Description Default <code>conn_type</code> <code>str</code> <p>The type of connection to retrieve.</p> required <p>Returns:</p> Type Description <code>type[BaseConnection]</code> <p>The connection class corresponding to the given type.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the connection type is not found.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>@staticmethod\ndef get_connection_by_type(conn_type: str) -&gt; type[BaseConnection]:\n    \"\"\"\n    Retrieves the connection class based on the given connection type.\n\n    Args:\n        conn_type: The type of connection to retrieve.\n\n    Returns:\n        The connection class corresponding to the given type.\n\n    Raises:\n        ValueError: If the connection type is not found.\n    \"\"\"\n    try:\n        entity_module, entity_name = conn_type.rsplit(\".\", 1)\n        imported_module = importlib.import_module(entity_module)\n        if entity := getattr(imported_module, entity_name, None):\n            return entity\n    except (ModuleNotFoundError, ImportError):\n        raise ValueError(f\"Connection type {conn_type} not found\")\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager.get_connection_client","title":"<code>get_connection_client(connection, init_type=ConnectionClientInitType.DEFAULT)</code>","text":"<p>Retrieves or initializes a connection client for the given connection.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>BaseConnection</code> <p>The connection object.</p> required <code>init_type</code> <code>ConnectionClientInitType</code> <p>The initialization type for the connection client.</p> <code>DEFAULT</code> <p>Returns:</p> Type Description <code>Any | None</code> <p>The initialized connection client.</p> <p>Raises:</p> Type Description <code>ConnectionManagerException</code> <p>If the connection does not support the specified initialization type.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>def get_connection_client(\n    self,\n    connection: BaseConnection,\n    init_type: ConnectionClientInitType = ConnectionClientInitType.DEFAULT,\n) -&gt; Any | None:\n    \"\"\"\n    Retrieves or initializes a connection client for the given connection.\n\n    Args:\n        connection: The connection object.\n        init_type: The initialization type for the connection client.\n\n    Returns:\n        The initialized connection client.\n\n    Raises:\n        ConnectionManagerException: If the connection does not support the specified initialization type.\n    \"\"\"\n    logger.debug(\n        f\"Get connection client for '{connection.id}-{connection.type}' \"\n        f\"with '{init_type.value.lower()}' initialization\"\n    )\n    conn_id = self.get_connection_id(connection, init_type)\n    if conn_client := self.connection_clients.get(conn_id):\n        if (conn_client_closed := getattr(conn_client, \"closed\", None)) is None:\n            return conn_client\n\n        if not conn_client_closed:\n            return conn_client\n\n    logger.debug(\n        f\"Init connection client for '{connection.id}-{connection.type}' \"\n        f\"with '{init_type.value.lower()}' initialization\"\n    )\n    conn_method_name = CONNECTION_METHOD_BY_INIT_TYPE[init_type]\n    if not (\n        conn_method := getattr(connection, conn_method_name, None)\n    ) or not callable(conn_method):\n        raise ConnectionManagerException(\n            f\"Connection '{connection.id}-{connection.type}' not support '{init_type.value}' initialization\"\n        )\n\n    conn_client = conn_method()\n    self.connection_clients[conn_id] = conn_client\n\n    return conn_client\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager.get_connection_id","title":"<code>get_connection_id(connection, init_type=ConnectionClientInitType.DEFAULT)</code>","text":"<p>Generates a unique connection ID based on the connection and initialization type.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>BaseConnection</code> <p>The connection object.</p> required <code>init_type</code> <code>ConnectionClientInitType</code> <p>The initialization type for the connection client.</p> <code>DEFAULT</code> <p>Returns:</p> Type Description <code>str</code> <p>A unique string identifier for the connection.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>def get_connection_id(\n    self,\n    connection: BaseConnection,\n    init_type: ConnectionClientInitType = ConnectionClientInitType.DEFAULT,\n) -&gt; str:\n    \"\"\"\n    Generates a unique connection ID based on the connection and initialization type.\n\n    Args:\n        connection: The connection object.\n        init_type: The initialization type for the connection client.\n\n    Returns:\n        A unique string identifier for the connection.\n    \"\"\"\n    conn_hash = self.hash(connection.model_dump_json())\n    return f\"{connection.type.lower()}:{init_type.lower()}:{conn_hash}\"\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager.hash","title":"<code>hash(data)</code>  <code>staticmethod</code>","text":"<p>Generates a SHA256 hash of the input string.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>The input string to hash.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The hexadecimal representation of the SHA256 hash.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>@staticmethod\ndef hash(data: str) -&gt; str:\n    \"\"\"\n    Generates a SHA256 hash of the input string.\n\n    Args:\n        data: The input string to hash.\n\n    Returns:\n        The hexadecimal representation of the SHA256 hash.\n    \"\"\"\n    return hashlib.sha256(data.encode()).hexdigest()\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManager.loads","title":"<code>loads(value)</code>","text":"<p>Deserializes the given value using the serializer.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The serialized string to deserialize.</p> required <p>Returns:</p> Type Description <p>The deserialized data.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>def loads(self, value: str):\n    \"\"\"\n    Deserializes the given value using the serializer.\n\n    Args:\n        value: The serialized string to deserialize.\n\n    Returns:\n        The deserialized data.\n    \"\"\"\n    return self.serializer.loads(value)\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.ConnectionManagerException","title":"<code>ConnectionManagerException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised for errors in the ConnectionManager.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>class ConnectionManagerException(Exception):\n    \"\"\"Exception raised for errors in the ConnectionManager.\"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/connections/managers/#dynamiq.connections.managers.get_connection_manager","title":"<code>get_connection_manager()</code>","text":"<p>A context manager that yields a ConnectionManager instance and ensures it's closed properly.</p> <p>Yields:</p> Type Description <p>A ConnectionManager instance.</p> Source code in <code>dynamiq/connections/managers.py</code> <pre><code>@contextmanager\ndef get_connection_manager():\n    \"\"\"\n    A context manager that yields a ConnectionManager instance and ensures it's closed properly.\n\n    Yields:\n        A ConnectionManager instance.\n    \"\"\"\n    cm = ConnectionManager()\n    yield cm\n    cm.close()\n</code></pre>"},{"location":"dynamiq/connections/storages/","title":"Storages","text":""},{"location":"dynamiq/connections/storages/#dynamiq.connections.storages.RedisConnection","title":"<code>RedisConnection</code>","text":"<p>               Bases: <code>BaseConnection</code></p> <p>Represents a connection to a Redis database.</p> <p>This class inherits from BaseConnection and provides specific attributes for connecting to a Redis database.</p> <p>Attributes:</p> Name Type Description <code>host</code> <code>str</code> <p>The hostname or IP address of the Redis server.</p> <code>port</code> <code>int</code> <p>The port number on which the Redis server is listening.</p> <code>db</code> <code>int</code> <p>The Redis database number to connect to.</p> <code>username</code> <code>str | None</code> <p>The username for authentication (optional).</p> <code>password</code> <code>str | None</code> <p>The password for authentication (optional).</p> Source code in <code>dynamiq/connections/storages.py</code> <pre><code>class RedisConnection(BaseConnection):\n    \"\"\"\n    Represents a connection to a Redis database.\n\n    This class inherits from BaseConnection and provides specific attributes\n    for connecting to a Redis database.\n\n    Attributes:\n        host (str): The hostname or IP address of the Redis server.\n        port (int): The port number on which the Redis server is listening.\n        db (int): The Redis database number to connect to.\n        username (str | None): The username for authentication (optional).\n        password (str | None): The password for authentication (optional).\n    \"\"\"\n\n    host: str\n    port: int\n    db: int\n    username: str | None = None\n    password: str | None = None\n\n    def connect(self):\n        \"\"\"\n        Establishes a connection to the Redis database.\n\n        This method is responsible for creating and initializing the connection\n        to the Redis server using the provided connection details.\n\n        Note:\n            This method is currently a placeholder and does not contain\n            the actual implementation for connecting to Redis.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/connections/storages/#dynamiq.connections.storages.RedisConnection.connect","title":"<code>connect()</code>","text":"<p>Establishes a connection to the Redis database.</p> <p>This method is responsible for creating and initializing the connection to the Redis server using the provided connection details.</p> Note <p>This method is currently a placeholder and does not contain the actual implementation for connecting to Redis.</p> Source code in <code>dynamiq/connections/storages.py</code> <pre><code>def connect(self):\n    \"\"\"\n    Establishes a connection to the Redis database.\n\n    This method is responsible for creating and initializing the connection\n    to the Redis server using the provided connection details.\n\n    Note:\n        This method is currently a placeholder and does not contain\n        the actual implementation for connecting to Redis.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/evaluations/base_evaluator/","title":"Base evaluator","text":""},{"location":"dynamiq/evaluations/base_evaluator/#dynamiq.evaluations.base_evaluator.BaseEvaluator","title":"<code>BaseEvaluator</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for evaluators.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the evaluator.</p> Source code in <code>dynamiq/evaluations/base_evaluator.py</code> <pre><code>class BaseEvaluator(BaseModel):\n    \"\"\"\n    Base class for evaluators.\n\n    Attributes:\n        name (str): Name of the evaluator.\n    \"\"\"\n\n    name: str\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @computed_field\n    @cached_property\n    def type(self) -&gt; str:\n        \"\"\"\n        Compute the type identifier for the evaluator.\n\n        Returns:\n            str: A string representing the module and class name.\n        \"\"\"\n        return f\"{self.__module__.rsplit('.', 1)[0]}.{self.__class__.__name__}\"\n\n    def run(self) -&gt; list[float]:\n        \"\"\"\n        Executes the evaluator.\n        Must be overridden by subclasses.\n\n        Returns:\n            list[float]: Scores for each reference/answer pair.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method.\")\n</code></pre>"},{"location":"dynamiq/evaluations/base_evaluator/#dynamiq.evaluations.base_evaluator.BaseEvaluator.type","title":"<code>type: str</code>  <code>cached</code> <code>property</code>","text":"<p>Compute the type identifier for the evaluator.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string representing the module and class name.</p>"},{"location":"dynamiq/evaluations/base_evaluator/#dynamiq.evaluations.base_evaluator.BaseEvaluator.run","title":"<code>run()</code>","text":"<p>Executes the evaluator. Must be overridden by subclasses.</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: Scores for each reference/answer pair.</p> Source code in <code>dynamiq/evaluations/base_evaluator.py</code> <pre><code>def run(self) -&gt; list[float]:\n    \"\"\"\n    Executes the evaluator.\n    Must be overridden by subclasses.\n\n    Returns:\n        list[float]: Scores for each reference/answer pair.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement this method.\")\n</code></pre>"},{"location":"dynamiq/evaluations/llm_evaluator/","title":"Llm evaluator","text":""},{"location":"dynamiq/evaluations/llm_evaluator/#dynamiq.evaluations.llm_evaluator.LLMEvaluator","title":"<code>LLMEvaluator</code>","text":"<p>Uses an LLM to evaluate inputs based on a prompt containing instructions and examples.</p> <p>The inputs and outputs are user-defined depending on the desired metric. The output is a dictionary with a key <code>results</code> containing a list of evaluation results. Each result is a dictionary with user-defined keys and values as specified in the outputs.</p> <p>Usage example:</p> <pre><code>from typing import List\nfrom dynamiq.components.evaluators.llm_evaluator import LLMEvaluator\n\nllm = ...  # Your LLM node instance\n\nevaluator = LLMEvaluator(\n    instructions=\"Is this answer problematic for children?\",\n    inputs=[{\"name\": \"answer\", \"type\": str}],\n    outputs=[{\"name\": \"score\", \"type\": int}],\n    examples=[\n        {\n            \"inputs\": {\"answer\": \"Damn, this is straight outta hell!!!\"},\n            \"outputs\": {\"score\": 1},\n        },\n        {\n            \"inputs\": {answer\": \"Football is the most popular sport.\"},\n            \"outputs\": {\"score\": 0},\n        },\n    ],\n    llm=llm,\n)\n\npredicted_answers = [\n    \"Football is the most popular sport with around 4 billion followers worldwide\",\n    \"Python language was created by Guido van Rossum.\",\n]\nresults = evaluator.run(answer=predicted_answers)\nprint(results)\n# Output: {'results': [{'score': 0}, {'score': 0}]}\n</code></pre> Source code in <code>dynamiq/evaluations/llm_evaluator.py</code> <pre><code>class LLMEvaluator:\n    \"\"\"\n    Uses an LLM to evaluate inputs based on a prompt containing instructions and examples.\n\n    The inputs and outputs are user-defined depending on the desired metric. The output\n    is a dictionary with a key `results` containing a list of evaluation results. Each result\n    is a dictionary with user-defined keys and values as specified in the outputs.\n\n    **Usage example:**\n\n    ```python\n    from typing import List\n    from dynamiq.components.evaluators.llm_evaluator import LLMEvaluator\n\n    llm = ...  # Your LLM node instance\n\n    evaluator = LLMEvaluator(\n        instructions=\"Is this answer problematic for children?\",\n        inputs=[{\"name\": \"answer\", \"type\": str}],\n        outputs=[{\"name\": \"score\", \"type\": int}],\n        examples=[\n            {\n                \"inputs\": {\"answer\": \"Damn, this is straight outta hell!!!\"},\n                \"outputs\": {\"score\": 1},\n            },\n            {\n                \"inputs\": {answer\": \"Football is the most popular sport.\"},\n                \"outputs\": {\"score\": 0},\n            },\n        ],\n        llm=llm,\n    )\n\n    predicted_answers = [\n        \"Football is the most popular sport with around 4 billion followers worldwide\",\n        \"Python language was created by Guido van Rossum.\",\n    ]\n    results = evaluator.run(answer=predicted_answers)\n    print(results)\n    # Output: {'results': [{'score': 0}, {'score': 0}]}\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        instructions: str,\n        outputs: list[dict[str, Any]],\n        examples: list[dict[str, Any]] | None = None,\n        inputs: list[dict[str, Any]] | None = None,\n        *,\n        raise_on_failure: bool = True,\n        llm: Node,\n        strings_to_omit_from_llm_output: tuple[str] = STRINGS_TO_OMIT_FROM_LLM_EVALUATOR_OUTPUT,\n    ):\n        \"\"\"\n        Initializes an instance of LLMEvaluator.\n\n        Args:\n            instructions (str): The prompt instructions to use for evaluation.\n            outputs (List[Dict[str, Any]]): A list of dictionaries defining the outputs.\n                Each output dict should have keys \"name\" and \"type\", where \"name\" is the\n                output name and \"type\" is its type.\n            examples (Optional[List[Dict[str, Any]]]): Few-shot examples conforming to the expected input and\n                output format as defined in the `inputs` and `outputs` parameters. Each example is a\n                dictionary with keys \"inputs\" and \"outputs\". They contain the input and output as\n                dictionaries respectively.\n            inputs (Optional[List[Dict[str, Any]]]): A list of dictionaries defining the inputs.\n                Each input dict should have keys \"name\" and \"type\", where \"name\" is the\n                input name and \"type\" is its type. Defaults to None.\n            raise_on_failure (bool): If True, the component will raise an exception on an\n                unsuccessful API call.\n            llm (Node): The LLM node to use for evaluation.\n            strings_to_omit_from_llm_output (Tuple[str]): A tuple of strings to omit from the LLM output.\n        \"\"\"\n        if inputs is None:\n            inputs = []\n        if examples is None:\n            examples = []\n        self._validate_init_parameters(inputs, outputs, examples)\n        self.raise_on_failure = raise_on_failure\n        self.instructions = instructions\n        self.inputs = inputs\n        self.outputs = outputs\n        self.examples = examples\n        self.api_params = {}\n\n        default_generation_kwargs = {\n            \"response_format\": {\"type\": \"json_object\"},\n            \"seed\": 42,\n        }\n        user_generation_kwargs = self.api_params.get(\"generation_kwargs\", {})\n        merged_generation_kwargs = {\n            **default_generation_kwargs,\n            **user_generation_kwargs,\n        }\n        self.api_params[\"generation_kwargs\"] = merged_generation_kwargs\n\n        # Prepare the prompt with placeholders\n        template = self._prepare_prompt_template()\n        message = Message(role=\"user\", content=template)\n        self.prompt = Prompt(messages=[message])\n\n        self.llm = llm\n        self.strings_to_omit_from_llm_output = strings_to_omit_from_llm_output\n\n    @staticmethod\n    def _validate_init_parameters(\n        inputs: list[dict[str, Any]],\n        outputs: list[dict[str, Any]],\n        examples: list[dict[str, Any]],\n    ):\n        \"\"\"\n        Validates the initialization parameters.\n\n        Args:\n            inputs (List[Dict[str, Any]]): The inputs to validate.\n            outputs (List[Dict[str, Any]]): The outputs to validate.\n            examples (List[Dict[str, Any]]): The examples to validate.\n\n        Raises:\n            ValueError: If the inputs or outputs are not correctly formatted.\n        \"\"\"\n        # Validate inputs\n        if not isinstance(inputs, list) or not all(isinstance(inp, dict) for inp in inputs):\n            msg = \"LLM evaluator expects inputs to be a list of dictionaries.\"\n            raise ValueError(msg)\n        for inp in inputs:\n            if \"name\" not in inp or \"type\" not in inp:\n                msg = f\"Each input dict must have 'name' and 'type' keys. Missing in {inp}.\"\n                raise ValueError(msg)\n            if not isinstance(inp[\"name\"], str):\n                msg = f\"Input 'name' must be a string. Got {inp['name']}.\"\n                raise ValueError(msg)\n            # No type check on 'type' to allow types from 'typing' module\n\n        # Validate outputs\n        if not isinstance(outputs, list) or not all(isinstance(outp, dict) for outp in outputs):\n            msg = \"LLM evaluator expects outputs to be a list of dictionaries.\"\n            raise ValueError(msg)\n        for outp in outputs:\n            if \"name\" not in outp or \"type\" not in outp:\n                msg = f\"Each output dict must have 'name' and 'type' keys. Missing in {outp}.\"\n                raise ValueError(msg)\n            if not isinstance(outp[\"name\"], str):\n                msg = f\"Output 'name' must be a string. Got {outp['name']}.\"\n                raise ValueError(msg)\n            # No type check on 'type' to allow types from 'typing' module\n\n        # Validate examples\n        if not isinstance(examples, list) or not all(isinstance(example, dict) for example in examples):\n            msg = f\"LLM evaluator expects examples to be a list of dictionaries but received {examples}.\"\n            raise ValueError(msg)\n\n        for example in examples:\n            if (\n                not all(k in example for k in (\"inputs\", \"outputs\"))\n                or not all(isinstance(example[param], dict) for param in [\"inputs\", \"outputs\"])\n                or not all(isinstance(key, str) for param in [\"inputs\", \"outputs\"] for key in example[param])\n            ):\n                msg = (\n                    f\"Each example must have 'inputs' and 'outputs' as dictionaries with string keys, \"\n                    f\"but received {example}.\"\n                )\n                raise ValueError(msg)\n\n    def run(self, **inputs) -&gt; dict[str, Any]:\n        \"\"\"\n        Runs the LLM evaluator.\n\n        Args:\n            inputs: The input values to evaluate. Keys are input names, values are lists.\n\n        Returns:\n            Dict[str, Any]: A dictionary with a 'results' key containing the evaluation results.\n\n        Raises:\n            ValueError: If input parameters are invalid or LLM execution fails.\n        \"\"\"\n        expected_inputs = {inp[\"name\"]: inp[\"type\"] for inp in self.inputs}\n        self._validate_input_parameters(expected=expected_inputs, received=inputs)\n\n        if self.inputs:\n            input_names = list(inputs.keys())\n            values = list(zip(*inputs.values()))\n            list_of_input_data = [dict(zip(input_names, v)) for v in values]\n        else:\n            # If no inputs are provided, create a list with a single empty dictionary\n            list_of_input_data = [{}]\n\n        results: list[dict[str, Any]] = []\n        errors = 0\n\n        for input_data in list_of_input_data:\n            # Pass the prompt and input_data to LLM\n            try:\n                result = self.llm.execute(input_data=input_data, prompt=self.prompt)\n            except Exception as e:\n                msg = f\"Error while generating response for input {input_data}: {e}\"\n                if self.raise_on_failure:\n                    raise ValueError(msg)\n                warn(msg)\n                results.append(None)\n                errors += 1\n                continue\n\n            expected_output_keys = [outp[\"name\"] for outp in self.outputs]\n            content = self._cleanup_output_content(result[\"content\"])\n\n            parsed_result = self._parse_and_validate_json_output(expected_keys=expected_output_keys, content=content)\n            if parsed_result is not None:\n                results.append(parsed_result)\n            else:\n                results.append(None)\n                errors += 1\n\n        if errors &gt; 0:\n            msg = f\"LLM evaluator failed for {errors} out of {len(list_of_input_data)} inputs.\"\n            warn(msg)\n\n        return {\"results\": results}\n\n    def _prepare_prompt_template(self) -&gt; str:\n        \"\"\"\n        Prepares the prompt template.\n\n        Returns:\n            str: The prompt template.\n        \"\"\"\n        prompt_parts = [\n            \"Instructions:\",\n            self.instructions.strip(),\n        ]\n\n        # Check if outputs are provided\n        if self.outputs:\n            # Prepare expected_output_section\n            expected_output_dict = {outp[\"name\"]: self._get_placeholder_for_type(outp[\"type\"]) for outp in self.outputs}\n            expected_output = json.dumps(expected_output_dict, indent=2)\n            prompt_parts.extend(\n                [\n                    (\n                        \"\\nYour task is to generate a JSON object that contains the following keys \"\n                        \"and their corresponding values.\"\n                    ),\n                    \"The output must be a valid JSON object and should exactly match the specified structure.\",\n                    \"Do not include any additional text, explanations, or markdown.\",\n                    \"Expected JSON format:\",\n                    expected_output,\n                ]\n            )\n\n        if self.examples:\n            # Prepare examples_section with explicit labels\n            examples_parts = []\n            for idx, example in enumerate(self.examples, start=1):\n                example_input = json.dumps(example[\"inputs\"], indent=2)\n                example_output = json.dumps(example[\"outputs\"], indent=2)\n                example_text = f\"Example {idx}:\\n\" f\"Input:\\n{example_input}\\n\" f\"Expected Output:\\n{example_output}\"\n                examples_parts.append(example_text)\n            examples_section = \"\\n\\n\".join(examples_parts)\n            prompt_parts.append(\"\\nHere are some examples:\")\n            prompt_parts.append(examples_section)\n\n        if self.inputs:\n            # Prepare inputs_section with placeholders using {{ variable_name }}\n            inputs_section = (\n                \"{\\n\" + \",\\n\".join([f'  \"{inp[\"name\"]}\": {{{{ {inp[\"name\"]} }}}}' for inp in self.inputs]) + \"\\n}\"\n            )\n            prompt_parts.append(\"\\nNow, process the following input:\")\n            prompt_parts.append(inputs_section)\n\n        prompt_parts.append(\"\\nProvide the output as per the format specified above.\")\n\n        return \"\\n\".join(prompt_parts)\n\n    def _get_placeholder_for_type(self, tp):\n        \"\"\"\n        Generates a placeholder value based on the type.\n\n        Args:\n            tp: The type to generate a placeholder for.\n\n        Returns:\n            An example value corresponding to the type.\n        \"\"\"\n        if tp == str:\n            return \"string_value\"\n        elif tp == int:\n            return 0\n        elif tp == float:\n            return 0.0\n        elif tp == bool:\n            return True\n        elif tp == list:\n            return []\n        elif tp == dict:\n            return {}\n        else:\n            return f\"{tp}\"\n\n    @staticmethod\n    def _get_type_name(tp):\n        \"\"\"\n        Helper function to get the name of a type, including typing types.\n\n        Args:\n            tp: The type to get the name of.\n\n        Returns:\n            str: The name of the type.\n        \"\"\"\n        if hasattr(tp, \"__name__\"):\n            return tp.__name__\n        elif hasattr(tp, \"_name\") and tp._name:\n            args = \", \".join(LLMEvaluator._get_type_name(arg) for arg in tp.__args__)\n            return f\"{tp._name}[{args}]\"\n        else:\n            return str(tp)\n\n    @staticmethod\n    def _validate_input_parameters(expected: dict[str, Any], received: dict[str, Any]) -&gt; None:\n        \"\"\"\n        Validates the input parameters.\n\n        Args:\n            expected (Dict[str, Any]): The expected input parameters with their types.\n            received (Dict[str, Any]): The received input parameters.\n\n        Raises:\n            ValueError: If input parameters are invalid.\n        \"\"\"\n        if expected:\n            for param in expected.keys():\n                if param not in received:\n                    msg = f\"LLM evaluator expected input parameter '{param}' but received {list(received.keys())}.\"\n                    raise ValueError(msg)\n\n            if not all(isinstance(value, list) for value in received.values()):\n                msg = (\n                    \"LLM evaluator expects all input values to be lists but received \"\n                    f\"{[type(value) for value in received.values()]}.\"\n                )\n                raise ValueError(msg)\n\n            inputs = received.values()\n            length = len(next(iter(inputs)))\n            if not all(len(value) == length for value in inputs):\n                msg = (\n                    \"LLM evaluator expects all input lists to have the same length but received input lengths \"\n                    f\"{[len(value) for value in inputs]}.\"\n                )\n                raise ValueError(msg)\n        else:\n            if received:\n                msg = f\"LLM evaluator does not expect any input parameters but received {list(received.keys())}.\"\n                raise ValueError(msg)\n\n    def _parse_and_validate_json_output(self, expected_keys: list[str], content: str) -&gt; dict[str, Any]:\n        \"\"\"\n        Parses the LLM output content as JSON and validates that it contains the expected keys.\n\n        Args:\n            expected_keys (List[str]): Expected output keys.\n            content (str): The received output as a JSON string.\n\n        Returns:\n            Dict[str, Any]: The parsed JSON output if valid, otherwise None.\n\n        Raises:\n            ValueError: If the output is invalid and raise_on_failure is True.\n        \"\"\"\n        try:\n            parsed_output = parse_llm_json_output(content)\n        except json.JSONDecodeError:\n            msg = f\"Response from LLM evaluator is not a valid JSON: {content}.\"\n            if self.raise_on_failure:\n                raise ValueError(msg)\n            warn(msg)\n            return None\n\n        if not all(key in parsed_output for key in expected_keys):\n            msg = (\n                f\"Expected response from LLM evaluator to have keys {expected_keys}, \"\n                f\"but got {list(parsed_output.keys())}.\"\n            )\n            if self.raise_on_failure:\n                raise ValueError(msg)\n            warn(msg)\n            return None\n\n        return parsed_output\n\n    def _cleanup_output_content(self, content: str) -&gt; str:\n        \"\"\"\n        Cleans up the output content by removing unwanted strings.\n\n        Args:\n            content (str): The content to clean up.\n\n        Returns:\n            str: The cleaned content.\n        \"\"\"\n        for omit_string in self.strings_to_omit_from_llm_output:\n            content = content.replace(omit_string, \"\")\n        return content.strip()\n</code></pre>"},{"location":"dynamiq/evaluations/llm_evaluator/#dynamiq.evaluations.llm_evaluator.LLMEvaluator.__init__","title":"<code>__init__(instructions, outputs, examples=None, inputs=None, *, raise_on_failure=True, llm, strings_to_omit_from_llm_output=STRINGS_TO_OMIT_FROM_LLM_EVALUATOR_OUTPUT)</code>","text":"<p>Initializes an instance of LLMEvaluator.</p> <p>Parameters:</p> Name Type Description Default <code>instructions</code> <code>str</code> <p>The prompt instructions to use for evaluation.</p> required <code>outputs</code> <code>List[Dict[str, Any]]</code> <p>A list of dictionaries defining the outputs. Each output dict should have keys \"name\" and \"type\", where \"name\" is the output name and \"type\" is its type.</p> required <code>examples</code> <code>Optional[List[Dict[str, Any]]]</code> <p>Few-shot examples conforming to the expected input and output format as defined in the <code>inputs</code> and <code>outputs</code> parameters. Each example is a dictionary with keys \"inputs\" and \"outputs\". They contain the input and output as dictionaries respectively.</p> <code>None</code> <code>inputs</code> <code>Optional[List[Dict[str, Any]]]</code> <p>A list of dictionaries defining the inputs. Each input dict should have keys \"name\" and \"type\", where \"name\" is the input name and \"type\" is its type. Defaults to None.</p> <code>None</code> <code>raise_on_failure</code> <code>bool</code> <p>If True, the component will raise an exception on an unsuccessful API call.</p> <code>True</code> <code>llm</code> <code>Node</code> <p>The LLM node to use for evaluation.</p> required <code>strings_to_omit_from_llm_output</code> <code>Tuple[str]</code> <p>A tuple of strings to omit from the LLM output.</p> <code>STRINGS_TO_OMIT_FROM_LLM_EVALUATOR_OUTPUT</code> Source code in <code>dynamiq/evaluations/llm_evaluator.py</code> <pre><code>def __init__(\n    self,\n    instructions: str,\n    outputs: list[dict[str, Any]],\n    examples: list[dict[str, Any]] | None = None,\n    inputs: list[dict[str, Any]] | None = None,\n    *,\n    raise_on_failure: bool = True,\n    llm: Node,\n    strings_to_omit_from_llm_output: tuple[str] = STRINGS_TO_OMIT_FROM_LLM_EVALUATOR_OUTPUT,\n):\n    \"\"\"\n    Initializes an instance of LLMEvaluator.\n\n    Args:\n        instructions (str): The prompt instructions to use for evaluation.\n        outputs (List[Dict[str, Any]]): A list of dictionaries defining the outputs.\n            Each output dict should have keys \"name\" and \"type\", where \"name\" is the\n            output name and \"type\" is its type.\n        examples (Optional[List[Dict[str, Any]]]): Few-shot examples conforming to the expected input and\n            output format as defined in the `inputs` and `outputs` parameters. Each example is a\n            dictionary with keys \"inputs\" and \"outputs\". They contain the input and output as\n            dictionaries respectively.\n        inputs (Optional[List[Dict[str, Any]]]): A list of dictionaries defining the inputs.\n            Each input dict should have keys \"name\" and \"type\", where \"name\" is the\n            input name and \"type\" is its type. Defaults to None.\n        raise_on_failure (bool): If True, the component will raise an exception on an\n            unsuccessful API call.\n        llm (Node): The LLM node to use for evaluation.\n        strings_to_omit_from_llm_output (Tuple[str]): A tuple of strings to omit from the LLM output.\n    \"\"\"\n    if inputs is None:\n        inputs = []\n    if examples is None:\n        examples = []\n    self._validate_init_parameters(inputs, outputs, examples)\n    self.raise_on_failure = raise_on_failure\n    self.instructions = instructions\n    self.inputs = inputs\n    self.outputs = outputs\n    self.examples = examples\n    self.api_params = {}\n\n    default_generation_kwargs = {\n        \"response_format\": {\"type\": \"json_object\"},\n        \"seed\": 42,\n    }\n    user_generation_kwargs = self.api_params.get(\"generation_kwargs\", {})\n    merged_generation_kwargs = {\n        **default_generation_kwargs,\n        **user_generation_kwargs,\n    }\n    self.api_params[\"generation_kwargs\"] = merged_generation_kwargs\n\n    # Prepare the prompt with placeholders\n    template = self._prepare_prompt_template()\n    message = Message(role=\"user\", content=template)\n    self.prompt = Prompt(messages=[message])\n\n    self.llm = llm\n    self.strings_to_omit_from_llm_output = strings_to_omit_from_llm_output\n</code></pre>"},{"location":"dynamiq/evaluations/llm_evaluator/#dynamiq.evaluations.llm_evaluator.LLMEvaluator.run","title":"<code>run(**inputs)</code>","text":"<p>Runs the LLM evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <p>The input values to evaluate. Keys are input names, values are lists.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: A dictionary with a 'results' key containing the evaluation results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input parameters are invalid or LLM execution fails.</p> Source code in <code>dynamiq/evaluations/llm_evaluator.py</code> <pre><code>def run(self, **inputs) -&gt; dict[str, Any]:\n    \"\"\"\n    Runs the LLM evaluator.\n\n    Args:\n        inputs: The input values to evaluate. Keys are input names, values are lists.\n\n    Returns:\n        Dict[str, Any]: A dictionary with a 'results' key containing the evaluation results.\n\n    Raises:\n        ValueError: If input parameters are invalid or LLM execution fails.\n    \"\"\"\n    expected_inputs = {inp[\"name\"]: inp[\"type\"] for inp in self.inputs}\n    self._validate_input_parameters(expected=expected_inputs, received=inputs)\n\n    if self.inputs:\n        input_names = list(inputs.keys())\n        values = list(zip(*inputs.values()))\n        list_of_input_data = [dict(zip(input_names, v)) for v in values]\n    else:\n        # If no inputs are provided, create a list with a single empty dictionary\n        list_of_input_data = [{}]\n\n    results: list[dict[str, Any]] = []\n    errors = 0\n\n    for input_data in list_of_input_data:\n        # Pass the prompt and input_data to LLM\n        try:\n            result = self.llm.execute(input_data=input_data, prompt=self.prompt)\n        except Exception as e:\n            msg = f\"Error while generating response for input {input_data}: {e}\"\n            if self.raise_on_failure:\n                raise ValueError(msg)\n            warn(msg)\n            results.append(None)\n            errors += 1\n            continue\n\n        expected_output_keys = [outp[\"name\"] for outp in self.outputs]\n        content = self._cleanup_output_content(result[\"content\"])\n\n        parsed_result = self._parse_and_validate_json_output(expected_keys=expected_output_keys, content=content)\n        if parsed_result is not None:\n            results.append(parsed_result)\n        else:\n            results.append(None)\n            errors += 1\n\n    if errors &gt; 0:\n        msg = f\"LLM evaluator failed for {errors} out of {len(list_of_input_data)} inputs.\"\n        warn(msg)\n\n    return {\"results\": results}\n</code></pre>"},{"location":"dynamiq/evaluations/python_evaluator/","title":"Python evaluator","text":"<p>thon_evaluator</p>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/","title":"Answer correctness","text":""},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.AnswerCorrectnessEvaluator","title":"<code>AnswerCorrectnessEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Evaluator for computing answer correctness using candidate statements with explanation of match decisions and weighted scoring.</p> <p>Overview: \u2022 The evaluator splits both the answer and the ground truth answer into a set of     core fact \u201ccandidate statements.\u201d \u2022 It then compares each statement from the answer with the statements from the ground     truth answer to decide if the core fact is present. A \"\u2705\" indicates that the statement     is supported by the ground truth, whereas a \"\u274c\" indicates it is not. \u2022 Similarly, ground truth statements are checked against the answer to see if any are missing. \u2022 Based on these comparisons, the metrics are computed:     - TP (True Positive): Number of answer statements that are correctly supported.     - FP (False Positive): Number of answer statements that are not supported.     - FN (False Negative): Number of ground truth statements missing from the answer.     - Precision = TP / (TP + FP)     - Recall    = TP / (TP + FN)     - F1 Score  = 2 * (Precision * Recall) / (Precision + Recall)</p> <p>The evaluator outputs both the final score and detailed reasoning explaining each step.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class AnswerCorrectnessEvaluator(BaseEvaluator):\n    \"\"\"\n    Evaluator for computing answer correctness using candidate statements with\n    explanation of match decisions and weighted scoring.\n\n    Overview:\n    \u2022 The evaluator splits both the answer and the ground truth answer into a set of\n        core fact \u201ccandidate statements.\u201d\n    \u2022 It then compares each statement from the answer with the statements from the ground\n        truth answer to decide if the core fact is present. A \"\u2705\" indicates that the statement\n        is supported by the ground truth, whereas a \"\u274c\" indicates it is not.\n    \u2022 Similarly, ground truth statements are checked against the answer to see if any are missing.\n    \u2022 Based on these comparisons, the metrics are computed:\n        - TP (True Positive): Number of answer statements that are correctly supported.\n        - FP (False Positive): Number of answer statements that are not supported.\n        - FN (False Negative): Number of ground truth statements missing from the answer.\n        - Precision = TP / (TP + FP)\n        - Recall    = TP / (TP + FN)\n        - F1 Score  = 2 * (Precision * Recall) / (Precision + Recall)\n\n    The evaluator outputs both the final score and detailed reasoning explaining each step.\n    \"\"\"\n    name: str = \"AnswerCorrectness\"\n    llm: BaseLLM\n\n    _statement_extractor: LLMEvaluator = PrivateAttr()\n    _statement_classifier: LLMEvaluator = PrivateAttr()\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._initialize_evaluators()\n\n    def _initialize_evaluators(self):\n        \"\"\"\n        Initialize the LLMEvaluators.\n        \"\"\"\n        extract_instr = (\n            \"Given a question and an answer, analyze each sentence of the answer and \"\n            \"break it down into one or more fully understandable unique statements. \"\n            \"Replace pronouns with explicit references. \"\n            \"Output the candidate statements as a JSON array of strings using double quotes.\"\n        )\n        self._statement_extractor = LLMEvaluator(\n            instructions=extract_instr.strip(),\n            inputs=[{\"name\": \"questions\", \"type\": list[str]}, {\"name\": \"texts\", \"type\": list[str]}],\n            outputs=[{\"name\": \"statements\", \"type\": list[str]}],\n            examples=[\n                {\n                    \"inputs\": {\n                        \"questions\": [\"What is the capital of France?\"],\n                        \"texts\": [\n                            (\n                                \"The capital of France is Paris. It is known for its rich history, art, \"\n                                \"culture, and landmarks such as the Eiffel Tower.\"\n                            )\n                        ],\n                    },\n                    \"outputs\": {\n                        \"statements\": [\n                            \"The capital of France is Paris.\",\n                            \"Paris is known for its rich history, art, culture, \"\n                            \"and landmarks such as the Eiffel Tower.\",\n                        ]\n                    },\n                },\n                {\n                    \"inputs\": {\n                        \"questions\": [\"Who developed the theory of relativity?\"],\n                        \"texts\": [\n                            (\n                                \"The theory of relativity was developed by Albert Einstein in the early \"\n                                \"20th century, revolutionizing our understanding of space and time.\"\n                            )\n                        ],\n                    },\n                    \"outputs\": {\n                        \"statements\": [\n                            \"The theory of relativity was developed by Albert Einstein in the early 20th century.\",\n                            \"The theory of relativity revolutionized our understanding of space and time.\",\n                        ]\n                    },\n                },\n            ],\n            llm=self.llm,\n        )\n\n        classify_instructions = (\n            \"Given a question, an answer statement, and a reference text, determine if the answer statement \"\n            \"is supported by the reference text. Explain briefly why the statement is or is not supported. \"\n            \"Return a JSON object with keys 'reasoning' (a short explanation) and 'match' (true/false)\"\n        )\n        self._statement_classifier = LLMEvaluator(\n            instructions=classify_instructions.strip(),\n            inputs=[\n                {\"name\": \"question\", \"type\": str},\n                {\"name\": \"answer_statement\", \"type\": str},\n                {\"name\": \"reference_text\", \"type\": str},\n            ],\n            outputs=[{\"name\": \"match\", \"type\": bool}, {\"name\": \"reasoning\", \"type\": str}],\n            examples=[\n                {\n                    \"inputs\": {\n                        \"question\": \"What is the capital of France?\",\n                        \"answer_statement\": \"The capital of France is Paris.\",\n                        \"reference_text\": \"Paris is the capital of France.\",\n                    },\n                    \"outputs\": {\n                        \"reasoning\": \"The statement exactly matches the core fact in the reference.\",\n                        \"match\": True,\n                    },\n                },\n                {\n                    \"inputs\": {\n                        \"question\": \"What is the capital of France?\",\n                        \"answer_statement\": \"Paris is known for its rich history.\",\n                        \"reference_text\": \"The capital of France is Paris.\",\n                    },\n                    \"outputs\": {\n                        \"reasoning\": \"The statement includes extra details about history \"\n                        \"that are not present in reference.\",\n                        \"match\": False,\n                    },\n                },\n                {\n                    \"inputs\": {\n                        \"question\": \"Who developed the theory of relativity?\",\n                        \"answer_statement\": \"The theory was developed by Albert Einstein.\",\n                        \"reference_text\": \"The theory of relativity was developed by Albert Einstein.\",\n                    },\n                    \"outputs\": {\n                        \"reasoning\": \"The statement conveys the same core fact as the reference \"\n                        \"despite wording differences.\",\n                        \"match\": True,\n                    },\n                },\n            ],\n            llm=self.llm,\n        )\n\n    def _get_unique_candidates(self, candidates: list[str]) -&gt; list[str]:\n        \"\"\"\n        Return unique candidate statements preserving order.\n        Comparison is done on lowercased, stripped strings.\n        \"\"\"\n        seen = set()\n        unique = []\n        for stmt in candidates:\n            norm = stmt.strip().lower()\n            if norm not in seen:\n                seen.add(norm)\n                unique.append(stmt)\n        return unique\n\n    def extract_statements(self, questions: list[str], texts: list[str]) -&gt; list[list[str]]:\n        \"\"\"\n        Run the extraction evaluator to get candidate statements.\n        \"\"\"\n        results = self._statement_extractor.run(questions=questions, texts=texts)\n        all_stmts = []\n        for res in results[\"results\"]:\n            stmts = res.get(\"statements\", [])\n            if not isinstance(stmts, list):\n                stmts = [stmts]\n            all_stmts.append(self._get_unique_candidates(stmts))\n        return all_stmts\n\n    def classify_statement(self, question: str, answer_stmt: str, ref_text: str) -&gt; tuple[bool, str]:\n        \"\"\"\n        Run the classification evaluator.\n        The ref_text is the string of candidate statements from the ground truth answer.\n        Returns a tuple (match, explanation).\n        \"\"\"\n        data = {\"question\": [question], \"answer_statement\": [answer_stmt], \"reference_text\": [ref_text]}\n        result = self._statement_classifier.run(**data)\n        m = bool(result[\"results\"][0].get(\"match\", False))\n        expl = result[\"results\"][0].get(\"reasoning\", \"\")\n        return m, expl\n\n    def _join_candidates(self, candidates: list[str]) -&gt; str:\n        \"\"\"\n        Join candidate statements into a single string. Append punctuation if needed.\n        \"\"\"\n        joined = \". \".join(candidates)\n        if joined and joined[-1] not in \".!?\":\n            joined += \".\"\n        return joined\n\n    def _evaluate_candidates(self, question: str, candidates: list[str], ref_text: str) -&gt; list[tuple[str, bool, str]]:\n        \"\"\"\n        Classify each candidate statement against the ground truth answer.\n        Returns a list of tuples (statement, match, explanation).\n        \"\"\"\n        outs = []\n        for stmt in candidates:\n            m, expl = self.classify_statement(question, stmt, ref_text)\n            outs.append((stmt, m, expl))\n        return outs\n\n    def _build_reasoning(\n        self,\n        ans_class: list[tuple[str, bool, str]],\n        gt_class: list[tuple[str, bool, str]],\n        tp: int,\n        fp: int,\n        fn: int,\n        precision: float,\n        recall: float,\n        f1: float,\n    ) -&gt; str:\n        \"\"\"\n        Build a detailed reasoning string.\n        This section explains:\n        \u2022 How the answer was split into statements and compared to the ground truth answer.\n        \u2022 What each symbol (\u2705/\u274c) means.\n        \u2022 How TP, FP, and FN are computed.\n        \u2022 How Precision, Recall, and F1 Score are calculated.\n        \"\"\"\n        lines = []\n        lines.extend(\n            [\n                \"Reasoning:\",\n                \"\",\n                \"Overview:\",\n                \"  The evaluator splits the answer and the ground truth answer into core fact statements.\",\n                \"  Each statement from the answer is compared to the ground truth answer to determine if\",\n                \"  the core fact is supported. Similarly, ground truth statements are checked for their\",\n                \"  presence in the answer. '\u2705' indicates support/presence, while '\u274c' indicates lack thereof.\",\n                \"\",\n                \"1. Answer Statements Analysis:\",\n                \"   The answer is split into statements and compared to the ground truth answer.\",\n                \"   '\u2705' means the statement's core fact is supported; '\u274c' means it is not.\",\n                \"\",\n                \"Answer Statements Classification:\",\n            ]\n        )\n\n        for stmt, m, expl in ans_class:\n            mark = \"\u2705\" if m else \"\u274c\"\n            lines.extend([f\" {mark} - {stmt}\", f\"     Explanation: {expl}\", \"\"])\n\n        lines.extend(\n            [\n                f\" -&gt; TP (supported) = {tp}  (correctly supported statements)\",\n                f\" -&gt; FP (not supported) = {fp}  (unsupported statements)\",\n            ]\n        )\n\n        if (tp + fp) &gt; 0:\n            lines.append(f\" -&gt; Precision = TP/(TP+FP) = {precision:.2f}\")\n        else:\n            lines.append(\" -&gt; Precision = 0.00\")\n\n        lines.extend(\n            [\n                \"\",\n                \"2. Ground Truth Statements Analysis:\",\n                \"   The ground truth answer is split into statements and compared to the answer.\",\n                \"   '\u2705' means the statement is present in the answer; '\u274c' means it is missing.\",\n                \"\",\n                \"Ground Truth Statements Classification:\",\n            ]\n        )\n\n        for stmt, m, expl in gt_class:\n            mark = \"\u2705\" if m else \"\u274c\"\n            lines.extend([f\" {mark} - {stmt}\", f\"     Explanation: {expl}\", \"\"])\n\n        lines.extend(\n            [\n                f\" -&gt; TP (present) = {tp}  (ground truth statements found in answer)\",\n                f\" -&gt; FN (missing) = {fn}  (ground truth statements not found)\",\n            ]\n        )\n\n        if (tp + fn) &gt; 0:\n            lines.append(f\" -&gt; Recall = TP/(TP+FN) = {recall:.2f}\")\n        else:\n            lines.append(\" -&gt; Recall = 0.00\")\n\n        lines.extend(\n            [\n                \"\",\n                \"3. Final Metrics:\",\n                \"   F1 Score is the harmonic mean of Precision and Recall:\",\n                \"       F1 Score = 2*(Precision*Recall)/(Precision+Recall)\",\n                f\"       F1 Score = {f1:.2f}\",\n                \"\",\n                f\"Final Score = F1 Score = {round(f1, 2)}\",\n            ]\n        )\n\n        return \"\\n\".join(lines)\n\n    def _evaluate_question(self, question: str, answer_stmts: list[str], gt_stmts: list[str]) -&gt; RunResult:\n        \"\"\"\n        Evaluate one question by comparing candidate statements.\n        \"\"\"\n        unique_ans = self._get_unique_candidates(answer_stmts)\n        unique_gt = self._get_unique_candidates(gt_stmts)\n        gt_text = self._join_candidates(unique_gt)\n        ans_class = self._evaluate_candidates(question, unique_ans, gt_text)\n        ans_text = self._join_candidates(unique_ans)\n        gt_class = self._evaluate_candidates(question, unique_gt, ans_text)\n        tp = sum(1 for _, m, _ in ans_class if m)\n        fp = len(ans_class) - tp\n        fn = sum(1 for _, m, _ in gt_class if not m)\n        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0.0\n        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0.0\n        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) &gt; 0 else 0.0\n        reasoning = self._build_reasoning(ans_class, gt_class, tp, fp, fn, precision, recall, f1)\n        return RunResult(score=round(f1, 2), reasoning=reasoning)\n\n    def run_single(self, question: str, answer: str, ground_truth_answer: str, verbose: bool = False) -&gt; RunResult:\n        \"\"\"\n        Evaluate answer correctness for a single sample.\n\n        Steps:\n          1) Extract candidate statements from both the answer and the ground truth answer.\n          2) Compare the candidate statements.\n          3) Compute Precision, Recall, and F1 Score.\n          4) Generate detailed reasoning.\n\n        Args:\n          question (str): The question.\n          answer (str): The answer.\n          ground_truth_answer (str): The ground truth answer.\n          verbose (bool): Flag to output verbose logs.\n\n        Returns:\n          RunResult: The evaluation result with score and reasoning.\n        \"\"\"\n        # Extract candidate statements for answer and ground truth\n        ans_candidates = self.extract_statements([question], [answer])[0]\n        gt_candidates = self.extract_statements([question], [ground_truth_answer])[0]\n        result = self._evaluate_question(question, ans_candidates, gt_candidates)\n        if verbose:\n            logger.debug(f\"Question: {question}\")\n            logger.debug(f\"Answer: {self._join_candidates(ans_candidates)}\")\n            logger.debug(f\"Ground Truth Answer: {self._join_candidates(gt_candidates)}\")\n            logger.debug(result.reasoning)\n        return result\n\n    def run(\n        self, questions: list[str], answers: list[str], ground_truth_answers: list[str], verbose: bool = False\n    ) -&gt; RunOutput:\n        \"\"\"\n        Evaluate answer correctness:\n          1) Extract candidate statements from both the answer and ground truth answer.\n          2) For each question, compare the answer statements to the ground truth answer\n             and vice versa.\n          3) Compute Precision, Recall, and F1 Score.\n          4) Generate detailed and easy-to-understand reasoning that explains the metrics.\n\n        Args:\n          questions (list[str]): List of questions.\n          answers (list[str]): List of answers.\n          ground_truth_answers (list[str]): List of ground truth answers.\n          verbose (bool): Flag for verbose logging.\n\n        Returns:\n          RunOutput: The overall evaluation results.\n        \"\"\"\n        run_input = RunInput(\n            questions=questions, answers=answers, ground_truth_answers=ground_truth_answers, verbose=verbose\n        )\n        out_results = []\n        for i in range(len(run_input.questions)):\n            result = self.run_single(\n                question=run_input.questions[i],\n                answer=run_input.answers[i],\n                ground_truth_answer=run_input.ground_truth_answers[i],\n                verbose=run_input.verbose,\n            )\n            out_results.append(result)\n        return RunOutput(results=out_results)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.AnswerCorrectnessEvaluator.classify_statement","title":"<code>classify_statement(question, answer_stmt, ref_text)</code>","text":"<p>Run the classification evaluator. The ref_text is the string of candidate statements from the ground truth answer. Returns a tuple (match, explanation).</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>def classify_statement(self, question: str, answer_stmt: str, ref_text: str) -&gt; tuple[bool, str]:\n    \"\"\"\n    Run the classification evaluator.\n    The ref_text is the string of candidate statements from the ground truth answer.\n    Returns a tuple (match, explanation).\n    \"\"\"\n    data = {\"question\": [question], \"answer_statement\": [answer_stmt], \"reference_text\": [ref_text]}\n    result = self._statement_classifier.run(**data)\n    m = bool(result[\"results\"][0].get(\"match\", False))\n    expl = result[\"results\"][0].get(\"reasoning\", \"\")\n    return m, expl\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.AnswerCorrectnessEvaluator.extract_statements","title":"<code>extract_statements(questions, texts)</code>","text":"<p>Run the extraction evaluator to get candidate statements.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>def extract_statements(self, questions: list[str], texts: list[str]) -&gt; list[list[str]]:\n    \"\"\"\n    Run the extraction evaluator to get candidate statements.\n    \"\"\"\n    results = self._statement_extractor.run(questions=questions, texts=texts)\n    all_stmts = []\n    for res in results[\"results\"]:\n        stmts = res.get(\"statements\", [])\n        if not isinstance(stmts, list):\n            stmts = [stmts]\n        all_stmts.append(self._get_unique_candidates(stmts))\n    return all_stmts\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.AnswerCorrectnessEvaluator.run","title":"<code>run(questions, answers, ground_truth_answers, verbose=False)</code>","text":"Evaluate answer correctness <p>1) Extract candidate statements from both the answer and ground truth answer. 2) For each question, compare the answer statements to the ground truth answer    and vice versa. 3) Compute Precision, Recall, and F1 Score. 4) Generate detailed and easy-to-understand reasoning that explains the metrics.</p> <p>Parameters:</p> Name Type Description Default <code>questions</code> <code>list[str]</code> <p>List of questions.</p> required <code>answers</code> <code>list[str]</code> <p>List of answers.</p> required <code>ground_truth_answers</code> <code>list[str]</code> <p>List of ground truth answers.</p> required <code>verbose</code> <code>bool</code> <p>Flag for verbose logging.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>RunOutput</code> <code>RunOutput</code> <p>The overall evaluation results.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>def run(\n    self, questions: list[str], answers: list[str], ground_truth_answers: list[str], verbose: bool = False\n) -&gt; RunOutput:\n    \"\"\"\n    Evaluate answer correctness:\n      1) Extract candidate statements from both the answer and ground truth answer.\n      2) For each question, compare the answer statements to the ground truth answer\n         and vice versa.\n      3) Compute Precision, Recall, and F1 Score.\n      4) Generate detailed and easy-to-understand reasoning that explains the metrics.\n\n    Args:\n      questions (list[str]): List of questions.\n      answers (list[str]): List of answers.\n      ground_truth_answers (list[str]): List of ground truth answers.\n      verbose (bool): Flag for verbose logging.\n\n    Returns:\n      RunOutput: The overall evaluation results.\n    \"\"\"\n    run_input = RunInput(\n        questions=questions, answers=answers, ground_truth_answers=ground_truth_answers, verbose=verbose\n    )\n    out_results = []\n    for i in range(len(run_input.questions)):\n        result = self.run_single(\n            question=run_input.questions[i],\n            answer=run_input.answers[i],\n            ground_truth_answer=run_input.ground_truth_answers[i],\n            verbose=run_input.verbose,\n        )\n        out_results.append(result)\n    return RunOutput(results=out_results)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.AnswerCorrectnessEvaluator.run_single","title":"<code>run_single(question, answer, ground_truth_answer, verbose=False)</code>","text":"<p>Evaluate answer correctness for a single sample.</p> Steps <p>1) Extract candidate statements from both the answer and the ground truth answer. 2) Compare the candidate statements. 3) Compute Precision, Recall, and F1 Score. 4) Generate detailed reasoning.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question.</p> required <code>answer</code> <code>str</code> <p>The answer.</p> required <code>ground_truth_answer</code> <code>str</code> <p>The ground truth answer.</p> required <code>verbose</code> <code>bool</code> <p>Flag to output verbose logs.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>RunResult</code> <code>RunResult</code> <p>The evaluation result with score and reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>def run_single(self, question: str, answer: str, ground_truth_answer: str, verbose: bool = False) -&gt; RunResult:\n    \"\"\"\n    Evaluate answer correctness for a single sample.\n\n    Steps:\n      1) Extract candidate statements from both the answer and the ground truth answer.\n      2) Compare the candidate statements.\n      3) Compute Precision, Recall, and F1 Score.\n      4) Generate detailed reasoning.\n\n    Args:\n      question (str): The question.\n      answer (str): The answer.\n      ground_truth_answer (str): The ground truth answer.\n      verbose (bool): Flag to output verbose logs.\n\n    Returns:\n      RunResult: The evaluation result with score and reasoning.\n    \"\"\"\n    # Extract candidate statements for answer and ground truth\n    ans_candidates = self.extract_statements([question], [answer])[0]\n    gt_candidates = self.extract_statements([question], [ground_truth_answer])[0]\n    result = self._evaluate_question(question, ans_candidates, gt_candidates)\n    if verbose:\n        logger.debug(f\"Question: {question}\")\n        logger.debug(f\"Answer: {self._join_candidates(ans_candidates)}\")\n        logger.debug(f\"Ground Truth Answer: {self._join_candidates(gt_candidates)}\")\n        logger.debug(result.reasoning)\n    return result\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.AnswerCorrectnessRunSingleInput","title":"<code>AnswerCorrectnessRunSingleInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single-run input model for answer correctness evaluation.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class AnswerCorrectnessRunSingleInput(BaseModel):\n    \"\"\"\n    Single-run input model for answer correctness evaluation.\n    \"\"\"\n\n    question: str = Field(description=\"The question to answer\")\n    answer: str = Field(description=\"The answer to the question\")\n    ground_truth_answer: str = Field(description=\"The ground truth answer\")\n    verbose: bool = False\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.ClassifyStatementInput","title":"<code>ClassifyStatementInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for classifying a candidate pair.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class ClassifyStatementInput(BaseModel):\n    \"\"\"\n    Input model for classifying a candidate pair.\n    \"\"\"\n    question: str = Field(description=\"The question for context\")\n    answer_statement: str = Field(description=\"A candidate statement from the answer\")\n    ground_truth_statement: str = Field(\n        description=(\"A string of candidate statements extracted from the ground truth answer\")\n    )\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.ClassifyStatementOutput","title":"<code>ClassifyStatementOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for classifying a candidate pair.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class ClassifyStatementOutput(BaseModel):\n    \"\"\"\n    Output model for classifying a candidate pair.\n    \"\"\"\n    match: bool = Field(\n        description=(\"Verdict: true if the core fact of the statement is supported by the ground truth\")\n    )\n    reasoning: str = Field(description=\"Explanation for why the statement is or is not supported\")\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.ExtractStatementsInput","title":"<code>ExtractStatementsInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for extracting candidate statements.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class ExtractStatementsInput(BaseModel):\n    \"\"\"\n    Input model for extracting candidate statements.\n    \"\"\"\n    question: str = Field(description=\"The question to answer\")\n    answer: str = Field(description=\"The answer to the question\")\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.ExtractStatementsOutput","title":"<code>ExtractStatementsOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for extracted candidate statements.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class ExtractStatementsOutput(BaseModel):\n    \"\"\"\n    Output model for extracted candidate statements.\n    \"\"\"\n    statements: list[str] = Field(description=\"The generated statements\")\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.F1Result","title":"<code>F1Result</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model for F1 score calculation.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class F1Result(BaseModel):\n    \"\"\"\n    Model for F1 score calculation.\n    \"\"\"\n    precision: float\n    recall: float\n    f1: float\n    tp: int\n    fp: int\n    fn: int\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.RunInput","title":"<code>RunInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for running the evaluator.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class RunInput(BaseModel):\n    \"\"\"\n    Input model for running the evaluator.\n    \"\"\"\n    questions: list[str]\n    answers: list[str]\n    ground_truth_answers: list[str]\n    verbose: bool = False\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self):\n        if len(self.questions) != len(self.answers) or len(self.questions) != len(self.ground_truth_answers):\n            raise ValueError(\"Questions, answers, and ground truth answers must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.RunOutput","title":"<code>RunOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for final scores and detailed reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class RunOutput(BaseModel):\n    \"\"\"\n    Output model for final scores and detailed reasoning.\n    \"\"\"\n    results: list[RunResult]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/answer_correctness/#dynamiq.evaluations.metrics.answer_correctness.RunResult","title":"<code>RunResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result containing final score and detailed, user-friendly reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/answer_correctness.py</code> <pre><code>class RunResult(BaseModel):\n    \"\"\"\n    Result containing final score and detailed, user-friendly reasoning.\n    \"\"\"\n    score: float\n    reasoning: str\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/","title":"Bleu score","text":""},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.BleuScoreEvaluator","title":"<code>BleuScoreEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Evaluates BLEU scores using the sacrebleu library.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the metric. Defaults to \"BleuScore\".</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>class BleuScoreEvaluator(BaseEvaluator):\n    \"\"\"\n    Evaluates BLEU scores using the sacrebleu library.\n\n    Attributes:\n        name (str): Name of the metric. Defaults to \"BleuScore\".\n    \"\"\"\n    name: str = \"BleuScore\"\n\n    # Private attribute to store the sacrebleu corpus_bleu function.\n    _corpus_bleu: Callable = PrivateAttr()\n\n    def __init__(self, **data):\n        \"\"\"\n        Initialize the BleuScoreEvaluator and load the sacrebleu corpus_bleu function.\n        \"\"\"\n        super().__init__(**data)\n        self._initialize_bleu()\n\n    def _initialize_bleu(self) -&gt; None:\n        \"\"\"\n        Initialize the corpus_bleu function from the sacrebleu library.\n\n        Raises:\n            ImportError: If sacrebleu is not installed.\n        \"\"\"\n        from sacrebleu import corpus_bleu\n\n        self._corpus_bleu = corpus_bleu\n\n    def run_single(self, ground_truth_answer: str, answer: str) -&gt; float:\n        \"\"\"\n        Compute the BLEU score for a single pair of ground truth (reference) and answer.\n\n        The input strings are into sentences. The reference is provided\n        in a format expected by sacrebleu (a list of lists) and the candidate is provided\n        as a list of sentences.\n\n        Args:\n            ground_truth_answer (str): The reference answer.\n            answer (str): The candidate answer.\n\n        Returns:\n            float: The computed BLEU score (as a fraction, e.g., 0.75 for 75%).\n        \"\"\"\n        # Validate inputs using the Pydantic model.\n        single_input = RunSingleInput(ground_truth_answer=ground_truth_answer, answer=answer)\n\n        # Process text into clean sentences\n        ref_sentences = self._process_text_for_bleu(single_input.ground_truth_answer)\n        resp_sentences = self._process_text_for_bleu(single_input.answer)\n\n        # Format the reference as a list of lists (one per sentence)\n        structured_refs = [[sent] for sent in ref_sentences]\n        hypothesis = resp_sentences\n\n        # Compute the BLEU score; sacrebleu returns a percentage, so we scale it by 1/100.\n        bleu_result = self._corpus_bleu(hypothesis, structured_refs).score / 100.0\n        score = round(float(bleu_result), 2)\n\n        output = RunSingleOutput(score=score)\n        return output.score\n\n    def _process_text_for_bleu(self, text: str) -&gt; list[str]:\n        \"\"\"\n        Process text into clean sentences for BLEU score computation.\n\n        Args:\n            text (str): The text to process.\n\n        Returns:\n            list[str]: List of cleaned sentences.\n        \"\"\"\n        # First split the text into sentences\n        raw_sentences = self._split_text_into_sentences(text)\n\n        # Then clean each sentence by removing punctuation\n        cleaned_sentences = [self._clean_sentence(sentence) for sentence in raw_sentences]\n\n        # Filter out empty or very short sentences (likely fragments)\n        return [s for s in cleaned_sentences if s and len(s.split()) &gt; 1]\n\n    def _split_text_into_sentences(self, text: str) -&gt; list[str]:\n        \"\"\"\n        Split text into sentences based on punctuation boundaries.\n\n        Args:\n            text (str): The text to split.\n\n        Returns:\n            list[str]: List of sentences.\n        \"\"\"\n        # Split on ., !, or ? followed by whitespace or end of string\n        sentences = re.split(r\"(?&lt;=[.!?])\\s+|(?&lt;=[.!?])$\", text)\n        return [s.strip() for s in sentences if s.strip()]\n\n    def _clean_sentence(self, sentence: str) -&gt; str:\n        \"\"\"\n        Clean a sentence by removing all punctuation.\n\n        Args:\n            sentence (str): The sentence to clean.\n\n        Returns:\n            str: Cleaned sentence with punctuation removed.\n        \"\"\"\n        # Remove leading/trailing whitespace\n        cleaned = sentence.strip()\n\n        # Remove all punctuation\n        cleaned = re.sub(r\"[^\\w\\s]\", \"\", cleaned)\n\n        return cleaned.strip()\n\n    def run(self, ground_truth_answers: list[str], answers: list[str]) -&gt; list[float]:\n        \"\"\"\n        Compute BLEU scores for each ground_truth_answer/answer pair in batch.\n\n        Args:\n            ground_truth_answers (list[str]): List of reference answers.\n            answers (list[str]): List of candidate answers.\n\n        Returns:\n            list[float]: List of computed BLEU scores.\n        \"\"\"\n        # Validate batch input.\n        input_data = RunInput(ground_truth_answers=ground_truth_answers, answers=answers)\n        scores = []\n\n        for gt, ans in zip(input_data.ground_truth_answers, input_data.answers):\n            score = self.run_single(ground_truth_answer=gt, answer=ans)\n            scores.append(score)\n\n        output_data = RunOutput(scores=scores)\n        return output_data.scores\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.BleuScoreEvaluator.__init__","title":"<code>__init__(**data)</code>","text":"<p>Initialize the BleuScoreEvaluator and load the sacrebleu corpus_bleu function.</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>def __init__(self, **data):\n    \"\"\"\n    Initialize the BleuScoreEvaluator and load the sacrebleu corpus_bleu function.\n    \"\"\"\n    super().__init__(**data)\n    self._initialize_bleu()\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.BleuScoreEvaluator.run","title":"<code>run(ground_truth_answers, answers)</code>","text":"<p>Compute BLEU scores for each ground_truth_answer/answer pair in batch.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_answers</code> <code>list[str]</code> <p>List of reference answers.</p> required <code>answers</code> <code>list[str]</code> <p>List of candidate answers.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: List of computed BLEU scores.</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>def run(self, ground_truth_answers: list[str], answers: list[str]) -&gt; list[float]:\n    \"\"\"\n    Compute BLEU scores for each ground_truth_answer/answer pair in batch.\n\n    Args:\n        ground_truth_answers (list[str]): List of reference answers.\n        answers (list[str]): List of candidate answers.\n\n    Returns:\n        list[float]: List of computed BLEU scores.\n    \"\"\"\n    # Validate batch input.\n    input_data = RunInput(ground_truth_answers=ground_truth_answers, answers=answers)\n    scores = []\n\n    for gt, ans in zip(input_data.ground_truth_answers, input_data.answers):\n        score = self.run_single(ground_truth_answer=gt, answer=ans)\n        scores.append(score)\n\n    output_data = RunOutput(scores=scores)\n    return output_data.scores\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.BleuScoreEvaluator.run_single","title":"<code>run_single(ground_truth_answer, answer)</code>","text":"<p>Compute the BLEU score for a single pair of ground truth (reference) and answer.</p> <p>The input strings are into sentences. The reference is provided in a format expected by sacrebleu (a list of lists) and the candidate is provided as a list of sentences.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_answer</code> <code>str</code> <p>The reference answer.</p> required <code>answer</code> <code>str</code> <p>The candidate answer.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed BLEU score (as a fraction, e.g., 0.75 for 75%).</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>def run_single(self, ground_truth_answer: str, answer: str) -&gt; float:\n    \"\"\"\n    Compute the BLEU score for a single pair of ground truth (reference) and answer.\n\n    The input strings are into sentences. The reference is provided\n    in a format expected by sacrebleu (a list of lists) and the candidate is provided\n    as a list of sentences.\n\n    Args:\n        ground_truth_answer (str): The reference answer.\n        answer (str): The candidate answer.\n\n    Returns:\n        float: The computed BLEU score (as a fraction, e.g., 0.75 for 75%).\n    \"\"\"\n    # Validate inputs using the Pydantic model.\n    single_input = RunSingleInput(ground_truth_answer=ground_truth_answer, answer=answer)\n\n    # Process text into clean sentences\n    ref_sentences = self._process_text_for_bleu(single_input.ground_truth_answer)\n    resp_sentences = self._process_text_for_bleu(single_input.answer)\n\n    # Format the reference as a list of lists (one per sentence)\n    structured_refs = [[sent] for sent in ref_sentences]\n    hypothesis = resp_sentences\n\n    # Compute the BLEU score; sacrebleu returns a percentage, so we scale it by 1/100.\n    bleu_result = self._corpus_bleu(hypothesis, structured_refs).score / 100.0\n    score = round(float(bleu_result), 2)\n\n    output = RunSingleOutput(score=score)\n    return output.score\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.RunInput","title":"<code>RunInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for batch BLEU score evaluation.</p> <p>Attributes:</p> Name Type Description <code>ground_truth_answers</code> <code>list[str]</code> <p>List of reference strings.</p> <code>answers</code> <code>list[str]</code> <p>List of candidate response strings.</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>class RunInput(BaseModel):\n    \"\"\"\n    Input model for batch BLEU score evaluation.\n\n    Attributes:\n        ground_truth_answers (list[str]): List of reference strings.\n        answers (list[str]): List of candidate response strings.\n    \"\"\"\n    ground_truth_answers: list[str]\n    answers: list[str]\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self) -&gt; \"RunInput\":\n        \"\"\"\n        Validate that the number of ground truth answers matches the number of answers.\n\n        Raises:\n            ValueError: If the lengths differ.\n\n        Returns:\n            RunInput: The validated instance.\n        \"\"\"\n        if len(self.ground_truth_answers) != len(self.answers):\n            raise ValueError(\"The number of ground truth answers must equal the number of answers.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.RunInput.check_equal_length","title":"<code>check_equal_length()</code>","text":"<p>Validate that the number of ground truth answers matches the number of answers.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the lengths differ.</p> <p>Returns:</p> Name Type Description <code>RunInput</code> <code>RunInput</code> <p>The validated instance.</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_equal_length(self) -&gt; \"RunInput\":\n    \"\"\"\n    Validate that the number of ground truth answers matches the number of answers.\n\n    Raises:\n        ValueError: If the lengths differ.\n\n    Returns:\n        RunInput: The validated instance.\n    \"\"\"\n    if len(self.ground_truth_answers) != len(self.answers):\n        raise ValueError(\"The number of ground truth answers must equal the number of answers.\")\n    return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.RunOutput","title":"<code>RunOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for batch BLEU score evaluation.</p> <p>Attributes:</p> Name Type Description <code>scores</code> <code>list[float]</code> <p>List of computed BLEU scores.</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>class RunOutput(BaseModel):\n    \"\"\"\n    Output model for batch BLEU score evaluation.\n\n    Attributes:\n        scores (list[float]): List of computed BLEU scores.\n    \"\"\"\n\n    scores: list[float]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.RunSingleInput","title":"<code>RunSingleInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single-run input model for BLEU score evaluation.</p> <p>Attributes:</p> Name Type Description <code>ground_truth_answer</code> <code>str</code> <p>The reference answer.</p> <code>answer</code> <code>str</code> <p>The candidate answer.</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>class RunSingleInput(BaseModel):\n    \"\"\"\n    Single-run input model for BLEU score evaluation.\n\n    Attributes:\n        ground_truth_answer (str): The reference answer.\n        answer (str): The candidate answer.\n    \"\"\"\n\n    ground_truth_answer: str\n    answer: str\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/bleu_score/#dynamiq.evaluations.metrics.bleu_score.RunSingleOutput","title":"<code>RunSingleOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single-run output model for BLEU score evaluation.</p> <p>Attributes:</p> Name Type Description <code>score</code> <code>float</code> <p>The computed BLEU score.</p> Source code in <code>dynamiq/evaluations/metrics/bleu_score.py</code> <pre><code>class RunSingleOutput(BaseModel):\n    \"\"\"\n    Single-run output model for BLEU score evaluation.\n\n    Attributes:\n        score (float): The computed BLEU score.\n    \"\"\"\n\n    score: float\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_precision/","title":"Context precision","text":""},{"location":"dynamiq/evaluations/metrics/context_precision/#dynamiq.evaluations.metrics.context_precision.ContextPrecisionEvaluator","title":"<code>ContextPrecisionEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Evaluator class for context precision metric.</p> <p>Attributes:</p> Name Type Description <code>llm</code> <code>BaseLLM</code> <p>The language model to use for evaluation.</p> Source code in <code>dynamiq/evaluations/metrics/context_precision.py</code> <pre><code>class ContextPrecisionEvaluator(BaseEvaluator):\n    \"\"\"\n    Evaluator class for context precision metric.\n\n    Attributes:\n        llm (BaseLLM): The language model to use for evaluation.\n    \"\"\"\n    name: str = \"ContextPrecision\"\n    llm: BaseLLM\n\n    # Private attribute (not a Pydantic model field)\n    _context_precision_evaluator: LLMEvaluator = PrivateAttr()\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._initialize_evaluator()\n\n    def _initialize_evaluator(self):\n        context_precision_instructions = (\n            'Given a \"Question\", \"Answer\", and \"Context\", verify if the Context was '\n            \"useful in arriving at the given Answer.\\n\"\n            '- Provide a \"verdict\": 1 if useful, 0 if not.\\n'\n            '- Provide a brief \"reason\" for the verdict.\\n'\n            '- Output the result as a JSON object with keys \"verdict\" and \"reason\".\\n'\n            \"- Ensure that your response is valid JSON, using double quotes for all \"\n            \"strings.\"\n        )\n\n        self._context_precision_evaluator = LLMEvaluator(\n            instructions=context_precision_instructions.strip(),\n            inputs=[\n                {\"name\": \"question\", \"type\": list[str]},\n                {\"name\": \"answer\", \"type\": list[str]},\n                {\"name\": \"context\", \"type\": list[str]},\n            ],\n            outputs=[\n                {\"name\": \"verdict\", \"type\": int},\n                {\"name\": \"reason\", \"type\": str},\n            ],\n            examples=[\n                {\n                    \"inputs\": {\n                        \"question\": [\"What can you tell me about Albert Einstein?\"],\n                        \"answer\": [\n                            (\n                                \"Albert Einstein, born on 14 March 1879, was a German-born theoretical \"\n                                \"physicist, widely held to be one of the greatest and most influential \"\n                                \"scientists of all time. He received the 1921 Nobel Prize in Physics \"\n                                \"for his services to theoretical physics.\"\n                            )\n                        ],\n                        \"context\": [\n                            (\n                                \"Albert Einstein (14 March 1879 \u2013 18 April 1955) was a German-born \"\n                                \"theoretical physicist, widely held to be one of the greatest and most \"\n                                \"influential scientists of all time. Best known for developing the theory \"\n                                \"of relativity, he also made important contributions to quantum mechanics, \"\n                                \"and was thus a central figure in modern physics. His mass\u2013energy equivalence \"\n                                \"formula E = mc2 has been called 'the world's most famous equation'.\"\n                            )\n                        ],\n                    },\n                    \"outputs\": {\n                        \"reason\": (\n                            \"The context provides detailed info about Einstein that is reflected in the \"\n                            \"answer (e.g. his contributions and Nobel Prize).\"\n                        ),\n                        \"verdict\": 1,\n                    },\n                },\n                {\n                    \"inputs\": {\n                        \"question\": [\"Who won the 2020 ICC World Cup?\"],\n                        \"answer\": [\"England\"],\n                        \"context\": [\n                            (\n                                \"The 2022 ICC Men's T20 World Cup was postponed from 2020 due to COVID-19. \"\n                                \"England won the tournament, defeating Pakistan in the final.\"\n                            )\n                        ],\n                    },\n                    \"outputs\": {\n                        \"reason\": (\n                            \"The context explains the tournament details and mentions England's victory, \"\n                            \"which is directly relevant.\"\n                        ),\n                        \"verdict\": 1,\n                    },\n                },\n                {\n                    \"inputs\": {\n                        \"question\": [\"What is the tallest mountain in the world?\"],\n                        \"answer\": [\"Mount Everest.\"],\n                        \"context\": [\n                            (\n                                \"The Andes is the longest continental mountain range, but it does not \"\n                                \"contain Mount Everest.\"\n                            )\n                        ],\n                    },\n                    \"outputs\": {\n                        \"reason\": (\"The context discusses the Andes, which is unrelated to Mount Everest.\"),\n                        \"verdict\": 0,\n                    },\n                },\n            ],\n            llm=self.llm,\n        )\n\n    @staticmethod\n    def calculate_average_precision(verdicts: list[int]) -&gt; float:\n        \"\"\"\n        Calculate the average precision based on verdicts.\n\n        Args:\n            verdicts (list[int]): List of verdicts (1 for useful, 0 for not useful).\n\n        Returns:\n            float: The average precision score.\n        \"\"\"\n        numerator = 0.0\n        cumulative_hits = 0\n        total_relevant = sum(verdicts)\n        if total_relevant == 0:\n            return 0.0\n        for index, verdict in enumerate(verdicts):\n            if verdict == 1:\n                cumulative_hits += 1\n                precision_at_index = cumulative_hits / (index + 1)\n                numerator += precision_at_index\n        average_precision = numerator / total_relevant\n        return round(float(average_precision), 2)\n\n    def _build_reasoning(\n        self,\n        question: str,\n        answer: str,\n        contexts: list[str],\n        verdicts: list[int],\n        verdict_details: list[str],\n        average_precision: float,\n    ) -&gt; str:\n        \"\"\"\n        Build a detailed reasoning string for context precision evaluation.\n\n        Explains:\n        \u2022 Each context is evaluated with a verdict (emojis used: \u2705 for supported, \u274c for not).\n        \u2022 The corresponding explanation for each verdict.\n        \u2022 How the average precision is calculated.\n\n        Args:\n            question (str): The evaluation question.\n            answer (str): The answer text.\n            contexts (list[str]): List of contexts evaluated.\n            verdicts (list[int]): List of verdicts (1 or 0) for each context.\n            verdict_details (list[str]): List of explanations for each verdict.\n            average_precision (float): The average precision score.\n\n        Returns:\n            str: Detailed reasoning.\n        \"\"\"\n        reasoning_strings = [\"Reasoning:\", \"\", f\"Question: {question}\", f\"Answer: {answer}\", \"\", \"Context Evaluations:\"]\n        for context_text, verdict_value, detail in zip(contexts, verdicts, verdict_details):\n            verdict_mark = \"\u2705\" if verdict_value == 1 else \"\u274c\"\n            reasoning_strings.extend(\n                [\n                    f\" - Context: {context_text}\",\n                    f\"   Verdict: {verdict_mark} (value: {verdict_value})\",\n                    f\"   Explanation: {detail}\",\n                    \"\",\n                ]\n            )\n        reasoning_strings.append(f\"Average Precision Score = {average_precision:.2f}\")\n        return \"\\n\".join(reasoning_strings)\n\n    def run_single(\n        self, question: str, answer: str, contexts: list[str], verbose: bool = False\n    ) -&gt; ContextPrecisionRunResult:\n        \"\"\"\n        Evaluate the context precision for a single sample.\n\n        Args:\n            question (str): The question.\n            answer (str): The corresponding answer.\n            contexts (list[str]): A list of contexts for this question.\n            verbose (bool): Flag to enable verbose logging.\n\n        Returns:\n            ContextPrecisionRunResult: Contains the computed average precision score and detailed reasoning.\n        \"\"\"\n        verdicts = []\n        verdict_details = []\n        for context in contexts:\n            evaluation_result = self._context_precision_evaluator.run(\n                question=[question], answer=[answer], context=[context]\n            )\n            if (\"results\" not in evaluation_result) or (not evaluation_result[\"results\"]):\n                default_verdict = 0\n                verdicts.append(default_verdict)\n                verdict_details.append(\"No results returned from evaluator.\")\n                if verbose:\n                    logger.debug(f\"Missing results for context: {context}. Defaulting verdict to {default_verdict}.\")\n                continue\n\n            result_item = evaluation_result[\"results\"][0]\n            verdict_raw = result_item.get(\"verdict\", \"0\")\n            try:\n                verdict = int(verdict_raw) if not isinstance(verdict_raw, str) else int(verdict_raw.strip())\n            except (ValueError, AttributeError):\n                verdict = 0\n            verdicts.append(verdict)\n            verdict_details.append(result_item.get(\"reason\", \"No reasoning provided\"))\n\n            if verbose:\n                logger.debug(f\"Question: {question}\")\n                logger.debug(f\"Answer: {answer}\")\n                logger.debug(f\"Context: {context}\")\n                logger.debug(f\"Verdict: {verdict}\")\n                logger.debug(f\"Reason: {result_item.get('reason', 'No reasoning provided')}\")\n                logger.debug(\"-\" * 50)\n\n        average_precision = self.calculate_average_precision(verdicts)\n        reasoning_text = self._build_reasoning(question, answer, contexts, verdicts, verdict_details, average_precision)\n        if verbose:\n            logger.debug(f\"Average Precision Score: {average_precision}\")\n            logger.debug(\"=\" * 50)\n        return ContextPrecisionRunResult(score=average_precision, reasoning=reasoning_text)\n\n    def run(\n        self,\n        questions: list[str],\n        answers: list[str],\n        contexts_list: list[list[str]] | list[str],\n        verbose: bool = False,\n    ) -&gt; ContextPrecisionOutput:\n        \"\"\"\n        Evaluate the context precision for each question.\n\n        Args:\n            questions (list[str]): List of questions.\n            answers (list[str]): List of corresponding answers.\n            contexts_list (list[list[str]] | list[str]): Either a list of contexts per question\n                (list[list[str]]) or a single list of context strings (list[str]).\n            verbose (bool): Flag to enable verbose logging (for internal logging only).\n\n        Returns:\n            ContextPrecisionOutput: Contains a list of context precision scores and reasoning.\n        \"\"\"\n        run_input = ContextPrecisionInput(\n            questions=questions,\n            answers=answers,\n            contexts_list=contexts_list,\n            verbose=verbose,\n        )\n        results_output = []\n        for index in range(len(run_input.questions)):\n            question = run_input.questions[index]\n            answer = run_input.answers[index]\n            contexts = run_input.contexts_list[index]\n            result_single = self.run_single(\n                question=question, answer=answer, contexts=contexts, verbose=run_input.verbose\n            )\n            results_output.append(result_single)\n        return ContextPrecisionOutput(results=results_output)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_precision/#dynamiq.evaluations.metrics.context_precision.ContextPrecisionEvaluator.calculate_average_precision","title":"<code>calculate_average_precision(verdicts)</code>  <code>staticmethod</code>","text":"<p>Calculate the average precision based on verdicts.</p> <p>Parameters:</p> Name Type Description Default <code>verdicts</code> <code>list[int]</code> <p>List of verdicts (1 for useful, 0 for not useful).</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The average precision score.</p> Source code in <code>dynamiq/evaluations/metrics/context_precision.py</code> <pre><code>@staticmethod\ndef calculate_average_precision(verdicts: list[int]) -&gt; float:\n    \"\"\"\n    Calculate the average precision based on verdicts.\n\n    Args:\n        verdicts (list[int]): List of verdicts (1 for useful, 0 for not useful).\n\n    Returns:\n        float: The average precision score.\n    \"\"\"\n    numerator = 0.0\n    cumulative_hits = 0\n    total_relevant = sum(verdicts)\n    if total_relevant == 0:\n        return 0.0\n    for index, verdict in enumerate(verdicts):\n        if verdict == 1:\n            cumulative_hits += 1\n            precision_at_index = cumulative_hits / (index + 1)\n            numerator += precision_at_index\n    average_precision = numerator / total_relevant\n    return round(float(average_precision), 2)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_precision/#dynamiq.evaluations.metrics.context_precision.ContextPrecisionEvaluator.run","title":"<code>run(questions, answers, contexts_list, verbose=False)</code>","text":"<p>Evaluate the context precision for each question.</p> <p>Parameters:</p> Name Type Description Default <code>questions</code> <code>list[str]</code> <p>List of questions.</p> required <code>answers</code> <code>list[str]</code> <p>List of corresponding answers.</p> required <code>contexts_list</code> <code>list[list[str]] | list[str]</code> <p>Either a list of contexts per question (list[list[str]]) or a single list of context strings (list[str]).</p> required <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging (for internal logging only).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>ContextPrecisionOutput</code> <code>ContextPrecisionOutput</code> <p>Contains a list of context precision scores and reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/context_precision.py</code> <pre><code>def run(\n    self,\n    questions: list[str],\n    answers: list[str],\n    contexts_list: list[list[str]] | list[str],\n    verbose: bool = False,\n) -&gt; ContextPrecisionOutput:\n    \"\"\"\n    Evaluate the context precision for each question.\n\n    Args:\n        questions (list[str]): List of questions.\n        answers (list[str]): List of corresponding answers.\n        contexts_list (list[list[str]] | list[str]): Either a list of contexts per question\n            (list[list[str]]) or a single list of context strings (list[str]).\n        verbose (bool): Flag to enable verbose logging (for internal logging only).\n\n    Returns:\n        ContextPrecisionOutput: Contains a list of context precision scores and reasoning.\n    \"\"\"\n    run_input = ContextPrecisionInput(\n        questions=questions,\n        answers=answers,\n        contexts_list=contexts_list,\n        verbose=verbose,\n    )\n    results_output = []\n    for index in range(len(run_input.questions)):\n        question = run_input.questions[index]\n        answer = run_input.answers[index]\n        contexts = run_input.contexts_list[index]\n        result_single = self.run_single(\n            question=question, answer=answer, contexts=contexts, verbose=run_input.verbose\n        )\n        results_output.append(result_single)\n    return ContextPrecisionOutput(results=results_output)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_precision/#dynamiq.evaluations.metrics.context_precision.ContextPrecisionEvaluator.run_single","title":"<code>run_single(question, answer, contexts, verbose=False)</code>","text":"<p>Evaluate the context precision for a single sample.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question.</p> required <code>answer</code> <code>str</code> <p>The corresponding answer.</p> required <code>contexts</code> <code>list[str]</code> <p>A list of contexts for this question.</p> required <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>ContextPrecisionRunResult</code> <code>ContextPrecisionRunResult</code> <p>Contains the computed average precision score and detailed reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/context_precision.py</code> <pre><code>def run_single(\n    self, question: str, answer: str, contexts: list[str], verbose: bool = False\n) -&gt; ContextPrecisionRunResult:\n    \"\"\"\n    Evaluate the context precision for a single sample.\n\n    Args:\n        question (str): The question.\n        answer (str): The corresponding answer.\n        contexts (list[str]): A list of contexts for this question.\n        verbose (bool): Flag to enable verbose logging.\n\n    Returns:\n        ContextPrecisionRunResult: Contains the computed average precision score and detailed reasoning.\n    \"\"\"\n    verdicts = []\n    verdict_details = []\n    for context in contexts:\n        evaluation_result = self._context_precision_evaluator.run(\n            question=[question], answer=[answer], context=[context]\n        )\n        if (\"results\" not in evaluation_result) or (not evaluation_result[\"results\"]):\n            default_verdict = 0\n            verdicts.append(default_verdict)\n            verdict_details.append(\"No results returned from evaluator.\")\n            if verbose:\n                logger.debug(f\"Missing results for context: {context}. Defaulting verdict to {default_verdict}.\")\n            continue\n\n        result_item = evaluation_result[\"results\"][0]\n        verdict_raw = result_item.get(\"verdict\", \"0\")\n        try:\n            verdict = int(verdict_raw) if not isinstance(verdict_raw, str) else int(verdict_raw.strip())\n        except (ValueError, AttributeError):\n            verdict = 0\n        verdicts.append(verdict)\n        verdict_details.append(result_item.get(\"reason\", \"No reasoning provided\"))\n\n        if verbose:\n            logger.debug(f\"Question: {question}\")\n            logger.debug(f\"Answer: {answer}\")\n            logger.debug(f\"Context: {context}\")\n            logger.debug(f\"Verdict: {verdict}\")\n            logger.debug(f\"Reason: {result_item.get('reason', 'No reasoning provided')}\")\n            logger.debug(\"-\" * 50)\n\n    average_precision = self.calculate_average_precision(verdicts)\n    reasoning_text = self._build_reasoning(question, answer, contexts, verdicts, verdict_details, average_precision)\n    if verbose:\n        logger.debug(f\"Average Precision Score: {average_precision}\")\n        logger.debug(\"=\" * 50)\n    return ContextPrecisionRunResult(score=average_precision, reasoning=reasoning_text)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_precision/#dynamiq.evaluations.metrics.context_precision.ContextPrecisionInput","title":"<code>ContextPrecisionInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for context precision evaluation.</p> <p>Attributes:</p> Name Type Description <code>questions</code> <code>list[str]</code> <p>List of questions.</p> <code>answers</code> <code>list[str]</code> <p>List of corresponding answers.</p> <code>contexts_list</code> <code>list[list[str]] | list[str]</code> <p>Either a list of lists of strings or a list of strings; it will be normalized to a list of lists.</p> <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> Source code in <code>dynamiq/evaluations/metrics/context_precision.py</code> <pre><code>class ContextPrecisionInput(BaseModel):\n    \"\"\"\n    Input model for context precision evaluation.\n\n    Attributes:\n        questions (list[str]): List of questions.\n        answers (list[str]): List of corresponding answers.\n        contexts_list (list[list[str]] | list[str]): Either a list of lists of\n            strings or a list of strings; it will be normalized to a list of lists.\n        verbose (bool): Flag to enable verbose logging.\n    \"\"\"\n    questions: list[str]\n    answers: list[str]\n    contexts_list: list[list[str]] | list[str]\n    verbose: bool = False\n\n    @field_validator(\"contexts_list\", mode=\"before\")\n    def normalize_contexts_list(cls, value):\n        # If the user provides a list[str], wrap it into [list[str]].\n        # If the user provides a list[list[str]], leave as-is.\n        # Otherwise, raise an error.\n        if isinstance(value, list):\n            if all(isinstance(item, str) for item in value):\n                return [value]  # e.g. [\"foo\", \"bar\"] becomes [[\"foo\", \"bar\"]]\n            if all(isinstance(item, list) and all(isinstance(x, str) for x in item) for item in value):\n                return value\n        raise ValueError(\"contexts_list must be either a list of strings or a list of list of strings.\")\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self):\n        # Now self.contexts_list will always be a list of lists of strings.\n        if not (len(self.questions) == len(self.answers) == len(self.contexts_list)):\n            raise ValueError(\"questions, answers, and contexts_list must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_precision/#dynamiq.evaluations.metrics.context_precision.ContextPrecisionOutput","title":"<code>ContextPrecisionOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for context precision evaluation.</p> <p>Attributes:</p> Name Type Description <code>results</code> <code>list[ContextPrecisionRunResult]</code> <p>List of evaluation results.</p> Source code in <code>dynamiq/evaluations/metrics/context_precision.py</code> <pre><code>class ContextPrecisionOutput(BaseModel):\n    \"\"\"\n    Output model for context precision evaluation.\n\n    Attributes:\n        results (list[ContextPrecisionRunResult]): List of evaluation results.\n    \"\"\"\n    results: list[ContextPrecisionRunResult]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_precision/#dynamiq.evaluations.metrics.context_precision.ContextPrecisionRunResult","title":"<code>ContextPrecisionRunResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result model for the context precision evaluation.</p> <p>Attributes:</p> Name Type Description <code>score</code> <code>float</code> <p>The computed context precision score.</p> <code>reasoning</code> <code>str</code> <p>Detailed reasoning explaining how the score was derived.</p> Source code in <code>dynamiq/evaluations/metrics/context_precision.py</code> <pre><code>class ContextPrecisionRunResult(BaseModel):\n    \"\"\"\n    Result model for the context precision evaluation.\n\n    Attributes:\n        score (float): The computed context precision score.\n        reasoning (str): Detailed reasoning explaining how the score was derived.\n    \"\"\"\n    score: float\n    reasoning: str\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_precision/#dynamiq.evaluations.metrics.context_precision.VerdictResult","title":"<code>VerdictResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model for the verdict result from the evaluator.</p> <p>Attributes:</p> Name Type Description <code>verdict</code> <code>int</code> <p>1 if the context was useful, 0 otherwise.</p> <code>reason</code> <code>str</code> <p>Reason for the verdict.</p> Source code in <code>dynamiq/evaluations/metrics/context_precision.py</code> <pre><code>class VerdictResult(BaseModel):\n    \"\"\"\n    Model for the verdict result from the evaluator.\n\n    Attributes:\n        verdict (int): 1 if the context was useful, 0 otherwise.\n        reason (str): Reason for the verdict.\n    \"\"\"\n    verdict: int\n    reason: str\n\n    @field_validator(\"verdict\")\n    @classmethod\n    def validate_verdict(cls, value):\n        if value not in (0, 1):\n            raise ValueError(\"Verdict must be either 0 or 1.\")\n        return value\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_recall/","title":"Context recall","text":""},{"location":"dynamiq/evaluations/metrics/context_recall/#dynamiq.evaluations.metrics.context_recall.ClassificationItem","title":"<code>ClassificationItem</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model for individual classification result.</p> <p>Attributes:</p> Name Type Description <code>statement</code> <code>str</code> <p>The statement being classified.</p> <code>reason</code> <code>str</code> <p>Reason for the classification.</p> <code>attributed</code> <code>int</code> <p>1 if attributed to context, 0 otherwise.</p> Source code in <code>dynamiq/evaluations/metrics/context_recall.py</code> <pre><code>class ClassificationItem(BaseModel):\n    \"\"\"\n    Model for individual classification result.\n\n    Attributes:\n        statement (str): The statement being classified.\n        reason (str): Reason for the classification.\n        attributed (int): 1 if attributed to context, 0 otherwise.\n    \"\"\"\n    statement: str\n    reason: str\n    attributed: int\n\n    @field_validator(\"attributed\")\n    @classmethod\n    def validate_attributed(cls, value):\n        if value not in (0, 1):\n            raise ValueError(\"Attributed must be either 0 or 1.\")\n        return value\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_recall/#dynamiq.evaluations.metrics.context_recall.ContextRecallEvaluator","title":"<code>ContextRecallEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Evaluator class for context recall metric.</p> <p>Attributes:</p> Name Type Description <code>llm</code> <code>BaseLLM</code> <p>The language model to use for evaluation.</p> Source code in <code>dynamiq/evaluations/metrics/context_recall.py</code> <pre><code>class ContextRecallEvaluator(BaseEvaluator):\n    \"\"\"\n    Evaluator class for context recall metric.\n\n    Attributes:\n        llm (BaseLLM): The language model to use for evaluation.\n    \"\"\"\n    name: str = \"ContextRecall\"\n    llm: BaseLLM\n\n    _classification_evaluator: LLMEvaluator = PrivateAttr()\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._initialize_evaluator()\n\n    def _initialize_evaluator(self):\n        class_instructions = (\n            'Given a \"Question\", \"Context\", and \"Answer\", analyze each sentence in the '\n            \"Answer and classify if the sentence can be attributed to the given Context \"\n            \"or not.\\n\"\n            \"- Use '1' (Yes) or '0' (No) for classification.\\n\"\n            '- Provide a brief \"reason\" for each classification.\\n'\n            '- Output as a JSON object with key \"classifications\", where the value is a list '\n            'of dictionaries with keys \"statement\", \"reason\", and \"attributed\".\\n'\n            \"- Ensure your response is valid JSON, using double quotes for all strings.\"\n        )\n\n        self._classification_evaluator = LLMEvaluator(\n            instructions=class_instructions.strip(),\n            inputs=[\n                {\"name\": \"question\", \"type\": list[str]},\n                {\"name\": \"context\", \"type\": list[str]},\n                {\"name\": \"answer\", \"type\": list[str]},\n            ],\n            outputs=[\n                {\"name\": \"classifications\", \"type\": list[dict[str, Any]]},\n            ],\n            examples=[\n                {\n                    \"inputs\": {\n                        \"question\": [\"What can you tell me about Albert Einstein?\"],\n                        \"context\": [\n                            (\n                                \"Albert Einstein (14 March 1879 - 18 April 1955) was a German-born \"\n                                \"theoretical physicist, widely held to be one of the greatest and most \"\n                                \"influential scientists of all time. Best known for developing the theory \"\n                                \"of relativity, he also made important contributions to quantum mechanics, \"\n                                \"and was thus a pivotal figure in modern physics.\"\n                            )\n                        ],\n                        \"answer\": [\n                            (\n                                \"Albert Einstein, born on 14 March 1879, was a German-born theoretical \"\n                                \"physicist, widely held to be one of the greatest and most influential \"\n                                \"scientists of all time. He received the 1921 Nobel Prize in Physics for his \"\n                                \"services to theoretical physics. He published 4 papers in 1905. Einstein \"\n                                \"moved to Switzerland in 1895.\"\n                            )\n                        ],\n                    },\n                    \"outputs\": {\n                        \"classifications\": [\n                            {\n                                \"statement\": (\n                                    \"Albert Einstein, born on 14 March 1879, was a German-born theoretical \"\n                                    \"physicist, widely held to be one of the greatest and most influential \"\n                                    \"scientists of all time.\"\n                                ),\n                                \"reason\": \"The birth date and status as a theoretical physicist are mentioned.\",\n                                \"attributed\": 1,\n                            },\n                            {\n                                \"statement\": (\n                                    \"He received the 1921 Nobel Prize in Physics for his services to theoretical \"\n                                    \"physics.\"\n                                ),\n                                \"reason\": \"The sentence is present in the context.\",\n                                \"attributed\": 1,\n                            },\n                            {\n                                \"statement\": \"He published 4 papers in 1905.\",\n                                \"reason\": \"There is no mention of his papers in the context.\",\n                                \"attributed\": 0,\n                            },\n                            {\n                                \"statement\": \"Einstein moved to Switzerland in 1895.\",\n                                \"reason\": \"There is no supporting evidence for this in the context.\",\n                                \"attributed\": 0,\n                            },\n                        ]\n                    },\n                },\n            ],\n            llm=self.llm,\n        )\n\n    def _build_reasoning(self, classifications: list[ClassificationItem], score: float) -&gt; str:\n        \"\"\"\n        Build a detailed reasoning string for context recall evaluation.\n\n        Explains:\n        \u2022 Each sentence in the answer is classified (using emojis: \u2705 for attributed, \u274c for not).\n        \u2022 A corresponding explanation is provided for each classification.\n        \u2022 The final context recall score is computed as the ratio of attributable sentences.\n\n        Args:\n            classifications (list[ClassificationItem]): List of classification results.\n            score (float): The computed recall score.\n\n        Returns:\n            str: Detailed reasoning.\n        \"\"\"\n        lines = []\n        lines.extend([\"Reasoning:\", \"\", \"Classifications:\"])\n        for item in classifications:\n            mark = \"\u2705\" if item.attributed == 1 else \"\u274c\"\n            lines.extend(\n                [\n                    f\" - Statement: {item.statement}\",\n                    f\"   Verdict: {mark} (value: {item.attributed})\",\n                    f\"   Explanation: {item.reason}\",\n                    \"\",\n                ]\n            )\n        lines.append(f\"Context Recall Score = {score:.2f}\")\n        return \"\\n\".join(lines)\n\n    def run_single(self, question: str, context: str, answer: str, verbose: bool = False) -&gt; ContextRecallRunResult:\n        \"\"\"\n        Evaluate the context recall for a single sample.\n\n        Args:\n            question (str): The question.\n            context (str): The context (already normalized as a single string).\n            answer (str): The answer.\n            verbose (bool): Flag to enable verbose logging.\n\n        Returns:\n            ContextRecallRunResult: The computed context recall score and detailed reasoning.\n        \"\"\"\n        result = self._classification_evaluator.run(\n            question=[question],\n            context=[context],\n            answer=[answer],\n        )\n\n        classifications = []\n        if \"results\" not in result or not result[\"results\"]:\n            if verbose:\n                logger.debug(f\"No results returned for question: {question}, context: {context}.\")\n        else:\n            first_result = result[\"results\"][0]\n            if \"classifications\" not in first_result or not first_result[\"classifications\"]:\n                if verbose:\n                    logger.debug(f\"No classifications returned for question: {question}, context: {context}.\")\n            else:\n                classifications_raw = first_result[\"classifications\"]\n                for item in classifications_raw:\n                    classification_item = ClassificationItem(\n                        statement=item[\"statement\"],\n                        reason=item[\"reason\"],\n                        attributed=int(item[\"attributed\"]),\n                    )\n                    classifications.append(classification_item)\n\n        attributed_list = [item.attributed for item in classifications]\n        num_sentences = len(attributed_list)\n        num_attributed = sum(attributed_list)\n        score = num_attributed / num_sentences if num_sentences &gt; 0 else 0.0\n        score = round(float(score), 2)\n\n        reasoning_str = self._build_reasoning(classifications, score)\n\n        if verbose:\n            logger.debug(f\"Question: {question}\")\n            logger.debug(f\"Answer: {answer}\")\n            logger.debug(f\"Context: {context}\")\n            logger.debug(\"Classifications:\")\n            logger.debug(json.dumps([item.dict() for item in classifications], indent=2))\n            logger.debug(f\"Context Recall Score: {score}\")\n            logger.debug(\"-\" * 50)\n\n        return ContextRecallRunResult(score=score, reasoning=reasoning_str)\n\n    def run(\n        self,\n        questions: list[str],\n        contexts: list[str] | list[list[str]],\n        answers: list[str],\n        verbose: bool = False,\n    ) -&gt; ContextRecallOutput:\n        \"\"\"\n        Evaluate the context recall for each question.\n\n        Args:\n            questions (list[str]): List of questions.\n            contexts (list[str] or list[list[str]]): Either a single list of context strings or a list\n                of context strings (one per question).\n            answers (list[str]): List of answers.\n            verbose (bool): Flag to enable verbose logging (for internal logging only).\n\n        Returns:\n            ContextRecallOutput: Contains a list of context recall run results.\n        \"\"\"\n        run_input = ContextRecallInput(\n            questions=questions,\n            contexts=contexts,\n            answers=answers,\n            verbose=verbose,\n        )\n        results_output = []\n        for i in range(len(run_input.questions)):\n            question = run_input.questions[i]\n            context = run_input.contexts[i]\n            answer = run_input.answers[i]\n            result_single = self.run_single(\n                question=question, context=context, answer=answer, verbose=run_input.verbose\n            )\n            results_output.append(result_single)\n        return ContextRecallOutput(results=results_output)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_recall/#dynamiq.evaluations.metrics.context_recall.ContextRecallEvaluator.run","title":"<code>run(questions, contexts, answers, verbose=False)</code>","text":"<p>Evaluate the context recall for each question.</p> <p>Parameters:</p> Name Type Description Default <code>questions</code> <code>list[str]</code> <p>List of questions.</p> required <code>contexts</code> <code>list[str] or list[list[str]]</code> <p>Either a single list of context strings or a list of context strings (one per question).</p> required <code>answers</code> <code>list[str]</code> <p>List of answers.</p> required <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging (for internal logging only).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>ContextRecallOutput</code> <code>ContextRecallOutput</code> <p>Contains a list of context recall run results.</p> Source code in <code>dynamiq/evaluations/metrics/context_recall.py</code> <pre><code>def run(\n    self,\n    questions: list[str],\n    contexts: list[str] | list[list[str]],\n    answers: list[str],\n    verbose: bool = False,\n) -&gt; ContextRecallOutput:\n    \"\"\"\n    Evaluate the context recall for each question.\n\n    Args:\n        questions (list[str]): List of questions.\n        contexts (list[str] or list[list[str]]): Either a single list of context strings or a list\n            of context strings (one per question).\n        answers (list[str]): List of answers.\n        verbose (bool): Flag to enable verbose logging (for internal logging only).\n\n    Returns:\n        ContextRecallOutput: Contains a list of context recall run results.\n    \"\"\"\n    run_input = ContextRecallInput(\n        questions=questions,\n        contexts=contexts,\n        answers=answers,\n        verbose=verbose,\n    )\n    results_output = []\n    for i in range(len(run_input.questions)):\n        question = run_input.questions[i]\n        context = run_input.contexts[i]\n        answer = run_input.answers[i]\n        result_single = self.run_single(\n            question=question, context=context, answer=answer, verbose=run_input.verbose\n        )\n        results_output.append(result_single)\n    return ContextRecallOutput(results=results_output)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_recall/#dynamiq.evaluations.metrics.context_recall.ContextRecallEvaluator.run_single","title":"<code>run_single(question, context, answer, verbose=False)</code>","text":"<p>Evaluate the context recall for a single sample.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question.</p> required <code>context</code> <code>str</code> <p>The context (already normalized as a single string).</p> required <code>answer</code> <code>str</code> <p>The answer.</p> required <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>ContextRecallRunResult</code> <code>ContextRecallRunResult</code> <p>The computed context recall score and detailed reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/context_recall.py</code> <pre><code>def run_single(self, question: str, context: str, answer: str, verbose: bool = False) -&gt; ContextRecallRunResult:\n    \"\"\"\n    Evaluate the context recall for a single sample.\n\n    Args:\n        question (str): The question.\n        context (str): The context (already normalized as a single string).\n        answer (str): The answer.\n        verbose (bool): Flag to enable verbose logging.\n\n    Returns:\n        ContextRecallRunResult: The computed context recall score and detailed reasoning.\n    \"\"\"\n    result = self._classification_evaluator.run(\n        question=[question],\n        context=[context],\n        answer=[answer],\n    )\n\n    classifications = []\n    if \"results\" not in result or not result[\"results\"]:\n        if verbose:\n            logger.debug(f\"No results returned for question: {question}, context: {context}.\")\n    else:\n        first_result = result[\"results\"][0]\n        if \"classifications\" not in first_result or not first_result[\"classifications\"]:\n            if verbose:\n                logger.debug(f\"No classifications returned for question: {question}, context: {context}.\")\n        else:\n            classifications_raw = first_result[\"classifications\"]\n            for item in classifications_raw:\n                classification_item = ClassificationItem(\n                    statement=item[\"statement\"],\n                    reason=item[\"reason\"],\n                    attributed=int(item[\"attributed\"]),\n                )\n                classifications.append(classification_item)\n\n    attributed_list = [item.attributed for item in classifications]\n    num_sentences = len(attributed_list)\n    num_attributed = sum(attributed_list)\n    score = num_attributed / num_sentences if num_sentences &gt; 0 else 0.0\n    score = round(float(score), 2)\n\n    reasoning_str = self._build_reasoning(classifications, score)\n\n    if verbose:\n        logger.debug(f\"Question: {question}\")\n        logger.debug(f\"Answer: {answer}\")\n        logger.debug(f\"Context: {context}\")\n        logger.debug(\"Classifications:\")\n        logger.debug(json.dumps([item.dict() for item in classifications], indent=2))\n        logger.debug(f\"Context Recall Score: {score}\")\n        logger.debug(\"-\" * 50)\n\n    return ContextRecallRunResult(score=score, reasoning=reasoning_str)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_recall/#dynamiq.evaluations.metrics.context_recall.ContextRecallInput","title":"<code>ContextRecallInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for context recall evaluation.</p> <p>Attributes:</p> Name Type Description <code>questions</code> <code>list[str]</code> <p>List of questions.</p> <code>contexts</code> <code>list[str]</code> <p>List of corresponding contexts (can also accept list[list[str]]).</p> <code>answers</code> <code>list[str]</code> <p>List of answers.</p> <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> Source code in <code>dynamiq/evaluations/metrics/context_recall.py</code> <pre><code>class ContextRecallInput(BaseModel):\n    \"\"\"\n    Input model for context recall evaluation.\n\n    Attributes:\n        questions (list[str]): List of questions.\n        contexts (list[str]): List of corresponding contexts (can also accept list[list[str]]).\n        answers (list[str]): List of answers.\n        verbose (bool): Flag to enable verbose logging.\n    \"\"\"\n    questions: list[str]\n    contexts: list[str] | list[list[str]]\n    answers: list[str]\n    verbose: bool = False\n\n    @field_validator(\"contexts\", mode=\"before\")\n    def unify_contexts(cls, value):\n        \"\"\"\n        If we receive a list of lists of strings, join each sublist into a single string.\n        Otherwise, if it's already list[str], do nothing.\n        \"\"\"\n        if not isinstance(value, list):\n            raise ValueError(\"contexts must be either a list[str] or a list[list[str]].\")\n        if all(isinstance(item, list) and all(isinstance(x, str) for x in item) for item in value):\n            return [\" \".join(sublist) for sublist in value]\n        if all(isinstance(item, str) for item in value):\n            return value\n        raise ValueError(\"contexts must be either a list[str] or a list[list[str]].\")\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self):\n        if not (len(self.questions) == len(self.contexts) == len(self.answers)):\n            raise ValueError(\"Questions, contexts, and answers must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_recall/#dynamiq.evaluations.metrics.context_recall.ContextRecallInput.unify_contexts","title":"<code>unify_contexts(value)</code>","text":"<p>If we receive a list of lists of strings, join each sublist into a single string. Otherwise, if it's already list[str], do nothing.</p> Source code in <code>dynamiq/evaluations/metrics/context_recall.py</code> <pre><code>@field_validator(\"contexts\", mode=\"before\")\ndef unify_contexts(cls, value):\n    \"\"\"\n    If we receive a list of lists of strings, join each sublist into a single string.\n    Otherwise, if it's already list[str], do nothing.\n    \"\"\"\n    if not isinstance(value, list):\n        raise ValueError(\"contexts must be either a list[str] or a list[list[str]].\")\n    if all(isinstance(item, list) and all(isinstance(x, str) for x in item) for item in value):\n        return [\" \".join(sublist) for sublist in value]\n    if all(isinstance(item, str) for item in value):\n        return value\n    raise ValueError(\"contexts must be either a list[str] or a list[list[str]].\")\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_recall/#dynamiq.evaluations.metrics.context_recall.ContextRecallOutput","title":"<code>ContextRecallOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for context recall evaluation.</p> <p>Attributes:</p> Name Type Description <code>results</code> <code>list[ContextRecallRunResult]</code> <p>Detailed run results.</p> Source code in <code>dynamiq/evaluations/metrics/context_recall.py</code> <pre><code>class ContextRecallOutput(BaseModel):\n    \"\"\"\n    Output model for context recall evaluation.\n\n    Attributes:\n        results (list[ContextRecallRunResult]): Detailed run results.\n    \"\"\"\n    results: list[ContextRecallRunResult]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/context_recall/#dynamiq.evaluations.metrics.context_recall.ContextRecallRunResult","title":"<code>ContextRecallRunResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result model for the context recall evaluation.</p> <p>Attributes:</p> Name Type Description <code>score</code> <code>float</code> <p>The computed context recall score.</p> <code>reasoning</code> <code>str</code> <p>Detailed reasoning explaining how the score was derived.</p> Source code in <code>dynamiq/evaluations/metrics/context_recall.py</code> <pre><code>class ContextRecallRunResult(BaseModel):\n    \"\"\"\n    Result model for the context recall evaluation.\n\n    Attributes:\n        score (float): The computed context recall score.\n        reasoning (str): Detailed reasoning explaining how the score was derived.\n    \"\"\"\n    score: float\n    reasoning: str\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/","title":"Factual correctness","text":""},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.DecomposeClaimsInput","title":"<code>DecomposeClaimsInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for decomposing texts into claims.</p> <p>Attributes:</p> Name Type Description <code>texts</code> <code>list[str]</code> <p>List of texts to decompose.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>class DecomposeClaimsInput(BaseModel):\n    \"\"\"\n    Input model for decomposing texts into claims.\n\n    Attributes:\n        texts (list[str]): List of texts to decompose.\n    \"\"\"\n    texts: list[str]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.DecomposeClaimsOutput","title":"<code>DecomposeClaimsOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for claim decomposition.</p> <p>Attributes:</p> Name Type Description <code>claims_list</code> <code>list[list[str]]</code> <p>List of lists of claims.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>class DecomposeClaimsOutput(BaseModel):\n    \"\"\"\n    Output model for claim decomposition.\n\n    Attributes:\n        claims_list (list[list[str]]): List of lists of claims.\n    \"\"\"\n    claims_list: list[list[str]]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.FactualCorrectnessEvaluator","title":"<code>FactualCorrectnessEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Evaluator class for factual correctness metric.</p> Pipeline <p>1) Claim Decomposition: The answer and context are decomposed into standalone,    verifiable claims. 2) Claim Verification: The answer claims are verified against the context to compute    precision (TP vs. FP). Optionally, context claims are verified against answer for    recall (FN). 3) Score Computation: Depending on mode, evaluate precision, recall, or F-beta score. 4) Detailed Reasoning: Generates a user-friendly explanation describing each step,    including claim lists, TP, FP, FN, and metric computations with emojis.</p> <p>Attributes:</p> Name Type Description <code>llm</code> <code>BaseLLM</code> <p>The language model to use for evaluation.</p> <code>mode</code> <code>str</code> <p>Evaluation mode ('precision', 'recall', or 'f1').</p> <code>beta</code> <code>float</code> <p>Beta value for F-beta score.</p> <code>atomicity</code> <code>str</code> <p>Level of atomicity ('low' or 'high').</p> <code>coverage</code> <code>str</code> <p>Level of coverage ('low' or 'high').</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>class FactualCorrectnessEvaluator(BaseEvaluator):\n    \"\"\"\n    Evaluator class for factual correctness metric.\n\n    Pipeline:\n      1) Claim Decomposition: The answer and context are decomposed into standalone,\n         verifiable claims.\n      2) Claim Verification: The answer claims are verified against the context to compute\n         precision (TP vs. FP). Optionally, context claims are verified against answer for\n         recall (FN).\n      3) Score Computation: Depending on mode, evaluate precision, recall, or F-beta score.\n      4) Detailed Reasoning: Generates a user-friendly explanation describing each step,\n         including claim lists, TP, FP, FN, and metric computations with emojis.\n\n    Attributes:\n        llm (BaseLLM): The language model to use for evaluation.\n        mode (str): Evaluation mode ('precision', 'recall', or 'f1').\n        beta (float): Beta value for F-beta score.\n        atomicity (str): Level of atomicity ('low' or 'high').\n        coverage (str): Level of coverage ('low' or 'high').\n    \"\"\"\n    name: str = \"FactualCorrectness\"\n    llm: BaseLLM\n    mode: str = \"f1\"\n    beta: float = 1.0\n    atomicity: str = \"low\"\n    coverage: str = \"low\"\n\n    _claim_decomposer: LLMEvaluator = PrivateAttr()\n    _nli_evaluator: LLMEvaluator = PrivateAttr()\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._initialize_evaluators()\n\n    def _initialize_evaluators(self):\n        # Claim Decomposition Evaluator\n        decomposition_instructions = (\n            \"Decompose the 'Input Text' into standalone factual claims.\\n\"\n            \"- Each claim should be a simple, verifiable statement.\\n\"\n            \"- Do not include personal opinions or interpretations.\\n\"\n            \"- Output a JSON object with key 'claims' containing the list of claims.\\n\"\n            \"- Ensure your response is valid JSON, using double quotes for all strings.\"\n        )\n        self._claim_decomposer = LLMEvaluator(\n            instructions=decomposition_instructions.strip(),\n            inputs=[{\"name\": \"input_text\", \"type\": list[str]}],\n            outputs=[{\"name\": \"claims\", \"type\": list[str]}],\n            examples=[\n                {\n                    \"inputs\": {\n                        \"input_text\": [\n                            \"Albert Einstein was a German theoretical physicist. \"\n                            \"He developed the theory of relativity and contributed \"\n                            \"to quantum mechanics.\"\n                        ]\n                    },\n                    \"outputs\": {\n                        \"claims\": [\n                            \"Albert Einstein was a German theoretical physicist.\",\n                            \"Albert Einstein developed the theory of relativity.\",\n                            \"Albert Einstein contributed to quantum mechanics.\",\n                        ]\n                    },\n                },\n            ],\n            llm=self.llm,\n        )\n\n        # NLI Evaluator\n        nli_instructions = (\n            \"For each 'Claim', determine if it is supported by the 'Premise'.\\n\"\n            \"- Return 'verdict': 1 for supported, 0 for unsupported claims.\\n\"\n            \"- Provide a brief 'reason' for each verdict.\\n\"\n            \"- Output a JSON object with key 'results' containing a list of verdicts.\\n\"\n            \"- Each item should have keys 'claim', 'verdict', and 'reason'.\\n\"\n            \"- Ensure your response is valid JSON, using double quotes for all strings.\"\n        )\n        self._nli_evaluator = LLMEvaluator(\n            instructions=nli_instructions.strip(),\n            inputs=[\n                {\"name\": \"premise\", \"type\": list[str]},\n                {\"name\": \"claims\", \"type\": list[list[str]]},\n            ],\n            outputs=[{\"name\": \"results\", \"type\": list[dict[str, Any]]}],\n            examples=[\n                {\n                    \"inputs\": {\n                        \"premise\": [\n                            \"Albert Einstein was a German-born theoretical physicist. \"\n                            \"He developed the theory of relativity.\"\n                        ],\n                        \"claims\": [\n                            [\n                                \"Albert Einstein was a German theoretical physicist.\",\n                                \"Albert Einstein developed the theory of relativity.\",\n                                \"Albert Einstein contributed to quantum mechanics.\",\n                            ]\n                        ],\n                    },\n                    \"outputs\": {\n                        \"results\": [\n                            {\n                                \"claim\": \"Albert Einstein was a German theoretical physicist.\",\n                                \"verdict\": 1,\n                                \"reason\": \"The premise states he was a German-born theoretical physicist.\",\n                            },\n                            {\n                                \"claim\": \"Albert Einstein developed the theory of relativity.\",\n                                \"verdict\": 1,\n                                \"reason\": \"This is explicitly mentioned in the premise.\",\n                            },\n                            {\n                                \"claim\": \"Albert Einstein contributed to quantum mechanics.\",\n                                \"verdict\": 0,\n                                \"reason\": \"The premise does not mention contributions to quantum mechanics.\",\n                            },\n                        ]\n                    },\n                },\n            ],\n            llm=self.llm,\n        )\n\n    def decompose_claims(self, texts: list[str]) -&gt; list[list[str]]:\n        \"\"\"\n        Decompose each text into claims.\n\n        Args:\n            texts (list[str]): List of texts to decompose.\n\n        Returns:\n            list[list[str]]: List of lists of claims.\n        \"\"\"\n        input_data = DecomposeClaimsInput(texts=texts)\n        results = self._claim_decomposer.run(input_text=input_data.texts)\n        claims_list = []\n        for result in results[\"results\"]:\n            claims = result.get(\"claims\")\n            if isinstance(claims, list):\n                claims_list.append(claims)\n            else:\n                claims_list.append([claims])\n        output_data = DecomposeClaimsOutput(claims_list=claims_list)\n        return output_data.claims_list\n\n    def verify_claims(self, premises: list[str], claims_list: list[list[str]]) -&gt; list[list[int]]:\n        \"\"\"\n        Verify the claims against the premises.\n\n        Args:\n            premises (list[str]): List of premises.\n            claims_list (list[list[str]]): List of lists of claims.\n\n        Returns:\n            list[list[int]]: List of lists of verdicts.\n        \"\"\"\n        input_data = VerifyClaimsInput(premises=premises, claims_list=claims_list)\n        results = self._nli_evaluator.run(\n            premise=input_data.premises,\n            claims=input_data.claims_list,\n        )\n        verdicts_list = []\n        for result in results[\"results\"]:\n            verdicts_raw = result[\"results\"]\n            verdicts = []\n            for item in verdicts_raw:\n                verdict = int(item[\"verdict\"])\n                verdicts.append(verdict)\n            verdicts_list.append(verdicts)\n        output_data = VerifyClaimsOutput(verdicts_list=verdicts_list)\n        return output_data.verdicts_list\n\n    def fbeta_score(self, tp: int, fp: int, fn: int, beta: float) -&gt; float:\n        \"\"\"\n        Calculate the F-beta score.\n\n        Args:\n            tp (int): True positives.\n            fp (int): False positives.\n            fn (int): False negatives.\n            beta (float): Beta value.\n\n        Returns:\n            float: F-beta score.\n        \"\"\"\n        precision = tp / (tp + fp + 1e-8) if (tp + fp) &gt; 0 else 0.0\n        recall = tp / (tp + fn + 1e-8) if (tp + fn) &gt; 0 else 0.0\n        if (precision + recall) == 0:\n            return 0.0\n        score = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-8)\n        return score\n\n    def _build_reasoning(\n        self,\n        answer_claims: list[str],\n        context_claims: list[str],\n        answer_verdicts: list[int],\n        context_verdicts: list[int],\n        tp: int,\n        fp: int,\n        fn: int,\n        score: float,\n        mode: str,\n        beta: float,\n    ) -&gt; str:\n        \"\"\"\n        Build a detailed reasoning string for factual correctness evaluation.\n\n        Explains:\n        \u2022 How the answer and context were decomposed into claims.\n        \u2022 How claim verification produced verdicts (TP, FP, FN) with emojis.\n        \u2022 The calculation of the final score depending on the mode.\n\n        Args:\n            answer_claims (list[str]): Claims from the answer.\n            context_claims (list[str]): Claims from the context.\n            answer_verdicts (list[int]): Verdicts from verifying context claims against answer.\n            context_verdicts (list[int]): Verdicts from verifying answer claims against context.\n            tp (int): True positive count.\n            fp (int): False positive count.\n            fn (int): False negative count.\n            score (float): Computed score.\n            mode (str): Evaluation mode.\n            beta (float): Beta value.\n\n        Returns:\n            str: Detailed reasoning.\n        \"\"\"\n        lines = []\n        lines.extend([\"Reasoning:\", \"\", \"1. Claim Decomposition:\", \"   Answer was decomposed into claims:\"])\n        for claim in answer_claims:\n            lines.append(f\"     - {claim}\")\n        lines.extend([\"   Context was decomposed into claims:\"])\n        for claim in context_claims:\n            lines.append(f\"     - {claim}\")\n        lines.extend([\"\", \"2. Claim Verification:\"])\n        # Map verdicts to emojis: 1 -&gt; \u2705, 0 -&gt; \u274c\n        mapped_context = [(\"\u2705\" if v == 1 else \"\u274c\") for v in context_verdicts]\n        lines.extend(\n            [\n                \"   Verification of answer claims against context yields:\",\n                f\"     Verdicts: {mapped_context}   (\u2705 = supported, \u274c = unsupported)\",\n                f\"     TP (supported): {tp}\",\n                f\"     FP (unsupported): {fp}\",\n            ]\n        )\n        if mode != \"precision\":\n            mapped_answer = [(\"\u2705\" if v == 1 else \"\u274c\") for v in answer_verdicts]\n            lines.extend(\n                [\n                    \"\",\n                    \"   Verification of context claims against answer yields:\",\n                    f\"     Verdicts: {mapped_answer}\",\n                    f\"     FN (not supported): {fn}\",\n                ]\n            )\n        lines.append(\"\")\n        if mode == \"precision\":\n            precision = tp / (tp + fp + 1e-8)\n            lines.extend([f\"Precision = TP/(TP+FP) = {precision:.2f}\"])\n        elif mode == \"recall\":\n            recall = tp / (tp + fn + 1e-8)\n            lines.extend([f\"Recall = TP/(TP+FN) = {recall:.2f}\"])\n        else:\n            precision = tp / (tp + fp + 1e-8)\n            recall = tp / (tp + fn + 1e-8) if (tp + fn) &gt; 0 else 0.0\n            lines.extend(\n                [\n                    f\"Precision = TP/(TP+FP) = {precision:.2f}\",\n                    f\"Recall = TP/(TP+FN) = {recall:.2f}\",\n                    f\"F-beta Score (beta={beta:.2f}) = {score:.2f}\",\n                ]\n            )\n        lines.extend([\"\", f\"Final Score = {score:.2f}\"])\n        return \"\\n\".join(lines)\n\n    def run_single(\n        self, answer: str, context: str, mode: str | None = None, beta: float | None = None, verbose: bool = False\n    ) -&gt; FactualCorrectnessRunResult:\n        \"\"\"\n        Evaluate the factual correctness for a single sample.\n\n        Args:\n            answer (str): The response text.\n            context (str): The reference text.\n            mode (str | None): Evaluation mode ('precision', 'recall', or 'f1').\n            beta (float | None): Beta value for F-beta score.\n            verbose (bool): Flag for verbose logging.\n\n        Returns:\n            FactualCorrectnessRunResult: The computed factual correctness score and detailed reasoning.\n        \"\"\"\n        evaluation_mode = mode or self.mode\n        beta_value = beta or self.beta\n\n        answer_claims_list = self.decompose_claims([answer])\n        if not answer_claims_list or answer_claims_list[0] is None:\n            if verbose:\n                logger.debug(f\"No claims decomposed for answer: {answer}. Using empty list.\")\n            answer_claims = []\n        else:\n            answer_claims = answer_claims_list[0]\n\n        context_claims_list = self.decompose_claims([context])\n        if not context_claims_list or context_claims_list[0] is None:\n            if verbose:\n                logger.debug(f\"No claims decomposed for context: {context}. Using empty list.\")\n            context_claims = []\n        else:\n            context_claims = context_claims_list[0]\n\n        # Verify answer claims against context (precision part).\n        context_verdicts_list = self.verify_claims(premises=[context], claims_list=[answer_claims])\n        if not context_verdicts_list or context_verdicts_list[0] is None:\n            if verbose:\n                logger.debug(f\"No verdicts returned when verifying answer claims against context for answer: {answer}\")\n            context_verdicts = []\n        else:\n            context_verdicts = context_verdicts_list[0]\n        tp = sum(context_verdicts)\n        fp = len(context_verdicts) - tp\n\n        # For recall or F1, verify context claims against answer.\n        if evaluation_mode not in (\"precision\", \"PRECISION\"):\n            answer_verdicts_list = self.verify_claims(premises=[answer], claims_list=[context_claims])\n            if not answer_verdicts_list or answer_verdicts_list[0] is None:\n                if verbose:\n                    logger.debug(\n                        f\"No verdicts returned when verifying context claims against answer for answer: {answer}\"\n                    )\n                answer_verdicts = []\n                fn = 0\n            else:\n                answer_verdicts = answer_verdicts_list[0]\n                fn = sum(1 - v for v in answer_verdicts)\n        else:\n            answer_verdicts = []\n            fn = 0\n\n        if evaluation_mode == \"precision\":\n            computed_score = tp / (tp + fp + 1e-8)\n        elif evaluation_mode == \"recall\":\n            computed_score = tp / (tp + fn + 1e-8)\n        else:\n            computed_score = self.fbeta_score(tp, fp, fn, beta_value)\n\n        reasoning_text = self._build_reasoning(\n            answer_claims=answer_claims,\n            context_claims=context_claims,\n            answer_verdicts=answer_verdicts,\n            context_verdicts=context_verdicts,\n            tp=tp,\n            fp=fp,\n            fn=fn,\n            score=computed_score,\n            mode=evaluation_mode,\n            beta=beta_value,\n        )\n\n        if verbose:\n            logger.debug(f\"Answer: {answer}\")\n            logger.debug(f\"Context: {context}\")\n            logger.debug(f\"Answer Claims: {answer_claims}\")\n            logger.debug(f\"Context Claims: {context_claims}\")\n            logger.debug(f\"TP: {tp}, FP: {fp}, FN: {fn}\")\n            logger.debug(f\"Score: {computed_score}\")\n            logger.debug(reasoning_text)\n            logger.debug(\"-\" * 50)\n\n        return FactualCorrectnessRunResult(score=round(computed_score, 2), reasoning=reasoning_text)\n\n    def run(\n        self,\n        answers: list[str],\n        contexts: list[str] | list[list[str]],\n        mode: str | None = None,\n        beta: float | None = None,\n        verbose: bool = False,\n    ) -&gt; RunOutput:\n        \"\"\"\n        Evaluate the factual correctness of answers against contexts.\n\n        Pipeline:\n        1) Decompose both answer and context into claims.\n        2) Verify answer claims against context to compute precision.\n        3) If mode is recall or F1, verify context claims against answer\n           to compute false negatives.\n        4) Compute the final score based on the selected mode.\n        5) Generate detailed reasoning regarding the claim decomposition,\n           verification, and final metric calculations with emojis.\n\n        Args:\n            answers (list[str]): List of response texts.\n            contexts (list[str] | list[list[str]]): List of context texts.\n            mode (str | None): Evaluation mode ('precision', 'recall', or 'f1').\n            beta (float | None): Beta value for F-beta score.\n            verbose (bool): Flag for verbose logging.\n\n        Returns:\n            RunOutput: Contains a list of FactualCorrectnessRunResult.\n        \"\"\"\n        run_input = RunInput(answers=answers, contexts=contexts, mode=mode, beta=beta, verbose=verbose)\n        evaluation_mode = run_input.mode or self.mode\n        beta_value = run_input.beta or self.beta\n\n        results_output = []\n        for index in range(len(run_input.answers)):\n            answer_sample = run_input.answers[index]\n            context_sample = run_input.contexts[index]\n            result_single = self.run_single(\n                answer=answer_sample,\n                context=context_sample,\n                mode=evaluation_mode,\n                beta=beta_value,\n                verbose=run_input.verbose,\n            )\n            results_output.append(result_single)\n        return RunOutput(results=results_output)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.FactualCorrectnessEvaluator.decompose_claims","title":"<code>decompose_claims(texts)</code>","text":"<p>Decompose each text into claims.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>list[str]</code> <p>List of texts to decompose.</p> required <p>Returns:</p> Type Description <code>list[list[str]]</code> <p>list[list[str]]: List of lists of claims.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>def decompose_claims(self, texts: list[str]) -&gt; list[list[str]]:\n    \"\"\"\n    Decompose each text into claims.\n\n    Args:\n        texts (list[str]): List of texts to decompose.\n\n    Returns:\n        list[list[str]]: List of lists of claims.\n    \"\"\"\n    input_data = DecomposeClaimsInput(texts=texts)\n    results = self._claim_decomposer.run(input_text=input_data.texts)\n    claims_list = []\n    for result in results[\"results\"]:\n        claims = result.get(\"claims\")\n        if isinstance(claims, list):\n            claims_list.append(claims)\n        else:\n            claims_list.append([claims])\n    output_data = DecomposeClaimsOutput(claims_list=claims_list)\n    return output_data.claims_list\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.FactualCorrectnessEvaluator.fbeta_score","title":"<code>fbeta_score(tp, fp, fn, beta)</code>","text":"<p>Calculate the F-beta score.</p> <p>Parameters:</p> Name Type Description Default <code>tp</code> <code>int</code> <p>True positives.</p> required <code>fp</code> <code>int</code> <p>False positives.</p> required <code>fn</code> <code>int</code> <p>False negatives.</p> required <code>beta</code> <code>float</code> <p>Beta value.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>F-beta score.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>def fbeta_score(self, tp: int, fp: int, fn: int, beta: float) -&gt; float:\n    \"\"\"\n    Calculate the F-beta score.\n\n    Args:\n        tp (int): True positives.\n        fp (int): False positives.\n        fn (int): False negatives.\n        beta (float): Beta value.\n\n    Returns:\n        float: F-beta score.\n    \"\"\"\n    precision = tp / (tp + fp + 1e-8) if (tp + fp) &gt; 0 else 0.0\n    recall = tp / (tp + fn + 1e-8) if (tp + fn) &gt; 0 else 0.0\n    if (precision + recall) == 0:\n        return 0.0\n    score = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-8)\n    return score\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.FactualCorrectnessEvaluator.run","title":"<code>run(answers, contexts, mode=None, beta=None, verbose=False)</code>","text":"<p>Evaluate the factual correctness of answers against contexts.</p> <p>Pipeline: 1) Decompose both answer and context into claims. 2) Verify answer claims against context to compute precision. 3) If mode is recall or F1, verify context claims against answer    to compute false negatives. 4) Compute the final score based on the selected mode. 5) Generate detailed reasoning regarding the claim decomposition,    verification, and final metric calculations with emojis.</p> <p>Parameters:</p> Name Type Description Default <code>answers</code> <code>list[str]</code> <p>List of response texts.</p> required <code>contexts</code> <code>list[str] | list[list[str]]</code> <p>List of context texts.</p> required <code>mode</code> <code>str | None</code> <p>Evaluation mode ('precision', 'recall', or 'f1').</p> <code>None</code> <code>beta</code> <code>float | None</code> <p>Beta value for F-beta score.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Flag for verbose logging.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>RunOutput</code> <code>RunOutput</code> <p>Contains a list of FactualCorrectnessRunResult.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>def run(\n    self,\n    answers: list[str],\n    contexts: list[str] | list[list[str]],\n    mode: str | None = None,\n    beta: float | None = None,\n    verbose: bool = False,\n) -&gt; RunOutput:\n    \"\"\"\n    Evaluate the factual correctness of answers against contexts.\n\n    Pipeline:\n    1) Decompose both answer and context into claims.\n    2) Verify answer claims against context to compute precision.\n    3) If mode is recall or F1, verify context claims against answer\n       to compute false negatives.\n    4) Compute the final score based on the selected mode.\n    5) Generate detailed reasoning regarding the claim decomposition,\n       verification, and final metric calculations with emojis.\n\n    Args:\n        answers (list[str]): List of response texts.\n        contexts (list[str] | list[list[str]]): List of context texts.\n        mode (str | None): Evaluation mode ('precision', 'recall', or 'f1').\n        beta (float | None): Beta value for F-beta score.\n        verbose (bool): Flag for verbose logging.\n\n    Returns:\n        RunOutput: Contains a list of FactualCorrectnessRunResult.\n    \"\"\"\n    run_input = RunInput(answers=answers, contexts=contexts, mode=mode, beta=beta, verbose=verbose)\n    evaluation_mode = run_input.mode or self.mode\n    beta_value = run_input.beta or self.beta\n\n    results_output = []\n    for index in range(len(run_input.answers)):\n        answer_sample = run_input.answers[index]\n        context_sample = run_input.contexts[index]\n        result_single = self.run_single(\n            answer=answer_sample,\n            context=context_sample,\n            mode=evaluation_mode,\n            beta=beta_value,\n            verbose=run_input.verbose,\n        )\n        results_output.append(result_single)\n    return RunOutput(results=results_output)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.FactualCorrectnessEvaluator.run_single","title":"<code>run_single(answer, context, mode=None, beta=None, verbose=False)</code>","text":"<p>Evaluate the factual correctness for a single sample.</p> <p>Parameters:</p> Name Type Description Default <code>answer</code> <code>str</code> <p>The response text.</p> required <code>context</code> <code>str</code> <p>The reference text.</p> required <code>mode</code> <code>str | None</code> <p>Evaluation mode ('precision', 'recall', or 'f1').</p> <code>None</code> <code>beta</code> <code>float | None</code> <p>Beta value for F-beta score.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Flag for verbose logging.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>FactualCorrectnessRunResult</code> <code>FactualCorrectnessRunResult</code> <p>The computed factual correctness score and detailed reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>def run_single(\n    self, answer: str, context: str, mode: str | None = None, beta: float | None = None, verbose: bool = False\n) -&gt; FactualCorrectnessRunResult:\n    \"\"\"\n    Evaluate the factual correctness for a single sample.\n\n    Args:\n        answer (str): The response text.\n        context (str): The reference text.\n        mode (str | None): Evaluation mode ('precision', 'recall', or 'f1').\n        beta (float | None): Beta value for F-beta score.\n        verbose (bool): Flag for verbose logging.\n\n    Returns:\n        FactualCorrectnessRunResult: The computed factual correctness score and detailed reasoning.\n    \"\"\"\n    evaluation_mode = mode or self.mode\n    beta_value = beta or self.beta\n\n    answer_claims_list = self.decompose_claims([answer])\n    if not answer_claims_list or answer_claims_list[0] is None:\n        if verbose:\n            logger.debug(f\"No claims decomposed for answer: {answer}. Using empty list.\")\n        answer_claims = []\n    else:\n        answer_claims = answer_claims_list[0]\n\n    context_claims_list = self.decompose_claims([context])\n    if not context_claims_list or context_claims_list[0] is None:\n        if verbose:\n            logger.debug(f\"No claims decomposed for context: {context}. Using empty list.\")\n        context_claims = []\n    else:\n        context_claims = context_claims_list[0]\n\n    # Verify answer claims against context (precision part).\n    context_verdicts_list = self.verify_claims(premises=[context], claims_list=[answer_claims])\n    if not context_verdicts_list or context_verdicts_list[0] is None:\n        if verbose:\n            logger.debug(f\"No verdicts returned when verifying answer claims against context for answer: {answer}\")\n        context_verdicts = []\n    else:\n        context_verdicts = context_verdicts_list[0]\n    tp = sum(context_verdicts)\n    fp = len(context_verdicts) - tp\n\n    # For recall or F1, verify context claims against answer.\n    if evaluation_mode not in (\"precision\", \"PRECISION\"):\n        answer_verdicts_list = self.verify_claims(premises=[answer], claims_list=[context_claims])\n        if not answer_verdicts_list or answer_verdicts_list[0] is None:\n            if verbose:\n                logger.debug(\n                    f\"No verdicts returned when verifying context claims against answer for answer: {answer}\"\n                )\n            answer_verdicts = []\n            fn = 0\n        else:\n            answer_verdicts = answer_verdicts_list[0]\n            fn = sum(1 - v for v in answer_verdicts)\n    else:\n        answer_verdicts = []\n        fn = 0\n\n    if evaluation_mode == \"precision\":\n        computed_score = tp / (tp + fp + 1e-8)\n    elif evaluation_mode == \"recall\":\n        computed_score = tp / (tp + fn + 1e-8)\n    else:\n        computed_score = self.fbeta_score(tp, fp, fn, beta_value)\n\n    reasoning_text = self._build_reasoning(\n        answer_claims=answer_claims,\n        context_claims=context_claims,\n        answer_verdicts=answer_verdicts,\n        context_verdicts=context_verdicts,\n        tp=tp,\n        fp=fp,\n        fn=fn,\n        score=computed_score,\n        mode=evaluation_mode,\n        beta=beta_value,\n    )\n\n    if verbose:\n        logger.debug(f\"Answer: {answer}\")\n        logger.debug(f\"Context: {context}\")\n        logger.debug(f\"Answer Claims: {answer_claims}\")\n        logger.debug(f\"Context Claims: {context_claims}\")\n        logger.debug(f\"TP: {tp}, FP: {fp}, FN: {fn}\")\n        logger.debug(f\"Score: {computed_score}\")\n        logger.debug(reasoning_text)\n        logger.debug(\"-\" * 50)\n\n    return FactualCorrectnessRunResult(score=round(computed_score, 2), reasoning=reasoning_text)\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.FactualCorrectnessEvaluator.verify_claims","title":"<code>verify_claims(premises, claims_list)</code>","text":"<p>Verify the claims against the premises.</p> <p>Parameters:</p> Name Type Description Default <code>premises</code> <code>list[str]</code> <p>List of premises.</p> required <code>claims_list</code> <code>list[list[str]]</code> <p>List of lists of claims.</p> required <p>Returns:</p> Type Description <code>list[list[int]]</code> <p>list[list[int]]: List of lists of verdicts.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>def verify_claims(self, premises: list[str], claims_list: list[list[str]]) -&gt; list[list[int]]:\n    \"\"\"\n    Verify the claims against the premises.\n\n    Args:\n        premises (list[str]): List of premises.\n        claims_list (list[list[str]]): List of lists of claims.\n\n    Returns:\n        list[list[int]]: List of lists of verdicts.\n    \"\"\"\n    input_data = VerifyClaimsInput(premises=premises, claims_list=claims_list)\n    results = self._nli_evaluator.run(\n        premise=input_data.premises,\n        claims=input_data.claims_list,\n    )\n    verdicts_list = []\n    for result in results[\"results\"]:\n        verdicts_raw = result[\"results\"]\n        verdicts = []\n        for item in verdicts_raw:\n            verdict = int(item[\"verdict\"])\n            verdicts.append(verdict)\n        verdicts_list.append(verdicts)\n    output_data = VerifyClaimsOutput(verdicts_list=verdicts_list)\n    return output_data.verdicts_list\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.FactualCorrectnessRunResult","title":"<code>FactualCorrectnessRunResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result model for factual correctness evaluation.</p> <p>Attributes:</p> Name Type Description <code>score</code> <code>float</code> <p>The computed factual correctness score.</p> <code>reasoning</code> <code>str</code> <p>Detailed reasoning explaining the evaluation.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>class FactualCorrectnessRunResult(BaseModel):\n    \"\"\"\n    Result model for factual correctness evaluation.\n\n    Attributes:\n        score (float): The computed factual correctness score.\n        reasoning (str): Detailed reasoning explaining the evaluation.\n    \"\"\"\n    score: float\n    reasoning: str\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.RunInput","title":"<code>RunInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for running factual correctness evaluation.</p> <p>Attributes:</p> Name Type Description <code>answers</code> <code>list[str]</code> <p>List of response texts.</p> <code>contexts</code> <code>list[str] | list[list[str]]</code> <p>List of reference texts, or list of lists of reference texts.</p> <code>mode</code> <code>str | None</code> <p>Evaluation mode ('precision', 'recall', or 'f1').</p> <code>beta</code> <code>float | None</code> <p>Beta value for F-beta score.</p> <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>class RunInput(BaseModel):\n    \"\"\"\n    Input model for running factual correctness evaluation.\n\n    Attributes:\n        answers (list[str]): List of response texts.\n        contexts (list[str] | list[list[str]]): List of reference texts, or list of lists of\n            reference texts.\n        mode (str | None): Evaluation mode ('precision', 'recall', or 'f1').\n        beta (float | None): Beta value for F-beta score.\n        verbose (bool): Flag to enable verbose logging.\n    \"\"\"\n    answers: list[str]\n    contexts: list[str] | list[list[str]]\n    mode: str | None = None\n    beta: float | None = None\n    verbose: bool = False\n\n    @field_validator(\"contexts\", mode=\"before\")\n    def unify_contexts(cls, value):\n        \"\"\"\n        Allow contexts to be either list[str] or list[list[str]]. If list[list[str]],\n        each sub-list is joined into one string. Otherwise, leave as-is.\n        \"\"\"\n        if not isinstance(value, list):\n            raise ValueError(\"contexts must be a list of strings or a list of lists of strings.\")\n        if all(isinstance(item, list) and all(isinstance(element, str) for element in item) for item in value):\n            return [\" \".join(sublist) for sublist in value]\n        if all(isinstance(item, str) for item in value):\n            return value\n        raise ValueError(\"contexts must be either a list of strings or a list of lists of strings.\")\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self):\n        \"\"\"\n        Confirm that answers and contexts have the same length.\n        \"\"\"\n        if len(self.answers) != len(self.contexts):\n            raise ValueError(\"answers and contexts must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.RunInput.check_equal_length","title":"<code>check_equal_length()</code>","text":"<p>Confirm that answers and contexts have the same length.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_equal_length(self):\n    \"\"\"\n    Confirm that answers and contexts have the same length.\n    \"\"\"\n    if len(self.answers) != len(self.contexts):\n        raise ValueError(\"answers and contexts must have the same length.\")\n    return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.RunInput.unify_contexts","title":"<code>unify_contexts(value)</code>","text":"<p>Allow contexts to be either list[str] or list[list[str]]. If list[list[str]], each sub-list is joined into one string. Otherwise, leave as-is.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>@field_validator(\"contexts\", mode=\"before\")\ndef unify_contexts(cls, value):\n    \"\"\"\n    Allow contexts to be either list[str] or list[list[str]]. If list[list[str]],\n    each sub-list is joined into one string. Otherwise, leave as-is.\n    \"\"\"\n    if not isinstance(value, list):\n        raise ValueError(\"contexts must be a list of strings or a list of lists of strings.\")\n    if all(isinstance(item, list) and all(isinstance(element, str) for element in item) for item in value):\n        return [\" \".join(sublist) for sublist in value]\n    if all(isinstance(item, str) for item in value):\n        return value\n    raise ValueError(\"contexts must be either a list of strings or a list of lists of strings.\")\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.RunOutput","title":"<code>RunOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for factual correctness evaluation.</p> <p>Attributes:</p> Name Type Description <code>results</code> <code>list[FactualCorrectnessRunResult]</code> <p>List of results with score and reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>class RunOutput(BaseModel):\n    \"\"\"\n    Output model for factual correctness evaluation.\n\n    Attributes:\n        results (list[FactualCorrectnessRunResult]): List of results with score and reasoning.\n    \"\"\"\n    results: list[FactualCorrectnessRunResult]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.VerifyClaimsInput","title":"<code>VerifyClaimsInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for verifying claims against premises.</p> <p>Attributes:</p> Name Type Description <code>premises</code> <code>list[str]</code> <p>List of premises.</p> <code>claims_list</code> <code>list[list[str]]</code> <p>List of lists of claims.</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>class VerifyClaimsInput(BaseModel):\n    \"\"\"\n    Input model for verifying claims against premises.\n\n    Attributes:\n        premises (list[str]): List of premises.\n        claims_list (list[list[str]]): List of lists of claims.\n    \"\"\"\n    premises: list[str]\n    claims_list: list[list[str]]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/factual_correctness/#dynamiq.evaluations.metrics.factual_correctness.VerifyClaimsOutput","title":"<code>VerifyClaimsOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for claim verification.</p> <p>Attributes:</p> Name Type Description <code>verdicts_list</code> <code>list[list[int]]</code> <p>List of lists of verdicts (0 or 1).</p> Source code in <code>dynamiq/evaluations/metrics/factual_correctness.py</code> <pre><code>class VerifyClaimsOutput(BaseModel):\n    \"\"\"\n    Output model for claim verification.\n\n    Attributes:\n        verdicts_list (list[list[int]]): List of lists of verdicts (0 or 1).\n    \"\"\"\n    verdicts_list: list[list[int]]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/","title":"Faithfulness","text":""},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.FaithfulnessEvaluator","title":"<code>FaithfulnessEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Evaluator class for faithfulness metric.</p> Pipeline <p>1) Statement Simplification: The answer is broken down into unambiguous statements    with no pronouns. 2) NLI Evaluation: Each statement is compared against the context. A verdict of 1 means    the statement is faithful; 0 means it is not. 3) Score Computation: The score is the ratio of faithful statements to total statements. 4) Detailed Reasoning: A user-friendly explanation is output with every step.</p> <p>Attributes:</p> Name Type Description <code>llm</code> <code>BaseLLM</code> <p>The language model used for evaluation.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class FaithfulnessEvaluator(BaseEvaluator):\n    \"\"\"\n    Evaluator class for faithfulness metric.\n\n    Pipeline:\n      1) Statement Simplification: The answer is broken down into unambiguous statements\n         with no pronouns.\n      2) NLI Evaluation: Each statement is compared against the context. A verdict of 1 means\n         the statement is faithful; 0 means it is not.\n      3) Score Computation: The score is the ratio of faithful statements to total statements.\n      4) Detailed Reasoning: A user-friendly explanation is output with every step.\n\n    Attributes:\n        llm (BaseLLM): The language model used for evaluation.\n    \"\"\"\n    name: str = \"Faithfulness\"\n    llm: BaseLLM\n\n    _statement_simplifier: LLMEvaluator = PrivateAttr()\n    _nli_evaluator: LLMEvaluator = PrivateAttr()\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._initialize_evaluators()\n\n    def _initialize_evaluators(self):\n        simplify_instructions = (\n            \"Given a 'Question' and an 'Answer', break down each sentence in the \"\n            \"Answer into one or more fully understandable statements.\\n\"\n            \"- Ensure no pronouns are used in each statement.\\n\"\n            \"- Output as a JSON object with key 'statements', where the value is a \"\n            \"list of statements.\\n\"\n            \"- Ensure your response is valid JSON, using double quotes for all strings.\"\n        )\n        self._statement_simplifier = LLMEvaluator(\n            instructions=simplify_instructions.strip(),\n            inputs=[{\"name\": \"question\", \"type\": list[str]}, {\"name\": \"answer\", \"type\": list[str]}],\n            outputs=[{\"name\": \"statements\", \"type\": list[str]}],\n            examples=[\n                {\n                    \"inputs\": {\n                        \"question\": [\"Who was Albert Einstein and what is he best known for?\"],\n                        \"answer\": [\n                            \"He was a German-born theoretical physicist, widely \"\n                            \"acknowledged to be one of the greatest and most influential \"\n                            \"physicists of all time. He was best known for developing \"\n                            \"the theory of relativity, he also made important contributions \"\n                            \"to the development of quantum mechanics.\"\n                        ],\n                    },\n                    \"outputs\": {\n                        \"statements\": [\n                            \"Albert Einstein was a German-born theoretical physicist.\",\n                            \"Albert Einstein is recognized as one of the greatest and most influential \"\n                            \"physicists of all time.\",\n                            \"Albert Einstein was best known for developing the theory of relativity.\",\n                            \"Albert Einstein also made important contributions to the development of \"\n                            \"quantum mechanics.\",\n                        ]\n                    },\n                },\n            ],\n            llm=self.llm,\n        )\n        nli_instructions = (\n            \"Your task is to judge the faithfulness of a series of statements based \"\n            \"on a given Context.\\n\"\n            \"- For each statement, return 'verdict': 1 if it can be directly inferred \"\n            \"from the Context, or 0 if not.\\n\"\n            \"- Provide a brief 'reason' for the verdict.\\n\"\n            \"- Output as a JSON object with key 'results', where the value is a list of \"\n            \"dictionaries with keys 'statement', 'verdict', and 'reason'.\\n\"\n            \"- Ensure your response is valid JSON, using double quotes for all strings.\"\n        )\n        self._nli_evaluator = LLMEvaluator(\n            instructions=nli_instructions.strip(),\n            inputs=[{\"name\": \"context\", \"type\": list[str]}, {\"name\": \"statements\", \"type\": list[list[str]]}],\n            outputs=[{\"name\": \"results\", \"type\": list[dict[str, Any]]}],\n            examples=[\n                {\n                    \"inputs\": {\n                        \"context\": [\n                            \"John is a student at XYZ University. He is pursuing a \"\n                            \"degree in Computer Science. He is enrolled in several courses \"\n                            \"this semester, including Data Structures, Algorithms, and \"\n                            \"Database Management. John is a diligent student and spends a \"\n                            \"significant amount of time studying and completing assignments. \"\n                            \"He often stays late in the library to work on his projects.\"\n                        ],\n                        \"statements\": [\n                            [\n                                \"John is majoring in Biology.\",\n                                \"John is taking a course on Artificial Intelligence.\",\n                                \"John is a dedicated student.\",\n                                \"John has a part-time job.\",\n                            ]\n                        ],\n                    },\n                    \"outputs\": {\n                        \"results\": [\n                            {\n                                \"statement\": \"John is majoring in Biology.\",\n                                \"reason\": \"The context states that John is pursuing a degree in \"\n                                \"Computer Science, not Biology.\",\n                                \"verdict\": 0,\n                            },\n                            {\n                                \"statement\": \"John is taking a course on Artificial Intelligence.\",\n                                \"reason\": \"The context lists his courses, and Artificial Intelligence \"\n                                \"is not mentioned.\",\n                                \"verdict\": 0,\n                            },\n                            {\n                                \"statement\": \"John is a dedicated student.\",\n                                \"reason\": \"The context mentions he spends significant time studying and \"\n                                \"stays late to work on projects.\",\n                                \"verdict\": 1,\n                            },\n                            {\n                                \"statement\": \"John has a part-time job.\",\n                                \"reason\": \"There is no information in the context about John having a \"\n                                \"part-time job.\",\n                                \"verdict\": 0,\n                            },\n                        ]\n                    },\n                },\n            ],\n            llm=self.llm,\n        )\n\n    def simplify_statements(self, questions: list[str], answers: list[str]) -&gt; list[list[str]]:\n        \"\"\"\n        Simplify the answers into clear, unambiguous statements.\n\n        Args:\n            questions (list[str]): List of questions.\n            answers (list[str]): List of corresponding answers.\n\n        Returns:\n            list[list[str]]: Simplified statements.\n        \"\"\"\n        input_data = SimplifyStatementsInput(questions=questions, answers=answers)\n        results = self._statement_simplifier.run(question=input_data.questions, answer=input_data.answers)\n        statements_list = []\n        for result in results[\"results\"]:\n            statements = result.get(\"statements\")\n            if isinstance(statements, list):\n                statements_list.append(statements)\n            else:\n                statements_list.append([statements])\n        output_data = SimplifyStatementsOutput(statements_list=statements_list)\n        return output_data.statements_list\n\n    def check_faithfulness(self, contexts: list[str], statements_list: list[list[str]]) -&gt; list[list[NLIResultItem]]:\n        \"\"\"\n        Check the faithfulness of statements against contexts.\n\n        Args:\n            contexts (list[str]): List of contexts.\n            statements_list (list[list[str]]): Simplified statements.\n\n        Returns:\n            list[list[NLIResultItem]]: NLI results.\n        \"\"\"\n        input_data = NLIInput(contexts=contexts, statements_list=statements_list)\n        results = self._nli_evaluator.run(context=input_data.contexts, statements=input_data.statements_list)\n        results_list = []\n        for result in results[\"results\"]:\n            items = []\n            for item in result[\"results\"]:\n                nli_item = NLIResultItem(\n                    statement=item[\"statement\"], verdict=int(item[\"verdict\"]), reason=item[\"reason\"]\n                )\n                items.append(nli_item)\n            results_list.append(items)\n        output_data = NLIOutput(results_list=results_list)\n        return output_data.results_list\n\n    def _build_reasoning(\n        self,\n        statements: list[str],\n        nli_results: list[NLIResultItem],\n        num_statements: int,\n        num_faithful: int,\n        score: float,\n    ) -&gt; str:\n        \"\"\"\n        Build detailed reasoning for the faithfulness evaluation.\n\n        This explanation covers:\n        \u2022 How the answer was simplified into candidate statements.\n        \u2022 The NLI verdict for each statement along with brief reasons.\n        \u2022 The calculation of the final faithfulness score.\n\n        Args:\n            statements (list[str]): Simplified candidate statements.\n            nli_results (list[NLIResultItem]): NLI results.\n            num_statements (int): Total number of statements.\n            num_faithful (int): Number of statements deemed faithful.\n            score (float): The computed faithfulness score.\n\n        Returns:\n            str: Detailed reasoning.\n        \"\"\"\n        lines = []\n        lines.extend(\n            [\n                \"Reasoning:\",\n                \"\",\n                \"Overview:\",\n                \"  The answer is first simplified into clear statements (without pronouns).\",\n                \"  Each statement is then evaluated for faithfulness against the context via NLI.\",\n                \"  A '\u2705' indicates the statement is faithful; '\u274c' indicates it is not.\",\n                \"\",\n                \"1. Simplified Statements:\",\n            ]\n        )\n\n        # Add each simplified statement\n        lines.extend([f\"   - {stmt}\" for stmt in statements])\n\n        lines.extend([\"\", \"2. NLI Evaluation Results:\"])\n\n        # Add each NLI result with its verdict and explanation\n        for res in nli_results:\n            mark = \"\u2705\" if res.verdict == 1 else \"\u274c\"\n            lines.extend([f\" {mark} - {res.statement}\", f\"     Explanation: {res.reason}\", \"\"])\n\n        lines.extend(\n            [\n                f\" -&gt; Faithful Statements = {num_faithful} out of {num_statements}\",\n                f\" -&gt; Faithfulness Score = {score:.2f} (faithful/total)\",\n                \"\",\n                f\"Final Score = {score:.2f}\",\n            ]\n        )\n\n        return \"\\n\".join(lines)\n\n    def run_single(self, question: str, answer: str, context: str, verbose: bool = False) -&gt; FaithfulnessRunResult:\n        \"\"\"\n        Evaluate the faithfulness for a single sample.\n\n        Args:\n            question (str): The question.\n            answer (str): The corresponding answer.\n            context (str): The evaluation context.\n            verbose (bool): Flag to enable verbose logging.\n\n        Returns:\n            FaithfulnessRunResult: The result with faithfulness score and detailed reasoning.\n        \"\"\"\n        # Validate the single input using a pydantic model\n        single_input = FaithfulnessRunSingleInput(question=question, answer=answer, context=context, verbose=verbose)\n\n        # Simplify the answer (using question and answer)\n        statements_list = self.simplify_statements([single_input.question], [single_input.answer])\n        if not statements_list or statements_list[0] is None:\n            if single_input.verbose:\n                logger.debug(f\"No simplified statements for answer: {single_input.answer}. Using empty list.\")\n            statements = []\n        else:\n            statements = statements_list[0]\n\n        # Evaluate faithfulness via NLI\n        nli_results_list = self.check_faithfulness([single_input.context], [statements])\n        if not nli_results_list or nli_results_list[0] is None:\n            if single_input.verbose:\n                logger.debug(\"No NLI results for context or statements. Using empty list for NLI evaluation.\")\n            nli_results = []\n        else:\n            nli_results = nli_results_list[0]\n\n        num_statements = len(nli_results)\n        num_faithful = sum(item.verdict for item in nli_results)\n        score = num_faithful / num_statements if num_statements else 0.0\n        score = round(float(score), 2)\n\n        reasoning = self._build_reasoning(\n            statements=statements,\n            nli_results=nli_results,\n            num_statements=num_statements,\n            num_faithful=num_faithful,\n            score=score,\n        )\n        if single_input.verbose:\n            logger.debug(f\"Question: {single_input.question}\")\n            logger.debug(f\"Answer: {single_input.answer}\")\n            logger.debug(f\"Context: {single_input.context}\")\n            logger.debug(\"Simplified Statements:\")\n            logger.debug(statements)\n            logger.debug(\"NLI Results:\")\n            logger.debug([item.model_dump() for item in nli_results])\n            logger.debug(reasoning)\n            logger.debug(\"-\" * 50)\n        result_item = FaithfulnessRunResult(score=score, reasoning=reasoning)\n        return result_item\n\n    def run(\n        self,\n        questions: list[str],\n        answers: list[str],\n        contexts: list[str] | list[list[str]],\n        verbose: bool = False,\n    ) -&gt; RunOutput:\n        \"\"\"\n        Evaluate the faithfulness of answers given contexts.\n\n        Pipeline:\n        1) Simplify the answer into clear candidate statements.\n        2) Evaluate each statement via NLI against the context.\n        3) Compute the faithfulness score as the ratio of faithful statements.\n        4) Generate detailed reasoning explaining the process and final score.\n\n        Args:\n            questions (list[str]): List of questions.\n            answers (list[str]): List of corresponding answers.\n            contexts (list[str] | list[list[str]]): List of context texts.\n            verbose (bool): Flag to enable verbose logging.\n\n        Returns:\n            RunOutput: Contains a list of FaithfulnessRunResult.\n        \"\"\"\n        input_data = RunInput(questions=questions, answers=answers, contexts=contexts, verbose=verbose)\n        results_out = []\n        for idx in range(len(input_data.questions)):\n            question = input_data.questions[idx]\n            answer = input_data.answers[idx]\n            context = input_data.contexts[idx]\n            result_item = self.run_single(question=question, answer=answer, context=context, verbose=input_data.verbose)\n            results_out.append(result_item)\n        output_data = RunOutput(results=results_out)\n        return output_data\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.FaithfulnessEvaluator.check_faithfulness","title":"<code>check_faithfulness(contexts, statements_list)</code>","text":"<p>Check the faithfulness of statements against contexts.</p> <p>Parameters:</p> Name Type Description Default <code>contexts</code> <code>list[str]</code> <p>List of contexts.</p> required <code>statements_list</code> <code>list[list[str]]</code> <p>Simplified statements.</p> required <p>Returns:</p> Type Description <code>list[list[NLIResultItem]]</code> <p>list[list[NLIResultItem]]: NLI results.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>def check_faithfulness(self, contexts: list[str], statements_list: list[list[str]]) -&gt; list[list[NLIResultItem]]:\n    \"\"\"\n    Check the faithfulness of statements against contexts.\n\n    Args:\n        contexts (list[str]): List of contexts.\n        statements_list (list[list[str]]): Simplified statements.\n\n    Returns:\n        list[list[NLIResultItem]]: NLI results.\n    \"\"\"\n    input_data = NLIInput(contexts=contexts, statements_list=statements_list)\n    results = self._nli_evaluator.run(context=input_data.contexts, statements=input_data.statements_list)\n    results_list = []\n    for result in results[\"results\"]:\n        items = []\n        for item in result[\"results\"]:\n            nli_item = NLIResultItem(\n                statement=item[\"statement\"], verdict=int(item[\"verdict\"]), reason=item[\"reason\"]\n            )\n            items.append(nli_item)\n        results_list.append(items)\n    output_data = NLIOutput(results_list=results_list)\n    return output_data.results_list\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.FaithfulnessEvaluator.run","title":"<code>run(questions, answers, contexts, verbose=False)</code>","text":"<p>Evaluate the faithfulness of answers given contexts.</p> <p>Pipeline: 1) Simplify the answer into clear candidate statements. 2) Evaluate each statement via NLI against the context. 3) Compute the faithfulness score as the ratio of faithful statements. 4) Generate detailed reasoning explaining the process and final score.</p> <p>Parameters:</p> Name Type Description Default <code>questions</code> <code>list[str]</code> <p>List of questions.</p> required <code>answers</code> <code>list[str]</code> <p>List of corresponding answers.</p> required <code>contexts</code> <code>list[str] | list[list[str]]</code> <p>List of context texts.</p> required <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>RunOutput</code> <code>RunOutput</code> <p>Contains a list of FaithfulnessRunResult.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>def run(\n    self,\n    questions: list[str],\n    answers: list[str],\n    contexts: list[str] | list[list[str]],\n    verbose: bool = False,\n) -&gt; RunOutput:\n    \"\"\"\n    Evaluate the faithfulness of answers given contexts.\n\n    Pipeline:\n    1) Simplify the answer into clear candidate statements.\n    2) Evaluate each statement via NLI against the context.\n    3) Compute the faithfulness score as the ratio of faithful statements.\n    4) Generate detailed reasoning explaining the process and final score.\n\n    Args:\n        questions (list[str]): List of questions.\n        answers (list[str]): List of corresponding answers.\n        contexts (list[str] | list[list[str]]): List of context texts.\n        verbose (bool): Flag to enable verbose logging.\n\n    Returns:\n        RunOutput: Contains a list of FaithfulnessRunResult.\n    \"\"\"\n    input_data = RunInput(questions=questions, answers=answers, contexts=contexts, verbose=verbose)\n    results_out = []\n    for idx in range(len(input_data.questions)):\n        question = input_data.questions[idx]\n        answer = input_data.answers[idx]\n        context = input_data.contexts[idx]\n        result_item = self.run_single(question=question, answer=answer, context=context, verbose=input_data.verbose)\n        results_out.append(result_item)\n    output_data = RunOutput(results=results_out)\n    return output_data\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.FaithfulnessEvaluator.run_single","title":"<code>run_single(question, answer, context, verbose=False)</code>","text":"<p>Evaluate the faithfulness for a single sample.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question.</p> required <code>answer</code> <code>str</code> <p>The corresponding answer.</p> required <code>context</code> <code>str</code> <p>The evaluation context.</p> required <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>FaithfulnessRunResult</code> <code>FaithfulnessRunResult</code> <p>The result with faithfulness score and detailed reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>def run_single(self, question: str, answer: str, context: str, verbose: bool = False) -&gt; FaithfulnessRunResult:\n    \"\"\"\n    Evaluate the faithfulness for a single sample.\n\n    Args:\n        question (str): The question.\n        answer (str): The corresponding answer.\n        context (str): The evaluation context.\n        verbose (bool): Flag to enable verbose logging.\n\n    Returns:\n        FaithfulnessRunResult: The result with faithfulness score and detailed reasoning.\n    \"\"\"\n    # Validate the single input using a pydantic model\n    single_input = FaithfulnessRunSingleInput(question=question, answer=answer, context=context, verbose=verbose)\n\n    # Simplify the answer (using question and answer)\n    statements_list = self.simplify_statements([single_input.question], [single_input.answer])\n    if not statements_list or statements_list[0] is None:\n        if single_input.verbose:\n            logger.debug(f\"No simplified statements for answer: {single_input.answer}. Using empty list.\")\n        statements = []\n    else:\n        statements = statements_list[0]\n\n    # Evaluate faithfulness via NLI\n    nli_results_list = self.check_faithfulness([single_input.context], [statements])\n    if not nli_results_list or nli_results_list[0] is None:\n        if single_input.verbose:\n            logger.debug(\"No NLI results for context or statements. Using empty list for NLI evaluation.\")\n        nli_results = []\n    else:\n        nli_results = nli_results_list[0]\n\n    num_statements = len(nli_results)\n    num_faithful = sum(item.verdict for item in nli_results)\n    score = num_faithful / num_statements if num_statements else 0.0\n    score = round(float(score), 2)\n\n    reasoning = self._build_reasoning(\n        statements=statements,\n        nli_results=nli_results,\n        num_statements=num_statements,\n        num_faithful=num_faithful,\n        score=score,\n    )\n    if single_input.verbose:\n        logger.debug(f\"Question: {single_input.question}\")\n        logger.debug(f\"Answer: {single_input.answer}\")\n        logger.debug(f\"Context: {single_input.context}\")\n        logger.debug(\"Simplified Statements:\")\n        logger.debug(statements)\n        logger.debug(\"NLI Results:\")\n        logger.debug([item.model_dump() for item in nli_results])\n        logger.debug(reasoning)\n        logger.debug(\"-\" * 50)\n    result_item = FaithfulnessRunResult(score=score, reasoning=reasoning)\n    return result_item\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.FaithfulnessEvaluator.simplify_statements","title":"<code>simplify_statements(questions, answers)</code>","text":"<p>Simplify the answers into clear, unambiguous statements.</p> <p>Parameters:</p> Name Type Description Default <code>questions</code> <code>list[str]</code> <p>List of questions.</p> required <code>answers</code> <code>list[str]</code> <p>List of corresponding answers.</p> required <p>Returns:</p> Type Description <code>list[list[str]]</code> <p>list[list[str]]: Simplified statements.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>def simplify_statements(self, questions: list[str], answers: list[str]) -&gt; list[list[str]]:\n    \"\"\"\n    Simplify the answers into clear, unambiguous statements.\n\n    Args:\n        questions (list[str]): List of questions.\n        answers (list[str]): List of corresponding answers.\n\n    Returns:\n        list[list[str]]: Simplified statements.\n    \"\"\"\n    input_data = SimplifyStatementsInput(questions=questions, answers=answers)\n    results = self._statement_simplifier.run(question=input_data.questions, answer=input_data.answers)\n    statements_list = []\n    for result in results[\"results\"]:\n        statements = result.get(\"statements\")\n        if isinstance(statements, list):\n            statements_list.append(statements)\n        else:\n            statements_list.append([statements])\n    output_data = SimplifyStatementsOutput(statements_list=statements_list)\n    return output_data.statements_list\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.FaithfulnessRunResult","title":"<code>FaithfulnessRunResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result model for faithfulness evaluation.</p> <p>Attributes:</p> Name Type Description <code>score</code> <code>float</code> <p>The computed faithfulness score.</p> <code>reasoning</code> <code>str</code> <p>Detailed reasoning explaining the evaluation.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class FaithfulnessRunResult(BaseModel):\n    \"\"\"\n    Result model for faithfulness evaluation.\n\n    Attributes:\n        score (float): The computed faithfulness score.\n        reasoning (str): Detailed reasoning explaining the evaluation.\n    \"\"\"\n    score: float\n    reasoning: str\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.FaithfulnessRunSingleInput","title":"<code>FaithfulnessRunSingleInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single-run input model for faithfulness evaluation.</p> <p>Attributes:</p> Name Type Description <code>question</code> <code>str</code> <p>The question.</p> <code>answer</code> <code>str</code> <p>The corresponding answer.</p> <code>context</code> <code>str</code> <p>The context for the evaluation.</p> <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class FaithfulnessRunSingleInput(BaseModel):\n    \"\"\"\n    Single-run input model for faithfulness evaluation.\n\n    Attributes:\n        question (str): The question.\n        answer (str): The corresponding answer.\n        context (str): The context for the evaluation.\n        verbose (bool): Flag to enable verbose logging.\n    \"\"\"\n\n    question: str\n    answer: str\n    context: str\n    verbose: bool = False\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.NLIInput","title":"<code>NLIInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for NLI evaluation.</p> <p>Attributes:</p> Name Type Description <code>contexts</code> <code>list[str]</code> <p>List of contexts.</p> <code>statements_list</code> <code>list[list[str]]</code> <p>List of lists of statements.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class NLIInput(BaseModel):\n    \"\"\"\n    Input model for NLI evaluation.\n\n    Attributes:\n        contexts (list[str]): List of contexts.\n        statements_list (list[list[str]]): List of lists of statements.\n    \"\"\"\n    contexts: list[str]\n    statements_list: list[list[str]]\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self):\n        if len(self.contexts) != len(self.statements_list):\n            raise ValueError(\"Contexts and statements_list must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.NLIOutput","title":"<code>NLIOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for NLI evaluation.</p> <p>Attributes:</p> Name Type Description <code>results_list</code> <code>list[list[NLIResultItem]]</code> <p>List of lists of NLI results.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class NLIOutput(BaseModel):\n    \"\"\"\n    Output model for NLI evaluation.\n\n    Attributes:\n        results_list (list[list[NLIResultItem]]): List of lists of NLI results.\n    \"\"\"\n    results_list: list[list[NLIResultItem]]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.NLIResultItem","title":"<code>NLIResultItem</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model for individual NLI result.</p> <p>Attributes:</p> Name Type Description <code>statement</code> <code>str</code> <p>The statement being evaluated.</p> <code>verdict</code> <code>int</code> <p>1 if faithful, 0 otherwise.</p> <code>reason</code> <code>str</code> <p>Reason for the verdict.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class NLIResultItem(BaseModel):\n    \"\"\"\n    Model for individual NLI result.\n\n    Attributes:\n        statement (str): The statement being evaluated.\n        verdict (int): 1 if faithful, 0 otherwise.\n        reason (str): Reason for the verdict.\n    \"\"\"\n    statement: str\n    verdict: int\n    reason: str\n\n    @field_validator(\"verdict\")\n    @classmethod\n    def validate_verdict(cls, v):\n        if v not in (0, 1):\n            raise ValueError(\"Verdict must be either 0 or 1.\")\n        return v\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.RunInput","title":"<code>RunInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for running the faithfulness evaluation.</p> <p>Attributes:</p> Name Type Description <code>questions</code> <code>list[str]</code> <p>List of questions.</p> <code>answers</code> <code>list[str]</code> <p>List of corresponding answers.</p> <code>contexts</code> <code>list[str] | list[list[str]]</code> <p>List of context texts for each question, which can be either one string per question or multiple strings per question.</p> <code>verbose</code> <code>bool</code> <p>Flag to enable verbose logging.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class RunInput(BaseModel):\n    \"\"\"\n    Input model for running the faithfulness evaluation.\n\n    Attributes:\n        questions (list[str]): List of questions.\n        answers (list[str]): List of corresponding answers.\n        contexts (list[str] | list[list[str]]): List of context texts for each question,\n            which can be either one string per question or multiple strings per question.\n        verbose (bool): Flag to enable verbose logging.\n    \"\"\"\n    questions: list[str]\n    answers: list[str]\n    contexts: list[str] | list[list[str]]\n    verbose: bool = False\n\n    @field_validator(\"contexts\", mode=\"before\")\n    def unify_contexts(cls, value):\n        \"\"\"\n        If contexts is list[list[str]], join each sublist with a space.\n        Otherwise, if list[str], leave as-is.\n        \"\"\"\n        if not isinstance(value, list):\n            raise ValueError(\"contexts must be either a list of strings or a list of list of strings\")\n        if all(isinstance(item, list) and all(isinstance(x, str) for x in item) for item in value):\n            return [\" \".join(sublist) for sublist in value]\n        if all(isinstance(item, str) for item in value):\n            return value\n        raise ValueError(\"contexts must be either a list[str] or a list[list[str]]\")\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self):\n        if not (len(self.questions) == len(self.answers) == len(self.contexts)):\n            raise ValueError(\"Questions, answers, and contexts must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.RunInput.unify_contexts","title":"<code>unify_contexts(value)</code>","text":"<p>If contexts is list[list[str]], join each sublist with a space. Otherwise, if list[str], leave as-is.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>@field_validator(\"contexts\", mode=\"before\")\ndef unify_contexts(cls, value):\n    \"\"\"\n    If contexts is list[list[str]], join each sublist with a space.\n    Otherwise, if list[str], leave as-is.\n    \"\"\"\n    if not isinstance(value, list):\n        raise ValueError(\"contexts must be either a list of strings or a list of list of strings\")\n    if all(isinstance(item, list) and all(isinstance(x, str) for x in item) for item in value):\n        return [\" \".join(sublist) for sublist in value]\n    if all(isinstance(item, str) for item in value):\n        return value\n    raise ValueError(\"contexts must be either a list[str] or a list[list[str]]\")\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.RunOutput","title":"<code>RunOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for faithfulness evaluation.</p> <p>Attributes:</p> Name Type Description <code>results</code> <code>list[FaithfulnessRunResult]</code> <p>List of results with score and reasoning.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class RunOutput(BaseModel):\n    \"\"\"\n    Output model for faithfulness evaluation.\n\n    Attributes:\n        results (list[FaithfulnessRunResult]): List of results with score and reasoning.\n    \"\"\"\n\n    results: list[FaithfulnessRunResult]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.SimplifyStatementsInput","title":"<code>SimplifyStatementsInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for simplifying statements.</p> <p>Attributes:</p> Name Type Description <code>questions</code> <code>list[str]</code> <p>List of questions.</p> <code>answers</code> <code>list[str]</code> <p>List of corresponding answers.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class SimplifyStatementsInput(BaseModel):\n    \"\"\"\n    Input model for simplifying statements.\n\n    Attributes:\n        questions (list[str]): List of questions.\n        answers (list[str]): List of corresponding answers.\n    \"\"\"\n    questions: list[str]\n    answers: list[str]\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self):\n        if len(self.questions) != len(self.answers):\n            raise ValueError(\"Questions and answers must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/faithfulness/#dynamiq.evaluations.metrics.faithfulness.SimplifyStatementsOutput","title":"<code>SimplifyStatementsOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for simplified statements.</p> <p>Attributes:</p> Name Type Description <code>statements_list</code> <code>list[list[str]]</code> <p>List of lists of simplified statements.</p> Source code in <code>dynamiq/evaluations/metrics/faithfulness.py</code> <pre><code>class SimplifyStatementsOutput(BaseModel):\n    \"\"\"\n    Output model for simplified statements.\n\n    Attributes:\n        statements_list (list[list[str]]): List of lists of simplified statements.\n    \"\"\"\n    statements_list: list[list[str]]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/","title":"Rouge score","text":""},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.MeasureType","title":"<code>MeasureType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of measurement types for ROUGE scores.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>class MeasureType(str, Enum):\n    \"\"\"\n    Enumeration of measurement types for ROUGE scores.\n    \"\"\"\n    fmeasure = \"fmeasure\"\n    precision = \"precision\"\n    recall = \"recall\"\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RougeScoreEvaluator","title":"<code>RougeScoreEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Evaluates ROUGE scores using the rouge_score library.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the evaluator. Defaults to \"RougeScore\".</p> <code>rouge_type</code> <code>RougeType</code> <p>ROUGE variant to compute. Defaults to RougeType.rougeL.</p> <code>measure_type</code> <code>MeasureType</code> <p>The field of the metric to retrieve. Defaults to MeasureType.fmeasure.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>class RougeScoreEvaluator(BaseEvaluator):\n    \"\"\"\n    Evaluates ROUGE scores using the rouge_score library.\n\n    Attributes:\n        name (str): Name of the evaluator. Defaults to \"RougeScore\".\n        rouge_type (RougeType): ROUGE variant to compute. Defaults to RougeType.rougeL.\n        measure_type (MeasureType): The field of the metric to retrieve. Defaults to MeasureType.fmeasure.\n    \"\"\"\n    name: str = \"RougeScore\"\n    rouge_type: RougeType = RougeType.rougeL\n    measure_type: MeasureType = MeasureType.fmeasure\n\n    _scorer: Callable = PrivateAttr()\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._initialize_rouge()\n\n    def _initialize_rouge(self) -&gt; None:\n        from rouge_score import rouge_scorer\n\n        self._scorer = rouge_scorer.RougeScorer([self.rouge_type.value], use_stemmer=True)\n\n    def run_single(self, ground_truth_answer: str, answer: str) -&gt; float:\n        \"\"\"\n        Compute the ROUGE score for a single pair of ground truth (reference) and answer.\n\n        Args:\n            ground_truth_answer (str): The reference string.\n            answer (str): The candidate string.\n\n        Returns:\n            float: The computed ROUGE score.\n        \"\"\"\n        # Validate input.\n        single_input = RunSingleInput(ground_truth_answer=ground_truth_answer, answer=answer)\n        rouge_result = self._scorer.score(single_input.ground_truth_answer, single_input.answer)\n        metric_value = getattr(rouge_result[self.rouge_type.value], self.measure_type.value)\n        score = round(float(metric_value), 2)\n\n        output = RunSingleOutput(score=score)\n        return output.score\n\n    def run(self, ground_truth_answers: list[str], answers: list[str]) -&gt; list[float]:\n        \"\"\"\n        Compute ROUGE scores for each reference-response pair in batch.\n\n        Args:\n            ground_truth_answers (list[str]): List of reference strings.\n            answers (list[str]): List of candidate strings.\n\n        Returns:\n            list[float]: List of computed ROUGE scores.\n        \"\"\"\n        input_data = RunInput(ground_truth_answers=ground_truth_answers, answers=answers)\n        scores = []\n        for gt, ans in zip(input_data.ground_truth_answers, input_data.answers):\n            score = self.run_single(ground_truth_answer=gt, answer=ans)\n            scores.append(score)\n        output_data = RunOutput(scores=scores)\n        return output_data.scores\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RougeScoreEvaluator.run","title":"<code>run(ground_truth_answers, answers)</code>","text":"<p>Compute ROUGE scores for each reference-response pair in batch.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_answers</code> <code>list[str]</code> <p>List of reference strings.</p> required <code>answers</code> <code>list[str]</code> <p>List of candidate strings.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>list[float]: List of computed ROUGE scores.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>def run(self, ground_truth_answers: list[str], answers: list[str]) -&gt; list[float]:\n    \"\"\"\n    Compute ROUGE scores for each reference-response pair in batch.\n\n    Args:\n        ground_truth_answers (list[str]): List of reference strings.\n        answers (list[str]): List of candidate strings.\n\n    Returns:\n        list[float]: List of computed ROUGE scores.\n    \"\"\"\n    input_data = RunInput(ground_truth_answers=ground_truth_answers, answers=answers)\n    scores = []\n    for gt, ans in zip(input_data.ground_truth_answers, input_data.answers):\n        score = self.run_single(ground_truth_answer=gt, answer=ans)\n        scores.append(score)\n    output_data = RunOutput(scores=scores)\n    return output_data.scores\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RougeScoreEvaluator.run_single","title":"<code>run_single(ground_truth_answer, answer)</code>","text":"<p>Compute the ROUGE score for a single pair of ground truth (reference) and answer.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_answer</code> <code>str</code> <p>The reference string.</p> required <code>answer</code> <code>str</code> <p>The candidate string.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed ROUGE score.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>def run_single(self, ground_truth_answer: str, answer: str) -&gt; float:\n    \"\"\"\n    Compute the ROUGE score for a single pair of ground truth (reference) and answer.\n\n    Args:\n        ground_truth_answer (str): The reference string.\n        answer (str): The candidate string.\n\n    Returns:\n        float: The computed ROUGE score.\n    \"\"\"\n    # Validate input.\n    single_input = RunSingleInput(ground_truth_answer=ground_truth_answer, answer=answer)\n    rouge_result = self._scorer.score(single_input.ground_truth_answer, single_input.answer)\n    metric_value = getattr(rouge_result[self.rouge_type.value], self.measure_type.value)\n    score = round(float(metric_value), 2)\n\n    output = RunSingleOutput(score=score)\n    return output.score\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RougeType","title":"<code>RougeType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of supported ROUGE types.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>class RougeType(str, Enum):\n    \"\"\"\n    Enumeration of supported ROUGE types.\n    \"\"\"\n    rouge1 = \"rouge1\"\n    rouge2 = \"rouge2\"\n    rougeL = \"rougeL\"\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RunInput","title":"<code>RunInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for batch ROUGE score evaluation.</p> <p>Attributes:</p> Name Type Description <code>ground_truth_answers</code> <code>list[str]</code> <p>List of reference strings.</p> <code>answers</code> <code>list[str]</code> <p>List of candidate response strings.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>class RunInput(BaseModel):\n    \"\"\"\n    Input model for batch ROUGE score evaluation.\n\n    Attributes:\n        ground_truth_answers (list[str]): List of reference strings.\n        answers (list[str]): List of candidate response strings.\n    \"\"\"\n    ground_truth_answers: list[str]\n    answers: list[str]\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self) -&gt; \"RunInput\":\n        \"\"\"\n        Validate that the number of ground truth answers matches the number of answers.\n\n        Raises:\n            ValueError: If the lengths of `ground_truth_answers` and `answers` do not match.\n\n        Returns:\n            RunInput: The validated instance.\n        \"\"\"\n        if len(self.ground_truth_answers) != len(self.answers):\n            raise ValueError(\"ground_truth_answers and answers must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RunInput.check_equal_length","title":"<code>check_equal_length()</code>","text":"<p>Validate that the number of ground truth answers matches the number of answers.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the lengths of <code>ground_truth_answers</code> and <code>answers</code> do not match.</p> <p>Returns:</p> Name Type Description <code>RunInput</code> <code>RunInput</code> <p>The validated instance.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_equal_length(self) -&gt; \"RunInput\":\n    \"\"\"\n    Validate that the number of ground truth answers matches the number of answers.\n\n    Raises:\n        ValueError: If the lengths of `ground_truth_answers` and `answers` do not match.\n\n    Returns:\n        RunInput: The validated instance.\n    \"\"\"\n    if len(self.ground_truth_answers) != len(self.answers):\n        raise ValueError(\"ground_truth_answers and answers must have the same length.\")\n    return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RunOutput","title":"<code>RunOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for ROUGE score evaluation.</p> <p>Attributes:</p> Name Type Description <code>scores</code> <code>list[float]</code> <p>List of computed ROUGE scores.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>class RunOutput(BaseModel):\n    \"\"\"\n    Output model for ROUGE score evaluation.\n\n    Attributes:\n        scores (list[float]): List of computed ROUGE scores.\n    \"\"\"\n\n    scores: list[float]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RunSingleInput","title":"<code>RunSingleInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single-run input model for ROUGE score evaluation.</p> <p>Attributes:</p> Name Type Description <code>ground_truth_answer</code> <code>str</code> <p>The reference string.</p> <code>answer</code> <code>str</code> <p>The candidate string.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>class RunSingleInput(BaseModel):\n    \"\"\"\n    Single-run input model for ROUGE score evaluation.\n\n    Attributes:\n        ground_truth_answer (str): The reference string.\n        answer (str): The candidate string.\n    \"\"\"\n\n    ground_truth_answer: str\n    answer: str\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/rouge_score/#dynamiq.evaluations.metrics.rouge_score.RunSingleOutput","title":"<code>RunSingleOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single-run output model for ROUGE score evaluation.</p> <p>Attributes:</p> Name Type Description <code>score</code> <code>float</code> <p>The computed ROUGE score.</p> Source code in <code>dynamiq/evaluations/metrics/rouge_score.py</code> <pre><code>class RunSingleOutput(BaseModel):\n    \"\"\"\n    Single-run output model for ROUGE score evaluation.\n\n    Attributes:\n        score (float): The computed ROUGE score.\n    \"\"\"\n\n    score: float\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/string_metrics/","title":"String metrics","text":""},{"location":"dynamiq/evaluations/metrics/string_metrics/#dynamiq.evaluations.metrics.string_metrics.DistanceMeasure","title":"<code>DistanceMeasure</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of supported distance measures for string similarity.</p> Source code in <code>dynamiq/evaluations/metrics/string_metrics.py</code> <pre><code>class DistanceMeasure(str, Enum):\n    \"\"\"\n    Enumeration of supported distance measures for string similarity.\n    \"\"\"\n    LEVENSHTEIN = \"levenshtein\"\n    HAMMING = \"hamming\"\n    JARO = \"jaro\"\n    JARO_WINKLER = \"jaro_winkler\"\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/string_metrics/#dynamiq.evaluations.metrics.string_metrics.ExactMatchEvaluator","title":"<code>ExactMatchEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>An evaluator that checks for exact string matches.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the evaluator. Defaults to \"exact_match\".</p> Source code in <code>dynamiq/evaluations/metrics/string_metrics.py</code> <pre><code>class ExactMatchEvaluator(BaseEvaluator):\n    \"\"\"\n    An evaluator that checks for exact string matches.\n\n    Attributes:\n        name (str): Name of the evaluator. Defaults to \"exact_match\".\n    \"\"\"\n    name: str = \"exact_match\"\n\n    def run_single(self, ground_truth_answer: str, answer: str) -&gt; float:\n        input_data = RunSingleInput(ground_truth_answer=ground_truth_answer, answer=answer)\n        exact_match = float(input_data.ground_truth_answer == input_data.answer)\n        logger.debug(f\"Single pair: Exact Match = {exact_match}\")\n        return exact_match\n\n    def run(self, ground_truth_answers: list[str], answers: list[str]) -&gt; list[float]:\n        input_data = RunInput(ground_truth_answers=ground_truth_answers, answers=answers)\n        scores = []\n        for gt, ans in zip(input_data.ground_truth_answers, input_data.answers):\n            score = self.run_single(ground_truth_answer=gt, answer=ans)\n            scores.append(score)\n        output_data = RunOutput(scores=scores)\n        return output_data.scores\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/string_metrics/#dynamiq.evaluations.metrics.string_metrics.RunInput","title":"<code>RunInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input model for batch string evaluations.</p> <p>Attributes:</p> Name Type Description <code>ground_truth_answers</code> <code>list[str]</code> <p>List of reference strings, one per example.</p> <code>answers</code> <code>list[str]</code> <p>List of candidate response strings, one per example.</p> Source code in <code>dynamiq/evaluations/metrics/string_metrics.py</code> <pre><code>class RunInput(BaseModel):\n    \"\"\"\n    Input model for batch string evaluations.\n\n    Attributes:\n        ground_truth_answers (list[str]): List of reference strings, one per example.\n        answers (list[str]): List of candidate response strings, one per example.\n    \"\"\"\n    ground_truth_answers: list[str]\n    answers: list[str]\n\n    @model_validator(mode=\"after\")\n    def check_equal_length(self) -&gt; \"RunInput\":\n        if len(self.ground_truth_answers) != len(self.answers):\n            raise ValueError(\"ground_truth_answers and answers must have the same length.\")\n        return self\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/string_metrics/#dynamiq.evaluations.metrics.string_metrics.RunOutput","title":"<code>RunOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Output model for string evaluations.</p> <p>Attributes:</p> Name Type Description <code>scores</code> <code>list[float]</code> <p>List of evaluator scores, one per reference/answer pair.</p> Source code in <code>dynamiq/evaluations/metrics/string_metrics.py</code> <pre><code>class RunOutput(BaseModel):\n    \"\"\"\n    Output model for string evaluations.\n\n    Attributes:\n        scores (list[float]): List of evaluator scores, one per reference/answer pair.\n    \"\"\"\n\n    scores: list[float]\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/string_metrics/#dynamiq.evaluations.metrics.string_metrics.RunSingleInput","title":"<code>RunSingleInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single-run input model for string evaluations.</p> <p>Attributes:</p> Name Type Description <code>ground_truth_answer</code> <code>str</code> <p>The reference string.</p> <code>answer</code> <code>str</code> <p>The candidate string.</p> Source code in <code>dynamiq/evaluations/metrics/string_metrics.py</code> <pre><code>class RunSingleInput(BaseModel):\n    \"\"\"\n    Single-run input model for string evaluations.\n\n    Attributes:\n        ground_truth_answer (str): The reference string.\n        answer (str): The candidate string.\n    \"\"\"\n\n    ground_truth_answer: str\n    answer: str\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/string_metrics/#dynamiq.evaluations.metrics.string_metrics.RunSingleOutput","title":"<code>RunSingleOutput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single-run output model for string evaluations.</p> <p>Attributes:</p> Name Type Description <code>score</code> <code>float</code> <p>The computed evaluator score.</p> Source code in <code>dynamiq/evaluations/metrics/string_metrics.py</code> <pre><code>class RunSingleOutput(BaseModel):\n    \"\"\"\n    Single-run output model for string evaluations.\n\n    Attributes:\n        score (float): The computed evaluator score.\n    \"\"\"\n\n    score: float\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/string_metrics/#dynamiq.evaluations.metrics.string_metrics.StringPresenceEvaluator","title":"<code>StringPresenceEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>An evaluator that checks if the reference string is present (as a substring) in the answer.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the evaluator. Defaults to \"string_presence\".</p> Source code in <code>dynamiq/evaluations/metrics/string_metrics.py</code> <pre><code>class StringPresenceEvaluator(BaseEvaluator):\n    \"\"\"\n    An evaluator that checks if the reference string is present (as a substring) in the answer.\n\n    Attributes:\n        name (str): Name of the evaluator. Defaults to \"string_presence\".\n    \"\"\"\n    name: str = \"string_presence\"\n\n    def run_single(self, ground_truth_answer: str, answer: str) -&gt; float:\n        input_data = RunSingleInput(ground_truth_answer=ground_truth_answer, answer=answer)\n        presence = float(input_data.ground_truth_answer in input_data.answer)\n        output = RunSingleOutput(score=presence)\n        return output.score\n\n    def run(self, ground_truth_answers: list[str], answers: list[str]) -&gt; list[float]:\n        input_data = RunInput(ground_truth_answers=ground_truth_answers, answers=answers)\n        scores = []\n        for gt, ans in zip(input_data.ground_truth_answers, input_data.answers):\n            score = self.run_single(ground_truth_answer=gt, answer=ans)\n            scores.append(score)\n        output_data = RunOutput(scores=scores)\n        return output_data.scores\n</code></pre>"},{"location":"dynamiq/evaluations/metrics/string_metrics/#dynamiq.evaluations.metrics.string_metrics.StringSimilarityEvaluator","title":"<code>StringSimilarityEvaluator</code>","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>An evaluator that calculates a similarity score (1 - normalized_distance) using RapidFuzz between reference and answer strings.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the evaluator. Defaults to \"non_llm_string_similarity\".</p> <code>distance_measure</code> <code>DistanceMeasure</code> <p>Which distance measure to use. Defaults to DistanceMeasure.LEVENSHTEIN.</p> Source code in <code>dynamiq/evaluations/metrics/string_metrics.py</code> <pre><code>class StringSimilarityEvaluator(BaseEvaluator):\n    \"\"\"\n    An evaluator that calculates a similarity score (1 - normalized_distance) using RapidFuzz\n    between reference and answer strings.\n\n    Attributes:\n        name (str): Name of the evaluator. Defaults to \"non_llm_string_similarity\".\n        distance_measure (DistanceMeasure): Which distance measure to use. Defaults to DistanceMeasure.LEVENSHTEIN.\n    \"\"\"\n    name: str = \"non_llm_string_similarity\"\n    distance_measure: DistanceMeasure = DistanceMeasure.LEVENSHTEIN\n\n    _distance_map: dict[DistanceMeasure, Callable] = PrivateAttr()\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        self._initialize_distance_map()\n\n    def _initialize_distance_map(self) -&gt; None:\n        from rapidfuzz import distance as rapidfuzz_distance\n        self._distance_map = {\n            DistanceMeasure.LEVENSHTEIN: rapidfuzz_distance.Levenshtein,\n            DistanceMeasure.HAMMING: rapidfuzz_distance.Hamming,\n            DistanceMeasure.JARO: rapidfuzz_distance.Jaro,\n            DistanceMeasure.JARO_WINKLER: rapidfuzz_distance.JaroWinkler,\n        }\n        logger.debug(f\"Initialized distance map: {self._distance_map}\")\n\n    def run_single(self, ground_truth_answer: str, answer: str) -&gt; float:\n        input_data = RunSingleInput(ground_truth_answer=ground_truth_answer, answer=answer)\n        distance_function = self._distance_map[self.distance_measure]\n        normalized_dist = distance_function.normalized_distance(input_data.ground_truth_answer, input_data.answer)\n        similarity = 1 - float(normalized_dist)\n        similarity_rounded = round(similarity, 2)\n        logger.debug(\n            f\"Single pair: Distance Measure = {self.distance_measure}, \"\n            f\"Normalized Distance = {normalized_dist}, \"\n            f\"Similarity = {similarity_rounded}\"\n        )\n        output = RunSingleOutput(score=similarity_rounded)\n        return output.score\n\n    def run(self, ground_truth_answers: list[str], answers: list[str]) -&gt; list[float]:\n        input_data = RunInput(ground_truth_answers=ground_truth_answers, answers=answers)\n        scores = []\n        for gt, ans in zip(input_data.ground_truth_answers, input_data.answers):\n            score = self.run_single(ground_truth_answer=gt, answer=ans)\n            scores.append(score)\n        output_data = RunOutput(scores=scores)\n        return output_data.scores\n</code></pre>"},{"location":"dynamiq/executors/base/","title":"Base","text":""},{"location":"dynamiq/executors/base/#dynamiq.executors.base.BaseExecutor","title":"<code>BaseExecutor</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for executors that run nodes in a workflow.</p> <p>Attributes:</p> Name Type Description <code>max_workers</code> <code>int | None</code> <p>Maximum number of concurrent workers. None means no limit.</p> Source code in <code>dynamiq/executors/base.py</code> <pre><code>class BaseExecutor(ABC):\n    \"\"\"\n    Abstract base class for executors that run nodes in a workflow.\n\n    Attributes:\n        max_workers (int | None): Maximum number of concurrent workers. None means no limit.\n    \"\"\"\n\n    def __init__(self, max_workers: int | None = None):\n        \"\"\"\n        Initialize the BaseExecutor.\n\n        Args:\n            max_workers (int | None, optional): Maximum number of concurrent workers. Defaults to None.\n        \"\"\"\n        self.max_workers = max_workers\n\n    @abstractmethod\n    def shutdown(self, wait: bool = True):\n        \"\"\"\n        Shut down the executor.\n\n        Args:\n            wait (bool, optional): Whether to wait for pending tasks to complete. Defaults to True.\n\n        Raises:\n            NotImplementedError: This method must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def execute(\n        self,\n        ready_nodes: list[NodeReadyToRun],\n        config: RunnableConfig = None,\n        **kwargs,\n    ) -&gt; dict[str, RunnableResult]:\n        \"\"\"\n        Execute the given nodes that are ready to run.\n\n        Args:\n            ready_nodes (list[NodeReadyToRun]): List of nodes ready for execution.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, RunnableResult]: A dictionary mapping node IDs to their execution results.\n\n        Raises:\n            NotImplementedError: This method must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/executors/base/#dynamiq.executors.base.BaseExecutor.__init__","title":"<code>__init__(max_workers=None)</code>","text":"<p>Initialize the BaseExecutor.</p> <p>Parameters:</p> Name Type Description Default <code>max_workers</code> <code>int | None</code> <p>Maximum number of concurrent workers. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/executors/base.py</code> <pre><code>def __init__(self, max_workers: int | None = None):\n    \"\"\"\n    Initialize the BaseExecutor.\n\n    Args:\n        max_workers (int | None, optional): Maximum number of concurrent workers. Defaults to None.\n    \"\"\"\n    self.max_workers = max_workers\n</code></pre>"},{"location":"dynamiq/executors/base/#dynamiq.executors.base.BaseExecutor.execute","title":"<code>execute(ready_nodes, config=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Execute the given nodes that are ready to run.</p> <p>Parameters:</p> Name Type Description Default <code>ready_nodes</code> <code>list[NodeReadyToRun]</code> <p>List of nodes ready for execution.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, RunnableResult]</code> <p>dict[str, RunnableResult]: A dictionary mapping node IDs to their execution results.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented by subclasses.</p> Source code in <code>dynamiq/executors/base.py</code> <pre><code>@abstractmethod\ndef execute(\n    self,\n    ready_nodes: list[NodeReadyToRun],\n    config: RunnableConfig = None,\n    **kwargs,\n) -&gt; dict[str, RunnableResult]:\n    \"\"\"\n    Execute the given nodes that are ready to run.\n\n    Args:\n        ready_nodes (list[NodeReadyToRun]): List of nodes ready for execution.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, RunnableResult]: A dictionary mapping node IDs to their execution results.\n\n    Raises:\n        NotImplementedError: This method must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/executors/base/#dynamiq.executors.base.BaseExecutor.shutdown","title":"<code>shutdown(wait=True)</code>  <code>abstractmethod</code>","text":"<p>Shut down the executor.</p> <p>Parameters:</p> Name Type Description Default <code>wait</code> <code>bool</code> <p>Whether to wait for pending tasks to complete. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method must be implemented by subclasses.</p> Source code in <code>dynamiq/executors/base.py</code> <pre><code>@abstractmethod\ndef shutdown(self, wait: bool = True):\n    \"\"\"\n    Shut down the executor.\n\n    Args:\n        wait (bool, optional): Whether to wait for pending tasks to complete. Defaults to True.\n\n    Raises:\n        NotImplementedError: This method must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/executors/pool/","title":"Pool","text":""},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.PoolExecutor","title":"<code>PoolExecutor</code>","text":"<p>               Bases: <code>BaseExecutor</code></p> <p>A pool executor that manages concurrent execution of nodes using either ThreadPoolExecutor or ProcessPoolExecutor.</p> <p>Parameters:</p> Name Type Description Default <code>pool_executor</code> <code>type</code> <p>The type of pool executor to use (ThreadPoolExecutor or ProcessPoolExecutor).</p> required <code>max_workers</code> <code>int</code> <p>The maximum number of workers in the pool. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>class PoolExecutor(BaseExecutor):\n    \"\"\"\n    A pool executor that manages concurrent execution of nodes using either ThreadPoolExecutor or\n    ProcessPoolExecutor.\n\n    Args:\n        pool_executor (type): The type of pool executor to use (ThreadPoolExecutor or\n            ProcessPoolExecutor).\n        max_workers (int, optional): The maximum number of workers in the pool. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        pool_executor: (\n            type[futures.ThreadPoolExecutor] | type[futures.ProcessPoolExecutor]\n        ),\n        max_workers: int | None = None,\n    ):\n        super().__init__(max_workers=max_workers)\n        self.executor = pool_executor(max_workers=max_workers)\n        self.node_by_future = {}\n\n    def shutdown(self, wait: bool = True):\n        \"\"\"\n        Shuts down the executor.\n\n        Args:\n            wait (bool, optional): Whether to wait for pending futures to complete. Defaults to True.\n        \"\"\"\n        self.executor.shutdown(wait=wait)\n\n    def execute(\n        self,\n        ready_nodes: list[NodeReadyToRun],\n        config: RunnableConfig = None,\n        **kwargs,\n    ) -&gt; dict[str, RunnableResult]:\n        \"\"\"\n        Executes the given ready nodes and returns their results.\n\n        Args:\n            ready_nodes (list[NodeReadyToRun]): List of nodes ready to run.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, RunnableResult]: A dictionary of node IDs and their execution results.\n        \"\"\"\n        self.run_nodes(ready_nodes=ready_nodes, config=config, **kwargs)\n        if not self.node_by_future:\n            return {}\n\n        completed_node_futures, _ = futures.wait(\n            fs=self.node_by_future.keys(), return_when=futures.FIRST_COMPLETED\n        )\n        results = self.complete_nodes(completed_node_futures=completed_node_futures)\n\n        return results\n\n    def run_nodes(\n        self,\n        ready_nodes: list[NodeReadyToRun],\n        config: RunnableConfig = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Submits ready nodes for execution.\n\n        Args:\n            ready_nodes (list[NodeReadyToRun]): List of nodes ready to run.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        for ready_node in ready_nodes:\n            if ready_node.is_ready:\n                future = self.run_node(ready_node=ready_node, config=config, **kwargs)\n                self.node_by_future[future] = ready_node.node\n            else:\n                logger.error(\n                    f\"Node {ready_node.node.name} - {ready_node.node.id}: not ready to run.\"\n                )\n\n    def complete_nodes(\n        self, completed_node_futures: list[futures.Future]\n    ) -&gt; dict[str, RunnableResult]:\n        \"\"\"\n        Processes completed node futures and returns their results.\n\n        Args:\n            completed_node_futures (list[futures.Future]): List of completed node futures.\n\n        Returns:\n            dict[str, RunnableResult]: A dictionary of node IDs and their execution results.\n        \"\"\"\n        results = {}\n        for f in completed_node_futures:\n            node = self.node_by_future.pop(f)\n            try:\n                node_result: RunnableResult = f.result()\n            except Exception as e:\n                logger.error(f\"Node {node.name} - {node.id}: execution failed due the unexpected error. Error: {e}\")\n                node_result = RunnableResult(status=RunnableStatus.FAILURE, error=RunnableResultError.from_exception(e))\n\n            results[node.id] = node_result\n\n        return results\n\n    def run_node(self, ready_node: NodeReadyToRun, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Submits ready node for execution.\n\n        Args:\n            ready_node (NodeReadyToRun): node ready to run.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        return self.executor.submit(\n            ready_node.node.run,\n            input_data=ready_node.input_data,\n            config=config,\n            depends_result=ready_node.depends_result,\n            **kwargs,\n        )\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.PoolExecutor.complete_nodes","title":"<code>complete_nodes(completed_node_futures)</code>","text":"<p>Processes completed node futures and returns their results.</p> <p>Parameters:</p> Name Type Description Default <code>completed_node_futures</code> <code>list[Future]</code> <p>List of completed node futures.</p> required <p>Returns:</p> Type Description <code>dict[str, RunnableResult]</code> <p>dict[str, RunnableResult]: A dictionary of node IDs and their execution results.</p> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>def complete_nodes(\n    self, completed_node_futures: list[futures.Future]\n) -&gt; dict[str, RunnableResult]:\n    \"\"\"\n    Processes completed node futures and returns their results.\n\n    Args:\n        completed_node_futures (list[futures.Future]): List of completed node futures.\n\n    Returns:\n        dict[str, RunnableResult]: A dictionary of node IDs and their execution results.\n    \"\"\"\n    results = {}\n    for f in completed_node_futures:\n        node = self.node_by_future.pop(f)\n        try:\n            node_result: RunnableResult = f.result()\n        except Exception as e:\n            logger.error(f\"Node {node.name} - {node.id}: execution failed due the unexpected error. Error: {e}\")\n            node_result = RunnableResult(status=RunnableStatus.FAILURE, error=RunnableResultError.from_exception(e))\n\n        results[node.id] = node_result\n\n    return results\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.PoolExecutor.execute","title":"<code>execute(ready_nodes, config=None, **kwargs)</code>","text":"<p>Executes the given ready nodes and returns their results.</p> <p>Parameters:</p> Name Type Description Default <code>ready_nodes</code> <code>list[NodeReadyToRun]</code> <p>List of nodes ready to run.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, RunnableResult]</code> <p>dict[str, RunnableResult]: A dictionary of node IDs and their execution results.</p> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>def execute(\n    self,\n    ready_nodes: list[NodeReadyToRun],\n    config: RunnableConfig = None,\n    **kwargs,\n) -&gt; dict[str, RunnableResult]:\n    \"\"\"\n    Executes the given ready nodes and returns their results.\n\n    Args:\n        ready_nodes (list[NodeReadyToRun]): List of nodes ready to run.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, RunnableResult]: A dictionary of node IDs and their execution results.\n    \"\"\"\n    self.run_nodes(ready_nodes=ready_nodes, config=config, **kwargs)\n    if not self.node_by_future:\n        return {}\n\n    completed_node_futures, _ = futures.wait(\n        fs=self.node_by_future.keys(), return_when=futures.FIRST_COMPLETED\n    )\n    results = self.complete_nodes(completed_node_futures=completed_node_futures)\n\n    return results\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.PoolExecutor.run_node","title":"<code>run_node(ready_node, config=None, **kwargs)</code>","text":"<p>Submits ready node for execution.</p> <p>Parameters:</p> Name Type Description Default <code>ready_node</code> <code>NodeReadyToRun</code> <p>node ready to run.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>def run_node(self, ready_node: NodeReadyToRun, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Submits ready node for execution.\n\n    Args:\n        ready_node (NodeReadyToRun): node ready to run.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    return self.executor.submit(\n        ready_node.node.run,\n        input_data=ready_node.input_data,\n        config=config,\n        depends_result=ready_node.depends_result,\n        **kwargs,\n    )\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.PoolExecutor.run_nodes","title":"<code>run_nodes(ready_nodes, config=None, **kwargs)</code>","text":"<p>Submits ready nodes for execution.</p> <p>Parameters:</p> Name Type Description Default <code>ready_nodes</code> <code>list[NodeReadyToRun]</code> <p>List of nodes ready to run.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>def run_nodes(\n    self,\n    ready_nodes: list[NodeReadyToRun],\n    config: RunnableConfig = None,\n    **kwargs,\n):\n    \"\"\"\n    Submits ready nodes for execution.\n\n    Args:\n        ready_nodes (list[NodeReadyToRun]): List of nodes ready to run.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    for ready_node in ready_nodes:\n        if ready_node.is_ready:\n            future = self.run_node(ready_node=ready_node, config=config, **kwargs)\n            self.node_by_future[future] = ready_node.node\n        else:\n            logger.error(\n                f\"Node {ready_node.node.name} - {ready_node.node.id}: not ready to run.\"\n            )\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.PoolExecutor.shutdown","title":"<code>shutdown(wait=True)</code>","text":"<p>Shuts down the executor.</p> <p>Parameters:</p> Name Type Description Default <code>wait</code> <code>bool</code> <p>Whether to wait for pending futures to complete. Defaults to True.</p> <code>True</code> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>def shutdown(self, wait: bool = True):\n    \"\"\"\n    Shuts down the executor.\n\n    Args:\n        wait (bool, optional): Whether to wait for pending futures to complete. Defaults to True.\n    \"\"\"\n    self.executor.shutdown(wait=wait)\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.ProcessExecutor","title":"<code>ProcessExecutor</code>","text":"<p>               Bases: <code>PoolExecutor</code></p> <p>A process-based pool executor.</p> <p>Parameters:</p> Name Type Description Default <code>max_workers</code> <code>int</code> <p>The maximum number of worker processes. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>class ProcessExecutor(PoolExecutor):\n    \"\"\"\n    A process-based pool executor.\n\n    Args:\n        max_workers (int, optional): The maximum number of worker processes. Defaults to None.\n    \"\"\"\n\n    def __init__(self, max_workers: int | None = None):\n        max_workers = max_workers or MAX_WORKERS_PROCESS_POOL_EXECUTOR\n        super().__init__(\n            pool_executor=futures.ProcessPoolExecutor, max_workers=max_workers\n        )\n\n    @staticmethod\n    def serialize_node(node: Node) -&gt; str:\n        \"\"\"\n        Serializes node data.\n\n        Args:\n            node (Node): Node instance.\n\n        Returns:\n            str: Serialized node data\n        \"\"\"\n        return jsonpickle.encode(node)\n\n    @staticmethod\n    def deserialize_node(node_data: str) -&gt; Node:\n        \"\"\"\n        Deserializes node data.\n\n        Args:\n            node_data (str): Serialized node data.\n\n        Returns:\n            Node: Node instance.\n        \"\"\"\n        return jsonpickle.decode(node_data)  # nosec\n\n    @classmethod\n    def _run_node(cls, node_data: str, **kwargs) -&gt; RunnableResult:\n        \"\"\"\n        Deserializes node data and runs the node.\n\n        Args:\n            node_data (str): Serialized node data.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        node_instance = cls.deserialize_node(node_data)\n        return node_instance.run(**kwargs)\n\n    def run_node(self, ready_node: NodeReadyToRun, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Submits ready node for execution.\n\n        Args:\n            ready_node (NodeReadyToRun): node ready to run.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        return self.executor.submit(\n            self._run_node,\n            node_data=self.serialize_node(ready_node.node),\n            input_data=ready_node.input_data,\n            config=config,\n            depends_result=ready_node.depends_result,\n            **kwargs,\n        )\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.ProcessExecutor.deserialize_node","title":"<code>deserialize_node(node_data)</code>  <code>staticmethod</code>","text":"<p>Deserializes node data.</p> <p>Parameters:</p> Name Type Description Default <code>node_data</code> <code>str</code> <p>Serialized node data.</p> required <p>Returns:</p> Name Type Description <code>Node</code> <code>Node</code> <p>Node instance.</p> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>@staticmethod\ndef deserialize_node(node_data: str) -&gt; Node:\n    \"\"\"\n    Deserializes node data.\n\n    Args:\n        node_data (str): Serialized node data.\n\n    Returns:\n        Node: Node instance.\n    \"\"\"\n    return jsonpickle.decode(node_data)  # nosec\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.ProcessExecutor.run_node","title":"<code>run_node(ready_node, config=None, **kwargs)</code>","text":"<p>Submits ready node for execution.</p> <p>Parameters:</p> Name Type Description Default <code>ready_node</code> <code>NodeReadyToRun</code> <p>node ready to run.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>def run_node(self, ready_node: NodeReadyToRun, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Submits ready node for execution.\n\n    Args:\n        ready_node (NodeReadyToRun): node ready to run.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    return self.executor.submit(\n        self._run_node,\n        node_data=self.serialize_node(ready_node.node),\n        input_data=ready_node.input_data,\n        config=config,\n        depends_result=ready_node.depends_result,\n        **kwargs,\n    )\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.ProcessExecutor.serialize_node","title":"<code>serialize_node(node)</code>  <code>staticmethod</code>","text":"<p>Serializes node data.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>Node instance.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Serialized node data</p> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>@staticmethod\ndef serialize_node(node: Node) -&gt; str:\n    \"\"\"\n    Serializes node data.\n\n    Args:\n        node (Node): Node instance.\n\n    Returns:\n        str: Serialized node data\n    \"\"\"\n    return jsonpickle.encode(node)\n</code></pre>"},{"location":"dynamiq/executors/pool/#dynamiq.executors.pool.ThreadExecutor","title":"<code>ThreadExecutor</code>","text":"<p>               Bases: <code>PoolExecutor</code></p> <p>A thread-based pool executor.</p> <p>Parameters:</p> Name Type Description Default <code>max_workers</code> <code>int</code> <p>The maximum number of worker threads. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/executors/pool.py</code> <pre><code>class ThreadExecutor(PoolExecutor):\n    \"\"\"\n    A thread-based pool executor.\n\n    Args:\n        max_workers (int, optional): The maximum number of worker threads. Defaults to None.\n    \"\"\"\n\n    def __init__(self, max_workers: int | None = None):\n        max_workers = max_workers or MAX_WORKERS_THREAD_POOL_EXECUTOR\n        super().__init__(\n            pool_executor=futures.ThreadPoolExecutor, max_workers=max_workers\n        )\n</code></pre>"},{"location":"dynamiq/flows/base/","title":"Base","text":""},{"location":"dynamiq/flows/base/#dynamiq.flows.base.BaseFlow","title":"<code>BaseFlow</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Runnable</code>, <code>ABC</code></p> <p>Base class for flow implementations.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the flow, generated using UUID.</p> Source code in <code>dynamiq/flows/base.py</code> <pre><code>class BaseFlow(BaseModel, Runnable, ABC):\n    \"\"\"\n    Base class for flow implementations.\n\n    Attributes:\n        id (str): Unique identifier for the flow, generated using UUID.\n\n    \"\"\"\n\n    id: str = Field(default_factory=generate_uuid)\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the BaseFlow instance.\n\n        Args:\n            **kwargs: Additional keyword arguments to be passed to the parent constructor.\n        \"\"\"\n        super().__init__(**kwargs)\n        self._results = {}\n\n    def reset_run_state(self):\n        \"\"\"Reset the internal run state by clearing the results dictionary.\"\"\"\n        self._results = {}\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict:\n        return {}\n\n    def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params)\n        kwargs.pop(\"for_tracing\", False)\n        data = self.model_dump(\n            exclude=exclude,\n            serialize_as_any=kwargs.pop(\"serialize_as_any\", True),\n            **kwargs,\n        )\n\n        return data\n\n    def run_on_flow_start(\n        self, input_data: Any, config: RunnableConfig = None, **kwargs: Any\n    ):\n        \"\"\"\n        Execute callbacks when the flow starts.\n\n        Args:\n            input_data (Any): The input data for the flow.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments to be passed to the callbacks.\n        \"\"\"\n        if config and config.callbacks:\n            for callback in config.callbacks:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_flow_start(self.to_dict(**dict_kwargs), input_data, **kwargs)\n\n    def run_on_flow_end(\n        self, output_data: Any, config: RunnableConfig = None, **kwargs: Any\n    ):\n        \"\"\"\n        Execute callbacks when the flow ends.\n\n        Args:\n            output_data (Any): The output data from the flow.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments to be passed to the callbacks.\n        \"\"\"\n        if config and config.callbacks:\n            for callback in config.callbacks:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_flow_end(self.to_dict(**dict_kwargs), output_data, **kwargs)\n\n    def run_on_flow_error(\n        self, error: BaseException, config: RunnableConfig = None, **kwargs: Any\n    ):\n        \"\"\"\n        Execute callbacks when an error occurs in the flow.\n\n        Args:\n            error (BaseException): The error that occurred during the flow execution.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments to be passed to the callbacks.\n        \"\"\"\n        if config and config.callbacks:\n            for callback in config.callbacks:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_flow_error(self.to_dict(**dict_kwargs), error, **kwargs)\n</code></pre>"},{"location":"dynamiq/flows/base/#dynamiq.flows.base.BaseFlow.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the BaseFlow instance.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to be passed to the parent constructor.</p> <code>{}</code> Source code in <code>dynamiq/flows/base.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the BaseFlow instance.\n\n    Args:\n        **kwargs: Additional keyword arguments to be passed to the parent constructor.\n    \"\"\"\n    super().__init__(**kwargs)\n    self._results = {}\n</code></pre>"},{"location":"dynamiq/flows/base/#dynamiq.flows.base.BaseFlow.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Reset the internal run state by clearing the results dictionary.</p> Source code in <code>dynamiq/flows/base.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"Reset the internal run state by clearing the results dictionary.\"\"\"\n    self._results = {}\n</code></pre>"},{"location":"dynamiq/flows/base/#dynamiq.flows.base.BaseFlow.run_on_flow_end","title":"<code>run_on_flow_end(output_data, config=None, **kwargs)</code>","text":"<p>Execute callbacks when the flow ends.</p> <p>Parameters:</p> Name Type Description Default <code>output_data</code> <code>Any</code> <p>The output data from the flow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the callbacks.</p> <code>{}</code> Source code in <code>dynamiq/flows/base.py</code> <pre><code>def run_on_flow_end(\n    self, output_data: Any, config: RunnableConfig = None, **kwargs: Any\n):\n    \"\"\"\n    Execute callbacks when the flow ends.\n\n    Args:\n        output_data (Any): The output data from the flow.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments to be passed to the callbacks.\n    \"\"\"\n    if config and config.callbacks:\n        for callback in config.callbacks:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_flow_end(self.to_dict(**dict_kwargs), output_data, **kwargs)\n</code></pre>"},{"location":"dynamiq/flows/base/#dynamiq.flows.base.BaseFlow.run_on_flow_error","title":"<code>run_on_flow_error(error, config=None, **kwargs)</code>","text":"<p>Execute callbacks when an error occurs in the flow.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>BaseException</code> <p>The error that occurred during the flow execution.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the callbacks.</p> <code>{}</code> Source code in <code>dynamiq/flows/base.py</code> <pre><code>def run_on_flow_error(\n    self, error: BaseException, config: RunnableConfig = None, **kwargs: Any\n):\n    \"\"\"\n    Execute callbacks when an error occurs in the flow.\n\n    Args:\n        error (BaseException): The error that occurred during the flow execution.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments to be passed to the callbacks.\n    \"\"\"\n    if config and config.callbacks:\n        for callback in config.callbacks:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_flow_error(self.to_dict(**dict_kwargs), error, **kwargs)\n</code></pre>"},{"location":"dynamiq/flows/base/#dynamiq.flows.base.BaseFlow.run_on_flow_start","title":"<code>run_on_flow_start(input_data, config=None, **kwargs)</code>","text":"<p>Execute callbacks when the flow starts.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>The input data for the flow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to be passed to the callbacks.</p> <code>{}</code> Source code in <code>dynamiq/flows/base.py</code> <pre><code>def run_on_flow_start(\n    self, input_data: Any, config: RunnableConfig = None, **kwargs: Any\n):\n    \"\"\"\n    Execute callbacks when the flow starts.\n\n    Args:\n        input_data (Any): The input data for the flow.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments to be passed to the callbacks.\n    \"\"\"\n    if config and config.callbacks:\n        for callback in config.callbacks:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_flow_start(self.to_dict(**dict_kwargs), input_data, **kwargs)\n</code></pre>"},{"location":"dynamiq/flows/base/#dynamiq.flows.base.BaseFlow.to_dict","title":"<code>to_dict(include_secure_params=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/flows/base.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params)\n    kwargs.pop(\"for_tracing\", False)\n    data = self.model_dump(\n        exclude=exclude,\n        serialize_as_any=kwargs.pop(\"serialize_as_any\", True),\n        **kwargs,\n    )\n\n    return data\n</code></pre>"},{"location":"dynamiq/flows/flow/","title":"Flow","text":""},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow","title":"<code>Flow</code>","text":"<p>               Bases: <code>BaseFlow</code></p> <p>A class for managing and executing a graph-like structure of nodes.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>list[Node]</code> <p>List of nodes in the flow.</p> <code>executor</code> <code>type[BaseExecutor]</code> <p>Executor class for running nodes. Defaults to ThreadExecutor.</p> <code>max_node_workers</code> <code>int | None</code> <p>Maximum number of concurrent node workers. Defaults to None.</p> <code>connection_manager</code> <code>ConnectionManager</code> <p>Manager for handling connections. Defaults to ConnectionManager().</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>class Flow(BaseFlow):\n    \"\"\"\n    A class for managing and executing a graph-like structure of nodes.\n\n    Attributes:\n        nodes (list[Node]): List of nodes in the flow.\n        executor (type[BaseExecutor]): Executor class for running nodes. Defaults to ThreadExecutor.\n        max_node_workers (int | None): Maximum number of concurrent node workers. Defaults to None.\n        connection_manager (ConnectionManager): Manager for handling connections. Defaults to ConnectionManager().\n    \"\"\"\n\n    name: str = \"Flow\"\n    nodes: list[Node] = []\n    executor: type[BaseExecutor] = ThreadExecutor\n    max_node_workers: int | None = None\n    connection_manager: ConnectionManager = Field(default_factory=ConnectionManager)\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the Flow instance.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        super().__init__(**kwargs)\n        self._node_by_id = {node.id: node for node in self.nodes}\n        self._ts = None\n\n        self._init_components()\n        self.reset_run_state()\n\n    @computed_field\n    @cached_property\n    def type(self) -&gt; str:\n        return f\"{self.__module__.rsplit('.', 1)[0]}.{self.__class__.__name__}\"\n\n    @property\n    def to_dict_exclude_params(self):\n        return {\"nodes\": True, \"connection_manager\": True}\n\n    def to_dict(self, include_secure_params: bool = True, for_tracing=False, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(include_secure_params=include_secure_params, **kwargs)\n        data[\"nodes\"] = [\n            node.to_dict(include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs)\n            for node in self.nodes\n        ]\n        return data\n\n    @field_validator(\"nodes\")\n    @classmethod\n    def validate_nodes(cls, nodes: list[Node]) -&gt; list[Node]:\n        \"\"\"\n        Validates the list of nodes in the flow.\n\n        Args:\n            nodes (list[Node]): List of nodes to validate.\n\n        Returns:\n            list[Node]: Validated list of nodes.\n\n        Raises:\n            ValueError: If there are duplicate node IDs or invalid dependencies.\n        \"\"\"\n        nodes_ids_unique = set()\n        nodes_deps_ids_unique = set()\n        for node in nodes:\n            if node.id in nodes_ids_unique:\n                raise ValueError(\n                    f\"Flow has nodes with duplicated ids: '{node.id}'. Node ids must be unique.\"\n                )\n\n            nodes_ids_unique.add(node.id)\n            node_deps_ids = [dep.node.id for dep in node.depends]\n            if len(set(node_deps_ids)) != len(node_deps_ids):\n                raise ValueError(\n                    f\"Flow node '{node.id}' has duplicated dependency ids. Node dependencies ids must be unique.\"\n                )\n\n            nodes_deps_ids_unique.update(node_deps_ids)\n\n        if not nodes_deps_ids_unique.issubset(nodes_ids_unique):\n            raise ValueError(\n                \"Flow nodes have dependencies that are not present in the flow.\"\n            )\n\n        return nodes\n\n    def _init_components(self):\n        \"\"\"Initializes components for nodes with postponed initialization.\"\"\"\n        for node in self.nodes:\n            if node.is_postponed_component_init:\n                node.init_components(self.connection_manager)\n\n    def _get_nodes_ready_to_run(self, input_data: Any) -&gt; list[NodeReadyToRun]:\n        \"\"\"\n        Gets the list of nodes that are ready to run.\n\n        Args:\n            input_data (Any): Input data for the nodes.\n\n        Returns:\n            list[NodeReadyToRun]: List of nodes ready to run.\n        \"\"\"\n        ready_ts_nodes = self._ts.get_ready()\n        ready_nodes = []\n\n        completed_result = {\n            node_id: result for node_id, result in self._results.items() if result.status != RunnableStatus.UNDEFINED\n        }\n\n        for node_id in ready_ts_nodes:\n            node = self._node_by_id[node_id]\n            is_ready = True\n            for dep in node.depends:\n                if dep.node.id not in completed_result:\n                    is_ready = False\n                    break\n\n            ready_node = NodeReadyToRun(\n                node=node,\n                is_ready=is_ready,\n                input_data=input_data,\n                depends_result=completed_result,\n            )\n            ready_nodes.append(ready_node)\n\n        return ready_nodes\n\n    def _get_output(self) -&gt; dict[str, dict]:\n        \"\"\"\n        Gets the output of the flow.\n\n        Returns:\n            dict[str, dict]: Output of the flow.\n        \"\"\"\n        return {\n            node_id: result.to_dict(skip_format_types={BytesIO, bytes}) for node_id, result in self._results.items()\n        }\n\n    @staticmethod\n    def init_node_topological_sorter(nodes: list[Node]):\n        \"\"\"\n        Initializes a topological sorter for the given nodes.\n\n        Args:\n            nodes (list[Node]): List of nodes to sort.\n\n        Returns:\n            TopologicalSorter: Initialized topological sorter.\n\n        Raises:\n            CycleError: If a cycle is detected in node dependencies.\n        \"\"\"\n        topological_sorter = TopologicalSorter()\n        for node in nodes:\n            topological_sorter.add(node.id, *[d.node.id for d in node.depends])\n\n        try:\n            topological_sorter.prepare()\n        except CycleError as e:\n            logger.error(f\"Node dependencies cycle detected. Error: {e}\")\n            raise\n\n        return topological_sorter\n\n    def reset_run_state(self):\n        \"\"\"Resets the run state of the flow.\"\"\"\n        self._results = {\n            node.id: RunnableResult(status=RunnableStatus.UNDEFINED)\n            for node in self.nodes\n        }\n        self._ts = self.init_node_topological_sorter(nodes=self.nodes)\n\n    def _cleanup_dry_run(self, config: RunnableConfig = None):\n        \"\"\"\n        Clean up resources created during dry run.\n\n        Args:\n            config (RunnableConfig, optional): Configuration for the run.\n        \"\"\"\n        if not config or not getattr(config.dry_run, \"enabled\", False):\n            return\n\n        logger.info(\"Starting dry run cleanup...\")\n        for node in self.nodes:\n            try:\n                node.dry_run_cleanup(config.dry_run)\n                logger.debug(f\"Cleaned up dry run resources for node {node.id}\")\n            except Exception as e:\n                logger.error(f\"Failed to clean up dry run resources for node {node.id}: {str(e)}\")\n\n    async def _cleanup_dry_run_async(self, config: RunnableConfig = None):\n        \"\"\"Async variant of dry-run cleanup. Runs synchronous cleanup functions in a thread.\"\"\"\n        if not config or not getattr(config.dry_run, \"enabled\", False):\n            return\n\n        logger.info(\"Starting async dry run cleanup...\")\n        nodes_with_cleanup = [node for node in self.nodes if hasattr(node, \"dry_run_cleanup\")]\n        tasks = [asyncio.to_thread(getattr(node, \"dry_run_cleanup\"), config.dry_run) for node in nodes_with_cleanup]\n\n        if not tasks:\n            return\n\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        for node, res in zip(nodes_with_cleanup, results):\n            if isinstance(res, Exception):\n                logger.error(f\"Failed to clean up dry run resources for node {node.id}: {res}\")\n            else:\n                logger.debug(f\"Cleaned up dry run resources for node {node.id}\")\n\n    def run_sync(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n        \"\"\"\n        Run the flow synchronously with the given input data and configuration.\n\n        Args:\n            input_data (Any): Input data for the flow.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: Result of the flow execution.\n        \"\"\"\n        self.reset_run_state()\n        run_id = uuid4()\n        merged_kwargs = kwargs | {\n            \"run_id\": run_id,\n            \"parent_run_id\": kwargs.get(\"parent_run_id\", None),\n        }\n\n        logger.info(f\"Flow {self.id}: execution started.\")\n        self.run_on_flow_start(input_data, config, **merged_kwargs)\n        time_start = datetime.now()\n\n        try:\n            if self.nodes:\n                max_workers = (\n                    config.max_node_workers if config else self.max_node_workers\n                )\n                run_executor = self.executor(max_workers=max_workers)\n\n                while self._ts.is_active():\n                    ready_nodes = self._get_nodes_ready_to_run(input_data=input_data)\n                    results = run_executor.execute(\n                        ready_nodes=ready_nodes,\n                        config=config,\n                        **(merged_kwargs | {\"parent_run_id\": run_id}),\n                    )\n                    self._results.update(results)\n                    self._ts.done(*results.keys())\n\n                    # Wait for ready nodes to be processed and reduce CPU usage\n                    time.sleep(0.003)\n\n                run_executor.shutdown()\n\n            output = self._get_output()\n            self.run_on_flow_end(output, config, **merged_kwargs)\n            logger.info(\n                f\"Flow {self.id}: execution succeeded in {format_duration(time_start, datetime.now())}.\"\n            )\n            return RunnableResult(\n                status=RunnableStatus.SUCCESS, input=input_data, output=output\n            )\n        except Exception as e:\n            self.run_on_flow_error(e, config, **merged_kwargs)\n            logger.error(f\"Flow {self.id}: execution failed in \" f\"{format_duration(time_start, datetime.now())}.\")\n            return RunnableResult(\n                status=RunnableStatus.FAILURE,\n                input=input_data,\n                error=RunnableResultError.from_exception(e),\n            )\n        finally:\n            self._cleanup_dry_run(config)\n\n    async def run_async(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n        \"\"\"\n        Run the flow asynchronously with the given input data and configuration.\n\n        Args:\n            input_data (Any): Input data for the flow.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: Result of the flow execution.\n        \"\"\"\n        self.reset_run_state()\n        run_id = uuid4()\n        merged_kwargs = kwargs | {\n            \"run_id\": run_id,\n            \"parent_run_id\": kwargs.get(\"parent_run_id\", run_id),\n        }\n\n        logger.info(f\"Flow {self.id}: execution started.\")\n        self.run_on_flow_start(input_data, config, **merged_kwargs)\n        time_start = datetime.now()\n\n        try:\n            if self.nodes:\n                while self._ts.is_active():\n                    ready_nodes = self._get_nodes_ready_to_run(input_data=input_data)\n                    nodes_to_run = [node for node in ready_nodes if node.is_ready]\n\n                    if nodes_to_run:\n                        tasks = [\n                            node.node.run_async(\n                                input_data=node.input_data,\n                                depends_result=node.depends_result,\n                                config=config,\n                                **(merged_kwargs | {\"parent_run_id\": run_id}),\n                            )\n                            for node in nodes_to_run\n                        ]\n\n                        results_list = await asyncio.gather(*tasks)\n\n                        results = {node.node.id: result for node, result in zip(nodes_to_run, results_list)}\n\n                        self._results.update(results)\n                        self._ts.done(*results.keys())\n\n                    # Wait for ready nodes to be processed and reduce CPU usage by yielding control to the event loop\n                    await asyncio.sleep(0.003)\n\n            output = self._get_output()\n            self.run_on_flow_end(output, config, **merged_kwargs)\n            logger.info(f\"Flow {self.id}: execution succeeded in {format_duration(time_start, datetime.now())}.\")\n            return RunnableResult(status=RunnableStatus.SUCCESS, input=input_data, output=output)\n        except Exception as e:\n            self.run_on_flow_error(e, config, **merged_kwargs)\n            logger.error(f\"Flow {self.id}: execution failed in {format_duration(time_start, datetime.now())}.\")\n            return RunnableResult(\n                status=RunnableStatus.FAILURE,\n                input=input_data,\n                error=RunnableResultError.from_exception(e),\n            )\n        finally:\n            try:\n                await self._cleanup_dry_run_async(config)\n            except Exception as e:\n                logger.error(f\"Async dry-run cleanup failed: {e}\")\n\n    def get_dependant_nodes(\n        self, nodes_types_to_skip: set[str] | None = None\n    ) -&gt; list[Node]:\n        \"\"\"\n        Gets the list of dependent nodes in the flow.\n\n        Args:\n            nodes_types_to_skip (set[NodeType] | None, optional): Set of node types to skip. Defaults to None.\n\n        Returns:\n            list[Node]: List of dependent nodes.\n        \"\"\"\n        if not nodes_types_to_skip:\n            nodes_types_to_skip = set()\n\n        return [\n            dep.node\n            for node in self.nodes\n            if node.type not in nodes_types_to_skip\n            for dep in node.depends\n        ]\n\n    def get_non_dependant_nodes(\n        self, nodes_types_to_skip: set[str] | None = None\n    ) -&gt; list[Node]:\n        \"\"\"\n        Gets the list of non-dependent nodes in the flow.\n\n        Args:\n            nodes_types_to_skip (set[NodeType] | None, optional): Set of node types to skip. Defaults to None.\n\n        Returns:\n            list[Node]: List of non-dependent nodes.\n        \"\"\"\n        if not nodes_types_to_skip:\n            nodes_types_to_skip = set()\n\n        dependant_nodes = self.get_dependant_nodes(\n            nodes_types_to_skip=nodes_types_to_skip\n        )\n        return [\n            node\n            for node in self.nodes\n            if node.type not in nodes_types_to_skip and node not in dependant_nodes\n        ]\n\n    def add_nodes(self, nodes: Node | list[Node]):\n        \"\"\"\n        Add one or more nodes to the flow.\n\n        Args:\n            nodes (Node or list[Node]): Node(s) to add to the flow.\n\n        Raises:\n            TypeError: If 'nodes' is not a Node or a list of Node.\n            ValueError: If 'nodes' is an empty list, if a node with the same id already exists in the flow,\n                        or if there are duplicate node ids in the input list.\n        \"\"\"\n\n        if nodes is None:\n            raise ValueError(\"No node provided. Nodes cannot be None.\")\n\n        # Convert a single Node to a list for consistent handling\n        if isinstance(nodes, Node):\n            nodes = [nodes]\n\n        # Check if it's a valid list of nodes\n        if not isinstance(nodes, list) or not all(isinstance(n, Node) for n in nodes):\n            raise TypeError(\"Nodes must be a Node instance or a list of Node instances.\")\n\n        if not nodes:\n            raise ValueError(\"Cannot add an empty list of nodes to the flow.\")\n\n        # Add nodes to the flow, checking for duplicates in the flow\n        for node in nodes:\n            if node.id in self._node_by_id:\n                raise ValueError(f\"Node with id {node.id} already exists in the flow.\")\n\n            self.nodes.append(node)\n            self._node_by_id[node.id] = node\n            if node.is_postponed_component_init:\n                node.init_components(self.connection_manager)\n        self.reset_run_state()\n\n        return self  # enable chaining\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the Flow instance.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the Flow instance.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    super().__init__(**kwargs)\n    self._node_by_id = {node.id: node for node in self.nodes}\n    self._ts = None\n\n    self._init_components()\n    self.reset_run_state()\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.add_nodes","title":"<code>add_nodes(nodes)</code>","text":"<p>Add one or more nodes to the flow.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>Node or list[Node]</code> <p>Node(s) to add to the flow.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If 'nodes' is not a Node or a list of Node.</p> <code>ValueError</code> <p>If 'nodes' is an empty list, if a node with the same id already exists in the flow,         or if there are duplicate node ids in the input list.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>def add_nodes(self, nodes: Node | list[Node]):\n    \"\"\"\n    Add one or more nodes to the flow.\n\n    Args:\n        nodes (Node or list[Node]): Node(s) to add to the flow.\n\n    Raises:\n        TypeError: If 'nodes' is not a Node or a list of Node.\n        ValueError: If 'nodes' is an empty list, if a node with the same id already exists in the flow,\n                    or if there are duplicate node ids in the input list.\n    \"\"\"\n\n    if nodes is None:\n        raise ValueError(\"No node provided. Nodes cannot be None.\")\n\n    # Convert a single Node to a list for consistent handling\n    if isinstance(nodes, Node):\n        nodes = [nodes]\n\n    # Check if it's a valid list of nodes\n    if not isinstance(nodes, list) or not all(isinstance(n, Node) for n in nodes):\n        raise TypeError(\"Nodes must be a Node instance or a list of Node instances.\")\n\n    if not nodes:\n        raise ValueError(\"Cannot add an empty list of nodes to the flow.\")\n\n    # Add nodes to the flow, checking for duplicates in the flow\n    for node in nodes:\n        if node.id in self._node_by_id:\n            raise ValueError(f\"Node with id {node.id} already exists in the flow.\")\n\n        self.nodes.append(node)\n        self._node_by_id[node.id] = node\n        if node.is_postponed_component_init:\n            node.init_components(self.connection_manager)\n    self.reset_run_state()\n\n    return self  # enable chaining\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.get_dependant_nodes","title":"<code>get_dependant_nodes(nodes_types_to_skip=None)</code>","text":"<p>Gets the list of dependent nodes in the flow.</p> <p>Parameters:</p> Name Type Description Default <code>nodes_types_to_skip</code> <code>set[NodeType] | None</code> <p>Set of node types to skip. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Node]</code> <p>list[Node]: List of dependent nodes.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>def get_dependant_nodes(\n    self, nodes_types_to_skip: set[str] | None = None\n) -&gt; list[Node]:\n    \"\"\"\n    Gets the list of dependent nodes in the flow.\n\n    Args:\n        nodes_types_to_skip (set[NodeType] | None, optional): Set of node types to skip. Defaults to None.\n\n    Returns:\n        list[Node]: List of dependent nodes.\n    \"\"\"\n    if not nodes_types_to_skip:\n        nodes_types_to_skip = set()\n\n    return [\n        dep.node\n        for node in self.nodes\n        if node.type not in nodes_types_to_skip\n        for dep in node.depends\n    ]\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.get_non_dependant_nodes","title":"<code>get_non_dependant_nodes(nodes_types_to_skip=None)</code>","text":"<p>Gets the list of non-dependent nodes in the flow.</p> <p>Parameters:</p> Name Type Description Default <code>nodes_types_to_skip</code> <code>set[NodeType] | None</code> <p>Set of node types to skip. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Node]</code> <p>list[Node]: List of non-dependent nodes.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>def get_non_dependant_nodes(\n    self, nodes_types_to_skip: set[str] | None = None\n) -&gt; list[Node]:\n    \"\"\"\n    Gets the list of non-dependent nodes in the flow.\n\n    Args:\n        nodes_types_to_skip (set[NodeType] | None, optional): Set of node types to skip. Defaults to None.\n\n    Returns:\n        list[Node]: List of non-dependent nodes.\n    \"\"\"\n    if not nodes_types_to_skip:\n        nodes_types_to_skip = set()\n\n    dependant_nodes = self.get_dependant_nodes(\n        nodes_types_to_skip=nodes_types_to_skip\n    )\n    return [\n        node\n        for node in self.nodes\n        if node.type not in nodes_types_to_skip and node not in dependant_nodes\n    ]\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.init_node_topological_sorter","title":"<code>init_node_topological_sorter(nodes)</code>  <code>staticmethod</code>","text":"<p>Initializes a topological sorter for the given nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node]</code> <p>List of nodes to sort.</p> required <p>Returns:</p> Name Type Description <code>TopologicalSorter</code> <p>Initialized topological sorter.</p> <p>Raises:</p> Type Description <code>CycleError</code> <p>If a cycle is detected in node dependencies.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>@staticmethod\ndef init_node_topological_sorter(nodes: list[Node]):\n    \"\"\"\n    Initializes a topological sorter for the given nodes.\n\n    Args:\n        nodes (list[Node]): List of nodes to sort.\n\n    Returns:\n        TopologicalSorter: Initialized topological sorter.\n\n    Raises:\n        CycleError: If a cycle is detected in node dependencies.\n    \"\"\"\n    topological_sorter = TopologicalSorter()\n    for node in nodes:\n        topological_sorter.add(node.id, *[d.node.id for d in node.depends])\n\n    try:\n        topological_sorter.prepare()\n    except CycleError as e:\n        logger.error(f\"Node dependencies cycle detected. Error: {e}\")\n        raise\n\n    return topological_sorter\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Resets the run state of the flow.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"Resets the run state of the flow.\"\"\"\n    self._results = {\n        node.id: RunnableResult(status=RunnableStatus.UNDEFINED)\n        for node in self.nodes\n    }\n    self._ts = self.init_node_topological_sorter(nodes=self.nodes)\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.run_async","title":"<code>run_async(input_data, config=None, **kwargs)</code>  <code>async</code>","text":"<p>Run the flow asynchronously with the given input data and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the flow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>RunnableResult</code> <code>RunnableResult</code> <p>Result of the flow execution.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>async def run_async(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n    \"\"\"\n    Run the flow asynchronously with the given input data and configuration.\n\n    Args:\n        input_data (Any): Input data for the flow.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        RunnableResult: Result of the flow execution.\n    \"\"\"\n    self.reset_run_state()\n    run_id = uuid4()\n    merged_kwargs = kwargs | {\n        \"run_id\": run_id,\n        \"parent_run_id\": kwargs.get(\"parent_run_id\", run_id),\n    }\n\n    logger.info(f\"Flow {self.id}: execution started.\")\n    self.run_on_flow_start(input_data, config, **merged_kwargs)\n    time_start = datetime.now()\n\n    try:\n        if self.nodes:\n            while self._ts.is_active():\n                ready_nodes = self._get_nodes_ready_to_run(input_data=input_data)\n                nodes_to_run = [node for node in ready_nodes if node.is_ready]\n\n                if nodes_to_run:\n                    tasks = [\n                        node.node.run_async(\n                            input_data=node.input_data,\n                            depends_result=node.depends_result,\n                            config=config,\n                            **(merged_kwargs | {\"parent_run_id\": run_id}),\n                        )\n                        for node in nodes_to_run\n                    ]\n\n                    results_list = await asyncio.gather(*tasks)\n\n                    results = {node.node.id: result for node, result in zip(nodes_to_run, results_list)}\n\n                    self._results.update(results)\n                    self._ts.done(*results.keys())\n\n                # Wait for ready nodes to be processed and reduce CPU usage by yielding control to the event loop\n                await asyncio.sleep(0.003)\n\n        output = self._get_output()\n        self.run_on_flow_end(output, config, **merged_kwargs)\n        logger.info(f\"Flow {self.id}: execution succeeded in {format_duration(time_start, datetime.now())}.\")\n        return RunnableResult(status=RunnableStatus.SUCCESS, input=input_data, output=output)\n    except Exception as e:\n        self.run_on_flow_error(e, config, **merged_kwargs)\n        logger.error(f\"Flow {self.id}: execution failed in {format_duration(time_start, datetime.now())}.\")\n        return RunnableResult(\n            status=RunnableStatus.FAILURE,\n            input=input_data,\n            error=RunnableResultError.from_exception(e),\n        )\n    finally:\n        try:\n            await self._cleanup_dry_run_async(config)\n        except Exception as e:\n            logger.error(f\"Async dry-run cleanup failed: {e}\")\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.run_sync","title":"<code>run_sync(input_data, config=None, **kwargs)</code>","text":"<p>Run the flow synchronously with the given input data and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the flow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>RunnableResult</code> <code>RunnableResult</code> <p>Result of the flow execution.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>def run_sync(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n    \"\"\"\n    Run the flow synchronously with the given input data and configuration.\n\n    Args:\n        input_data (Any): Input data for the flow.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        RunnableResult: Result of the flow execution.\n    \"\"\"\n    self.reset_run_state()\n    run_id = uuid4()\n    merged_kwargs = kwargs | {\n        \"run_id\": run_id,\n        \"parent_run_id\": kwargs.get(\"parent_run_id\", None),\n    }\n\n    logger.info(f\"Flow {self.id}: execution started.\")\n    self.run_on_flow_start(input_data, config, **merged_kwargs)\n    time_start = datetime.now()\n\n    try:\n        if self.nodes:\n            max_workers = (\n                config.max_node_workers if config else self.max_node_workers\n            )\n            run_executor = self.executor(max_workers=max_workers)\n\n            while self._ts.is_active():\n                ready_nodes = self._get_nodes_ready_to_run(input_data=input_data)\n                results = run_executor.execute(\n                    ready_nodes=ready_nodes,\n                    config=config,\n                    **(merged_kwargs | {\"parent_run_id\": run_id}),\n                )\n                self._results.update(results)\n                self._ts.done(*results.keys())\n\n                # Wait for ready nodes to be processed and reduce CPU usage\n                time.sleep(0.003)\n\n            run_executor.shutdown()\n\n        output = self._get_output()\n        self.run_on_flow_end(output, config, **merged_kwargs)\n        logger.info(\n            f\"Flow {self.id}: execution succeeded in {format_duration(time_start, datetime.now())}.\"\n        )\n        return RunnableResult(\n            status=RunnableStatus.SUCCESS, input=input_data, output=output\n        )\n    except Exception as e:\n        self.run_on_flow_error(e, config, **merged_kwargs)\n        logger.error(f\"Flow {self.id}: execution failed in \" f\"{format_duration(time_start, datetime.now())}.\")\n        return RunnableResult(\n            status=RunnableStatus.FAILURE,\n            input=input_data,\n            error=RunnableResultError.from_exception(e),\n        )\n    finally:\n        self._cleanup_dry_run(config)\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.to_dict","title":"<code>to_dict(include_secure_params=True, for_tracing=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>def to_dict(self, include_secure_params: bool = True, for_tracing=False, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(include_secure_params=include_secure_params, **kwargs)\n    data[\"nodes\"] = [\n        node.to_dict(include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs)\n        for node in self.nodes\n    ]\n    return data\n</code></pre>"},{"location":"dynamiq/flows/flow/#dynamiq.flows.flow.Flow.validate_nodes","title":"<code>validate_nodes(nodes)</code>  <code>classmethod</code>","text":"<p>Validates the list of nodes in the flow.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node]</code> <p>List of nodes to validate.</p> required <p>Returns:</p> Type Description <code>list[Node]</code> <p>list[Node]: Validated list of nodes.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are duplicate node IDs or invalid dependencies.</p> Source code in <code>dynamiq/flows/flow.py</code> <pre><code>@field_validator(\"nodes\")\n@classmethod\ndef validate_nodes(cls, nodes: list[Node]) -&gt; list[Node]:\n    \"\"\"\n    Validates the list of nodes in the flow.\n\n    Args:\n        nodes (list[Node]): List of nodes to validate.\n\n    Returns:\n        list[Node]: Validated list of nodes.\n\n    Raises:\n        ValueError: If there are duplicate node IDs or invalid dependencies.\n    \"\"\"\n    nodes_ids_unique = set()\n    nodes_deps_ids_unique = set()\n    for node in nodes:\n        if node.id in nodes_ids_unique:\n            raise ValueError(\n                f\"Flow has nodes with duplicated ids: '{node.id}'. Node ids must be unique.\"\n            )\n\n        nodes_ids_unique.add(node.id)\n        node_deps_ids = [dep.node.id for dep in node.depends]\n        if len(set(node_deps_ids)) != len(node_deps_ids):\n            raise ValueError(\n                f\"Flow node '{node.id}' has duplicated dependency ids. Node dependencies ids must be unique.\"\n            )\n\n        nodes_deps_ids_unique.update(node_deps_ids)\n\n    if not nodes_deps_ids_unique.issubset(nodes_ids_unique):\n        raise ValueError(\n            \"Flow nodes have dependencies that are not present in the flow.\"\n        )\n\n    return nodes\n</code></pre>"},{"location":"dynamiq/memory/memory/","title":"Memory","text":""},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.FormatType","title":"<code>FormatType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for message format types.</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>class FormatType(str, Enum):\n    \"\"\"Enum for message format types.\"\"\"\n    PLAIN = \"plain\"\n    MARKDOWN = \"markdown\"\n    XML = \"xml\"\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory","title":"<code>Memory</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Manages the storage and retrieval of messages.</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>class Memory(BaseModel):\n    \"\"\"Manages the storage and retrieval of messages.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    DEFAULT_LIMIT: ClassVar[int] = 1000\n\n    message_limit: int = Field(default=DEFAULT_LIMIT, gt=0, description=\"Default limit for message retrieval\")\n    backend: MemoryBackend = Field(default_factory=InMemory, description=\"Backend storage implementation\")\n    filters: dict[str, Any] = Field(default_factory=dict, description=\"Default filters to apply to searches\")\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict[str, bool]:\n        \"\"\"Define parameters to exclude during serialization.\"\"\"\n        return {\"backend\": True}\n\n    def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        for_tracing = kwargs.pop(\"for_tracing\", False)\n        data = self.model_dump(exclude=kwargs.pop(\"exclude\", self.to_dict_exclude_params), **kwargs)\n        data[\"backend\"] = self.backend.to_dict(\n            include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs\n        )\n        return data\n\n    def add(self, role: MessageRole, content: str, metadata: dict[str, Any] | None = None) -&gt; None:\n        \"\"\"\n        Adds a message to the memory.\n\n        Args:\n            role: The role of the message sender\n            content: The message content\n            metadata: Additional metadata for the message\n\n        Raises:\n            MemoryError: If the message cannot be added\n        \"\"\"\n        try:\n            metadata = metadata or {}\n            if \"timestamp\" not in metadata:\n                metadata[\"timestamp\"] = datetime.now(timezone.utc).timestamp()\n\n            sanitized_metadata = {}\n            for key, value in metadata.items():\n                sanitized_metadata[key] = \"\" if value is None else value\n\n            message = Message(role=role, content=content, metadata=sanitized_metadata)\n            self.backend.add(message)\n\n            logger.debug(\n                f\"Memory {self.backend.name}: \"\n                f\"Added message: {message.role}: {message.content[:min(20, len(message.content))]}...\"\n            )\n        except Exception as e:\n            logger.error(f\"Unexpected error adding message: {e}\")\n            raise MemoryError(f\"Unexpected error adding message: {e}\") from e\n\n    def get_all(self, limit: int | None = None) -&gt; list[Message]:\n        \"\"\"\n        Retrieves all messages from the memory, optionally limited to most recent.\n\n        Args:\n            limit: Maximum number of messages to return. If provided, returns the most recent messages.\n                  If None, uses the configured message_limit.\n\n        Returns:\n            List of messages sorted by timestamp (oldest first)\n\n        Raises:\n            MemoryError: If messages cannot be retrieved\n        \"\"\"\n        try:\n            effective_limit = limit if limit is not None else self.message_limit\n\n            messages = self.backend.get_all(limit=effective_limit)\n            retrieved_messages = [Message(**msg.model_dump()) for msg in messages]\n            logger.debug(f\"Memory {self.backend.name}: Retrieved {len(retrieved_messages)} messages\")\n            return retrieved_messages\n        except Exception as e:\n            logger.error(f\"Unexpected error retrieving messages: {e}\")\n            raise MemoryError(f\"Unexpected error retrieving messages: {e}\") from e\n\n    def get_all_messages_as_string(self, format_type: FormatType = FormatType.PLAIN) -&gt; str:\n        \"\"\"\n        Retrieves all messages as a formatted string.\n\n        Args:\n            format_type: Format to use for the string output\n\n        Returns:\n            Formatted string representation of all messages\n\n        Raises:\n            MemoryError: If messages cannot be retrieved or formatted\n        \"\"\"\n        messages = self.get_all()\n        return self._format_messages_as_string(messages=messages, format_type=format_type)\n\n    def search(\n        self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n    ) -&gt; list[Message]:\n        \"\"\"\n        Searches for messages relevant to the query or filters.\n\n        Args:\n            query: Search query string (optional)\n            filters: Optional metadata filters to apply (overrides default filters)\n            limit: Maximum number of messages to return (defaults to message_limit)\n\n        Returns:\n            List of matching messages sorted by relevance\n\n        Raises:\n            MemoryError: If search operation fails\n        \"\"\"\n        try:\n            effective_filters = self.filters.copy()\n            if filters:\n                effective_filters.update(filters)\n\n            effective_limit = limit if limit is not None else self.message_limit\n\n            results = self.backend.search(query=query, filters=effective_filters, limit=effective_limit)\n\n            retrieved_messages = [Message(**msg.model_dump()) for msg in results]\n            logger.debug(\n                f\"Memory {self.backend.name}: Found {len(retrieved_messages)} search results for query: {query}, \"\n                f\"filters: {effective_filters}\"\n            )\n            return retrieved_messages\n        except Exception as e:\n            logger.error(f\"Unexpected error searching memory: {e}\")\n            raise MemoryError(f\"Unexpected error searching memory: {e}\") from e\n\n    def get_search_results_as_string(\n        self, query: str, filters: dict[str, Any] | None = None, format_type: FormatType = FormatType.PLAIN\n    ) -&gt; str:\n        \"\"\"\n        Searches for messages relevant to the query and returns them as a string.\n\n        Args:\n            query: Search query string\n            filters: Optional metadata filters to apply\n            format_type: Format to use for the string output\n\n        Returns:\n            Formatted string representation of search results\n\n        Raises:\n            MemoryError: If search operation fails or results cannot be formatted\n        \"\"\"\n        messages = self.search(query, filters)\n        return self._format_messages_as_string(messages=messages, format_type=format_type)\n\n    def _format_messages_as_string(self, messages: list[Message], format_type: FormatType = FormatType.PLAIN) -&gt; str:\n        \"\"\"\n        Converts a list of messages to a formatted string.\n\n        Args:\n            messages: List of messages to format\n            format_type: Format to use for the string output\n\n        Returns:\n            Formatted string representation of messages\n\n        Raises:\n            ValueError: If an unsupported format type is provided\n        \"\"\"\n        if format_type == FormatType.PLAIN:\n            return \"\\n\".join([f\"{msg.role.value}: {msg.content}\" for msg in messages])\n\n        elif format_type == FormatType.MARKDOWN:\n            return \"\\n\".join([f\"**{msg.role.value}:** {msg.content}\" for msg in messages])\n\n        elif format_type == FormatType.XML:\n            return \"\\n\".join(\n                [\n                    \"&lt;messages&gt;\",\n                    *[\n                        \"\\n\".join(\n                            [\n                                \"  &lt;message&gt;\",\n                                f\"    &lt;role&gt;{msg.role.value}&lt;/role&gt;\",\n                                f\"    &lt;content&gt;{msg.content}&lt;/content&gt;\",\n                                \"  &lt;/message&gt;\",\n                            ]\n                        )\n                        for msg in messages\n                    ],\n                    \"&lt;/messages&gt;\",\n                ]\n            )\n\n        raise ValueError(f\"Unsupported format: {format_type}\")\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"\n        Checks if the memory is empty.\n\n        Returns:\n            True if the memory is empty, False otherwise\n\n        Raises:\n            MemoryError: If the check fails\n        \"\"\"\n        try:\n            return self.backend.is_empty()\n        except Exception as e:\n            logger.error(f\"Unexpected error checking if memory is empty: {e}\")\n            raise MemoryError(f\"Unexpected error checking if memory is empty: {e}\") from e\n\n    def clear(self) -&gt; None:\n        \"\"\"\n        Clears the memory.\n\n        Raises:\n            MemoryError: If the memory cannot be cleared\n        \"\"\"\n        try:\n            self.backend.clear()\n            logger.debug(f\"Memory {self.backend.name}: Cleared memory\")\n        except Exception as e:\n            logger.error(f\"Unexpected error clearing memory: {e}\")\n            raise MemoryError(f\"Unexpected error clearing memory: {e}\") from e\n\n    def get_agent_conversation(\n        self,\n        query: str | None = None,\n        limit: int | None = None,\n        filters: dict[str, Any] | None = None,\n        strategy: MemoryRetrievalStrategy = MemoryRetrievalStrategy.ALL,\n    ) -&gt; list[Message]:\n        \"\"\"\n        Retrieves messages from an agent's conversation history based on various filtering criteria.\n\n        This method supports three retrieval strategies:\n        - ALL: Returns the most recent messages without semantic search\n        - RELEVANT: Returns only messages relevant to the query using semantic search\n        - BOTH: Returns a combination of recent messages and those relevant to the query\n\n        Parameters:\n        -----------\n        query : str | None, optional\n            The search query to filter messages by relevance. Required for RELEVANT and BOTH strategies.\n            Ignored when strategy is ALL. Default is None.\n\n        limit : int | None, optional\n            Maximum number of messages to return. If None, falls back to self.message_limit.\n\n        filters : dict[str, Any] | None, optional\n            Additional metadata filters to apply to the search results.\n\n        strategy : MemoryRetrievalStrategy, optional\n            The strategy to use for retrieving messages. Choices are:\n            - MemoryRetrievalStrategy.ALL: Return most recent messages\n            - MemoryRetrievalStrategy.RELEVANT: Return messages relevant to query\n            - MemoryRetrievalStrategy.BOTH: Return both recent and relevant messages\n            Default is MemoryRetrievalStrategy.ALL.\n\n        Returns:\n        --------\n        list[Message]\n            A list of conversation messages matching the search criteria, ordered chronologically.\n\n        Raises:\n        -------\n        MemoryError\n            If there is an error retrieving the conversation history.\n        \"\"\"\n        logger.debug(\"Retrieving agent conversation...\")\n        try:\n            effective_limit = limit if limit is not None else self.message_limit\n\n            search_limit = effective_limit * 3\n\n            if strategy == MemoryRetrievalStrategy.RELEVANT and query:\n                messages = self.search(query=query, filters=filters, limit=search_limit)\n            elif strategy == MemoryRetrievalStrategy.BOTH and query:\n                recent_messages = self.search(query=None, filters=filters, limit=max(search_limit, self.DEFAULT_LIMIT))\n\n                relevant_messages = self.search(query=query, filters=filters, limit=search_limit)\n\n                message_dict = {msg.metadata.get(\"timestamp\", 0): msg for msg in recent_messages}\n                for msg in relevant_messages:\n                    message_dict[msg.metadata.get(\"timestamp\", 0)] = msg\n\n                messages = [msg for _, msg in sorted(message_dict.items())]\n            else:\n                messages = self.search(query=None, filters=filters, limit=search_limit)\n\n            final_messages = self._extract_valid_conversation(messages, effective_limit)\n            return final_messages\n        except Exception as e:\n            logger.error(f\"Error retrieving agent conversation: {e}\")\n            raise MemoryError(f\"Failed to retrieve agent conversation: {e}\") from e\n\n    def _extract_valid_conversation(self, messages: list[Message], limit: int) -&gt; list[Message]:\n        \"\"\"\n        Extracts a valid conversation from a list of messages, ensuring it starts with a user message.\n\n        Ensures:\n        1. Messages are sorted chronologically (timestamp, with USER priority for ties).\n        2. The final list respects the message limit (most recent messages).\n        3. The returned list *always* starts with a USER message, unless empty.\n\n        Args:\n            messages: List of messages to process.\n            limit: Maximum number of messages to include in the result.\n\n        Returns:\n            List of messages forming a valid conversation, starting with USER, or an empty list.\n        \"\"\"\n        if not messages:\n            return []\n\n        def message_sort_key(msg):\n            timestamp = msg.metadata.get(\"timestamp\", float(\"inf\"))\n            role_priority = 0 if msg.role == MessageRole.USER else 0.1\n            return (timestamp, role_priority)\n\n        sorted_messages = sorted(messages, key=message_sort_key)\n\n        if limit and len(sorted_messages) &gt; limit:\n            limited_messages = sorted_messages[-limit:]\n        else:\n            limited_messages = sorted_messages\n\n        if not limited_messages:\n            return []\n\n        if limited_messages[0].role == MessageRole.USER:\n            return limited_messages\n        else:\n            first_user_idx = next((i for i, msg in enumerate(limited_messages) if msg.role == MessageRole.USER), None)\n\n            if first_user_idx is not None:\n                return limited_messages[first_user_idx:]\n            else:\n                logger.warning(\n                    f\"Memory._extract_valid_conversation: No USER message found within the \"\n                    f\"last {len(limited_messages)} messages. Returning empty history.\"\n                )\n                return []\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.to_dict_exclude_params","title":"<code>to_dict_exclude_params: dict[str, bool]</code>  <code>property</code>","text":"<p>Define parameters to exclude during serialization.</p>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.add","title":"<code>add(role, content, metadata=None)</code>","text":"<p>Adds a message to the memory.</p> <p>Parameters:</p> Name Type Description Default <code>role</code> <code>MessageRole</code> <p>The role of the message sender</p> required <code>content</code> <code>str</code> <p>The message content</p> required <code>metadata</code> <code>dict[str, Any] | None</code> <p>Additional metadata for the message</p> <code>None</code> <p>Raises:</p> Type Description <code>MemoryError</code> <p>If the message cannot be added</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def add(self, role: MessageRole, content: str, metadata: dict[str, Any] | None = None) -&gt; None:\n    \"\"\"\n    Adds a message to the memory.\n\n    Args:\n        role: The role of the message sender\n        content: The message content\n        metadata: Additional metadata for the message\n\n    Raises:\n        MemoryError: If the message cannot be added\n    \"\"\"\n    try:\n        metadata = metadata or {}\n        if \"timestamp\" not in metadata:\n            metadata[\"timestamp\"] = datetime.now(timezone.utc).timestamp()\n\n        sanitized_metadata = {}\n        for key, value in metadata.items():\n            sanitized_metadata[key] = \"\" if value is None else value\n\n        message = Message(role=role, content=content, metadata=sanitized_metadata)\n        self.backend.add(message)\n\n        logger.debug(\n            f\"Memory {self.backend.name}: \"\n            f\"Added message: {message.role}: {message.content[:min(20, len(message.content))]}...\"\n        )\n    except Exception as e:\n        logger.error(f\"Unexpected error adding message: {e}\")\n        raise MemoryError(f\"Unexpected error adding message: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.clear","title":"<code>clear()</code>","text":"<p>Clears the memory.</p> <p>Raises:</p> Type Description <code>MemoryError</code> <p>If the memory cannot be cleared</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clears the memory.\n\n    Raises:\n        MemoryError: If the memory cannot be cleared\n    \"\"\"\n    try:\n        self.backend.clear()\n        logger.debug(f\"Memory {self.backend.name}: Cleared memory\")\n    except Exception as e:\n        logger.error(f\"Unexpected error clearing memory: {e}\")\n        raise MemoryError(f\"Unexpected error clearing memory: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.get_agent_conversation","title":"<code>get_agent_conversation(query=None, limit=None, filters=None, strategy=MemoryRetrievalStrategy.ALL)</code>","text":"<p>Retrieves messages from an agent's conversation history based on various filtering criteria.</p> <p>This method supports three retrieval strategies: - ALL: Returns the most recent messages without semantic search - RELEVANT: Returns only messages relevant to the query using semantic search - BOTH: Returns a combination of recent messages and those relevant to the query</p>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.get_agent_conversation--parameters","title":"Parameters:","text":"<p>query : str | None, optional     The search query to filter messages by relevance. Required for RELEVANT and BOTH strategies.     Ignored when strategy is ALL. Default is None.</p> int | None, optional <p>Maximum number of messages to return. If None, falls back to self.message_limit.</p> dict[str, Any] | None, optional <p>Additional metadata filters to apply to the search results.</p> MemoryRetrievalStrategy, optional <p>The strategy to use for retrieving messages. Choices are: - MemoryRetrievalStrategy.ALL: Return most recent messages - MemoryRetrievalStrategy.RELEVANT: Return messages relevant to query - MemoryRetrievalStrategy.BOTH: Return both recent and relevant messages Default is MemoryRetrievalStrategy.ALL.</p>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.get_agent_conversation--returns","title":"Returns:","text":"<p>list[Message]     A list of conversation messages matching the search criteria, ordered chronologically.</p>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.get_agent_conversation--raises","title":"Raises:","text":"<p>MemoryError     If there is an error retrieving the conversation history.</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def get_agent_conversation(\n    self,\n    query: str | None = None,\n    limit: int | None = None,\n    filters: dict[str, Any] | None = None,\n    strategy: MemoryRetrievalStrategy = MemoryRetrievalStrategy.ALL,\n) -&gt; list[Message]:\n    \"\"\"\n    Retrieves messages from an agent's conversation history based on various filtering criteria.\n\n    This method supports three retrieval strategies:\n    - ALL: Returns the most recent messages without semantic search\n    - RELEVANT: Returns only messages relevant to the query using semantic search\n    - BOTH: Returns a combination of recent messages and those relevant to the query\n\n    Parameters:\n    -----------\n    query : str | None, optional\n        The search query to filter messages by relevance. Required for RELEVANT and BOTH strategies.\n        Ignored when strategy is ALL. Default is None.\n\n    limit : int | None, optional\n        Maximum number of messages to return. If None, falls back to self.message_limit.\n\n    filters : dict[str, Any] | None, optional\n        Additional metadata filters to apply to the search results.\n\n    strategy : MemoryRetrievalStrategy, optional\n        The strategy to use for retrieving messages. Choices are:\n        - MemoryRetrievalStrategy.ALL: Return most recent messages\n        - MemoryRetrievalStrategy.RELEVANT: Return messages relevant to query\n        - MemoryRetrievalStrategy.BOTH: Return both recent and relevant messages\n        Default is MemoryRetrievalStrategy.ALL.\n\n    Returns:\n    --------\n    list[Message]\n        A list of conversation messages matching the search criteria, ordered chronologically.\n\n    Raises:\n    -------\n    MemoryError\n        If there is an error retrieving the conversation history.\n    \"\"\"\n    logger.debug(\"Retrieving agent conversation...\")\n    try:\n        effective_limit = limit if limit is not None else self.message_limit\n\n        search_limit = effective_limit * 3\n\n        if strategy == MemoryRetrievalStrategy.RELEVANT and query:\n            messages = self.search(query=query, filters=filters, limit=search_limit)\n        elif strategy == MemoryRetrievalStrategy.BOTH and query:\n            recent_messages = self.search(query=None, filters=filters, limit=max(search_limit, self.DEFAULT_LIMIT))\n\n            relevant_messages = self.search(query=query, filters=filters, limit=search_limit)\n\n            message_dict = {msg.metadata.get(\"timestamp\", 0): msg for msg in recent_messages}\n            for msg in relevant_messages:\n                message_dict[msg.metadata.get(\"timestamp\", 0)] = msg\n\n            messages = [msg for _, msg in sorted(message_dict.items())]\n        else:\n            messages = self.search(query=None, filters=filters, limit=search_limit)\n\n        final_messages = self._extract_valid_conversation(messages, effective_limit)\n        return final_messages\n    except Exception as e:\n        logger.error(f\"Error retrieving agent conversation: {e}\")\n        raise MemoryError(f\"Failed to retrieve agent conversation: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.get_all","title":"<code>get_all(limit=None)</code>","text":"<p>Retrieves all messages from the memory, optionally limited to most recent.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int | None</code> <p>Maximum number of messages to return. If provided, returns the most recent messages.   If None, uses the configured message_limit.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Message]</code> <p>List of messages sorted by timestamp (oldest first)</p> <p>Raises:</p> Type Description <code>MemoryError</code> <p>If messages cannot be retrieved</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def get_all(self, limit: int | None = None) -&gt; list[Message]:\n    \"\"\"\n    Retrieves all messages from the memory, optionally limited to most recent.\n\n    Args:\n        limit: Maximum number of messages to return. If provided, returns the most recent messages.\n              If None, uses the configured message_limit.\n\n    Returns:\n        List of messages sorted by timestamp (oldest first)\n\n    Raises:\n        MemoryError: If messages cannot be retrieved\n    \"\"\"\n    try:\n        effective_limit = limit if limit is not None else self.message_limit\n\n        messages = self.backend.get_all(limit=effective_limit)\n        retrieved_messages = [Message(**msg.model_dump()) for msg in messages]\n        logger.debug(f\"Memory {self.backend.name}: Retrieved {len(retrieved_messages)} messages\")\n        return retrieved_messages\n    except Exception as e:\n        logger.error(f\"Unexpected error retrieving messages: {e}\")\n        raise MemoryError(f\"Unexpected error retrieving messages: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.get_all_messages_as_string","title":"<code>get_all_messages_as_string(format_type=FormatType.PLAIN)</code>","text":"<p>Retrieves all messages as a formatted string.</p> <p>Parameters:</p> Name Type Description Default <code>format_type</code> <code>FormatType</code> <p>Format to use for the string output</p> <code>PLAIN</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string representation of all messages</p> <p>Raises:</p> Type Description <code>MemoryError</code> <p>If messages cannot be retrieved or formatted</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def get_all_messages_as_string(self, format_type: FormatType = FormatType.PLAIN) -&gt; str:\n    \"\"\"\n    Retrieves all messages as a formatted string.\n\n    Args:\n        format_type: Format to use for the string output\n\n    Returns:\n        Formatted string representation of all messages\n\n    Raises:\n        MemoryError: If messages cannot be retrieved or formatted\n    \"\"\"\n    messages = self.get_all()\n    return self._format_messages_as_string(messages=messages, format_type=format_type)\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.get_search_results_as_string","title":"<code>get_search_results_as_string(query, filters=None, format_type=FormatType.PLAIN)</code>","text":"<p>Searches for messages relevant to the query and returns them as a string.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query string</p> required <code>filters</code> <code>dict[str, Any] | None</code> <p>Optional metadata filters to apply</p> <code>None</code> <code>format_type</code> <code>FormatType</code> <p>Format to use for the string output</p> <code>PLAIN</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string representation of search results</p> <p>Raises:</p> Type Description <code>MemoryError</code> <p>If search operation fails or results cannot be formatted</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def get_search_results_as_string(\n    self, query: str, filters: dict[str, Any] | None = None, format_type: FormatType = FormatType.PLAIN\n) -&gt; str:\n    \"\"\"\n    Searches for messages relevant to the query and returns them as a string.\n\n    Args:\n        query: Search query string\n        filters: Optional metadata filters to apply\n        format_type: Format to use for the string output\n\n    Returns:\n        Formatted string representation of search results\n\n    Raises:\n        MemoryError: If search operation fails or results cannot be formatted\n    \"\"\"\n    messages = self.search(query, filters)\n    return self._format_messages_as_string(messages=messages, format_type=format_type)\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.is_empty","title":"<code>is_empty()</code>","text":"<p>Checks if the memory is empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the memory is empty, False otherwise</p> <p>Raises:</p> Type Description <code>MemoryError</code> <p>If the check fails</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"\n    Checks if the memory is empty.\n\n    Returns:\n        True if the memory is empty, False otherwise\n\n    Raises:\n        MemoryError: If the check fails\n    \"\"\"\n    try:\n        return self.backend.is_empty()\n    except Exception as e:\n        logger.error(f\"Unexpected error checking if memory is empty: {e}\")\n        raise MemoryError(f\"Unexpected error checking if memory is empty: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.search","title":"<code>search(query=None, filters=None, limit=None)</code>","text":"<p>Searches for messages relevant to the query or filters.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str | None</code> <p>Search query string (optional)</p> <code>None</code> <code>filters</code> <code>dict[str, Any] | None</code> <p>Optional metadata filters to apply (overrides default filters)</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Maximum number of messages to return (defaults to message_limit)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Message]</code> <p>List of matching messages sorted by relevance</p> <p>Raises:</p> Type Description <code>MemoryError</code> <p>If search operation fails</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def search(\n    self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n) -&gt; list[Message]:\n    \"\"\"\n    Searches for messages relevant to the query or filters.\n\n    Args:\n        query: Search query string (optional)\n        filters: Optional metadata filters to apply (overrides default filters)\n        limit: Maximum number of messages to return (defaults to message_limit)\n\n    Returns:\n        List of matching messages sorted by relevance\n\n    Raises:\n        MemoryError: If search operation fails\n    \"\"\"\n    try:\n        effective_filters = self.filters.copy()\n        if filters:\n            effective_filters.update(filters)\n\n        effective_limit = limit if limit is not None else self.message_limit\n\n        results = self.backend.search(query=query, filters=effective_filters, limit=effective_limit)\n\n        retrieved_messages = [Message(**msg.model_dump()) for msg in results]\n        logger.debug(\n            f\"Memory {self.backend.name}: Found {len(retrieved_messages)} search results for query: {query}, \"\n            f\"filters: {effective_filters}\"\n        )\n        return retrieved_messages\n    except Exception as e:\n        logger.error(f\"Unexpected error searching memory: {e}\")\n        raise MemoryError(f\"Unexpected error searching memory: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.Memory.to_dict","title":"<code>to_dict(include_secure_params=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    for_tracing = kwargs.pop(\"for_tracing\", False)\n    data = self.model_dump(exclude=kwargs.pop(\"exclude\", self.to_dict_exclude_params), **kwargs)\n    data[\"backend\"] = self.backend.to_dict(\n        include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs\n    )\n    return data\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.MemoryError","title":"<code>MemoryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for Memory errors.</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>class MemoryError(Exception):\n    \"\"\"Base exception for Memory errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/memory/memory/#dynamiq.memory.memory.MemoryRetrievalStrategy","title":"<code>MemoryRetrievalStrategy</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for memory retrieval strategies.</p> Source code in <code>dynamiq/memory/memory.py</code> <pre><code>class MemoryRetrievalStrategy(str, Enum):\n    \"\"\"Enum for memory retrieval strategies.\"\"\"\n    ALL = \"all\"\n    RELEVANT = \"relevant\"\n    BOTH = \"both\"\n</code></pre>"},{"location":"dynamiq/memory/backends/base/","title":"Base","text":""},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend","title":"<code>MemoryBackend</code>","text":"<p>               Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>Abstract base class for memory storage backends.</p> Source code in <code>dynamiq/memory/backends/base.py</code> <pre><code>class MemoryBackend(ABC, BaseModel):\n    \"\"\"Abstract base class for memory storage backends.\"\"\"\n\n    name: str = \"MemoryBackend\"\n    id: str = Field(default_factory=generate_uuid)\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict[str, bool]:\n        \"\"\"Define parameters to exclude during serialization.\"\"\"\n        return {}\n\n    def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        kwargs.pop(\"include_secure_params\", None)\n        kwargs.pop(\"for_tracing\", None)\n        return self.model_dump(exclude=kwargs.pop(\"exclude\", self.to_dict_exclude_params), **kwargs)\n\n    @computed_field\n    @cached_property\n    def type(self) -&gt; str:\n        \"\"\"Returns the backend type as a string.\"\"\"\n        return f\"{self.__module__.rsplit('.', 1)[0]}.{self.__class__.__name__}\"\n\n    @abstractmethod\n    def add(self, message: Message) -&gt; None:\n        \"\"\"\n        Adds a message to the memory storage.\n\n        Args:\n            message: Message to add to storage\n\n        Raises:\n            MemoryBackendError: If the message cannot be added\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_all(self, limit: int | None = None) -&gt; list[Message]:\n        \"\"\"\n        Retrieves all messages from the memory storage, optionally limited.\n\n        Args:\n            limit: Maximum number of messages to return. If provided, returns the most recent messages.\n                  If None, uses the backend's default limit (if applicable).\n\n        Returns:\n            List of messages sorted by timestamp (oldest first)\n\n        Raises:\n            MemoryBackendError: If messages cannot be retrieved\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def search(\n        self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n    ) -&gt; list[Message]:\n        \"\"\"\n        Searches for messages relevant to the query.\n\n        Args:\n            query: Search query string (optional)\n            filters: Optional metadata filters to apply\n            limit: Maximum number of messages to return. If None, uses the backend's default limit.\n\n        Returns:\n            List of messages sorted by relevance (most relevant first)\n\n        Raises:\n            MemoryBackendError: If search operation fails\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def is_empty(self) -&gt; bool:\n        \"\"\"\n        Checks if the memory storage is empty.\n\n        Returns:\n            True if the memory is empty, False otherwise\n\n        Raises:\n            MemoryBackendError: If the check fails\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def clear(self) -&gt; None:\n        \"\"\"\n        Clears the memory storage.\n\n        Raises:\n            MemoryBackendError: If the memory cannot be cleared\n        \"\"\"\n        raise NotImplementedError\n\n    def _prepare_filters(self, filters: dict[str, Any] | None = None) -&gt; dict[str, Any] | None:\n        \"\"\"\n        Default implementation for preparing filters. Override in backend-specific implementations.\n\n        Args:\n            filters: Raw filters to prepare\n\n        Returns:\n            Prepared filters in backend-specific format\n        \"\"\"\n        return filters\n</code></pre>"},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend.to_dict_exclude_params","title":"<code>to_dict_exclude_params: dict[str, bool]</code>  <code>property</code>","text":"<p>Define parameters to exclude during serialization.</p>"},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend.type","title":"<code>type: str</code>  <code>cached</code> <code>property</code>","text":"<p>Returns the backend type as a string.</p>"},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend.add","title":"<code>add(message)</code>  <code>abstractmethod</code>","text":"<p>Adds a message to the memory storage.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>Message to add to storage</p> required <p>Raises:</p> Type Description <code>MemoryBackendError</code> <p>If the message cannot be added</p> Source code in <code>dynamiq/memory/backends/base.py</code> <pre><code>@abstractmethod\ndef add(self, message: Message) -&gt; None:\n    \"\"\"\n    Adds a message to the memory storage.\n\n    Args:\n        message: Message to add to storage\n\n    Raises:\n        MemoryBackendError: If the message cannot be added\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend.clear","title":"<code>clear()</code>  <code>abstractmethod</code>","text":"<p>Clears the memory storage.</p> <p>Raises:</p> Type Description <code>MemoryBackendError</code> <p>If the memory cannot be cleared</p> Source code in <code>dynamiq/memory/backends/base.py</code> <pre><code>@abstractmethod\ndef clear(self) -&gt; None:\n    \"\"\"\n    Clears the memory storage.\n\n    Raises:\n        MemoryBackendError: If the memory cannot be cleared\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend.get_all","title":"<code>get_all(limit=None)</code>  <code>abstractmethod</code>","text":"<p>Retrieves all messages from the memory storage, optionally limited.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int | None</code> <p>Maximum number of messages to return. If provided, returns the most recent messages.   If None, uses the backend's default limit (if applicable).</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Message]</code> <p>List of messages sorted by timestamp (oldest first)</p> <p>Raises:</p> Type Description <code>MemoryBackendError</code> <p>If messages cannot be retrieved</p> Source code in <code>dynamiq/memory/backends/base.py</code> <pre><code>@abstractmethod\ndef get_all(self, limit: int | None = None) -&gt; list[Message]:\n    \"\"\"\n    Retrieves all messages from the memory storage, optionally limited.\n\n    Args:\n        limit: Maximum number of messages to return. If provided, returns the most recent messages.\n              If None, uses the backend's default limit (if applicable).\n\n    Returns:\n        List of messages sorted by timestamp (oldest first)\n\n    Raises:\n        MemoryBackendError: If messages cannot be retrieved\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend.is_empty","title":"<code>is_empty()</code>  <code>abstractmethod</code>","text":"<p>Checks if the memory storage is empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the memory is empty, False otherwise</p> <p>Raises:</p> Type Description <code>MemoryBackendError</code> <p>If the check fails</p> Source code in <code>dynamiq/memory/backends/base.py</code> <pre><code>@abstractmethod\ndef is_empty(self) -&gt; bool:\n    \"\"\"\n    Checks if the memory storage is empty.\n\n    Returns:\n        True if the memory is empty, False otherwise\n\n    Raises:\n        MemoryBackendError: If the check fails\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend.search","title":"<code>search(query=None, filters=None, limit=None)</code>  <code>abstractmethod</code>","text":"<p>Searches for messages relevant to the query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str | None</code> <p>Search query string (optional)</p> <code>None</code> <code>filters</code> <code>dict[str, Any] | None</code> <p>Optional metadata filters to apply</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Maximum number of messages to return. If None, uses the backend's default limit.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Message]</code> <p>List of messages sorted by relevance (most relevant first)</p> <p>Raises:</p> Type Description <code>MemoryBackendError</code> <p>If search operation fails</p> Source code in <code>dynamiq/memory/backends/base.py</code> <pre><code>@abstractmethod\ndef search(\n    self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n) -&gt; list[Message]:\n    \"\"\"\n    Searches for messages relevant to the query.\n\n    Args:\n        query: Search query string (optional)\n        filters: Optional metadata filters to apply\n        limit: Maximum number of messages to return. If None, uses the backend's default limit.\n\n    Returns:\n        List of messages sorted by relevance (most relevant first)\n\n    Raises:\n        MemoryBackendError: If search operation fails\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"dynamiq/memory/backends/base/#dynamiq.memory.backends.base.MemoryBackend.to_dict","title":"<code>to_dict(include_secure_params=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/memory/backends/base.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    kwargs.pop(\"include_secure_params\", None)\n    kwargs.pop(\"for_tracing\", None)\n    return self.model_dump(exclude=kwargs.pop(\"exclude\", self.to_dict_exclude_params), **kwargs)\n</code></pre>"},{"location":"dynamiq/memory/backends/dynamo_db/","title":"Dynamo db","text":""},{"location":"dynamiq/memory/backends/dynamo_db/#dynamiq.memory.backends.dynamo_db.DynamoDB","title":"<code>DynamoDB</code>","text":"<p>               Bases: <code>MemoryBackend</code></p> <p>AWS DynamoDB implementation of memory storage using ONLY table scans.</p> <p>Relies exclusively on DynamoDB Scan operations. Scans read the entire table and can be slow and costly for large datasets.</p> <p>Assumed Table Schema: - PK: <code>message_id</code> (String) - SK: <code>timestamp</code> (Number - Unix float stored as Decimal) - Attributes: <code>role</code> (String), <code>content</code> (String), <code>metadata</code> (Map)</p> Source code in <code>dynamiq/memory/backends/dynamo_db.py</code> <pre><code>class DynamoDB(MemoryBackend):\n    \"\"\"\n    AWS DynamoDB implementation of memory storage using ONLY table scans.\n\n    Relies exclusively on DynamoDB Scan operations. Scans read the\n    entire table and can be slow and costly for large datasets.\n\n    Assumed Table Schema:\n    - PK: `message_id` (String)\n    - SK: `timestamp` (Number - Unix float stored as Decimal)\n    - Attributes: `role` (String), `content` (String), `metadata` (Map)\n    \"\"\"\n\n    _MAX_SCAN_PAGE_LIMIT: int = 1000\n    _DEFAULT_SCAN_SIZE: int = 5000\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str = \"DynamoDB\"\n    connection: AWS = Field(default_factory=AWS)\n    table_name: str = Field(\"conversations\", description=\"Name of the DynamoDB table.\")\n    create_if_not_exist: bool = Field(default=False)\n    billing_mode: BillingMode = Field(\n        default=BillingMode.PAY_PER_REQUEST,\n        description=\"DynamoDB billing mode\",\n    )\n    read_capacity_units: int = Field(default=1, gt=0)\n    write_capacity_units: int = Field(default=1, gt=0)\n\n    partition_key_name: str = Field(default=\"message_id\")\n    sort_key_name: str = Field(default=\"timestamp\")\n    role_attribute_name: str = Field(default=\"role\")\n    content_attribute_name: str = Field(default=\"content\")\n    metadata_attribute_name: str = Field(default=\"metadata\")\n    scan_fetch_target_multiplier: int = Field(\n        default=10,\n        gt=0,\n        description=(\n            \"When a limit is provided, multiply the limit by this factor \"\n            \"to determine the initial target number of items to fetch via scan, \"\n            \"before client-side filtering/sorting/limiting.\"\n        ),\n    )\n    default_scan_fetch_target: int = Field(\n        default=_DEFAULT_SCAN_SIZE,\n        gt=0,\n        description=(\n            \"Default target number of items to fetch during a scan operation \"\n            \"when no specific limit is provided but client-side filtering might occur. \"\n            \"Helps balance fetching enough data vs. excessive scanning.\"\n        ),\n    )\n\n    _dynamodb_resource: Any = PrivateAttr(default=None)\n    _dynamodb_table: Any = PrivateAttr(default=None)\n    _dynamodb_client: Any = PrivateAttr(default=None)\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"Define parameters to exclude when converting the class instance to a dictionary.\"\"\"\n        return super().to_dict_exclude_params | {\n            \"connection\": True,\n        }\n\n    def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict[str, Any]:\n        exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params.copy())\n        data = self.model_dump(exclude=exclude, **kwargs)\n        data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n        if \"type\" not in data:\n            data[\"type\"] = self.type\n        return data\n\n    def model_post_init(self, __context: Any) -&gt; None:\n        try:\n            session = self.connection.get_boto3_session()\n            self._dynamodb_resource = session.resource(\"dynamodb\")\n            self._dynamodb_client = session.client(\"dynamodb\")\n            self._dynamodb_table = self._get_or_create_table()\n            region = session.region_name or \"default\"\n            logger.debug(f\"DynamoDB backend (Scan Only) connected to table '{self.table_name}' in region '{region}'.\")\n        except ClientError as e:\n            logger.error(f\"Failed to initialize DynamoDB connection or table: {e}\")\n            raise DynamoDBMemoryError(f\"Failed to initialize DynamoDB connection or table: {e}\") from e\n        except Exception as e:\n            logger.error(f\"Unexpected error initializing DynamoDB backend: {e}\")\n            raise DynamoDBMemoryError(f\"Unexpected error initializing DynamoDB backend: {e}\") from e\n\n    def _get_or_create_table(self):\n        if self._dynamodb_resource is None:\n            raise DynamoDBMemoryError(\"DynamoDB resource not initialized.\")\n        table = self._dynamodb_resource.Table(self.table_name)\n        try:\n            table.load()\n            logger.debug(f\"DynamoDB table '{self.table_name}' found.\")\n            return table\n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"ResourceNotFoundException\":\n                if self.create_if_not_exist:\n                    logger.info(f\"DynamoDB table '{self.table_name}' not found. Attempting creation (Scan Only)...\")\n                    return self._create_table()\n                else:\n                    logger.error(f\"DynamoDB table '{self.table_name}' not found and create_if_not_exist is False.\")\n                    raise DynamoDBMemoryError(f\"DynamoDB table '{self.table_name}' not found.\") from e\n            else:\n                raise\n\n    def _create_table(self):\n        \"\"\"Creates the DynamoDB table WITHOUT any GSIs.\"\"\"\n        if self._dynamodb_resource is None:\n            raise DynamoDBMemoryError(\"DynamoDB resource not initialized.\")\n        attribute_definitions = [\n            {\"AttributeName\": self.partition_key_name, \"AttributeType\": \"S\"},\n            {\"AttributeName\": self.sort_key_name, \"AttributeType\": \"N\"},\n        ]\n        key_schema = [\n            {\"AttributeName\": self.partition_key_name, \"KeyType\": \"HASH\"},\n            {\"AttributeName\": self.sort_key_name, \"KeyType\": \"RANGE\"},\n        ]\n        create_params = {\n            \"TableName\": self.table_name,\n            \"AttributeDefinitions\": attribute_definitions,\n            \"KeySchema\": key_schema,\n            \"BillingMode\": self.billing_mode,\n        }\n        if self.billing_mode == BillingMode.PROVISIONED:\n            create_params[\"ProvisionedThroughput\"] = {\n                \"ReadCapacityUnits\": self.read_capacity_units,\n                \"WriteCapacityUnits\": self.write_capacity_units,\n            }\n        try:\n            table = self._dynamodb_resource.create_table(**create_params)\n            logger.info(f\"Waiting for table '{self.table_name}' to become active...\")\n            table.wait_until_exists()\n            logger.info(f\"DynamoDB table '{self.table_name}' created successfully (Scan Only - No GSIs).\")\n            return table\n        except ClientError as e:\n            logger.error(f\"Failed to create DynamoDB table '{self.table_name}': {e}\")\n            raise DynamoDBMemoryError(f\"Failed to create DynamoDB table '{self.table_name}': {e}\") from e\n\n    def _serialize_timestamp(self, ts: float | int | Decimal) -&gt; Decimal:\n        if isinstance(ts, (float, int)):\n            if ts != ts or ts == float(\"inf\") or ts == float(\"-inf\"):\n                raise ValueError(f\"Cannot serialize non-finite float {ts} as timestamp\")\n            try:\n                return Decimal(str(ts))\n            except InvalidOperation:\n                raise ValueError(f\"Could not convert numeric value {ts} to Decimal\")\n        elif isinstance(ts, Decimal):\n            if ts.is_infinite():\n                raise ValueError(f\"Cannot serialize infinite Decimal {ts} as timestamp\")\n            elif ts.is_nan():\n                raise ValueError(\"Cannot serialize NaN Decimal as timestamp\")\n            return ts\n        else:\n            raise TypeError(f\"Timestamp must be float, int, or Decimal, not {type(ts)}\")\n\n    def _deserialize_item(self, item: dict[str, Any]) -&gt; Message | None:\n        try:\n            metadata_raw = item.get(self.metadata_attribute_name, {})\n            metadata = metadata_raw\n            timestamp_val = item.get(self.sort_key_name)\n            timestamp = float(timestamp_val) if isinstance(timestamp_val, Decimal) else timestamp_val\n            metadata[self.sort_key_name] = timestamp\n            metadata[self.partition_key_name] = item.get(self.partition_key_name)\n            return Message(\n                role=MessageRole(item.get(self.role_attribute_name, MessageRole.USER.value)),\n                content=item.get(self.content_attribute_name, \"\"),\n                metadata=metadata,\n            )\n        except (TypeError, ValueError, KeyError, InvalidOperation) as e:\n            logger.error(f\"Error deserializing DynamoDB item {item.get(self.partition_key_name)}: {e}. Item: {item}\")\n            return None\n\n    def add(self, message: Message) -&gt; None:\n        if self._dynamodb_table is None:\n            raise DynamoDBMemoryError(\"DynamoDB table not initialized.\")\n        try:\n            message_id = message.metadata.get(self.partition_key_name, str(uuid.uuid4()))\n            timestamp_input = message.metadata.get(self.sort_key_name, time.time())\n            timestamp_decimal = self._serialize_timestamp(timestamp_input)\n            metadata_to_store = message.metadata.copy() if message.metadata else {}\n            metadata_to_store[self.sort_key_name] = timestamp_decimal\n            metadata_to_store[self.partition_key_name] = message_id\n            processed_metadata = _convert_floats_to_decimals(metadata_to_store)\n            logger.debug(\n                f\"Saving item with PK: {message_id}, SK: {timestamp_decimal},\"\n                f\" Metadata: {json.dumps(processed_metadata, default=str)}\"\n            )\n            item = {\n                self.partition_key_name: message_id,\n                self.sort_key_name: timestamp_decimal,\n                self.role_attribute_name: message.role.value,\n                self.content_attribute_name: message.content,\n                self.metadata_attribute_name: processed_metadata,\n            }\n            self._dynamodb_table.put_item(Item=item)\n        except (ClientError, ValueError, TypeError) as e:\n            logger.error(f\"Error adding message to DynamoDB: {e}\")\n            raise DynamoDBMemoryError(f\"Error adding message to DynamoDB: {e}\") from e\n        except Exception as e:\n            logger.error(f\"Unexpected error adding message to DynamoDB: {e}\")\n            try:\n                logger.error(f\"Problematic metadata (attempted): {json.dumps(message.metadata, default=str)}\")\n            except Exception:\n                logger.error(\"Could not serialize problematic metadata for logging.\")\n            raise DynamoDBMemoryError(f\"Unexpected error adding message: {e}\") from e\n\n    def _scan_and_process(\n        self, limit: int | None = None, filters: dict | None = None, query: str | None = None\n    ) -&gt; list[Message]:\n        \"\"\"Scans table, applies filters/query client-side, sorts, and limits.\"\"\"\n        if self._dynamodb_table is None:\n            raise DynamoDBMemoryError(\"DynamoDB table not initialized.\")\n        logger.warning(\n            f\"Performing DynamoDB Scan on table '{self.table_name}' for search/get_all. This can be slow and costly.\"\n        )\n\n        scan_params = {}\n        processed_filters = _convert_floats_to_decimals(filters) if filters else None\n        filter_expression_attr = self._build_filter_expression_attr(processed_filters)\n        if filter_expression_attr:\n            scan_params[\"FilterExpression\"] = filter_expression_attr\n            logger.debug(f\"Using server-side FilterExpression object: {filter_expression_attr}\")\n        elif filters:\n            logger.debug(\"No filters provided or FilterExpression could not be built.\")\n\n        all_items = []\n        last_evaluated_key = None\n        items_processed = 0\n        scan_fetch_target = (limit * self.scan_fetch_target_multiplier) if limit else self.default_scan_fetch_target\n        try:\n            while True:\n                if last_evaluated_key:\n                    scan_params[\"ExclusiveStartKey\"] = last_evaluated_key\n\n                scan_params[\"Limit\"] = (\n                    min(self._MAX_SCAN_PAGE_LIMIT, scan_fetch_target - items_processed)\n                    if limit\n                    else self._MAX_SCAN_PAGE_LIMIT\n                )\n                if scan_params[\"Limit\"] &lt;= 0 and limit:\n                    break\n\n                logger.debug(f\"Scanning page with params: {scan_params}\")\n                response = self._dynamodb_table.scan(**scan_params)\n                page_items = response.get(\"Items\", [])\n                all_items.extend(page_items)\n                items_processed += len(page_items)\n                logger.debug(f\"Scan page returned {len(page_items)} items. Total fetched: {items_processed}.\")\n\n                last_evaluated_key = response.get(\"LastEvaluatedKey\")\n                if not last_evaluated_key or (limit and items_processed &gt;= scan_fetch_target):\n                    if limit and items_processed &gt;= scan_fetch_target:\n                        logger.debug(f\"Reached scan fetch target ({scan_fetch_target}), stopping pagination.\")\n                    break\n\n            logger.info(f\"Scan completed. Fetched {len(all_items)} total items.\")\n\n            messages = [self._deserialize_item(item) for item in all_items]\n            valid_messages = [msg for msg in messages if msg is not None]\n            logger.debug(f\"Deserialized {len(valid_messages)} valid messages.\")\n\n            if filters:\n                original_count = len(valid_messages)\n                valid_messages = self._apply_filters_client_side_messages(valid_messages, filters)\n                logger.debug(\n                    f\"Applied client-side filters ({filters}). \"\n                    f\"Count changed from {original_count} to {len(valid_messages)}.\"\n                )\n\n            if query:\n                original_count = len(valid_messages)\n                query_lower = query.lower()\n                valid_messages = [msg for msg in valid_messages if query_lower in msg.content.lower()]\n                logger.debug(\n                    f\"Applied client-side text query ('{query}').\"\n                    f\" Count changed from {original_count} to {len(valid_messages)}.\"\n                )\n\n            valid_messages.sort(key=lambda m: m.metadata.get(self.sort_key_name, 0))\n            logger.debug(\"Sorted messages by timestamp.\")\n\n            if limit is not None and limit &gt; 0:\n                original_count = len(valid_messages)\n                final_results = valid_messages[-limit:]\n                logger.debug(\n                    f\"Applied final limit ({limit}). Count changed from {original_count} to {len(final_results)}.\"\n                )\n            else:\n                final_results = valid_messages\n                logger.debug(\"No final limit applied.\")\n\n            return final_results\n\n        except ClientError as e:\n            logger.error(f\"Error scanning DynamoDB table '{self.table_name}': {e}\")\n            logger.error(f\"Scan parameters used: {scan_params}\")  # Log params on error\n            raise DynamoDBMemoryError(f\"Error scanning DynamoDB table: {e}\") from e\n        except Exception as e:\n            logger.error(f\"Unexpected error during scan processing: {e}\")\n            raise DynamoDBMemoryError(f\"Unexpected error during scan processing: {e}\") from e\n\n    def get_all(self, limit: int | None = None) -&gt; list[Message]:\n        \"\"\"Retrieves messages via table scan, sorts chronologically.\"\"\"\n        return self._scan_and_process(limit=limit)\n\n    def search(\n        self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n    ) -&gt; list[Message]:\n        \"\"\"Searches messages via table scan, applying filters and query client-side.\"\"\"\n        return self._scan_and_process(limit=limit, filters=filters, query=query)\n\n    def _build_filter_expression_attr(self, filters: dict | None) -&gt; Attr | None:\n        \"\"\"Builds a combined Attr object for FilterExpression.\"\"\"\n        if not filters:\n            return None\n\n        fe: Attr | None = None\n        for key, value in filters.items():\n            try:\n                current_cond = Attr(f\"{self.metadata_attribute_name}.{key}\").eq(value)\n            except Exception as e:\n                logger.error(f\"Could not build Attr condition for filter key '{key}': {e}. Skipping this filter.\")\n                continue\n\n            if fe is None:\n                fe = current_cond\n            else:\n                fe = fe &amp; current_cond\n\n        if fe:\n            logger.debug(f\"Built FilterExpression Attr object: {fe}\")\n        return fe\n\n    def _apply_filters_client_side_messages(self, messages: list[Message], filters: dict) -&gt; list[Message]:\n        \"\"\"Applies filters to a list of Message objects (client-side).\"\"\"\n        if not filters:\n            return messages\n        filtered_messages = []\n        processed_filters = _convert_floats_to_decimals(filters)\n\n        for msg in messages:\n            match = True\n            for key, filter_value in processed_filters.items():\n                metadata_value = msg.metadata.get(key)\n                try:\n                    if isinstance(filter_value, Decimal) and isinstance(metadata_value, (float, int)):\n                        metadata_value_cmp = Decimal(str(metadata_value))\n                    else:\n                        metadata_value_cmp = metadata_value\n                    if isinstance(filter_value, list):\n                        if metadata_value_cmp not in filter_value:\n                            match = False\n                            break\n                    elif metadata_value_cmp != filter_value:\n                        match = False\n                        break\n                except (TypeError, ValueError, InvalidOperation):\n                    match = False\n                    break\n            if match:\n                filtered_messages.append(msg)\n        return filtered_messages\n\n    def is_empty(self) -&gt; bool:\n        if self._dynamodb_table is None:\n            raise DynamoDBMemoryError(\"DynamoDB table not initialized.\")\n        try:\n            response = self._dynamodb_table.scan(Limit=1, Select=\"COUNT\")\n            return response.get(\"Count\", 0) == 0\n        except ClientError as e:\n            logger.error(f\"Error checking emptiness for DynamoDB table '{self.table_name}': {e}\")\n            raise DynamoDBMemoryError(f\"Error checking if DynamoDB memory is empty: {e}\") from e\n\n    def clear(self) -&gt; None:\n        \"\"\"Clears memory by deleting all items via scan (slow, costly).\"\"\"\n        if self._dynamodb_table is None:\n            raise DynamoDBMemoryError(\"DynamoDB table not initialized.\")\n        logger.warning(\n            f\"Clearing all items from DynamoDB table '{self.table_name}'\"\n            f\" via Scan/Delete. This may take time and consume capacity.\"\n        )\n        try:\n            with self._dynamodb_table.batch_writer() as batch:\n                scan_params = {\"ProjectionExpression\": f\"{self.partition_key_name}, {self.sort_key_name}\"}\n                while True:\n                    response = self._dynamodb_table.scan(**scan_params)\n                    items = response.get(\"Items\", [])\n                    if not items:\n                        break\n                    for item in items:\n                        batch.delete_item(\n                            Key={\n                                self.partition_key_name: item[self.partition_key_name],\n                                self.sort_key_name: item[self.sort_key_name],\n                            }\n                        )\n                    if \"LastEvaluatedKey\" in response:\n                        scan_params[\"ExclusiveStartKey\"] = response[\"LastEvaluatedKey\"]\n                    else:\n                        break\n            logger.info(f\"DynamoDB Memory ({self.table_name}): Finished clearing items.\")\n        except ClientError as e:\n            logger.error(f\"Error clearing DynamoDB table '{self.table_name}': {e}\")\n            raise DynamoDBMemoryError(f\"Error clearing DynamoDB memory: {e}\") from e\n        except Exception as e:\n            logger.error(f\"Unexpected error clearing DynamoDB memory: {e}\")\n            raise DynamoDBMemoryError(f\"Unexpected error clearing DynamoDB memory: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/dynamo_db/#dynamiq.memory.backends.dynamo_db.DynamoDB.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Define parameters to exclude when converting the class instance to a dictionary.</p>"},{"location":"dynamiq/memory/backends/dynamo_db/#dynamiq.memory.backends.dynamo_db.DynamoDB.clear","title":"<code>clear()</code>","text":"<p>Clears memory by deleting all items via scan (slow, costly).</p> Source code in <code>dynamiq/memory/backends/dynamo_db.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clears memory by deleting all items via scan (slow, costly).\"\"\"\n    if self._dynamodb_table is None:\n        raise DynamoDBMemoryError(\"DynamoDB table not initialized.\")\n    logger.warning(\n        f\"Clearing all items from DynamoDB table '{self.table_name}'\"\n        f\" via Scan/Delete. This may take time and consume capacity.\"\n    )\n    try:\n        with self._dynamodb_table.batch_writer() as batch:\n            scan_params = {\"ProjectionExpression\": f\"{self.partition_key_name}, {self.sort_key_name}\"}\n            while True:\n                response = self._dynamodb_table.scan(**scan_params)\n                items = response.get(\"Items\", [])\n                if not items:\n                    break\n                for item in items:\n                    batch.delete_item(\n                        Key={\n                            self.partition_key_name: item[self.partition_key_name],\n                            self.sort_key_name: item[self.sort_key_name],\n                        }\n                    )\n                if \"LastEvaluatedKey\" in response:\n                    scan_params[\"ExclusiveStartKey\"] = response[\"LastEvaluatedKey\"]\n                else:\n                    break\n        logger.info(f\"DynamoDB Memory ({self.table_name}): Finished clearing items.\")\n    except ClientError as e:\n        logger.error(f\"Error clearing DynamoDB table '{self.table_name}': {e}\")\n        raise DynamoDBMemoryError(f\"Error clearing DynamoDB memory: {e}\") from e\n    except Exception as e:\n        logger.error(f\"Unexpected error clearing DynamoDB memory: {e}\")\n        raise DynamoDBMemoryError(f\"Unexpected error clearing DynamoDB memory: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/dynamo_db/#dynamiq.memory.backends.dynamo_db.DynamoDB.get_all","title":"<code>get_all(limit=None)</code>","text":"<p>Retrieves messages via table scan, sorts chronologically.</p> Source code in <code>dynamiq/memory/backends/dynamo_db.py</code> <pre><code>def get_all(self, limit: int | None = None) -&gt; list[Message]:\n    \"\"\"Retrieves messages via table scan, sorts chronologically.\"\"\"\n    return self._scan_and_process(limit=limit)\n</code></pre>"},{"location":"dynamiq/memory/backends/dynamo_db/#dynamiq.memory.backends.dynamo_db.DynamoDB.search","title":"<code>search(query=None, filters=None, limit=None)</code>","text":"<p>Searches messages via table scan, applying filters and query client-side.</p> Source code in <code>dynamiq/memory/backends/dynamo_db.py</code> <pre><code>def search(\n    self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n) -&gt; list[Message]:\n    \"\"\"Searches messages via table scan, applying filters and query client-side.\"\"\"\n    return self._scan_and_process(limit=limit, filters=filters, query=query)\n</code></pre>"},{"location":"dynamiq/memory/backends/dynamo_db/#dynamiq.memory.backends.dynamo_db.DynamoDBMemoryError","title":"<code>DynamoDBMemoryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for DynamoDB Memory Backend errors.</p> Source code in <code>dynamiq/memory/backends/dynamo_db.py</code> <pre><code>class DynamoDBMemoryError(Exception):\n    \"\"\"Base exception class for DynamoDB Memory Backend errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/","title":"In memory","text":""},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.BM25DocumentRanker","title":"<code>BM25DocumentRanker</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>BM25 implementation for scoring documents.</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>class BM25DocumentRanker(BaseModel):\n    \"\"\"BM25 implementation for scoring documents.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    documents: list[str]\n    k1: float = 1.5\n    b: float = 0.75\n    avg_dl: float = 0.0\n\n    def model_post_init(self, __context) -&gt; None:\n        \"\"\"Initialize average document length after model creation.\"\"\"\n        self.avg_dl = self._calculate_avg_dl()\n\n    def _calculate_avg_dl(self) -&gt; float:\n        \"\"\"Calculates the average document length (number of terms per document).\"\"\"\n        if not self.documents:\n            return 0.0\n        total_length = sum(len(doc.lower().split()) for doc in self.documents)\n        return total_length / len(self.documents)\n\n    def _idf(self, term: str, N: int, df: int) -&gt; float:\n        \"\"\"Calculates the IDF (inverse document frequency) of a term.\"\"\"\n        return math.log((N - df + 0.5) / (df + 0.5) + 1)\n\n    def score(self, query_terms: list[str], document: str) -&gt; float:\n        \"\"\"Calculates the BM25 score for a document.\"\"\"\n        doc_terms = document.lower().split()\n        doc_len = len(doc_terms)\n        doc_term_freqs = Counter(doc_terms)\n        N = len(self.documents)\n        score = 0.0\n\n        for term in query_terms:\n            term_freq = doc_term_freqs.get(term, 0)\n            if term_freq == 0:\n                continue\n            df = sum(1 for doc in self.documents if term in doc.lower().split())\n            idf = self._idf(term, N, df)\n            numerator = term_freq * (self.k1 + 1)\n            denominator = term_freq + self.k1 * (1 - self.b + self.b * (doc_len / self.avg_dl))\n            score += idf * (numerator / denominator)\n\n        return score\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.BM25DocumentRanker.model_post_init","title":"<code>model_post_init(__context)</code>","text":"<p>Initialize average document length after model creation.</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>def model_post_init(self, __context) -&gt; None:\n    \"\"\"Initialize average document length after model creation.\"\"\"\n    self.avg_dl = self._calculate_avg_dl()\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.BM25DocumentRanker.score","title":"<code>score(query_terms, document)</code>","text":"<p>Calculates the BM25 score for a document.</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>def score(self, query_terms: list[str], document: str) -&gt; float:\n    \"\"\"Calculates the BM25 score for a document.\"\"\"\n    doc_terms = document.lower().split()\n    doc_len = len(doc_terms)\n    doc_term_freqs = Counter(doc_terms)\n    N = len(self.documents)\n    score = 0.0\n\n    for term in query_terms:\n        term_freq = doc_term_freqs.get(term, 0)\n        if term_freq == 0:\n            continue\n        df = sum(1 for doc in self.documents if term in doc.lower().split())\n        idf = self._idf(term, N, df)\n        numerator = term_freq * (self.k1 + 1)\n        denominator = term_freq + self.k1 * (1 - self.b + self.b * (doc_len / self.avg_dl))\n        score += idf * (numerator / denominator)\n\n    return score\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.InMemory","title":"<code>InMemory</code>","text":"<p>               Bases: <code>MemoryBackend</code></p> <p>In-memory implementation of the memory storage backend.</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>class InMemory(MemoryBackend):\n    \"\"\"In-memory implementation of the memory storage backend.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str = \"InMemory\"\n    messages: list[Message] = Field(default_factory=list)\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict[str, bool]:\n        \"\"\"Define parameters to exclude during serialization.\"\"\"\n        return {\"messages\": True}\n\n    def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        return super().to_dict(include_secure_params=include_secure_params, **kwargs)\n\n    def add(self, message: Message) -&gt; None:\n        \"\"\"\n        Adds a message to the in-memory list.\n\n        Args:\n            message: Message to add to storage\n\n        Raises:\n            MemoryBackendError: If the message cannot be added\n        \"\"\"\n        self.messages.append(message)\n\n    def get_all(self, limit: int | None = None) -&gt; list[Message]:\n        \"\"\"\n        Retrieves all messages from the in-memory list.\n\n        Args:\n            limit: Maximum number of messages to return. If provided, returns the most recent messages.\n                  If None, returns all messages.\n\n        Returns:\n            List of messages sorted by timestamp (oldest first)\n        \"\"\"\n        # Sort messages by timestamp\n        sorted_messages = sorted(self.messages, key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n\n        # Apply limit if provided\n        if limit and len(sorted_messages) &gt; limit:\n            return sorted_messages[-limit:]\n\n        return sorted_messages\n\n    def _apply_filters(self, messages: list[Message], filters: dict[str, Any] | None = None) -&gt; list[Message]:\n        \"\"\"\n        Applies metadata filters to the list of messages.\n\n        Args:\n            messages: List of messages to filter\n            filters: Metadata filters to apply\n\n        Returns:\n            Filtered list of messages\n        \"\"\"\n        if not filters:\n            return messages\n\n        filtered_messages = messages\n        for key, value in filters.items():\n            if isinstance(value, list):\n                filtered_messages = [msg for msg in filtered_messages if msg.metadata.get(key) in value]\n            else:\n                filtered_messages = [msg for msg in filtered_messages if msg.metadata.get(key) == value]\n\n        return filtered_messages\n\n    def search(\n        self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n    ) -&gt; list[Message]:\n        \"\"\"\n        Searches for messages using BM25 scoring, with optional filters.\n\n        Args:\n            query: Search query string (optional)\n            filters: Optional metadata filters to apply\n            limit: Maximum number of messages to return. If None, returns all matching messages.\n\n        Returns:\n            List of messages sorted by relevance score (highest first)\n\n        Raises:\n            MemoryBackendError: If the search operation fails\n        \"\"\"\n        # Apply filters first to reduce search space\n        filtered_messages = self._apply_filters(self.messages, filters)\n\n        # If no query provided, return filtered messages\n        if not query:\n            sorted_messages = sorted(filtered_messages, key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n            if limit:\n                return sorted_messages[-limit:]\n            return sorted_messages\n\n        # Perform BM25 search with query\n        query_terms = query.lower().split()\n        document_texts = [msg.content for msg in filtered_messages]\n\n        # Handle empty document list\n        if not document_texts:\n            return []\n\n        # Calculate BM25 scores\n        bm25 = BM25DocumentRanker(documents=document_texts)\n        scored_messages = [(msg, bm25.score(query_terms, msg.content)) for msg in filtered_messages]\n\n        # Filter out zero scores\n        scored_messages = [(msg, score) for msg, score in scored_messages if score &gt; 0]\n\n        # Sort by score (descending)\n        scored_messages.sort(key=lambda x: x[1], reverse=True)\n\n        # Apply limit\n        result = [msg for msg, _ in scored_messages]\n        if limit:\n            return result[:limit]\n\n        return result\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"\n        Checks if the in-memory list is empty.\n\n        Returns:\n            True if the memory is empty, False otherwise\n        \"\"\"\n        return len(self.messages) == 0\n\n    def clear(self) -&gt; None:\n        \"\"\"\n        Clears the in-memory list.\n\n        Raises:\n            MemoryBackendError: If the memory cannot be cleared\n        \"\"\"\n        self.messages = []\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.InMemory.to_dict_exclude_params","title":"<code>to_dict_exclude_params: dict[str, bool]</code>  <code>property</code>","text":"<p>Define parameters to exclude during serialization.</p>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.InMemory.add","title":"<code>add(message)</code>","text":"<p>Adds a message to the in-memory list.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Message</code> <p>Message to add to storage</p> required <p>Raises:</p> Type Description <code>MemoryBackendError</code> <p>If the message cannot be added</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>def add(self, message: Message) -&gt; None:\n    \"\"\"\n    Adds a message to the in-memory list.\n\n    Args:\n        message: Message to add to storage\n\n    Raises:\n        MemoryBackendError: If the message cannot be added\n    \"\"\"\n    self.messages.append(message)\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.InMemory.clear","title":"<code>clear()</code>","text":"<p>Clears the in-memory list.</p> <p>Raises:</p> Type Description <code>MemoryBackendError</code> <p>If the memory cannot be cleared</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"\n    Clears the in-memory list.\n\n    Raises:\n        MemoryBackendError: If the memory cannot be cleared\n    \"\"\"\n    self.messages = []\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.InMemory.get_all","title":"<code>get_all(limit=None)</code>","text":"<p>Retrieves all messages from the in-memory list.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int | None</code> <p>Maximum number of messages to return. If provided, returns the most recent messages.   If None, returns all messages.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Message]</code> <p>List of messages sorted by timestamp (oldest first)</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>def get_all(self, limit: int | None = None) -&gt; list[Message]:\n    \"\"\"\n    Retrieves all messages from the in-memory list.\n\n    Args:\n        limit: Maximum number of messages to return. If provided, returns the most recent messages.\n              If None, returns all messages.\n\n    Returns:\n        List of messages sorted by timestamp (oldest first)\n    \"\"\"\n    # Sort messages by timestamp\n    sorted_messages = sorted(self.messages, key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n\n    # Apply limit if provided\n    if limit and len(sorted_messages) &gt; limit:\n        return sorted_messages[-limit:]\n\n    return sorted_messages\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.InMemory.is_empty","title":"<code>is_empty()</code>","text":"<p>Checks if the in-memory list is empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the memory is empty, False otherwise</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"\n    Checks if the in-memory list is empty.\n\n    Returns:\n        True if the memory is empty, False otherwise\n    \"\"\"\n    return len(self.messages) == 0\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.InMemory.search","title":"<code>search(query=None, filters=None, limit=None)</code>","text":"<p>Searches for messages using BM25 scoring, with optional filters.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str | None</code> <p>Search query string (optional)</p> <code>None</code> <code>filters</code> <code>dict[str, Any] | None</code> <p>Optional metadata filters to apply</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Maximum number of messages to return. If None, returns all matching messages.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Message]</code> <p>List of messages sorted by relevance score (highest first)</p> <p>Raises:</p> Type Description <code>MemoryBackendError</code> <p>If the search operation fails</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>def search(\n    self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n) -&gt; list[Message]:\n    \"\"\"\n    Searches for messages using BM25 scoring, with optional filters.\n\n    Args:\n        query: Search query string (optional)\n        filters: Optional metadata filters to apply\n        limit: Maximum number of messages to return. If None, returns all matching messages.\n\n    Returns:\n        List of messages sorted by relevance score (highest first)\n\n    Raises:\n        MemoryBackendError: If the search operation fails\n    \"\"\"\n    # Apply filters first to reduce search space\n    filtered_messages = self._apply_filters(self.messages, filters)\n\n    # If no query provided, return filtered messages\n    if not query:\n        sorted_messages = sorted(filtered_messages, key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n        if limit:\n            return sorted_messages[-limit:]\n        return sorted_messages\n\n    # Perform BM25 search with query\n    query_terms = query.lower().split()\n    document_texts = [msg.content for msg in filtered_messages]\n\n    # Handle empty document list\n    if not document_texts:\n        return []\n\n    # Calculate BM25 scores\n    bm25 = BM25DocumentRanker(documents=document_texts)\n    scored_messages = [(msg, bm25.score(query_terms, msg.content)) for msg in filtered_messages]\n\n    # Filter out zero scores\n    scored_messages = [(msg, score) for msg, score in scored_messages if score &gt; 0]\n\n    # Sort by score (descending)\n    scored_messages.sort(key=lambda x: x[1], reverse=True)\n\n    # Apply limit\n    result = [msg for msg, _ in scored_messages]\n    if limit:\n        return result[:limit]\n\n    return result\n</code></pre>"},{"location":"dynamiq/memory/backends/in_memory/#dynamiq.memory.backends.in_memory.InMemory.to_dict","title":"<code>to_dict(include_secure_params=False, for_tracing=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/memory/backends/in_memory.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    return super().to_dict(include_secure_params=include_secure_params, **kwargs)\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/","title":"Pinecone","text":""},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone","title":"<code>Pinecone</code>","text":"<p>               Bases: <code>MemoryBackend</code></p> <p>Pinecone memory backend implementation.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>class Pinecone(MemoryBackend):\n    \"\"\"Pinecone memory backend implementation.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    name: str = \"Pinecone\"\n    connection: PineconeConnection\n    embedder: DocumentEmbedder\n    index_type: PineconeIndexType\n    index_name: str = Field(default=\"conversations\")\n    dimension: int = Field(default=1536)\n    metric: PineconeSimilarityMetric = Field(default=PineconeSimilarityMetric.COSINE)\n    create_if_not_exist: bool = Field(default=True)\n    namespace: str = Field(default=\"default\")\n    cloud: str | None = Field(default=None)\n    region: str | None = Field(default=None)\n    environment: str | None = Field(default=None)\n    pod_type: str | None = Field(default=None)\n    pods: int = Field(default=1)\n    vector_store: PineconeVectorStore | None = None\n    message_truncation_enabled: bool = Field(\n        default=True, description=\"Enable automatic message truncation for embeddings\"\n    )\n    message_max_tokens: int = Field(default=6000, description=\"Maximum tokens for message content before truncation\")\n    message_truncation_method: TruncationMethod = Field(\n        default=TruncationMethod.START, description=\"Method to use for message truncation\"\n    )\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"Define parameters to exclude when converting the class instance to a dictionary.\"\"\"\n        return super().to_dict_exclude_params | {\n            \"embedder\": True,\n            \"vector_store\": True,\n            \"connection\": True,\n        }\n\n    def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        kwargs.pop(\"include_secure_params\", None)\n        data = super().to_dict(**kwargs)\n        data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n        data[\"embedder\"] = self.embedder.to_dict(\n            include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs\n        )\n        return data\n\n    def model_post_init(self, __context) -&gt; None:\n        \"\"\"Initialize the vector store after model initialization.\"\"\"\n        if not self.vector_store:\n            self.vector_store = PineconeVectorStore(\n                connection=self.connection,\n                index_name=self.index_name,\n                namespace=self.namespace,\n                create_if_not_exist=self.create_if_not_exist,\n                dimension=self.dimension,\n                metric=self.metric,\n                index_type=self.index_type,\n                cloud=self.cloud,\n                region=self.region,\n                environment=self.environment,\n                pod_type=self.pod_type,\n                pods=self.pods,\n            )\n\n        if not self.vector_store._index:\n            raise PineconeError(\"Failed to initialize Pinecone index\")\n\n        # Configure embedder truncation settings\n        self.embedder.document_embedder.truncation_enabled = self.message_truncation_enabled\n        self.embedder.document_embedder.max_input_tokens = self.message_max_tokens\n        self.embedder.document_embedder.truncation_method = self.message_truncation_method\n\n    def _message_to_document(self, message: Message) -&gt; Document:\n        \"\"\"Converts a Message object to a Document object.\"\"\"\n        content = message.content\n        metadata = {\"role\": message.role.value, **(message.metadata or {})}\n\n        if self.message_truncation_enabled and content:\n            original_length = len(content)\n            truncated_content = truncate_text_for_embedding(\n                text=content,\n                max_tokens=self.message_max_tokens,\n                truncation_method=self.message_truncation_method\n            )\n\n            if len(truncated_content) &lt; original_length:\n                content = truncated_content\n                metadata[\"truncated\"] = True\n                metadata[\"original_length\"] = original_length\n                metadata[\"truncated_length\"] = len(content)\n                metadata[\"truncation_method\"] = self.message_truncation_method.value\n\n        return Document(\n            id=str(uuid.uuid4()),\n            content=content,\n            metadata=metadata,\n            embedding=None,\n        )\n\n    def _document_to_message(self, document: Document) -&gt; Message:\n        \"\"\"Converts a Document object to a Message object.\"\"\"\n        metadata = dict(document.metadata)\n        role = metadata.pop(\"role\")\n        return Message(content=document.content, role=role, metadata=metadata)\n\n    def add(self, message: Message) -&gt; None:\n        \"\"\"Stores a message in Pinecone.\"\"\"\n        try:\n            document = self._message_to_document(message)\n            embedding_result = self.embedder.execute(input_data=DocumentEmbedderInputSchema(documents=[document]))\n            document_embedding = embedding_result.get(\"documents\")[0].embedding\n            document.embedding = document_embedding\n            self.vector_store.write_documents([document])\n\n        except Exception as e:\n            raise PineconeError(f\"Error adding message to Pinecone: {e}\") from e\n\n    def get_all(self, limit: int = 10000) -&gt; list[Message]:\n        \"\"\"Retrieves all messages from Pinecone.\"\"\"\n        try:\n            documents = self.vector_store.list_documents(include_embeddings=False)\n            messages = [self._document_to_message(doc) for doc in documents]\n            return sorted(messages, key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n        except Exception as e:\n            raise PineconeError(f\"Error retrieving messages from Pinecone: {e}\") from e\n\n    def _prepare_filters(self, filters: dict | None = None) -&gt; dict | None:\n        \"\"\"Convert simple filters to Pinecone filter format.\"\"\"\n        if not filters:\n            return None\n\n        if all(isinstance(v, (str, int, float, bool)) for v in filters.values()):\n            conditions = []\n            for key, value in filters.items():\n                conditions.append({\"field\": key, \"operator\": \"==\", \"value\": value})\n            return {\"operator\": \"AND\", \"conditions\": conditions}\n        return filters\n\n    def search(self, query: str | None = None, filters: dict | None = None, limit: int = 1000) -&gt; list[Message]:\n        \"\"\"Searches for messages in Pinecone based on the query and/or filters.\"\"\"\n        try:\n            normalized_filters = self._prepare_filters(filters)\n\n            if query:\n                embedding_result = (\n                    self.embedder.execute(\n                        input_data=DocumentEmbedderInputSchema(\n                            documents=[Document(id=str(uuid.uuid4()), content=query)]\n                        )\n                    )\n                    .get(\"documents\")[0]\n                    .embedding\n                )\n                documents = self.vector_store._embedding_retrieval(\n                    query_embedding=embedding_result,\n                    namespace=self.namespace,\n                    filters=normalized_filters,\n                    top_k=limit,\n                    exclude_document_embeddings=True,\n                )\n            elif normalized_filters:\n                dummy_vector = [0.0] * self.vector_store.dimension\n                documents = self.vector_store._embedding_retrieval(\n                    query_embedding=dummy_vector,\n                    namespace=self.namespace,\n                    filters=normalized_filters,\n                    top_k=limit,\n                    exclude_document_embeddings=True,\n                )\n            else:\n                return []\n\n            return [self._document_to_message(doc) for doc in documents]\n        except Exception as e:\n            raise PineconeError(f\"Error searching in Pinecone: {e}\") from e\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Checks if the Pinecone index is empty.\"\"\"\n        try:\n            return self.vector_store.count_documents() == 0\n        except Exception as e:\n            raise PineconeError(f\"Error checking if Pinecone index is empty: {e}\") from e\n\n    def clear(self) -&gt; None:\n        \"\"\"Clears the Pinecone index.\"\"\"\n        try:\n            self.vector_store.delete_documents(delete_all=True)\n        except Exception as e:\n            raise PineconeError(f\"Error clearing Pinecone index: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Define parameters to exclude when converting the class instance to a dictionary.</p>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone.add","title":"<code>add(message)</code>","text":"<p>Stores a message in Pinecone.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>def add(self, message: Message) -&gt; None:\n    \"\"\"Stores a message in Pinecone.\"\"\"\n    try:\n        document = self._message_to_document(message)\n        embedding_result = self.embedder.execute(input_data=DocumentEmbedderInputSchema(documents=[document]))\n        document_embedding = embedding_result.get(\"documents\")[0].embedding\n        document.embedding = document_embedding\n        self.vector_store.write_documents([document])\n\n    except Exception as e:\n        raise PineconeError(f\"Error adding message to Pinecone: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone.clear","title":"<code>clear()</code>","text":"<p>Clears the Pinecone index.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clears the Pinecone index.\"\"\"\n    try:\n        self.vector_store.delete_documents(delete_all=True)\n    except Exception as e:\n        raise PineconeError(f\"Error clearing Pinecone index: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone.get_all","title":"<code>get_all(limit=10000)</code>","text":"<p>Retrieves all messages from Pinecone.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>def get_all(self, limit: int = 10000) -&gt; list[Message]:\n    \"\"\"Retrieves all messages from Pinecone.\"\"\"\n    try:\n        documents = self.vector_store.list_documents(include_embeddings=False)\n        messages = [self._document_to_message(doc) for doc in documents]\n        return sorted(messages, key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n    except Exception as e:\n        raise PineconeError(f\"Error retrieving messages from Pinecone: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone.is_empty","title":"<code>is_empty()</code>","text":"<p>Checks if the Pinecone index is empty.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Checks if the Pinecone index is empty.\"\"\"\n    try:\n        return self.vector_store.count_documents() == 0\n    except Exception as e:\n        raise PineconeError(f\"Error checking if Pinecone index is empty: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone.model_post_init","title":"<code>model_post_init(__context)</code>","text":"<p>Initialize the vector store after model initialization.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>def model_post_init(self, __context) -&gt; None:\n    \"\"\"Initialize the vector store after model initialization.\"\"\"\n    if not self.vector_store:\n        self.vector_store = PineconeVectorStore(\n            connection=self.connection,\n            index_name=self.index_name,\n            namespace=self.namespace,\n            create_if_not_exist=self.create_if_not_exist,\n            dimension=self.dimension,\n            metric=self.metric,\n            index_type=self.index_type,\n            cloud=self.cloud,\n            region=self.region,\n            environment=self.environment,\n            pod_type=self.pod_type,\n            pods=self.pods,\n        )\n\n    if not self.vector_store._index:\n        raise PineconeError(\"Failed to initialize Pinecone index\")\n\n    # Configure embedder truncation settings\n    self.embedder.document_embedder.truncation_enabled = self.message_truncation_enabled\n    self.embedder.document_embedder.max_input_tokens = self.message_max_tokens\n    self.embedder.document_embedder.truncation_method = self.message_truncation_method\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone.search","title":"<code>search(query=None, filters=None, limit=1000)</code>","text":"<p>Searches for messages in Pinecone based on the query and/or filters.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>def search(self, query: str | None = None, filters: dict | None = None, limit: int = 1000) -&gt; list[Message]:\n    \"\"\"Searches for messages in Pinecone based on the query and/or filters.\"\"\"\n    try:\n        normalized_filters = self._prepare_filters(filters)\n\n        if query:\n            embedding_result = (\n                self.embedder.execute(\n                    input_data=DocumentEmbedderInputSchema(\n                        documents=[Document(id=str(uuid.uuid4()), content=query)]\n                    )\n                )\n                .get(\"documents\")[0]\n                .embedding\n            )\n            documents = self.vector_store._embedding_retrieval(\n                query_embedding=embedding_result,\n                namespace=self.namespace,\n                filters=normalized_filters,\n                top_k=limit,\n                exclude_document_embeddings=True,\n            )\n        elif normalized_filters:\n            dummy_vector = [0.0] * self.vector_store.dimension\n            documents = self.vector_store._embedding_retrieval(\n                query_embedding=dummy_vector,\n                namespace=self.namespace,\n                filters=normalized_filters,\n                top_k=limit,\n                exclude_document_embeddings=True,\n            )\n        else:\n            return []\n\n        return [self._document_to_message(doc) for doc in documents]\n    except Exception as e:\n        raise PineconeError(f\"Error searching in Pinecone: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.Pinecone.to_dict","title":"<code>to_dict(include_secure_params=False, for_tracing=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    kwargs.pop(\"include_secure_params\", None)\n    data = super().to_dict(**kwargs)\n    data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n    data[\"embedder\"] = self.embedder.to_dict(\n        include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs\n    )\n    return data\n</code></pre>"},{"location":"dynamiq/memory/backends/pinecone/#dynamiq.memory.backends.pinecone.PineconeError","title":"<code>PineconeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for Pinecone-related errors.</p> Source code in <code>dynamiq/memory/backends/pinecone.py</code> <pre><code>class PineconeError(Exception):\n    \"\"\"Base exception class for Pinecone-related errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/","title":"Postgresql","text":""},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.FetchMode","title":"<code>FetchMode</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for SQL fetch modes.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>class FetchMode(str, Enum):\n    \"\"\"Enum for SQL fetch modes.\"\"\"\n\n    ONE = \"one\"\n    ALL = \"all\"\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL","title":"<code>PostgreSQL</code>","text":"<p>               Bases: <code>MemoryBackend</code></p> <p>PostgreSQL implementation of the memory storage backend.</p> <p>Stores messages in a specified PostgreSQL table, using a JSONB column for metadata to allow flexible filtering.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>class PostgreSQL(MemoryBackend):\n    \"\"\"\n    PostgreSQL implementation of the memory storage backend.\n\n    Stores messages in a specified PostgreSQL table, using a JSONB column\n    for metadata to allow flexible filtering.\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str = \"PostgreSQL\"\n    connection: PostgreSQLConnection = Field(default_factory=PostgreSQLConnection)\n    table_name: str = Field(default=\"conversations\")\n    create_if_not_exist: bool = Field(default=True)\n\n    message_id_col: str = Field(default=\"message_id\")\n    role_col: str = Field(default=\"role\")\n    content_col: str = Field(default=\"content\")\n    metadata_col: str = Field(default=\"metadata\")\n    timestamp_col: str = Field(default=\"timestamp\")\n\n    _conn: psycopg.Connection | None = PrivateAttr(default=None)\n    _is_closed: bool = PrivateAttr(default=False)\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict[str, bool]:\n        \"\"\"Define parameters to exclude during serialization.\"\"\"\n        return super().to_dict_exclude_params | {\n            \"_conn\": True,\n            \"_is_closed\": True,\n            \"connection\": True,\n        }\n\n    def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params.copy())\n        data = self.model_dump(exclude=exclude, **kwargs)\n        data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n        if \"type\" not in data:\n            data[\"type\"] = self.type\n        return data\n\n    def model_post_init(self, __context: Any) -&gt; None:\n        \"\"\"Initialize the PostgreSQL connection and ensure table exists.\"\"\"\n        try:\n            self._conn = self.connection.connect()\n            self._is_closed = False\n            if self.create_if_not_exist:\n                self._create_table_and_indices()\n            logger.debug(f\"PostgreSQL backend connected to table '{self.table_name}'.\")\n        except psycopg.Error as e:\n            logger.error(f\"Failed to initialize PostgreSQL connection or table '{self.table_name}': {e}\")\n            raise PostgresMemoryError(f\"Failed to initialize PostgreSQL connection or table: {e}\") from e\n        except Exception as e:\n            logger.error(f\"Unexpected error initializing PostgreSQL backend: {e}\")\n            raise PostgresMemoryError(f\"Unexpected error initializing PostgreSQL backend: {e}\") from e\n\n    def close(self) -&gt; None:\n        \"\"\"\n        Explicitly close the PostgreSQL connection.\n\n        This is the recommended way to clean up resources when you're done\n        with the memory backend. Safe to call multiple times.\n        \"\"\"\n        if self._conn and not self._conn.closed:\n            try:\n                self._conn.close()\n                logger.debug(\"PostgreSQL connection closed explicitly.\")\n            except Exception as e:\n                logger.error(f\"Error closing PostgreSQL connection: {e}\")\n            finally:\n                self._is_closed = True\n        else:\n            self._is_closed = True\n\n    def __enter__(self):\n        \"\"\"Context manager entry point.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit point - automatically close connection.\"\"\"\n        self.close()\n\n    def _check_connection_state(self) -&gt; None:\n        \"\"\"Check if the backend has been explicitly closed.\"\"\"\n        if self._is_closed:\n            raise PostgresMemoryError(\"PostgreSQL backend has been closed. Create a new instance to reconnect.\")\n\n    def _execute_sql(self, sql_query: SQL | str, params: tuple | list | None = None, fetch: FetchMode | None = None):\n        \"\"\"Helper to execute SQL, handling potential connection issues.\"\"\"\n        self._check_connection_state()\n\n        if self._conn is None or self._conn.closed:\n            logger.warning(\"PostgreSQL connection lost or not initialized. Attempting to reconnect.\")\n            try:\n                self._conn = self.connection.connect()\n            except Exception as e:\n                raise PostgresMemoryError(f\"Failed to re-establish PostgreSQL connection: {e}\") from e\n\n        try:\n            with self._conn.cursor() as cur:\n                cur.execute(sql_query, params)\n                if fetch == FetchMode.ONE:\n                    return cur.fetchone()\n                elif fetch == FetchMode.ALL:\n                    return cur.fetchall()\n                return None\n        except psycopg.Error as e:\n            sql_str = sql_query.as_string(cur) if isinstance(sql_query, SQL) else str(sql_query)\n            logger.error(f\"PostgreSQL error executing SQL: {e}\\nSQL: {sql_str}\\nParams: {params}\")\n            raise PostgresMemoryError(f\"PostgreSQL error: {e}\") from e\n\n    def _create_table_and_indices(self) -&gt; None:\n        \"\"\"Creates the table and necessary indices if they don't exist.\"\"\"\n        logger.debug(f\"Ensuring table '{self.table_name}' and indices exist...\")\n\n        table_sql = SQL(\n            \"\"\"\n            CREATE TABLE IF NOT EXISTS {table_name} (\n                {message_id_col} UUID PRIMARY KEY,\n                {role_col} TEXT NOT NULL,\n                {content_col} TEXT,\n                {metadata_col} JSONB,\n                {timestamp_col} DOUBLE PRECISION NOT NULL\n            );\n        \"\"\"\n        ).format(\n            table_name=Identifier(self.table_name),\n            message_id_col=Identifier(self.message_id_col),\n            role_col=Identifier(self.role_col),\n            content_col=Identifier(self.content_col),\n            metadata_col=Identifier(self.metadata_col),\n            timestamp_col=Identifier(self.timestamp_col),\n        )\n        self._execute_sql(table_sql)\n\n        table_short_name = \"\".join(filter(str.isalnum, self.table_name))[:10]\n\n        ts_index_sql = SQL(\n            \"\"\"\n            CREATE INDEX IF NOT EXISTS {index_name} ON {table_name} ({timestamp_col});\n        \"\"\"\n        ).format(\n            index_name=Identifier(f\"idx_{table_short_name}_timestamp\"),\n            table_name=Identifier(self.table_name),\n            timestamp_col=Identifier(self.timestamp_col),\n        )\n        self._execute_sql(ts_index_sql)\n\n        meta_index_sql = SQL(\n            \"\"\"\n            CREATE INDEX IF NOT EXISTS {index_name} ON {table_name} USING GIN ({metadata_col});\n        \"\"\"\n        ).format(\n            index_name=Identifier(f\"idx_{table_short_name}_metadata_gin\"),\n            table_name=Identifier(self.table_name),\n            metadata_col=Identifier(self.metadata_col),\n        )\n        self._execute_sql(meta_index_sql)\n        logger.debug(f\"Table '{self.table_name}' and indices checked/created.\")\n\n    def _row_to_message(self, row: dict) -&gt; Message:\n        \"\"\"Converts a database row (dict) to a Message object.\"\"\"\n        metadata = row.get(self.metadata_col) or {}\n        if \"timestamp\" not in metadata:\n            metadata[\"timestamp\"] = row.get(self.timestamp_col)\n        if \"message_id\" not in metadata:\n            metadata[\"message_id\"] = row.get(self.message_id_col)\n\n        return Message(\n            role=MessageRole(row.get(self.role_col, MessageRole.USER.value)),\n            content=row.get(self.content_col, \"\"),\n            metadata=metadata,\n        )\n\n    def add(self, message: Message) -&gt; None:\n        \"\"\"Adds a message to the PostgreSQL table.\"\"\"\n        try:\n            message_id = message.metadata.get(\"message_id\", uuid.uuid4())\n            timestamp = float(message.metadata.get(\"timestamp\", time.time()))\n            metadata_to_store = message.metadata or {}\n\n            sql = SQL(\n                \"\"\"\n                INSERT INTO {table_name} ({message_id_col}, {role_col}, {content_col}, {metadata_col}, {timestamp_col})\n                VALUES (%s, %s, %s, %s, %s);\n            \"\"\"\n            ).format(\n                table_name=Identifier(self.table_name),\n                message_id_col=Identifier(self.message_id_col),\n                role_col=Identifier(self.role_col),\n                content_col=Identifier(self.content_col),\n                metadata_col=Identifier(self.metadata_col),\n                timestamp_col=Identifier(self.timestamp_col),\n            )\n            params = (\n                message_id,\n                message.role.value,\n                message.content,\n                json.dumps(metadata_to_store),\n                timestamp,\n            )\n            self._execute_sql(sql, params)\n            logger.debug(f\"PostgreSQL Memory ({self.table_name}): Added message {message_id}\")\n\n        except (TypeError, ValueError) as e:\n            logger.error(f\"Error preparing message data for PostgreSQL: {e}\")\n            raise PostgresMemoryError(f\"Error preparing message data: {e}\") from e\n\n    def get_all(self, limit: int | None = None) -&gt; list[Message]:\n        \"\"\"Retrieves messages from PostgreSQL, sorted chronologically.\"\"\"\n        sql = SQL(\n            \"\"\"\n            SELECT {message_id_col}, {role_col}, {content_col}, {metadata_col}, {timestamp_col}\n            FROM {table_name}\n            ORDER BY {timestamp_col} ASC\n        \"\"\"\n        ).format(\n            table_name=Identifier(self.table_name),\n            message_id_col=Identifier(self.message_id_col),\n            role_col=Identifier(self.role_col),\n            content_col=Identifier(self.content_col),\n            metadata_col=Identifier(self.metadata_col),\n            timestamp_col=Identifier(self.timestamp_col),\n        )\n\n        params = []\n        if limit is not None and limit &gt; 0:\n            sql = sql + SQL(\" LIMIT %s\")\n            params.append(limit)\n\n        rows = self._execute_sql(sql, params, fetch=FetchMode.ALL)\n        messages = [self._row_to_message(row) for row in rows]\n        logger.debug(f\"PostgreSQL Memory ({self.table_name}): Retrieved {len(messages)} messages.\")\n        return messages\n\n    def _build_where_clause(self, query: str | None, filters: dict | None) -&gt; tuple[SQL, list]:\n        \"\"\"Builds the WHERE clause and parameters for search.\"\"\"\n        where_clauses = []\n        params = []\n\n        if filters:\n            for key, value in filters.items():\n                where_clauses.append(SQL(\"{metadata_col}-&gt;&gt;%s = %s\").format(metadata_col=Identifier(self.metadata_col)))\n                params.extend([key, str(value)])  # Compare as text\n\n        if query:\n            where_clauses.append(SQL(\"{content_col} ILIKE %s\").format(content_col=Identifier(self.content_col)))\n            params.append(f\"%{query}%\")\n\n        if not where_clauses:\n            return SQL(\"\"), []\n\n        where_clause_sql = SQL(\"WHERE \") + SQL(\" AND \").join(where_clauses)\n        return where_clause_sql, params\n\n    def search(\n        self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n    ) -&gt; list[Message]:\n        \"\"\"Searches messages using ILIKE for query and JSONB operators for filters.\"\"\"\n\n        where_clause, params = self._build_where_clause(query, filters)\n\n        sql = SQL(\n            \"\"\"\n            SELECT {message_id_col}, {role_col}, {content_col}, {metadata_col}, {timestamp_col}\n            FROM {table_name}\n        \"\"\"\n        ).format(\n            table_name=Identifier(self.table_name),\n            message_id_col=Identifier(self.message_id_col),\n            role_col=Identifier(self.role_col),\n            content_col=Identifier(self.content_col),\n            metadata_col=Identifier(self.metadata_col),\n            timestamp_col=Identifier(self.timestamp_col),\n        )\n\n        if where_clause:\n            sql = sql + SQL(\" \") + where_clause\n\n        sql = sql + SQL(\" ORDER BY {timestamp_col} DESC\").format(timestamp_col=Identifier(self.timestamp_col))\n\n        if limit is not None and limit &gt; 0:\n            sql = sql + SQL(\" LIMIT %s\")\n            params.append(limit)\n\n        rows = self._execute_sql(sql, params, fetch=FetchMode.ALL)\n        messages = [self._row_to_message(row) for row in rows]\n\n        logger.debug(\n            f\"PostgreSQL Memory ({self.table_name}): Found {len(messages)} search results \"\n            f\"(Query: {'Yes' if query else 'No'}, Filters: {'Yes' if filters else 'No'}, Limit: {limit})\"\n        )\n        return messages\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Checks if the PostgreSQL table is empty.\"\"\"\n        sql = SQL(\"SELECT EXISTS (SELECT 1 FROM {table_name} LIMIT 1);\").format(table_name=Identifier(self.table_name))\n        result = self._execute_sql(sql, fetch=FetchMode.ONE)\n        return not (result and result.get(\"exists\", False))\n\n    def clear(self) -&gt; None:\n        \"\"\"Clears the PostgreSQL table using TRUNCATE.\"\"\"\n        logger.warning(f\"Clearing all messages from PostgreSQL table '{self.table_name}' using TRUNCATE.\")\n        sql = SQL(\"TRUNCATE TABLE {table_name};\").format(table_name=Identifier(self.table_name))\n        self._execute_sql(sql)\n        logger.info(f\"PostgreSQL Memory ({self.table_name}): Cleared table.\")\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.to_dict_exclude_params","title":"<code>to_dict_exclude_params: dict[str, bool]</code>  <code>property</code>","text":"<p>Define parameters to exclude during serialization.</p>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry point.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry point.\"\"\"\n    return self\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Context manager exit point - automatically close connection.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Context manager exit point - automatically close connection.\"\"\"\n    self.close()\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.add","title":"<code>add(message)</code>","text":"<p>Adds a message to the PostgreSQL table.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def add(self, message: Message) -&gt; None:\n    \"\"\"Adds a message to the PostgreSQL table.\"\"\"\n    try:\n        message_id = message.metadata.get(\"message_id\", uuid.uuid4())\n        timestamp = float(message.metadata.get(\"timestamp\", time.time()))\n        metadata_to_store = message.metadata or {}\n\n        sql = SQL(\n            \"\"\"\n            INSERT INTO {table_name} ({message_id_col}, {role_col}, {content_col}, {metadata_col}, {timestamp_col})\n            VALUES (%s, %s, %s, %s, %s);\n        \"\"\"\n        ).format(\n            table_name=Identifier(self.table_name),\n            message_id_col=Identifier(self.message_id_col),\n            role_col=Identifier(self.role_col),\n            content_col=Identifier(self.content_col),\n            metadata_col=Identifier(self.metadata_col),\n            timestamp_col=Identifier(self.timestamp_col),\n        )\n        params = (\n            message_id,\n            message.role.value,\n            message.content,\n            json.dumps(metadata_to_store),\n            timestamp,\n        )\n        self._execute_sql(sql, params)\n        logger.debug(f\"PostgreSQL Memory ({self.table_name}): Added message {message_id}\")\n\n    except (TypeError, ValueError) as e:\n        logger.error(f\"Error preparing message data for PostgreSQL: {e}\")\n        raise PostgresMemoryError(f\"Error preparing message data: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.clear","title":"<code>clear()</code>","text":"<p>Clears the PostgreSQL table using TRUNCATE.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clears the PostgreSQL table using TRUNCATE.\"\"\"\n    logger.warning(f\"Clearing all messages from PostgreSQL table '{self.table_name}' using TRUNCATE.\")\n    sql = SQL(\"TRUNCATE TABLE {table_name};\").format(table_name=Identifier(self.table_name))\n    self._execute_sql(sql)\n    logger.info(f\"PostgreSQL Memory ({self.table_name}): Cleared table.\")\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.close","title":"<code>close()</code>","text":"<p>Explicitly close the PostgreSQL connection.</p> <p>This is the recommended way to clean up resources when you're done with the memory backend. Safe to call multiple times.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Explicitly close the PostgreSQL connection.\n\n    This is the recommended way to clean up resources when you're done\n    with the memory backend. Safe to call multiple times.\n    \"\"\"\n    if self._conn and not self._conn.closed:\n        try:\n            self._conn.close()\n            logger.debug(\"PostgreSQL connection closed explicitly.\")\n        except Exception as e:\n            logger.error(f\"Error closing PostgreSQL connection: {e}\")\n        finally:\n            self._is_closed = True\n    else:\n        self._is_closed = True\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.get_all","title":"<code>get_all(limit=None)</code>","text":"<p>Retrieves messages from PostgreSQL, sorted chronologically.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def get_all(self, limit: int | None = None) -&gt; list[Message]:\n    \"\"\"Retrieves messages from PostgreSQL, sorted chronologically.\"\"\"\n    sql = SQL(\n        \"\"\"\n        SELECT {message_id_col}, {role_col}, {content_col}, {metadata_col}, {timestamp_col}\n        FROM {table_name}\n        ORDER BY {timestamp_col} ASC\n    \"\"\"\n    ).format(\n        table_name=Identifier(self.table_name),\n        message_id_col=Identifier(self.message_id_col),\n        role_col=Identifier(self.role_col),\n        content_col=Identifier(self.content_col),\n        metadata_col=Identifier(self.metadata_col),\n        timestamp_col=Identifier(self.timestamp_col),\n    )\n\n    params = []\n    if limit is not None and limit &gt; 0:\n        sql = sql + SQL(\" LIMIT %s\")\n        params.append(limit)\n\n    rows = self._execute_sql(sql, params, fetch=FetchMode.ALL)\n    messages = [self._row_to_message(row) for row in rows]\n    logger.debug(f\"PostgreSQL Memory ({self.table_name}): Retrieved {len(messages)} messages.\")\n    return messages\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.is_empty","title":"<code>is_empty()</code>","text":"<p>Checks if the PostgreSQL table is empty.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Checks if the PostgreSQL table is empty.\"\"\"\n    sql = SQL(\"SELECT EXISTS (SELECT 1 FROM {table_name} LIMIT 1);\").format(table_name=Identifier(self.table_name))\n    result = self._execute_sql(sql, fetch=FetchMode.ONE)\n    return not (result and result.get(\"exists\", False))\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.model_post_init","title":"<code>model_post_init(__context)</code>","text":"<p>Initialize the PostgreSQL connection and ensure table exists.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def model_post_init(self, __context: Any) -&gt; None:\n    \"\"\"Initialize the PostgreSQL connection and ensure table exists.\"\"\"\n    try:\n        self._conn = self.connection.connect()\n        self._is_closed = False\n        if self.create_if_not_exist:\n            self._create_table_and_indices()\n        logger.debug(f\"PostgreSQL backend connected to table '{self.table_name}'.\")\n    except psycopg.Error as e:\n        logger.error(f\"Failed to initialize PostgreSQL connection or table '{self.table_name}': {e}\")\n        raise PostgresMemoryError(f\"Failed to initialize PostgreSQL connection or table: {e}\") from e\n    except Exception as e:\n        logger.error(f\"Unexpected error initializing PostgreSQL backend: {e}\")\n        raise PostgresMemoryError(f\"Unexpected error initializing PostgreSQL backend: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.search","title":"<code>search(query=None, filters=None, limit=None)</code>","text":"<p>Searches messages using ILIKE for query and JSONB operators for filters.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def search(\n    self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n) -&gt; list[Message]:\n    \"\"\"Searches messages using ILIKE for query and JSONB operators for filters.\"\"\"\n\n    where_clause, params = self._build_where_clause(query, filters)\n\n    sql = SQL(\n        \"\"\"\n        SELECT {message_id_col}, {role_col}, {content_col}, {metadata_col}, {timestamp_col}\n        FROM {table_name}\n    \"\"\"\n    ).format(\n        table_name=Identifier(self.table_name),\n        message_id_col=Identifier(self.message_id_col),\n        role_col=Identifier(self.role_col),\n        content_col=Identifier(self.content_col),\n        metadata_col=Identifier(self.metadata_col),\n        timestamp_col=Identifier(self.timestamp_col),\n    )\n\n    if where_clause:\n        sql = sql + SQL(\" \") + where_clause\n\n    sql = sql + SQL(\" ORDER BY {timestamp_col} DESC\").format(timestamp_col=Identifier(self.timestamp_col))\n\n    if limit is not None and limit &gt; 0:\n        sql = sql + SQL(\" LIMIT %s\")\n        params.append(limit)\n\n    rows = self._execute_sql(sql, params, fetch=FetchMode.ALL)\n    messages = [self._row_to_message(row) for row in rows]\n\n    logger.debug(\n        f\"PostgreSQL Memory ({self.table_name}): Found {len(messages)} search results \"\n        f\"(Query: {'Yes' if query else 'No'}, Filters: {'Yes' if filters else 'No'}, Limit: {limit})\"\n    )\n    return messages\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgreSQL.to_dict","title":"<code>to_dict(include_secure_params=False, for_tracing=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params.copy())\n    data = self.model_dump(exclude=exclude, **kwargs)\n    data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n    if \"type\" not in data:\n        data[\"type\"] = self.type\n    return data\n</code></pre>"},{"location":"dynamiq/memory/backends/postgresql/#dynamiq.memory.backends.postgresql.PostgresMemoryError","title":"<code>PostgresMemoryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for PostgreSQL Memory Backend errors.</p> Source code in <code>dynamiq/memory/backends/postgresql.py</code> <pre><code>class PostgresMemoryError(Exception):\n    \"\"\"Base exception class for PostgreSQL Memory Backend errors.\"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/","title":"Qdrant","text":""},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant","title":"<code>Qdrant</code>","text":"<p>               Bases: <code>MemoryBackend</code></p> <p>Qdrant implementation of the memory storage backend.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>class Qdrant(MemoryBackend):\n    \"\"\"Qdrant implementation of the memory storage backend.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str = \"Qdrant\"\n    connection: QdrantConnection\n    embedder: DocumentEmbedder\n    index_name: str = Field(default=\"conversations\")\n    dimension: int = Field(default=1536)\n    metric: str = Field(default=\"cosine\")\n    on_disk: bool = Field(default=False)\n    create_if_not_exist: bool = Field(default=True)\n    recreate_index: bool = Field(default=False)\n    vector_store: QdrantVectorStore | None = None\n    message_truncation_enabled: bool = Field(\n        default=True, description=\"Enable automatic message truncation for embeddings\"\n    )\n    message_max_tokens: int = Field(default=6000, description=\"Maximum tokens for message content before truncation\")\n    message_truncation_method: TruncationMethod = Field(\n        default=TruncationMethod.START, description=\"Method to use for message truncation\"\n    )\n    _client: QdrantClient | None = PrivateAttr(default=None)\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"Define parameters to exclude when converting the class instance to a dictionary.\"\"\"\n        return super().to_dict_exclude_params | {\n            \"embedder\": True,\n            \"vector_store\": True,\n            \"connection\": True,\n        }\n\n    def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        kwargs.pop(\"include_secure_params\", None)\n        data = super().to_dict(**kwargs)\n        data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n        data[\"embedder\"] = self.embedder.to_dict(\n            include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs\n        )\n        return data\n\n    def model_post_init(self, __context) -&gt; None:\n        \"\"\"Initialize the vector store after model initialization.\"\"\"\n        if not self.vector_store:\n            self.vector_store = QdrantVectorStore(\n                connection=self.connection,\n                index_name=self.index_name,\n                dimension=self.dimension,\n                metric=self.metric,\n                on_disk=self.on_disk,\n                create_if_not_exist=self.create_if_not_exist,\n                recreate_index=self.recreate_index,\n            )\n\n        self._client = self.vector_store._client\n        if not self._client:\n            raise QdrantError(\"Failed to initialize Qdrant client\")\n\n        # Configure embedder truncation settings\n        self.embedder.document_embedder.truncation_enabled = self.message_truncation_enabled\n        self.embedder.document_embedder.max_input_tokens = self.message_max_tokens\n        self.embedder.document_embedder.truncation_method = self.message_truncation_method\n\n    def _message_to_document(self, message: Message) -&gt; Document:\n        \"\"\"Converts a Message object to a Document object.\"\"\"\n        content = message.content\n        metadata = {\"role\": message.role.value, **(message.metadata or {})}\n\n        if self.message_truncation_enabled and content:\n            original_length = len(content)\n            truncated_content = truncate_text_for_embedding(\n                text=content,\n                max_tokens=self.message_max_tokens,\n                truncation_method=self.message_truncation_method\n            )\n\n            if len(truncated_content) &lt; original_length:\n                content = truncated_content\n                metadata[\"truncated\"] = True\n                metadata[\"original_length\"] = original_length\n                metadata[\"truncated_length\"] = len(content)\n                metadata[\"truncation_method\"] = self.message_truncation_method.value\n\n        return Document(\n            id=str(uuid.uuid4()),\n            content=content,\n            metadata=metadata,\n            embedding=None,\n        )\n\n    def _document_to_message(self, document: Document) -&gt; Message:\n        \"\"\"Converts a Document object to a Message object.\"\"\"\n        metadata = dict(document.metadata)\n        role = metadata.pop(\"role\")\n        return Message(content=document.content, role=role, metadata=metadata)\n\n    def add(self, message: Message) -&gt; None:\n        \"\"\"Stores a message in Qdrant.\"\"\"\n        try:\n            document = self._message_to_document(message)\n            embedding_result = (\n                self.embedder.execute(input_data=DocumentEmbedderInputSchema(documents=[document]))\n                .get(\"documents\")[0]\n                .embedding\n            )\n            document.embedding = embedding_result\n\n            self.vector_store.write_documents(documents=[document], policy=DuplicatePolicy.SKIP)\n        except Exception as e:\n            raise QdrantError(f\"Failed to add message to Qdrant: {e}\") from e\n\n    def get_all(self, limit: int | None = None) -&gt; list[Message]:\n        \"\"\"Retrieves all messages from Qdrant.\"\"\"\n        try:\n            documents = self.vector_store.list_documents(include_embeddings=False)\n            messages = [self._document_to_message(doc) for doc in documents]\n            return sorted(messages, key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n        except Exception as e:\n            raise QdrantError(f\"Failed to retrieve messages from Qdrant: {e}\") from e\n\n    def search(self, query: str | None = None, limit: int = 1000, filters: dict | None = None) -&gt; list[Message]:\n        \"\"\"Searches for messages in Qdrant.\"\"\"\n        try:\n            try:\n                if not self._collection_exists():\n                    if self.create_if_not_exist:\n                        self._create_collection()\n                    else:\n                        return []\n            except Exception:\n                return []\n\n            qdrant_filters = self._prepare_filters(filters)\n            if query:\n                embedding_result = (\n                    self.embedder.execute(\n                        input_data=DocumentEmbedderInputSchema(documents=[Document(id=\"query\", content=query)])\n                    )\n                    .get(\"documents\")[0]\n                    .embedding\n                )\n                documents = self.vector_store._query_by_embedding(\n                    query_embedding=embedding_result,\n                    filters=qdrant_filters,\n                    top_k=limit,\n                    return_embedding=False,\n                )\n            elif filters:\n                documents = self.vector_store.filter_documents(filters=qdrant_filters)\n                if limit:\n                    documents = documents[:limit]\n            else:\n                return []\n\n            return [self._document_to_message(doc) for doc in documents]\n        except Exception as e:\n            raise QdrantError(f\"Error searching in Qdrant: {e}\") from e\n\n    def _prepare_filters(self, filters: dict | None = None) -&gt; dict | None:\n        \"\"\"Prepares simple filters for Qdrant vector store format.\"\"\"\n        if not filters:\n            return None\n\n        conditions = []\n        for key, value in filters.items():\n            if isinstance(value, (str, int, float, bool)):\n                condition = {\"operator\": \"==\", \"field\": key, \"value\": value}\n            elif isinstance(value, list):\n                condition = {\"operator\": \"in\", \"field\": key, \"value\": value}\n            elif isinstance(value, dict) and any(k in value for k in [\"gte\", \"lte\", \"gt\", \"lt\"]):\n                condition = {\"operator\": \"range\", \"field\": key, **value}\n            else:\n                raise QdrantError(f\"Unsupported filter value type for key '{key}': {type(value)}\")\n\n            conditions.append(condition)\n        return {\"operator\": \"AND\", \"conditions\": conditions} if conditions else None\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Checks if the Qdrant collection is empty.\"\"\"\n        try:\n            return self.vector_store.count_documents() == 0\n        except UnexpectedResponse as e:\n            if e.status_code == 404:  # Collection doesn't exist\n                return True\n            raise QdrantError(f\"Failed to check if Qdrant collection is empty: {e}\") from e\n\n    def clear(self) -&gt; None:\n        \"\"\"Clears the Qdrant collection.\"\"\"\n        try:\n            self.vector_store.delete_documents(delete_all=True)\n        except Exception as e:\n            raise QdrantError(f\"Failed to clear Qdrant collection: {e}\") from e\n\n    def _collection_exists(self) -&gt; bool:\n        \"\"\"Check if the collection exists in Qdrant.\"\"\"\n        collections = self._client.get_collections()\n        return any(collection.name == self.index_name for collection in collections.collections)\n\n    def _create_collection(self) -&gt; None:\n        \"\"\"Create the collection in Qdrant.\"\"\"\n        self._client.create_collection(\n            collection_name=self.index_name,\n            vectors_config={\"default\": {\"size\": self.dimension, \"distance\": self.metric}},\n        )\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Define parameters to exclude when converting the class instance to a dictionary.</p>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant.add","title":"<code>add(message)</code>","text":"<p>Stores a message in Qdrant.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>def add(self, message: Message) -&gt; None:\n    \"\"\"Stores a message in Qdrant.\"\"\"\n    try:\n        document = self._message_to_document(message)\n        embedding_result = (\n            self.embedder.execute(input_data=DocumentEmbedderInputSchema(documents=[document]))\n            .get(\"documents\")[0]\n            .embedding\n        )\n        document.embedding = embedding_result\n\n        self.vector_store.write_documents(documents=[document], policy=DuplicatePolicy.SKIP)\n    except Exception as e:\n        raise QdrantError(f\"Failed to add message to Qdrant: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant.clear","title":"<code>clear()</code>","text":"<p>Clears the Qdrant collection.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clears the Qdrant collection.\"\"\"\n    try:\n        self.vector_store.delete_documents(delete_all=True)\n    except Exception as e:\n        raise QdrantError(f\"Failed to clear Qdrant collection: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant.get_all","title":"<code>get_all(limit=None)</code>","text":"<p>Retrieves all messages from Qdrant.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>def get_all(self, limit: int | None = None) -&gt; list[Message]:\n    \"\"\"Retrieves all messages from Qdrant.\"\"\"\n    try:\n        documents = self.vector_store.list_documents(include_embeddings=False)\n        messages = [self._document_to_message(doc) for doc in documents]\n        return sorted(messages, key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n    except Exception as e:\n        raise QdrantError(f\"Failed to retrieve messages from Qdrant: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant.is_empty","title":"<code>is_empty()</code>","text":"<p>Checks if the Qdrant collection is empty.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Checks if the Qdrant collection is empty.\"\"\"\n    try:\n        return self.vector_store.count_documents() == 0\n    except UnexpectedResponse as e:\n        if e.status_code == 404:  # Collection doesn't exist\n            return True\n        raise QdrantError(f\"Failed to check if Qdrant collection is empty: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant.model_post_init","title":"<code>model_post_init(__context)</code>","text":"<p>Initialize the vector store after model initialization.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>def model_post_init(self, __context) -&gt; None:\n    \"\"\"Initialize the vector store after model initialization.\"\"\"\n    if not self.vector_store:\n        self.vector_store = QdrantVectorStore(\n            connection=self.connection,\n            index_name=self.index_name,\n            dimension=self.dimension,\n            metric=self.metric,\n            on_disk=self.on_disk,\n            create_if_not_exist=self.create_if_not_exist,\n            recreate_index=self.recreate_index,\n        )\n\n    self._client = self.vector_store._client\n    if not self._client:\n        raise QdrantError(\"Failed to initialize Qdrant client\")\n\n    # Configure embedder truncation settings\n    self.embedder.document_embedder.truncation_enabled = self.message_truncation_enabled\n    self.embedder.document_embedder.max_input_tokens = self.message_max_tokens\n    self.embedder.document_embedder.truncation_method = self.message_truncation_method\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant.search","title":"<code>search(query=None, limit=1000, filters=None)</code>","text":"<p>Searches for messages in Qdrant.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>def search(self, query: str | None = None, limit: int = 1000, filters: dict | None = None) -&gt; list[Message]:\n    \"\"\"Searches for messages in Qdrant.\"\"\"\n    try:\n        try:\n            if not self._collection_exists():\n                if self.create_if_not_exist:\n                    self._create_collection()\n                else:\n                    return []\n        except Exception:\n            return []\n\n        qdrant_filters = self._prepare_filters(filters)\n        if query:\n            embedding_result = (\n                self.embedder.execute(\n                    input_data=DocumentEmbedderInputSchema(documents=[Document(id=\"query\", content=query)])\n                )\n                .get(\"documents\")[0]\n                .embedding\n            )\n            documents = self.vector_store._query_by_embedding(\n                query_embedding=embedding_result,\n                filters=qdrant_filters,\n                top_k=limit,\n                return_embedding=False,\n            )\n        elif filters:\n            documents = self.vector_store.filter_documents(filters=qdrant_filters)\n            if limit:\n                documents = documents[:limit]\n        else:\n            return []\n\n        return [self._document_to_message(doc) for doc in documents]\n    except Exception as e:\n        raise QdrantError(f\"Error searching in Qdrant: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.Qdrant.to_dict","title":"<code>to_dict(include_secure_params=False, for_tracing=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    kwargs.pop(\"include_secure_params\", None)\n    data = super().to_dict(**kwargs)\n    data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n    data[\"embedder\"] = self.embedder.to_dict(\n        include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs\n    )\n    return data\n</code></pre>"},{"location":"dynamiq/memory/backends/qdrant/#dynamiq.memory.backends.qdrant.QdrantError","title":"<code>QdrantError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for Qdrant-related errors.</p> Source code in <code>dynamiq/memory/backends/qdrant.py</code> <pre><code>class QdrantError(Exception):\n    \"\"\"Base exception for Qdrant-related errors.\"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/","title":"Sqlite","text":""},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite","title":"<code>SQLite</code>","text":"<p>               Bases: <code>MemoryBackend</code></p> <p>SQLite implementation of the memory storage backend.</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>class SQLite(MemoryBackend):\n    \"\"\"SQLite implementation of the memory storage backend.\"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str = \"SQLite\"\n    db_path: Annotated[str, Field(default=\"conversations.db\")]\n    index_name: Annotated[str, Field(default=\"conversations\")]\n\n    # SQL Query Constants\n    CREATE_TABLE_QUERY: ClassVar[\n        str\n    ] = \"\"\"\n        CREATE TABLE IF NOT EXISTS {index_name} (\n            id TEXT PRIMARY KEY,\n            role TEXT NOT NULL,\n            content TEXT NOT NULL,\n            metadata TEXT,\n            timestamp REAL\n        )\n    \"\"\"\n\n    VALIDATE_TABLE_QUERY: ClassVar[str] = \"SELECT name FROM sqlite_master WHERE type='table' AND name=?\"\n    INSERT_MESSAGE_QUERY: ClassVar[\n        str\n    ] = \"\"\"\n        INSERT INTO {index_name} (id, role, content, metadata, timestamp)\n        VALUES (?, ?, ?, ?, ?)\n    \"\"\"\n    SELECT_ALL_MESSAGES_QUERY: ClassVar[\n        str\n    ] = \"\"\"\n        SELECT id, role, content, metadata, timestamp\n        FROM {index_name}\n        ORDER BY timestamp ASC\n    \"\"\"\n    CHECK_IF_EMPTY_QUERY: ClassVar[str] = \"SELECT COUNT(*) FROM {index_name}\"\n    CLEAR_TABLE_QUERY: ClassVar[str] = \"DELETE FROM {index_name}\"\n    SEARCH_MESSAGES_QUERY: ClassVar[\n        str\n    ] = \"\"\"\n        SELECT id, role, content, metadata\n        FROM {index_name}\n    \"\"\"\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"Define parameters to exclude during serialization.\"\"\"\n        return super().to_dict_exclude_params | {\n            \"CREATE_TABLE_QUERY\": True,\n            \"VALIDATE_TABLE_QUERY\": True,\n            \"INSERT_MESSAGE_QUERY\": True,\n            \"SELECT_ALL_MESSAGES_QUERY\": True,\n            \"CHECK_IF_EMPTY_QUERY\": True,\n            \"CLEAR_TABLE_QUERY\": True,\n            \"SEARCH_MESSAGES_QUERY\": True,\n        }\n\n    def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Args:\n            include_secure_params (bool): Whether to include secure parameters\n            **kwargs: Additional arguments\n\n        Returns:\n            dict: Dictionary representation of the instance\n        \"\"\"\n        kwargs.pop(\"include_secure_params\", None)\n        kwargs.pop(\"for_tracing\", None)\n        data = super().to_dict(**kwargs)\n\n        if not include_secure_params:\n            data.pop(\"db_path\", None)\n\n        return data\n\n    def model_post_init(self, __context) -&gt; None:\n        \"\"\"Initialize the SQLite database after model initialization.\"\"\"\n        try:\n            self._validate_table_name(create_if_not_exists=True)\n        except Exception as e:\n            raise SQLiteError(f\"Error initializing SQLite backend: {e}\") from e\n\n    def _validate_table_name(self, create_if_not_exists: bool = False) -&gt; None:\n        \"\"\"Validates the table name to prevent SQL injection and optionally creates it.\"\"\"\n        if not re.match(r\"^[A-Za-z0-9_]+$\", self.index_name):\n            raise SQLiteError(f\"Invalid table name: '{self.index_name}'\")\n\n        try:\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(self.VALIDATE_TABLE_QUERY, (self.index_name,))\n                result = cursor.fetchone()\n\n                if result is None:\n                    if create_if_not_exists:\n                        self._create_table()\n                    else:\n                        raise SQLiteError(f\"Table '{self.index_name}' does not exist in the database.\")\n\n        except sqlite3.Error as e:\n            raise SQLiteError(f\"Error validating or creating table: {e}\") from e\n\n    def _create_table(self) -&gt; None:\n        \"\"\"Creates the messages table.\"\"\"\n        query = self.CREATE_TABLE_QUERY.format(index_name=self.index_name)\n        try:\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query)\n                conn.commit()\n        except sqlite3.Error as e:\n            raise SQLiteError(f\"Error creating table: {e}\") from e\n\n    def add(self, message: Message) -&gt; None:\n        \"\"\"Stores a message in the SQLite database.\"\"\"\n        try:\n            query = self.INSERT_MESSAGE_QUERY.format(index_name=self.index_name)\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                message_id = str(uuid.uuid4())\n                cursor.execute(\n                    query,\n                    (\n                        message_id,\n                        message.role.value,\n                        message.content,\n                        json.dumps(message.metadata),\n                        message.metadata.get(\"timestamp\", 0),\n                    ),\n                )\n                conn.commit()\n\n        except sqlite3.Error as e:\n            raise SQLiteError(f\"Error adding message to database: {e}\") from e\n\n    def get_all(self) -&gt; list[Message]:\n        \"\"\"Retrieves all messages from the SQLite database.\"\"\"\n        try:\n            query = self.SELECT_ALL_MESSAGES_QUERY.format(index_name=self.index_name)\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query)\n                rows = cursor.fetchall()\n            return [Message(role=row[1], content=row[2], metadata=json.loads(row[3] or \"{}\")) for row in rows]\n\n        except sqlite3.Error as e:\n            raise SQLiteError(f\"Error retrieving messages from database: {e}\") from e\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Checks if the SQLite database is empty.\"\"\"\n        try:\n            query = self.CHECK_IF_EMPTY_QUERY.format(index_name=self.index_name)\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query)\n                count = cursor.fetchone()[0]\n            return count == 0\n\n        except sqlite3.Error as e:\n            raise SQLiteError(f\"Error checking if database is empty: {e}\") from e\n\n    def clear(self) -&gt; None:\n        \"\"\"Clears the SQLite database by deleting all rows in the table.\"\"\"\n        try:\n            query = self.CLEAR_TABLE_QUERY.format(index_name=self.index_name)\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query)\n                conn.commit()\n        except sqlite3.Error as e:\n            raise SQLiteError(f\"Error clearing database: {e}\") from e\n\n    def search(self, query: str | None = None, limit: int = 10, filters: dict | None = None) -&gt; list[Message]:\n        \"\"\"Searches for messages in SQLite based on the query and/or filters.\"\"\"\n        try:\n            where_clauses = []\n            params = []\n\n            if query:\n                where_clauses.append(\"content LIKE ?\")\n                params.append(f\"%{query}%\")\n\n            if filters:\n                for key, value in filters.items():\n                    if isinstance(value, list):\n                        placeholders = \",\".join(\"?\" for _ in value)\n                        where_clauses.append(f\"json_extract(metadata, '$.{key}') IN ({placeholders})\")\n                        params.extend(value)\n                    else:\n                        if isinstance(value, str) and \"%\" in value:\n                            where_clauses.append(f\"json_extract(metadata, '$.{key}') LIKE ?\")\n                            params.append(value)\n                        else:\n                            where_clauses.append(f\"json_extract(metadata, '$.{key}') = ?\")\n                            params.append(value)\n\n            query_str = self.SEARCH_MESSAGES_QUERY.format(index_name=self.index_name)\n            if where_clauses:\n                query_str += f\" WHERE {' AND '.join(where_clauses)}\"\n            query_str += \" ORDER BY id DESC LIMIT ?\"\n            params.append(limit)\n\n            with sqlite3.connect(self.db_path) as conn:\n                cursor = conn.cursor()\n                cursor.execute(query_str, params)\n                rows = cursor.fetchall()\n\n            return [Message(role=row[1], content=row[2], metadata=json.loads(row[3] or \"{}\")) for row in rows]\n\n        except sqlite3.Error as e:\n            raise SQLiteError(f\"Error searching in database: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Define parameters to exclude during serialization.</p>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite.add","title":"<code>add(message)</code>","text":"<p>Stores a message in the SQLite database.</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>def add(self, message: Message) -&gt; None:\n    \"\"\"Stores a message in the SQLite database.\"\"\"\n    try:\n        query = self.INSERT_MESSAGE_QUERY.format(index_name=self.index_name)\n        with sqlite3.connect(self.db_path) as conn:\n            cursor = conn.cursor()\n            message_id = str(uuid.uuid4())\n            cursor.execute(\n                query,\n                (\n                    message_id,\n                    message.role.value,\n                    message.content,\n                    json.dumps(message.metadata),\n                    message.metadata.get(\"timestamp\", 0),\n                ),\n            )\n            conn.commit()\n\n    except sqlite3.Error as e:\n        raise SQLiteError(f\"Error adding message to database: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite.clear","title":"<code>clear()</code>","text":"<p>Clears the SQLite database by deleting all rows in the table.</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clears the SQLite database by deleting all rows in the table.\"\"\"\n    try:\n        query = self.CLEAR_TABLE_QUERY.format(index_name=self.index_name)\n        with sqlite3.connect(self.db_path) as conn:\n            cursor = conn.cursor()\n            cursor.execute(query)\n            conn.commit()\n    except sqlite3.Error as e:\n        raise SQLiteError(f\"Error clearing database: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite.get_all","title":"<code>get_all()</code>","text":"<p>Retrieves all messages from the SQLite database.</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>def get_all(self) -&gt; list[Message]:\n    \"\"\"Retrieves all messages from the SQLite database.\"\"\"\n    try:\n        query = self.SELECT_ALL_MESSAGES_QUERY.format(index_name=self.index_name)\n        with sqlite3.connect(self.db_path) as conn:\n            cursor = conn.cursor()\n            cursor.execute(query)\n            rows = cursor.fetchall()\n        return [Message(role=row[1], content=row[2], metadata=json.loads(row[3] or \"{}\")) for row in rows]\n\n    except sqlite3.Error as e:\n        raise SQLiteError(f\"Error retrieving messages from database: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite.is_empty","title":"<code>is_empty()</code>","text":"<p>Checks if the SQLite database is empty.</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Checks if the SQLite database is empty.\"\"\"\n    try:\n        query = self.CHECK_IF_EMPTY_QUERY.format(index_name=self.index_name)\n        with sqlite3.connect(self.db_path) as conn:\n            cursor = conn.cursor()\n            cursor.execute(query)\n            count = cursor.fetchone()[0]\n        return count == 0\n\n    except sqlite3.Error as e:\n        raise SQLiteError(f\"Error checking if database is empty: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite.model_post_init","title":"<code>model_post_init(__context)</code>","text":"<p>Initialize the SQLite database after model initialization.</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>def model_post_init(self, __context) -&gt; None:\n    \"\"\"Initialize the SQLite database after model initialization.\"\"\"\n    try:\n        self._validate_table_name(create_if_not_exists=True)\n    except Exception as e:\n        raise SQLiteError(f\"Error initializing SQLite backend: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite.search","title":"<code>search(query=None, limit=10, filters=None)</code>","text":"<p>Searches for messages in SQLite based on the query and/or filters.</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>def search(self, query: str | None = None, limit: int = 10, filters: dict | None = None) -&gt; list[Message]:\n    \"\"\"Searches for messages in SQLite based on the query and/or filters.\"\"\"\n    try:\n        where_clauses = []\n        params = []\n\n        if query:\n            where_clauses.append(\"content LIKE ?\")\n            params.append(f\"%{query}%\")\n\n        if filters:\n            for key, value in filters.items():\n                if isinstance(value, list):\n                    placeholders = \",\".join(\"?\" for _ in value)\n                    where_clauses.append(f\"json_extract(metadata, '$.{key}') IN ({placeholders})\")\n                    params.extend(value)\n                else:\n                    if isinstance(value, str) and \"%\" in value:\n                        where_clauses.append(f\"json_extract(metadata, '$.{key}') LIKE ?\")\n                        params.append(value)\n                    else:\n                        where_clauses.append(f\"json_extract(metadata, '$.{key}') = ?\")\n                        params.append(value)\n\n        query_str = self.SEARCH_MESSAGES_QUERY.format(index_name=self.index_name)\n        if where_clauses:\n            query_str += f\" WHERE {' AND '.join(where_clauses)}\"\n        query_str += \" ORDER BY id DESC LIMIT ?\"\n        params.append(limit)\n\n        with sqlite3.connect(self.db_path) as conn:\n            cursor = conn.cursor()\n            cursor.execute(query_str, params)\n            rows = cursor.fetchall()\n\n        return [Message(role=row[1], content=row[2], metadata=json.loads(row[3] or \"{}\")) for row in rows]\n\n    except sqlite3.Error as e:\n        raise SQLiteError(f\"Error searching in database: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLite.to_dict","title":"<code>to_dict(include_secure_params=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>include_secure_params</code> <code>bool</code> <p>Whether to include secure parameters</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary representation of the instance</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Args:\n        include_secure_params (bool): Whether to include secure parameters\n        **kwargs: Additional arguments\n\n    Returns:\n        dict: Dictionary representation of the instance\n    \"\"\"\n    kwargs.pop(\"include_secure_params\", None)\n    kwargs.pop(\"for_tracing\", None)\n    data = super().to_dict(**kwargs)\n\n    if not include_secure_params:\n        data.pop(\"db_path\", None)\n\n    return data\n</code></pre>"},{"location":"dynamiq/memory/backends/sqlite/#dynamiq.memory.backends.sqlite.SQLiteError","title":"<code>SQLiteError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for SQLite-related errors in the memory backend.</p> Source code in <code>dynamiq/memory/backends/sqlite.py</code> <pre><code>class SQLiteError(Exception):\n    \"\"\"Base exception class for SQLite-related errors in the memory backend.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/","title":"Weaviate","text":""},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate","title":"<code>Weaviate</code>","text":"<p>               Bases: <code>MemoryBackend</code></p> <p>Weaviate implementation of the memory storage backend.</p> <p>Uses WeaviateVectorStore to manage documents (messages) in a Weaviate collection. Leverages vector embeddings for semantic search and metadata for filtering and chronological ordering.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>class Weaviate(MemoryBackend):\n    \"\"\"\n    Weaviate implementation of the memory storage backend.\n\n    Uses WeaviateVectorStore to manage documents (messages) in a Weaviate collection.\n    Leverages vector embeddings for semantic search and metadata for filtering\n    and chronological ordering.\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    name: str = \"Weaviate\"\n    connection: WeaviateConnection = Field(default_factory=WeaviateConnection)\n    embedder: DocumentEmbedder\n    collection_name: str = Field(default=\"conversations\")\n    tenant_name: str | None = Field(default=None)\n    create_if_not_exist: bool = Field(default=True)\n    content_property_name: str = Field(default=\"message_content\")\n    alpha: float = Field(default=0.5, description=\"Alpha for hybrid search (0=keyword, 1=vector)\")\n    message_truncation_enabled: bool = Field(\n        default=True, description=\"Enable automatic message truncation for embeddings\"\n    )\n    message_max_tokens: int = Field(default=6000, description=\"Maximum tokens for message content before truncation\")\n    message_truncation_method: TruncationMethod = Field(\n        default=TruncationMethod.START, description=\"Method to use for message truncation\"\n    )\n\n    _vector_store: WeaviateVectorStore | None = PrivateAttr(default=None)\n\n    _ROLE_KEY: ClassVar[str] = \"message_role\"\n    _TIMESTAMP_KEY: ClassVar[str] = \"message_timestamp\"\n    _MESSAGE_ID_KEY: ClassVar[str] = \"message_id\"\n\n    _CORE_MEMORY_PROPERTIES: ClassVar[list[str]] = [\n        \"message_role\",\n        \"message_timestamp\",\n        \"message_id\",\n        \"user_id\",\n        \"session_id\",\n        \"_original_id\",\n    ]\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict[str, bool]:\n        \"\"\"Define parameters to exclude during serialization.\"\"\"\n        return super().to_dict_exclude_params | {\"embedder\": True, \"_vector_store\": True, \"connection\": True}\n\n    def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params.copy())\n        data = self.model_dump(exclude=exclude, **kwargs)\n        data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n        data[\"embedder\"] = self.embedder.to_dict(\n            include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs\n        )\n\n        if \"type\" not in data:\n            data[\"type\"] = self.type\n\n        return data\n\n    def model_post_init(self, __context: Any) -&gt; None:\n        \"\"\"Initialize the Weaviate vector store and ensure schema properties.\"\"\"\n        try:\n            writer_params = WeaviateWriterVectorStoreParams(\n                collection_name=self.collection_name,\n                create_if_not_exist=self.create_if_not_exist,\n                content_property_name=self.content_property_name,\n                tenant_name=self.tenant_name,\n            )\n\n            properties_to_define = list(self._CORE_MEMORY_PROPERTIES)\n            properties_to_define.append(self.content_property_name)\n\n            self._vector_store = WeaviateVectorStore(\n                connection=self.connection,\n                **writer_params.model_dump(),\n                alpha=self.alpha,\n            )\n\n            logger.debug(\n                f\"Weaviate backend '{self.name}' (ID: {self.id}) initialized \"\n                f\"for collection '{self._vector_store._collection.name}'\"\n                f\"{f' with tenant {self.tenant_name}' if self.tenant_name else ''}.\"\n            )\n\n            if self._vector_store and self.create_if_not_exist:\n                properties_to_ensure = list(self._CORE_MEMORY_PROPERTIES)\n                properties_to_ensure.append(self.content_property_name)\n                self._vector_store.ensure_properties_exist(properties_to_ensure)\n\n            # Configure embedder truncation settings\n            self.embedder.document_embedder.truncation_enabled = self.message_truncation_enabled\n            self.embedder.document_embedder.max_input_tokens = self.message_max_tokens\n            self.embedder.document_embedder.truncation_method = self.message_truncation_method\n\n        except Exception as e:\n            logger.error(f\"Weaviate backend '{self.name}' failed to initialize vector store: {e}\")\n            raise WeaviateMemoryError(f\"Failed to initialize Weaviate vector store: {e}\") from e\n\n    def _message_to_document(self, message: Message) -&gt; Document:\n        \"\"\"Converts a Message object to a Document object for Weaviate.\"\"\"\n        if not self._vector_store:\n            raise WeaviateMemoryError(\"Vector store not initialized.\")\n\n        message_id = message.metadata.get(self._MESSAGE_ID_KEY, str(uuid.uuid4()))\n        timestamp = message.metadata.get(\"timestamp\", time.time())\n\n        doc_metadata = {\n            self._ROLE_KEY: message.role.value,\n            self._TIMESTAMP_KEY: timestamp,\n            self._MESSAGE_ID_KEY: message_id,\n            **(message.metadata or {}),\n        }\n\n        content = message.content\n        if self.message_truncation_enabled and content:\n            original_length = len(content)\n            truncated_content = truncate_text_for_embedding(\n                text=content,\n                max_tokens=self.message_max_tokens,\n                truncation_method=self.message_truncation_method\n            )\n\n            if len(truncated_content) &lt; original_length:\n                content = truncated_content\n                doc_metadata[\"truncated\"] = True\n                doc_metadata[\"original_length\"] = original_length\n                doc_metadata[\"truncated_length\"] = len(content)\n                doc_metadata[\"truncation_method\"] = self.message_truncation_method.value\n\n        sanitized_metadata = {}\n        for k, v in doc_metadata.items():\n            if self._vector_store.is_valid_property_name(k):\n                sanitized_metadata[k] = v\n            else:\n                logger.warning(f\"Skipping invalid metadata key for Weaviate: '{k}'\")\n\n        doc_id = message_id\n\n        return Document(\n            id=doc_id,\n            content=content,\n            metadata=sanitized_metadata,\n            embedding=None,\n        )\n\n    def _document_to_message(self, document: Document) -&gt; Message:\n        \"\"\"Converts a Document object from Weaviate back to a Message object.\"\"\"\n        if not document.metadata:\n            logger.warning(f\"Document {document.id} from Weaviate has no metadata. Cannot reconstruct message fully.\")\n            return Message(role=MessageRole.SYSTEM, content=document.content, metadata={\"retrieval_issue\": True})\n\n        metadata = dict(document.metadata)\n\n        role_str = metadata.pop(self._ROLE_KEY, MessageRole.USER.value)\n        try:\n            role = MessageRole(role_str)\n        except ValueError:\n            logger.warning(f\"Invalid role '{role_str}' found in document {document.id}. Defaulting to USER.\")\n            role = MessageRole.USER\n\n        timestamp = metadata.get(self._TIMESTAMP_KEY)\n        message_id = metadata.get(self._MESSAGE_ID_KEY)\n\n        if document.score is not None:\n            metadata[\"score\"] = document.score\n\n        metadata.pop(self._TIMESTAMP_KEY, None)\n        metadata.pop(self._MESSAGE_ID_KEY, None)\n\n        final_metadata = metadata\n        if timestamp is not None:\n            final_metadata[\"timestamp\"] = timestamp\n        if message_id is not None:\n            final_metadata[\"message_id\"] = message_id\n\n        return Message(role=role, content=document.content or \"\", metadata=final_metadata)\n\n    def add(self, message: Message) -&gt; None:\n        \"\"\"Adds a message to the Weaviate memory.\"\"\"\n        if self._vector_store is None:\n            raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n        if self.embedder is None:\n            raise WeaviateMemoryError(\"Embedder is required for Weaviate memory backend.\")\n\n        try:\n            document = self._message_to_document(message)\n\n            embedding_input = DocumentEmbedderInputSchema(\n                documents=[Document(id=document.id, content=document.content)]\n            )\n            embedding_result = self.embedder.execute(input_data=embedding_input)\n\n            if not embedding_result or not embedding_result.get(\"documents\"):\n                raise WeaviateMemoryError(\"Failed to generate embedding for the message.\")\n\n            document.embedding = embedding_result[\"documents\"][0].embedding\n            if not document.embedding:\n                raise WeaviateMemoryError(\"Generated embedding is empty.\")\n\n            self._vector_store.write_documents([document], content_key=self.content_property_name)\n            logger.debug(f\"Weaviate Memory ({self.collection_name}): Added message {document.id}\")\n\n        except Exception as e:\n            logger.error(f\"Error adding message to Weaviate: {e}\")\n            raise WeaviateMemoryError(f\"Error adding message to Weaviate: {e}\") from e\n\n    def get_all(self, limit: int | None = None) -&gt; list[Message]:\n        \"\"\"\n        Retrieves messages from Weaviate, sorted chronologically (oldest first).\n\n        Note: This fetches all documents and sorts client-side by timestamp.\n              May be inefficient for very large collections.\n              Returns the `limit` most recent messages if limit is specified.\n        \"\"\"\n        if self._vector_store is None:\n            raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n\n        try:\n            documents = self._vector_store.list_documents(\n                include_embeddings=False, content_key=self.content_property_name\n            )\n\n            messages = [self._document_to_message(doc) for doc in documents]\n\n            messages.sort(key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n\n            if limit is not None and limit &gt; 0:\n                retrieved_messages = messages[-limit:]\n            else:\n                retrieved_messages = messages\n\n            logger.debug(\n                f\"Weaviate Memory ({self.collection_name}): Retrieved {len(retrieved_messages)} messages\"\n                f\"{f' (limited to {limit})' if limit else ''}.\"\n            )\n            return retrieved_messages\n\n        except Exception as e:\n            logger.error(f\"Error retrieving messages from Weaviate: {e}\")\n            raise WeaviateMemoryError(f\"Error retrieving messages from Weaviate: {e}\") from e\n\n    def _prepare_filters(self, filters: dict | None = None) -&gt; dict | None:\n        \"\"\"\n        Convert simple key-value filters to the Weaviate filter format if necessary.\n        If the input `filters` already seem to be in Weaviate format (contain 'operator'\n        or 'field'), they are passed through directly. Otherwise, assumes a simple\n        dictionary where keys are fields and values are the values to match with '=='\n        operator, combined with 'AND'.\n\n        Args:\n            filters: Raw filters dictionary.\n\n        Returns:\n            Prepared filters in Weaviate-compatible format, or None.\n        \"\"\"\n        if not filters:\n            return None\n\n        if \"operator\" in filters and \"conditions\" in filters:\n            logger.debug(\"Filters appear to be in Weaviate logical format, passing through.\")\n            return filters\n        if \"field\" in filters and \"operator\" in filters and \"value\" in filters:\n            logger.debug(\"Filters appear to be in Weaviate comparison format, passing through.\")\n            return filters\n\n        logger.debug(\"Filters appear to be simple key-value, converting to Weaviate AND format.\")\n        conditions = []\n        for key, value in filters.items():\n            if self._vector_store and self._vector_store.is_valid_property_name(key):\n                conditions.append({\"field\": key, \"operator\": \"==\", \"value\": value})\n            else:\n                logger.warning(f\"Skipping filter key '{key}' as it's not a valid Weaviate property name.\")\n\n        if not conditions:\n            return None\n        return {\"operator\": \"AND\", \"conditions\": conditions}\n\n    def search(\n        self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n    ) -&gt; list[Message]:\n        \"\"\"\n        Searches for messages in Weaviate using vector similarity and/or filters.\n\n        Args:\n            query: Optional search string for semantic search.\n            filters: Optional dictionary for filtering messages by metadata.\n                     This should be in the Weaviate filter format.\n            limit: Maximum number of messages to return.\n\n        Returns:\n            List of matching messages sorted by relevance (if query provided)\n            or potentially unsorted/timestamp-sorted (if only filters provided).\n            Note: Sorting for filter-only results happens in the Memory class if needed.\n        \"\"\"\n        if self._vector_store is None:\n            raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n        if query and self.embedder is None:\n            raise WeaviateMemoryError(\"Embedder is required for search with query.\")\n\n        prepared_filters = self._prepare_filters(filters)\n\n        try:\n            effective_limit = limit if limit is not None else 10\n\n            if query:\n                embedding_input = DocumentEmbedderInputSchema(documents=[Document(id=\"query\", content=query)])\n                embedding_result = self.embedder.execute(input_data=embedding_input)\n                query_embedding = embedding_result[\"documents\"][0].embedding\n\n                if not query_embedding:\n                    raise WeaviateMemoryError(\"Failed to generate embedding for the search query.\")\n\n                documents = self._vector_store._hybrid_retrieval(\n                    query_embedding=query_embedding,\n                    query=query,\n                    filters=prepared_filters,\n                    top_k=effective_limit,\n                    exclude_document_embeddings=True,\n                    alpha=self.alpha,\n                    content_key=self.content_property_name,\n                )\n                retrieved_messages = [self._document_to_message(doc) for doc in documents]\n\n            elif prepared_filters:\n                documents = self._vector_store.filter_documents(\n                    filters=prepared_filters, content_key=self.content_property_name\n                )\n                retrieved_messages = [self._document_to_message(doc) for doc in documents]\n                if effective_limit &gt; 0:\n                    retrieved_messages = retrieved_messages[:effective_limit]\n\n            else:\n                logger.debug(\n                    f\"Weaviate Memory ({self.collection_name}): Search called with no \"\n                    f\"query or filters. Returning empty.\"\n                )\n                retrieved_messages = []\n\n            logger.debug(\n                f\"Weaviate Memory ({self.collection_name}):\"\n                f\" Found {len(retrieved_messages)} search results \"\n                f\"(Query: {'Yes' if query else 'No'}, \"\n                f\"Filters: {'Yes' if prepared_filters else 'No'}, Limit: {effective_limit})\"\n            )\n            return retrieved_messages\n\n        except Exception as e:\n            if isinstance(e, WeaviateMemoryError) and \"key missing\" in str(e):\n                logger.error(f\"Filter format error during Weaviate search. Filters received: {prepared_filters}\")\n            logger.error(f\"Error searching Weaviate memory: {e}\")\n            raise WeaviateMemoryError(f\"Error searching Weaviate memory: {e}\") from e\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Checks if the Weaviate collection associated with this memory is empty.\"\"\"\n        if self._vector_store is None:\n            raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n        try:\n            count = self._vector_store.count_documents()\n            return count == 0\n        except Exception as e:\n            logger.error(f\"Error checking if Weaviate memory is empty: {e}\")\n            raise WeaviateMemoryError(f\"Error checking if Weaviate memory is empty: {e}\") from e\n\n    def clear(self) -&gt; None:\n        \"\"\"Clears the Weaviate memory by deleting all documents in the collection/tenant.\"\"\"\n        if self._vector_store is None:\n            raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n        try:\n            count = self._vector_store.count_documents()\n            if count &gt; 0:\n                self._vector_store.delete_documents(delete_all=True)\n                logger.info(\n                    f\"Weaviate Memory ({self.collection_name}): Cleared {count} documents \"\n                    f\"{f'from tenant {self.tenant_name}' if self.tenant_name else 'from collection'}.\"\n                )\n            else:\n                logger.info(f\"Weaviate Memory ({self.collection_name}): Clear called, but memory was already empty.\")\n        except Exception as e:\n            logger.error(f\"Error clearing Weaviate memory: {e}\")\n            raise WeaviateMemoryError(f\"Error clearing Weaviate memory: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate.to_dict_exclude_params","title":"<code>to_dict_exclude_params: dict[str, bool]</code>  <code>property</code>","text":"<p>Define parameters to exclude during serialization.</p>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate.add","title":"<code>add(message)</code>","text":"<p>Adds a message to the Weaviate memory.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>def add(self, message: Message) -&gt; None:\n    \"\"\"Adds a message to the Weaviate memory.\"\"\"\n    if self._vector_store is None:\n        raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n    if self.embedder is None:\n        raise WeaviateMemoryError(\"Embedder is required for Weaviate memory backend.\")\n\n    try:\n        document = self._message_to_document(message)\n\n        embedding_input = DocumentEmbedderInputSchema(\n            documents=[Document(id=document.id, content=document.content)]\n        )\n        embedding_result = self.embedder.execute(input_data=embedding_input)\n\n        if not embedding_result or not embedding_result.get(\"documents\"):\n            raise WeaviateMemoryError(\"Failed to generate embedding for the message.\")\n\n        document.embedding = embedding_result[\"documents\"][0].embedding\n        if not document.embedding:\n            raise WeaviateMemoryError(\"Generated embedding is empty.\")\n\n        self._vector_store.write_documents([document], content_key=self.content_property_name)\n        logger.debug(f\"Weaviate Memory ({self.collection_name}): Added message {document.id}\")\n\n    except Exception as e:\n        logger.error(f\"Error adding message to Weaviate: {e}\")\n        raise WeaviateMemoryError(f\"Error adding message to Weaviate: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate.clear","title":"<code>clear()</code>","text":"<p>Clears the Weaviate memory by deleting all documents in the collection/tenant.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clears the Weaviate memory by deleting all documents in the collection/tenant.\"\"\"\n    if self._vector_store is None:\n        raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n    try:\n        count = self._vector_store.count_documents()\n        if count &gt; 0:\n            self._vector_store.delete_documents(delete_all=True)\n            logger.info(\n                f\"Weaviate Memory ({self.collection_name}): Cleared {count} documents \"\n                f\"{f'from tenant {self.tenant_name}' if self.tenant_name else 'from collection'}.\"\n            )\n        else:\n            logger.info(f\"Weaviate Memory ({self.collection_name}): Clear called, but memory was already empty.\")\n    except Exception as e:\n        logger.error(f\"Error clearing Weaviate memory: {e}\")\n        raise WeaviateMemoryError(f\"Error clearing Weaviate memory: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate.get_all","title":"<code>get_all(limit=None)</code>","text":"<p>Retrieves messages from Weaviate, sorted chronologically (oldest first).</p> This fetches all documents and sorts client-side by timestamp. <p>May be inefficient for very large collections. Returns the <code>limit</code> most recent messages if limit is specified.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>def get_all(self, limit: int | None = None) -&gt; list[Message]:\n    \"\"\"\n    Retrieves messages from Weaviate, sorted chronologically (oldest first).\n\n    Note: This fetches all documents and sorts client-side by timestamp.\n          May be inefficient for very large collections.\n          Returns the `limit` most recent messages if limit is specified.\n    \"\"\"\n    if self._vector_store is None:\n        raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n\n    try:\n        documents = self._vector_store.list_documents(\n            include_embeddings=False, content_key=self.content_property_name\n        )\n\n        messages = [self._document_to_message(doc) for doc in documents]\n\n        messages.sort(key=lambda msg: msg.metadata.get(\"timestamp\", 0))\n\n        if limit is not None and limit &gt; 0:\n            retrieved_messages = messages[-limit:]\n        else:\n            retrieved_messages = messages\n\n        logger.debug(\n            f\"Weaviate Memory ({self.collection_name}): Retrieved {len(retrieved_messages)} messages\"\n            f\"{f' (limited to {limit})' if limit else ''}.\"\n        )\n        return retrieved_messages\n\n    except Exception as e:\n        logger.error(f\"Error retrieving messages from Weaviate: {e}\")\n        raise WeaviateMemoryError(f\"Error retrieving messages from Weaviate: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate.is_empty","title":"<code>is_empty()</code>","text":"<p>Checks if the Weaviate collection associated with this memory is empty.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Checks if the Weaviate collection associated with this memory is empty.\"\"\"\n    if self._vector_store is None:\n        raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n    try:\n        count = self._vector_store.count_documents()\n        return count == 0\n    except Exception as e:\n        logger.error(f\"Error checking if Weaviate memory is empty: {e}\")\n        raise WeaviateMemoryError(f\"Error checking if Weaviate memory is empty: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate.model_post_init","title":"<code>model_post_init(__context)</code>","text":"<p>Initialize the Weaviate vector store and ensure schema properties.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>def model_post_init(self, __context: Any) -&gt; None:\n    \"\"\"Initialize the Weaviate vector store and ensure schema properties.\"\"\"\n    try:\n        writer_params = WeaviateWriterVectorStoreParams(\n            collection_name=self.collection_name,\n            create_if_not_exist=self.create_if_not_exist,\n            content_property_name=self.content_property_name,\n            tenant_name=self.tenant_name,\n        )\n\n        properties_to_define = list(self._CORE_MEMORY_PROPERTIES)\n        properties_to_define.append(self.content_property_name)\n\n        self._vector_store = WeaviateVectorStore(\n            connection=self.connection,\n            **writer_params.model_dump(),\n            alpha=self.alpha,\n        )\n\n        logger.debug(\n            f\"Weaviate backend '{self.name}' (ID: {self.id}) initialized \"\n            f\"for collection '{self._vector_store._collection.name}'\"\n            f\"{f' with tenant {self.tenant_name}' if self.tenant_name else ''}.\"\n        )\n\n        if self._vector_store and self.create_if_not_exist:\n            properties_to_ensure = list(self._CORE_MEMORY_PROPERTIES)\n            properties_to_ensure.append(self.content_property_name)\n            self._vector_store.ensure_properties_exist(properties_to_ensure)\n\n        # Configure embedder truncation settings\n        self.embedder.document_embedder.truncation_enabled = self.message_truncation_enabled\n        self.embedder.document_embedder.max_input_tokens = self.message_max_tokens\n        self.embedder.document_embedder.truncation_method = self.message_truncation_method\n\n    except Exception as e:\n        logger.error(f\"Weaviate backend '{self.name}' failed to initialize vector store: {e}\")\n        raise WeaviateMemoryError(f\"Failed to initialize Weaviate vector store: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate.search","title":"<code>search(query=None, filters=None, limit=None)</code>","text":"<p>Searches for messages in Weaviate using vector similarity and/or filters.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str | None</code> <p>Optional search string for semantic search.</p> <code>None</code> <code>filters</code> <code>dict[str, Any] | None</code> <p>Optional dictionary for filtering messages by metadata.      This should be in the Weaviate filter format.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Maximum number of messages to return.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>list[Message]</code> <p>List of matching messages sorted by relevance (if query provided)</p> <code>list[Message]</code> <p>or potentially unsorted/timestamp-sorted (if only filters provided).</p> <code>Note</code> <code>list[Message]</code> <p>Sorting for filter-only results happens in the Memory class if needed.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>def search(\n    self, query: str | None = None, filters: dict[str, Any] | None = None, limit: int | None = None\n) -&gt; list[Message]:\n    \"\"\"\n    Searches for messages in Weaviate using vector similarity and/or filters.\n\n    Args:\n        query: Optional search string for semantic search.\n        filters: Optional dictionary for filtering messages by metadata.\n                 This should be in the Weaviate filter format.\n        limit: Maximum number of messages to return.\n\n    Returns:\n        List of matching messages sorted by relevance (if query provided)\n        or potentially unsorted/timestamp-sorted (if only filters provided).\n        Note: Sorting for filter-only results happens in the Memory class if needed.\n    \"\"\"\n    if self._vector_store is None:\n        raise WeaviateMemoryError(\"Weaviate vector store not initialized.\")\n    if query and self.embedder is None:\n        raise WeaviateMemoryError(\"Embedder is required for search with query.\")\n\n    prepared_filters = self._prepare_filters(filters)\n\n    try:\n        effective_limit = limit if limit is not None else 10\n\n        if query:\n            embedding_input = DocumentEmbedderInputSchema(documents=[Document(id=\"query\", content=query)])\n            embedding_result = self.embedder.execute(input_data=embedding_input)\n            query_embedding = embedding_result[\"documents\"][0].embedding\n\n            if not query_embedding:\n                raise WeaviateMemoryError(\"Failed to generate embedding for the search query.\")\n\n            documents = self._vector_store._hybrid_retrieval(\n                query_embedding=query_embedding,\n                query=query,\n                filters=prepared_filters,\n                top_k=effective_limit,\n                exclude_document_embeddings=True,\n                alpha=self.alpha,\n                content_key=self.content_property_name,\n            )\n            retrieved_messages = [self._document_to_message(doc) for doc in documents]\n\n        elif prepared_filters:\n            documents = self._vector_store.filter_documents(\n                filters=prepared_filters, content_key=self.content_property_name\n            )\n            retrieved_messages = [self._document_to_message(doc) for doc in documents]\n            if effective_limit &gt; 0:\n                retrieved_messages = retrieved_messages[:effective_limit]\n\n        else:\n            logger.debug(\n                f\"Weaviate Memory ({self.collection_name}): Search called with no \"\n                f\"query or filters. Returning empty.\"\n            )\n            retrieved_messages = []\n\n        logger.debug(\n            f\"Weaviate Memory ({self.collection_name}):\"\n            f\" Found {len(retrieved_messages)} search results \"\n            f\"(Query: {'Yes' if query else 'No'}, \"\n            f\"Filters: {'Yes' if prepared_filters else 'No'}, Limit: {effective_limit})\"\n        )\n        return retrieved_messages\n\n    except Exception as e:\n        if isinstance(e, WeaviateMemoryError) and \"key missing\" in str(e):\n            logger.error(f\"Filter format error during Weaviate search. Filters received: {prepared_filters}\")\n        logger.error(f\"Error searching Weaviate memory: {e}\")\n        raise WeaviateMemoryError(f\"Error searching Weaviate memory: {e}\") from e\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.Weaviate.to_dict","title":"<code>to_dict(include_secure_params=False, for_tracing=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, for_tracing: bool = False, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params.copy())\n    data = self.model_dump(exclude=exclude, **kwargs)\n    data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing)\n    data[\"embedder\"] = self.embedder.to_dict(\n        include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs\n    )\n\n    if \"type\" not in data:\n        data[\"type\"] = self.type\n\n    return data\n</code></pre>"},{"location":"dynamiq/memory/backends/weaviate/#dynamiq.memory.backends.weaviate.WeaviateMemoryError","title":"<code>WeaviateMemoryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for Weaviate Memory Backend errors.</p> Source code in <code>dynamiq/memory/backends/weaviate.py</code> <pre><code>class WeaviateMemoryError(Exception):\n    \"\"\"Base exception class for Weaviate Memory Backend errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/dry_run/","title":"Dry run","text":""},{"location":"dynamiq/nodes/dry_run/#dynamiq.nodes.dry_run.DryRunMixin","title":"<code>DryRunMixin</code>","text":"<p>Mixin class to add dry run functionality to vector stores.</p> <p>This mixin provides resource tracking and cleanup capabilities for vector stores operating in dry run mode. It tracks ingested documents and created collections to enable cleanup based on the DryRunConfig settings.</p> Source code in <code>dynamiq/nodes/dry_run.py</code> <pre><code>class DryRunMixin:\n    \"\"\"Mixin class to add dry run functionality to vector stores.\n\n    This mixin provides resource tracking and cleanup capabilities for vector stores\n    operating in dry run mode. It tracks ingested documents and created collections\n    to enable cleanup based on the DryRunConfig settings.\n    \"\"\"\n\n    def __init__(self, dry_run_config: DryRunConfig | None = None):\n        \"\"\"Initialize the DryRunMixin.\n\n        Args:\n            dry_run_config: Configuration for dry run behavior. If None, default config is used.\n        \"\"\"\n        self._dry_run_config = dry_run_config or DryRunConfig()\n        self._tracked_documents: list[str] = []\n        self._tracked_collection: str | None = None\n\n    def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n        \"\"\"Delete documents by their IDs.\n\n        Args:\n            document_ids: List of document IDs to delete.\n            delete_all: Whether to delete all documents.\n        \"\"\"\n        pass\n\n    def delete_collection(self, collection_name: str) -&gt; None:\n        \"\"\"Delete a collection by its name.\n\n        Args:\n            collection_name: Name of the collection to delete.\n        \"\"\"\n        pass\n\n    def _track_documents(self, document_ids: list[str]) -&gt; None:\n        \"\"\"Track multiple documents for potential cleanup.\n\n        Args:\n            document_ids: List of document IDs to track.\n        \"\"\"\n        self._tracked_documents.extend(document_ids)\n        logger.debug(f\"Tracked {len(document_ids)} documents\")\n\n    def _track_collection(self, collection_name: str) -&gt; None:\n        \"\"\"Track a collection for potential cleanup.\n\n        Args:\n            collection_name: Name of the collection to track.\n        \"\"\"\n        self._tracked_collection = collection_name\n        logger.debug(f\"Tracked collection: {collection_name}\")\n\n    def dry_run_cleanup(self, dry_run_config: DryRunConfig) -&gt; None:\n        \"\"\"Clean up tracked resources based on configuration.\n\n        Args:\n            dry_run_config: Configuration for dry run behavior.\n        \"\"\"\n\n        if dry_run_config.delete_documents and self._tracked_documents:\n            try:\n                self.delete_documents(list(self._tracked_documents))\n                logger.debug(f\"Cleaned up {len(self._tracked_documents)} tracked documents\")\n                self._tracked_documents = []\n            except Exception as e:\n                logger.error(f\"Failed to clean up tracked documents: {e}\")\n\n        if dry_run_config.delete_collection and self._tracked_collection:\n            try:\n                self.delete_collection(self._tracked_collection)\n                logger.debug(f\"Cleaned up collection: {self._tracked_collection}\")\n                self._tracked_collection = None\n            except Exception as e:\n                logger.error(f\"Failed to clean up collection {self._tracked_collection}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/dry_run/#dynamiq.nodes.dry_run.DryRunMixin.__init__","title":"<code>__init__(dry_run_config=None)</code>","text":"<p>Initialize the DryRunMixin.</p> <p>Parameters:</p> Name Type Description Default <code>dry_run_config</code> <code>DryRunConfig | None</code> <p>Configuration for dry run behavior. If None, default config is used.</p> <code>None</code> Source code in <code>dynamiq/nodes/dry_run.py</code> <pre><code>def __init__(self, dry_run_config: DryRunConfig | None = None):\n    \"\"\"Initialize the DryRunMixin.\n\n    Args:\n        dry_run_config: Configuration for dry run behavior. If None, default config is used.\n    \"\"\"\n    self._dry_run_config = dry_run_config or DryRunConfig()\n    self._tracked_documents: list[str] = []\n    self._tracked_collection: str | None = None\n</code></pre>"},{"location":"dynamiq/nodes/dry_run/#dynamiq.nodes.dry_run.DryRunMixin.delete_collection","title":"<code>delete_collection(collection_name)</code>","text":"<p>Delete a collection by its name.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>Name of the collection to delete.</p> required Source code in <code>dynamiq/nodes/dry_run.py</code> <pre><code>def delete_collection(self, collection_name: str) -&gt; None:\n    \"\"\"Delete a collection by its name.\n\n    Args:\n        collection_name: Name of the collection to delete.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/dry_run/#dynamiq.nodes.dry_run.DryRunMixin.delete_documents","title":"<code>delete_documents(document_ids=None, delete_all=False)</code>","text":"<p>Delete documents by their IDs.</p> <p>Parameters:</p> Name Type Description Default <code>document_ids</code> <code>list[str] | None</code> <p>List of document IDs to delete.</p> <code>None</code> <code>delete_all</code> <code>bool</code> <p>Whether to delete all documents.</p> <code>False</code> Source code in <code>dynamiq/nodes/dry_run.py</code> <pre><code>def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n    \"\"\"Delete documents by their IDs.\n\n    Args:\n        document_ids: List of document IDs to delete.\n        delete_all: Whether to delete all documents.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/dry_run/#dynamiq.nodes.dry_run.DryRunMixin.dry_run_cleanup","title":"<code>dry_run_cleanup(dry_run_config)</code>","text":"<p>Clean up tracked resources based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>dry_run_config</code> <code>DryRunConfig</code> <p>Configuration for dry run behavior.</p> required Source code in <code>dynamiq/nodes/dry_run.py</code> <pre><code>def dry_run_cleanup(self, dry_run_config: DryRunConfig) -&gt; None:\n    \"\"\"Clean up tracked resources based on configuration.\n\n    Args:\n        dry_run_config: Configuration for dry run behavior.\n    \"\"\"\n\n    if dry_run_config.delete_documents and self._tracked_documents:\n        try:\n            self.delete_documents(list(self._tracked_documents))\n            logger.debug(f\"Cleaned up {len(self._tracked_documents)} tracked documents\")\n            self._tracked_documents = []\n        except Exception as e:\n            logger.error(f\"Failed to clean up tracked documents: {e}\")\n\n    if dry_run_config.delete_collection and self._tracked_collection:\n        try:\n            self.delete_collection(self._tracked_collection)\n            logger.debug(f\"Cleaned up collection: {self._tracked_collection}\")\n            self._tracked_collection = None\n        except Exception as e:\n            logger.error(f\"Failed to clean up collection {self._tracked_collection}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/exceptions/","title":"Exceptions","text":""},{"location":"dynamiq/nodes/exceptions/#dynamiq.nodes.exceptions.NodeConditionFailedException","title":"<code>NodeConditionFailedException</code>","text":"<p>               Bases: <code>NodeException</code></p> <p>Exception raised when a node's condition fails to be met.</p> <p>This exception is a subclass of NodeException and inherits its attributes and methods.</p> Source code in <code>dynamiq/nodes/exceptions.py</code> <pre><code>class NodeConditionFailedException(NodeException):\n    \"\"\"\n    Exception raised when a node's condition fails to be met.\n\n    This exception is a subclass of NodeException and inherits its attributes and methods.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/exceptions/#dynamiq.nodes.exceptions.NodeConditionSkippedException","title":"<code>NodeConditionSkippedException</code>","text":"<p>               Bases: <code>NodeException</code></p> <p>Exception raised when a node's condition skipped.</p> <p>This exception is a subclass of NodeException and inherits its attributes and methods.</p> Source code in <code>dynamiq/nodes/exceptions.py</code> <pre><code>class NodeConditionSkippedException(NodeException):\n    \"\"\"\n    Exception raised when a node's condition skipped.\n\n    This exception is a subclass of NodeException and inherits its attributes and methods.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/exceptions/#dynamiq.nodes.exceptions.NodeException","title":"<code>NodeException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for node-related errors.</p> <p>Parameters:</p> Name Type Description Default <code>failed_depend</code> <code>NodeDependency</code> <p>The dependency that caused the exception. Defaults to None.</p> <code>None</code> <code>message</code> <code>str</code> <p>Additional error message. Defaults to None.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>failed_depend</code> <code>NodeDependency</code> <p>The dependency that caused the exception.</p> Source code in <code>dynamiq/nodes/exceptions.py</code> <pre><code>class NodeException(Exception):\n    \"\"\"\n    Base exception class for node-related errors.\n\n    Args:\n        failed_depend (NodeDependency, optional): The dependency that caused the exception. Defaults to None.\n        message (str, optional): Additional error message. Defaults to None.\n\n    Attributes:\n        failed_depend (NodeDependency): The dependency that caused the exception.\n    \"\"\"\n\n    def __init__(\n        self, failed_depend: Optional[\"NodeDependency\"] = None, message: str = None, recoverable: bool = False\n    ):\n        super().__init__(message)\n        self.failed_depend = failed_depend\n        self.recoverable = recoverable\n</code></pre>"},{"location":"dynamiq/nodes/exceptions/#dynamiq.nodes.exceptions.NodeFailedException","title":"<code>NodeFailedException</code>","text":"<p>               Bases: <code>NodeException</code></p> <p>Exception raised when a node fails to execute.</p> <p>This exception is a subclass of NodeException and inherits its attributes and methods.</p> Source code in <code>dynamiq/nodes/exceptions.py</code> <pre><code>class NodeFailedException(NodeException):\n    \"\"\"\n    Exception raised when a node fails to execute.\n\n    This exception is a subclass of NodeException and inherits its attributes and methods.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/exceptions/#dynamiq.nodes.exceptions.NodeSkippedException","title":"<code>NodeSkippedException</code>","text":"<p>               Bases: <code>NodeException</code></p> <p>Exception raised when a node is skipped during execution.</p> <p>This exception is a subclass of NodeException and inherits its attributes and methods.</p> Source code in <code>dynamiq/nodes/exceptions.py</code> <pre><code>class NodeSkippedException(NodeException):\n    \"\"\"\n    Exception raised when a node is skipped during execution.\n\n    This exception is a subclass of NodeException and inherits its attributes and methods.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/managers/","title":"Managers","text":""},{"location":"dynamiq/nodes/managers/#dynamiq.nodes.managers.NodeManager","title":"<code>NodeManager</code>","text":"<p>A class for managing and retrieving node types.</p> Source code in <code>dynamiq/nodes/managers.py</code> <pre><code>class NodeManager:\n    \"\"\"A class for managing and retrieving node types.\"\"\"\n\n    @staticmethod\n    def get_node_by_type(node_type: str) -&gt; type[Node]:\n        \"\"\"\n        Retrieves a node class based on the given node type.\n\n        Args:\n            node_type (str): The type of node to retrieve.\n\n        Returns:\n            type[Node]: The node class corresponding to the given type.\n\n        Raises:\n            ValueError: If the node type is not found.\n\n        Example:\n            &gt;&gt;&gt; node_class = NodeManager.get_node_by_type(\"LLM_OPENAI\")\n            &gt;&gt;&gt; isinstance(node_class, type(Node))\n            True\n        \"\"\"\n        try:\n            entity_module, entity_name = node_type.rsplit(\".\", 1)\n            imported_module = importlib.import_module(entity_module)\n            if entity := getattr(imported_module, entity_name, None):\n                return entity\n        except (ModuleNotFoundError, ImportError):\n            raise ValueError(f\"Node type {node_type} not found\")\n</code></pre>"},{"location":"dynamiq/nodes/managers/#dynamiq.nodes.managers.NodeManager.get_node_by_type","title":"<code>get_node_by_type(node_type)</code>  <code>staticmethod</code>","text":"<p>Retrieves a node class based on the given node type.</p> <p>Parameters:</p> Name Type Description Default <code>node_type</code> <code>str</code> <p>The type of node to retrieve.</p> required <p>Returns:</p> Type Description <code>type[Node]</code> <p>type[Node]: The node class corresponding to the given type.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the node type is not found.</p> Example <p>node_class = NodeManager.get_node_by_type(\"LLM_OPENAI\") isinstance(node_class, type(Node)) True</p> Source code in <code>dynamiq/nodes/managers.py</code> <pre><code>@staticmethod\ndef get_node_by_type(node_type: str) -&gt; type[Node]:\n    \"\"\"\n    Retrieves a node class based on the given node type.\n\n    Args:\n        node_type (str): The type of node to retrieve.\n\n    Returns:\n        type[Node]: The node class corresponding to the given type.\n\n    Raises:\n        ValueError: If the node type is not found.\n\n    Example:\n        &gt;&gt;&gt; node_class = NodeManager.get_node_by_type(\"LLM_OPENAI\")\n        &gt;&gt;&gt; isinstance(node_class, type(Node))\n        True\n    \"\"\"\n    try:\n        entity_module, entity_name = node_type.rsplit(\".\", 1)\n        imported_module = importlib.import_module(entity_module)\n        if entity := getattr(imported_module, entity_name, None):\n            return entity\n    except (ModuleNotFoundError, ImportError):\n        raise ValueError(f\"Node type {node_type} not found\")\n</code></pre>"},{"location":"dynamiq/nodes/node/","title":"Node","text":""},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.CachingConfig","title":"<code>CachingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for node caching.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether caching is enabled for the node.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class CachingConfig(BaseModel):\n    \"\"\"\n    Configuration for node caching.\n\n    Attributes:\n        enabled (bool): Whether caching is enabled for the node.\n    \"\"\"\n    enabled: bool = False\n\n    def to_dict(self, for_tracing: bool = False, **kwargs) -&gt; dict:\n        if for_tracing and not self.enabled:\n            return {\"enabled\": False}\n        return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.ConnectionNode","title":"<code>ConnectionNode</code>","text":"<p>               Bases: <code>Node</code>, <code>ABC</code></p> <p>Abstract base class for nodes that require a connection.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>BaseConnection | None</code> <p>The connection to use.</p> <code>client</code> <code>Any | None</code> <p>The client instance.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class ConnectionNode(Node, ABC):\n    \"\"\"\n    Abstract base class for nodes that require a connection.\n\n    Attributes:\n        connection (BaseConnection | None): The connection to use.\n        client (Any | None): The client instance.\n    \"\"\"\n\n    connection: BaseConnection | None = None\n    client: Any | None = None\n\n    @model_validator(mode=\"after\")\n    def validate_connection_client(self):\n        \"\"\"Validate that either connection or client is specified.\"\"\"\n        if not self.client and not self.connection:\n            raise ValueError(\"'connection' or 'client' should be specified\")\n        return self\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize components for the node.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.client is None:\n            self.client = connection_manager.get_connection_client(\n                connection=self.connection\n            )\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.ConnectionNode.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize components for the node.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize components for the node.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.client is None:\n        self.client = connection_manager.get_connection_client(\n            connection=self.connection\n        )\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.ConnectionNode.validate_connection_client","title":"<code>validate_connection_client()</code>","text":"<p>Validate that either connection or client is specified.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_connection_client(self):\n    \"\"\"Validate that either connection or client is specified.\"\"\"\n    if not self.client and not self.connection:\n        raise ValueError(\"'connection' or 'client' should be specified\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.ErrorHandling","title":"<code>ErrorHandling</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for error handling in nodes.</p> <p>Attributes:</p> Name Type Description <code>timeout_seconds</code> <code>float | None</code> <p>Timeout in seconds for node execution.</p> <code>retry_interval_seconds</code> <code>float</code> <p>Interval between retries in seconds.</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retries.</p> <code>backoff_rate</code> <code>float</code> <p>Rate of increase for retry intervals.</p> <code>behavior</code> <code>Behavior</code> <p>Behavior for error handling.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class ErrorHandling(BaseModel):\n    \"\"\"\n    Configuration for error handling in nodes.\n\n    Attributes:\n        timeout_seconds (float | None): Timeout in seconds for node execution.\n        retry_interval_seconds (float): Interval between retries in seconds.\n        max_retries (int): Maximum number of retries.\n        backoff_rate (float): Rate of increase for retry intervals.\n        behavior (Behavior): Behavior for error handling.\n    \"\"\"\n    timeout_seconds: float | None = None\n    retry_interval_seconds: float = 1\n    max_retries: int = 0\n    backoff_rate: float = 1\n    behavior: Behavior = Behavior.RAISE\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.InputTransformer","title":"<code>InputTransformer</code>","text":"<p>               Bases: <code>Transformer</code></p> <p>Input transformer for nodes.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class InputTransformer(Transformer):\n    \"\"\"Input transformer for nodes.\"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node","title":"<code>Node</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Runnable</code>, <code>DryRunMixin</code>, <code>ABC</code></p> <p>Abstract base class for all nodes in the workflow.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the node.</p> <code>name</code> <code>str | None</code> <p>Optional name for the node.</p> <code>group</code> <code>NodeGroup</code> <p>Group the node belongs to.</p> <code>description</code> <code>str | None</code> <p>Optional description for the node.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Error handling configuration.</p> <code>input_transformer</code> <code>InputTransformer</code> <p>Input data transformer.</p> <code>output_transformer</code> <code>OutputTransformer</code> <p>Output data transformer.</p> <code>caching</code> <code>CachingConfig</code> <p>Caching configuration.</p> <code>depends</code> <code>list[NodeDependency]</code> <p>List of node dependencies.</p> <code>metadata</code> <code>NodeMetadata | None</code> <p>Optional metadata for the node.</p> <code>is_postponed_component_init</code> <code>bool</code> <p>Whether component initialization is postponed.</p> <code>is_optimized_for_agents</code> <code>bool</code> <p>Whether to optimize output for agents. By default is set to False.</p> <code>is_files_allowed</code> <code>bool</code> <p>Whether the node is permitted to access files. By default is set to False.</p> <code>_json_schema_fields</code> <code>list[str]</code> <p>List of parameter names that will be used when generating json schema with _generate_json_schema.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class Node(BaseModel, Runnable, DryRunMixin, ABC):\n    \"\"\"\n    Abstract base class for all nodes in the workflow.\n\n    Attributes:\n        id (str): Unique identifier for the node.\n        name (str | None): Optional name for the node.\n        group (NodeGroup): Group the node belongs to.\n        description (str | None): Optional description for the node.\n        error_handling (ErrorHandling): Error handling configuration.\n        input_transformer (InputTransformer): Input data transformer.\n        output_transformer (OutputTransformer): Output data transformer.\n        caching (CachingConfig): Caching configuration.\n        depends (list[NodeDependency]): List of node dependencies.\n        metadata (NodeMetadata | None): Optional metadata for the node.\n        is_postponed_component_init (bool): Whether component initialization is postponed.\n        is_optimized_for_agents (bool): Whether to optimize output for agents. By default is set to False.\n        is_files_allowed (bool): Whether the node is permitted to access files. By default is set to False.\n        _json_schema_fields (list[str]): List of parameter names that will be used when generating json schema\n          with _generate_json_schema.\n\n    \"\"\"\n    id: str = Field(default_factory=generate_uuid)\n    name: str | None = None\n    description: str | None = None\n    group: NodeGroup\n    error_handling: ErrorHandling = Field(default_factory=ErrorHandling)\n    input_transformer: InputTransformer = Field(default_factory=InputTransformer)\n    input_mapping: dict[str, Any] = {}\n    output_transformer: OutputTransformer = Field(default_factory=OutputTransformer)\n    caching: CachingConfig = Field(default_factory=CachingConfig)\n    streaming: StreamingConfig = Field(default_factory=StreamingConfig)\n    approval: ApprovalConfig = Field(default_factory=ApprovalConfig)\n    depends: list[NodeDependency] = []\n    metadata: NodeMetadata | None = None\n\n    is_postponed_component_init: bool = False\n    is_optimized_for_agents: bool = False\n    is_files_allowed: bool = Field(default=False, description=\"Whether the node is permitted to access files.\")\n\n    _output_references: NodeOutputReferences = PrivateAttr()\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: type[BaseModel] | None = None\n    callbacks: list[NodeCallbackHandler] = []\n    _json_schema_fields: ClassVar[list[str]] = []\n    _clone_init_methods_names: ClassVar[list[str]] = [\"reset_run_state\"]\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        if not self.is_postponed_component_init:\n            self.init_components()\n\n        self._output_references = NodeOutputReferences(node=self)\n\n    @classmethod\n    def _generate_json_schema(cls, fields: list[str] = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Generates base json schema of Node for specified parameters.\n        This schema is designed for compatibility with the WorkflowYamlParser,\n        containing enough partial information to instantiate an Node.\n        Parameters name to be included in the schema are either defined in the _json_schema_fields class variable or\n        passed via the fields parameter.\n\n        Supported Nodes: Simple (non-nested) nodes and agents.\n\n        Args:\n            fields (list[str]): List of parameters to include in schema.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: Generated json schema.\n        \"\"\"\n        fields_to_include = {}\n        generated_schemas = {}\n        for name in fields or cls._json_schema_fields:\n            field = cls.model_fields[name]\n            annotation = clear_annotation(field.annotation)\n\n            schema_annotation = annotation\n            if isinstance(annotation, type) and issubclass(annotation, BaseModel) and annotation is not BaseModel:\n                schema_annotation = object\n\n            parameter_name = name\n            if field.alias:\n                parameter_name = field.alias\n            if hasattr(annotation, \"_generate_json_schema\"):\n                generated_schemas[name] = annotation._generate_json_schema()\n            else:\n                description = (\n                    field.description\n                    if field.description\n                    else (\n                        annotation.__doc__\n                        if issubclass(annotation, BaseModel) and annotation.__doc__\n                        else \"No description.\"\n                    )\n                )\n                fields_to_include[parameter_name] = (schema_annotation, Field(..., description=description))\n\n        model = create_model(cls.__name__, **fields_to_include)\n        schema = model.model_json_schema()\n        schema[\"additionalProperties\"] = False\n        for param, param_schema in generated_schemas.items():\n            schema[\"properties\"][param] = param_schema\n\n        class_type = f\"{cls.__module__.rsplit('.', 1)[0]}.{cls.__name__}\"\n\n        schema[\"properties\"][\"type\"] = {\"type\": \"string\", \"enum\": [class_type]}\n\n        if \"required\" not in schema:\n            schema[\"required\"] = []\n        schema[\"required\"].append(\"type\")\n\n        schema[\"type\"] = \"object\"\n        return schema\n\n    @computed_field\n    @cached_property\n    def type(self) -&gt; str:\n        return f\"{self.__module__.rsplit('.', 1)[0]}.{self.__class__.__name__}\"\n\n    @staticmethod\n    def _validate_dependency_status(depend: NodeDependency, depends_result: dict[str, RunnableResult]):\n        \"\"\"\n        Validate the status of a dependency.\n\n        Args:\n            depend (NodeDependency): The dependency to validate.\n            depends_result (dict[str, RunnableResult]): Results of dependent nodes.\n\n        Raises:\n            NodeException: If the dependency result is missing.\n            NodeFailedException: If the dependency failed.\n            NodeSkippedException: If the dependency was skipped.\n        \"\"\"\n        if not (dep_result := depends_result.get(depend.node.id)):\n            raise NodeException(\n                failed_depend=depend,\n                message=f\"Dependency {depend.node.id}: result missed\",\n            )\n\n        if dep_result.status == RunnableStatus.FAILURE and depend.node.error_handling.behavior == Behavior.RAISE:\n            raise NodeFailedException(\n                failed_depend=depend, message=f\"Dependency {depend.node.id}: failed\"\n            )\n\n        if dep_result.status == RunnableStatus.SKIP and depend.node.error_handling.behavior == Behavior.RAISE:\n            raise NodeSkippedException(failed_depend=depend, message=f\"Dependency {depend.node.id}: skipped\")\n\n    @staticmethod\n    def _validate_dependency_option(depend: NodeDependency, depends_result: dict[str, RunnableResult]):\n        \"\"\"\n        Validate the option of a dependency.\n\n        Args:\n            depend (NodeDependency): The dependency to validate.\n            depends_result (dict[str, RunnableResult]): Results of dependent nodes.\n\n        Raises:\n            NodeConditionFailedException: If the dependency option is not met.\n            NodeConditionSkippedException: If the dependency option is skipped.\n        \"\"\"\n        if (\n            (dep_output_data := depends_result.get(depend.node.id))\n            and (isinstance(dep_output_data.output, dict))\n            and (dep_condition_result := dep_output_data.output.get(depend.option))\n        ):\n            if dep_condition_result.status == RunnableStatus.FAILURE:\n                raise NodeConditionFailedException(\n                    failed_depend=depend,\n                    message=f\"Dependency {depend.node.id} option {depend.option}: result is false\",\n                )\n            if dep_condition_result.status == RunnableStatus.SKIP:\n                raise NodeConditionSkippedException(\n                    failed_depend=depend,\n                    message=f\"Dependency {depend.node.id} option {depend.option}: skipped\",\n                )\n\n    @staticmethod\n    def _validate_dependency_condition(depend: NodeDependency, depends_result: dict[str, RunnableResult]):\n        \"\"\"\n        Validate the result condition of a dependency.\n\n        Args:\n            depend (NodeDependency): The dependency to validate.\n            depends_result (dict[str, RunnableResult]): Results of dependent nodes.\n\n        Raises:\n            NodeConditionFailedException: If the dependency result condition is not met.\n        \"\"\"\n        if dep_result := depends_result.get(depend.node.id):\n            from dynamiq.nodes.operators.operators import Choice\n\n            if not Choice.evaluate(depend.condition, dep_result.to_dict()):\n                raise NodeConditionFailedException(\n                    failed_depend=depend,\n                    message=f\"Dependency {depend.node.id} result condition `{depend.condition}`: result is false\",\n                )\n\n    @staticmethod\n    def _validate_input_mapping_value_func(func: Callable):\n        \"\"\"\n        Validate input mapping value function.\n\n        Args:\n            func (Callable): Input mapping value function.\n\n        Raises:\n            ValueError: If the function does not accept 'inputs' and 'outputs' or **kwargs.\n        \"\"\"\n        params = inspect.signature(func).parameters\n\n        # Check if the function accepts the at least 'inputs' and 'outputs' parameters\n        if len(params) &gt;= 2:\n            return\n\n        # Check if the function accepts **kwargs\n        elif params and list(params.values())[0].kind == inspect.Parameter.VAR_KEYWORD:\n            return\n\n        raise ValueError(f\"Input function '{func.__name__}' must accept parameters 'inputs' and 'outputs' or **kwargs.\")\n\n    def validate_depends(self, depends_result: dict[str, RunnableResult]):\n        \"\"\"\n        Validate all dependencies of the node.\n\n        Args:\n            depends_result (dict): Results of dependent nodes.\n            input_data (dict): Input data for the node.\n\n        Raises:\n            Various exceptions based on dependency validation results.\n        \"\"\"\n        for dep in self.depends:\n            self._validate_dependency_status(depend=dep, depends_result=depends_result)\n            if dep.condition:\n                self._validate_dependency_condition(depend=dep, depends_result=depends_result)\n            if dep.option:\n                self._validate_dependency_option(depend=dep, depends_result=depends_result)\n\n    def validate_input_schema(self, input_data: dict[str, Any], **kwargs) -&gt; dict[str, Any] | BaseModel:\n        \"\"\"\n        Validate input data against the input schema. Returns instance of input_schema if it is provided.\n\n        Args:\n            input_data (Any): Input data to validate.\n\n        Raises:\n            NodeException: If input data does not match the input schema.\n        \"\"\"\n        from dynamiq.nodes.agents.exceptions import RecoverableAgentException\n\n        if self.input_schema:\n            try:\n                return self.input_schema.model_validate(\n                    input_data, context=kwargs | self.get_context_for_input_schema()\n                )\n            except Exception as e:\n                if kwargs.get(\"recoverable_error\", False):\n                    raise RecoverableAgentException(f\"Input data validation failed: {e}\")\n                raise e\n\n        return input_data\n\n    def transform_input(\n        self, input_data: dict, depends_result: dict[Any, RunnableResult], use_input_transformer: bool = True, **kwargs\n    ) -&gt; dict:\n        \"\"\"\n        Transform input data for the node.\n\n        Args:\n            input_data (dict): Input data for the node.\n            depends_result (dict): Results of dependent nodes.\n            use_input_transformer (bool): Determines if InputTransformer will be applied to the input.\n\n        Raises:\n            NodeException: If a dependency result is missing or input mapping fails.\n\n        Returns:\n            dict: Transformed input data.\n        \"\"\"\n        # Apply input transformer\n        if (self.input_transformer.path or self.input_transformer.selector) and use_input_transformer:\n            depends_result_as_dict = {k: result.to_depend_dict() for k, result in depends_result.items()}\n            inputs = self.transform(input_data | depends_result_as_dict, self.input_transformer)\n        else:\n            inputs = input_data | {k: result.to_tracing_depend_dict() for k, result in depends_result.items()}\n\n        # Apply input bindings\n        for key, value in self.input_mapping.items():\n            if isinstance(value, NodeOutputReference):\n                depend_result = depends_result.get(value.node.id)\n                if not depend_result:\n                    raise NodeException(message=f\"Dependency {value.node.id}: result not found.\")\n                if value.output_key not in depend_result.output:\n                    raise NodeException(message=f\"Dependency {value.node.id} output {value.output_key}: not found.\")\n\n                inputs[key] = depend_result.output[value.output_key]\n\n            elif callable(value):\n                try:\n                    inputs[key] = value(inputs, {d_id: result.output for d_id, result in depends_result.items()})\n                except Exception:\n                    raise NodeException(message=f\"Input mapping {key}: failed.\")\n            else:\n                inputs[key] = value\n\n        return inputs\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize node components.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager.\n        \"\"\"\n        self.is_postponed_component_init = False\n\n    @staticmethod\n    def transform(data: Any, transformer: Transformer) -&gt; Any:\n        \"\"\"\n        Apply transformation to data.\n\n        Args:\n            data (Any): Input data to transform.\n            transformer (Transformer): Transformer to apply.\n\n        Returns:\n            Any: Transformed data.\n        \"\"\"\n        output = jsonpath_filter(data, transformer.path)\n        output = jsonpath_mapper(output, transformer.selector)\n        return output\n\n    def transform_output(self, output_data: Any, **kwargs) -&gt; Any:\n        \"\"\"\n        Transform output data from the node.\n\n        Args:\n            output_data (Any): Output data to transform.\n\n        Returns:\n            Any: Transformed output data.\n        \"\"\"\n        return self.transform(output_data, self.output_transformer)\n\n    def get_clone_init_methods_names(self) -&gt; list[str]:\n        \"\"\"List of method names to call on the clone to reset per-run state.\"\"\"\n        return list(self._clone_init_methods_names)\n\n    def get_clone_attr_initializers(self) -&gt; dict[str, Callable[[\"Node\"], Any]]:\n        \"\"\"Mapping of attribute name -&gt; initializer callable(node) -&gt; value.\n\n        Default: provides streaming isolation so clones do not share runtime state.\n        \"\"\"\n        return {}\n\n    def clone(self) -&gt; \"Node\":\n        \"\"\"Create a safe clone of the node.\"\"\"\n        cloned_node = self.model_copy(deep=False)\n\n        def _clone_nested(value: Any) -&gt; Any:\n            # Do not attempt to copy modules/functions/classes or other callables\n            if isinstance(value, (ModuleType, FunctionType)) or isinstance(value, type) or callable(value):\n                return value\n            if isinstance(value, Node):\n                return value.clone()\n            elif isinstance(value, BaseModel):\n                try:\n                    bm_copy = value.model_copy(deep=False)\n                    for fname in getattr(value, \"model_fields\", {}):\n                        try:\n                            setattr(bm_copy, fname, _clone_nested(getattr(value, fname)))\n                        except Exception as e:\n                            logger.warning(f\"Clone: failed to clone BaseModel field '{fname}': {e}\")\n\n                    return bm_copy\n                except Exception as e:\n                    logger.warning(f\"Clone: BaseModel copy failed, falling back to shallow copy: {e}\")\n                    return copy.copy(value)\n            elif isinstance(value, list):\n                return [_clone_nested(v) for v in value]\n            elif isinstance(value, dict):\n                return {k: _clone_nested(v) for k, v in value.items()}\n            try:\n                return copy.copy(value)\n            except Exception as e:\n                logger.warning(f\"Clone: failed to clone field '{value}': {e}\")\n                return value\n\n        for _field_name in getattr(cloned_node, \"model_fields\", {}):\n            _val = getattr(cloned_node, _field_name)\n            _new_val = _clone_nested(_val)\n            if _new_val is not _val:\n                try:\n                    setattr(cloned_node, _field_name, _new_val)\n                except Exception as e:\n                    logger.warning(f\"Clone: unable to set field '{_field_name}' during nested clone: {e}\")\n\n        init_map = self.get_clone_attr_initializers()\n        for attr_name, init_fn in init_map.items():\n            try:\n                if hasattr(cloned_node, attr_name):\n                    value = init_fn(cloned_node) if callable(init_fn) else None\n                    if value is not None:\n                        setattr(cloned_node, attr_name, value)\n                    else:\n                        try:\n                            setattr(cloned_node, attr_name, None)\n                        except Exception as e:\n                            logger.warning(f\"Clone: failed to set attr '{attr_name}': {e}\")\n            except Exception as e:\n                logger.warning(f\"Clone: initializer for attr '{attr_name}' failed: {e}\")\n\n        for method_name in self.get_clone_init_methods_names():\n            try:\n                method = getattr(cloned_node, method_name, None)\n                if callable(method):\n                    method()\n            except Exception as e:\n                logger.warning(f\"Clone: method '{method_name}' invocation failed: {e}\")\n\n        return cloned_node\n\n    @property\n    def to_dict_exclude_params(self):\n        return {\n            \"client\": True,\n            \"vector_store\": True,\n            \"depends\": True,\n            \"input_mapping\": True,\n            \"input_transformer\": True,\n            \"output_transformer\": True,\n            \"caching\": True,\n            \"streaming\": True,\n            \"approval\": True,\n        }\n\n    @property\n    def to_dict_exclude_secure_params(self):\n        return self.to_dict_exclude_params | {\"connection\": True}\n\n    def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        for_tracing: bool = kwargs.pop(\"for_tracing\", False)\n        exclude = kwargs.pop(\n            \"exclude\", self.to_dict_exclude_params if include_secure_params else self.to_dict_exclude_secure_params\n        )\n        data = self.model_dump(\n            exclude=exclude,\n            serialize_as_any=kwargs.pop(\"serialize_as_any\", True),\n            **kwargs,\n        )\n\n        it = self.input_transformer.to_dict(for_tracing=for_tracing, **kwargs)\n        if it is not None:\n            data[\"input_transformer\"] = it\n        ot = self.output_transformer.to_dict(for_tracing=for_tracing, **kwargs)\n        if ot is not None:\n            data[\"output_transformer\"] = ot\n        data[\"caching\"] = self.caching.to_dict(for_tracing=for_tracing, **kwargs)\n        data[\"streaming\"] = self.streaming.to_dict(for_tracing=for_tracing, **kwargs)\n        data[\"approval\"] = self.approval.to_dict(for_tracing=for_tracing, **kwargs)\n\n        data[\"depends\"] = [depend.to_dict(for_tracing=for_tracing, **kwargs) for depend in self.depends]\n        data[\"input_mapping\"] = format_value(self.input_mapping)\n\n        if getattr(self, \"connection\", None):\n            data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing, **kwargs)\n\n        if for_tracing:\n            data = {k: v for k, v in data.items() if v is not None or k in (\"input\", \"output\")}\n        return data\n\n    def send_streaming_approval_message(\n        self, template: str, input_data: dict, approval_config: ApprovalConfig, config: RunnableConfig = None, **kwargs\n    ) -&gt; ApprovalInputData:\n        \"\"\"\n        Sends approval message and waits for response.\n\n        Args:\n            template (str): Template to send.\n            input_data (dict): Data that will be sent.\n            approval_config (ApprovalConfig): Configuration for approval.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Return:\n            ApprovalInputData: Response to approval message.\n\n        \"\"\"\n        event = ApprovalStreamingOutputEventMessage(\n            wf_run_id=config.run_id,\n            entity_id=self.id,\n            data={\"template\": template, \"data\": input_data, \"mutable_data_params\": approval_config.mutable_data_params},\n            event=approval_config.event,\n        )\n\n        logger.info(f\"Node {self.name} - {self.id}: sending approval.\")\n\n        self.run_on_node_execute_stream(callbacks=config.callbacks, event=event, **kwargs)\n\n        output: ApprovalInputData = self.get_input_streaming_event(\n            event=approval_config.event, event_msg_type=ApprovalStreamingInputEventMessage, config=config\n        ).data\n\n        return output\n\n    def send_console_approval_message(self, template: str) -&gt; ApprovalInputData:\n        \"\"\"\n        Sends approval message in console and waits for response.\n\n        Args:\n            template (dict): Template to send.\n        Returns:\n            ApprovalInputData: Response to approval message.\n        \"\"\"\n        feedback = input(template)\n        return ApprovalInputData(feedback=feedback)\n\n    def send_approval_message(\n        self, approval_config: ApprovalConfig, input_data: dict, config: RunnableConfig = None, **kwargs\n    ) -&gt; ApprovalInputData:\n        \"\"\"\n        Sends approval message and determines if it was approved or disapproved (canceled).\n\n        Args:\n            approval_config (ApprovalConfig): Configuration for the approval.\n            input_data (dict): Data that will be sent.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            ApprovalInputData: Result of approval.\n        \"\"\"\n\n        message = Template(approval_config.msg_template).render(self.to_dict(), input_data=input_data)\n        match approval_config.feedback_method:\n            case FeedbackMethod.STREAM:\n                approval_result = self.send_streaming_approval_message(\n                    message, input_data, approval_config, config=config, **kwargs\n                )\n            case FeedbackMethod.CONSOLE:\n                approval_result = self.send_console_approval_message(message)\n            case _:\n                raise ValueError(f\"Error: Incorrect feedback method is chosen {approval_config.feedback_method}.\")\n\n        update_params = {\n            feature_name: approval_result.data[feature_name]\n            for feature_name in approval_config.mutable_data_params\n            if feature_name in approval_result.data\n        }\n        approval_result.data = {**input_data, **update_params}\n\n        if approval_result.is_approved is None:\n            if approval_result.feedback == approval_config.accept_pattern:\n                logger.info(\n                    f\"Node {self.name} action was approved by human \"\n                    f\"with provided feedback '{approval_result.feedback}'.\"\n                )\n                approval_result.is_approved = True\n\n            else:\n                approval_result.is_approved = False\n                logger.info(\n                    f\"Node {self.name} action was canceled by human\"\n                    f\"with provided feedback '{approval_result.feedback}'.\"\n                )\n\n        return approval_result\n\n    def get_approved_data_or_origin(\n        self, input_data: dict[str, Any], config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Approves or disapproves (cancels) Node execution by requesting feedback.\n        Updates input data according to the feedback or leaves it the same.\n        Raises NodeException if execution was canceled by feedback.\n\n        Args:\n            input_data(dict[str, Any]): Input data.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: Updated input data.\n\n        Raises:\n            NodeException: If Node execution was canceled by feedback.\n        \"\"\"\n        if self.approval.enabled:\n            approval_result = self.send_approval_message(self.approval, input_data, config=config, **kwargs)\n            if not approval_result.is_approved:\n                raise NodeException(\n                    message=f\"Execution was canceled by human with feedback {approval_result.feedback}\",\n                    recoverable=True,\n                    failed_depend=NodeDependency(self, option=\"Execution was canceled.\"),\n                )\n            return approval_result.data\n\n        return input_data\n\n    def run_sync(\n        self,\n        input_data: dict,\n        config: RunnableConfig = None,\n        depends_result: dict = None,\n        **kwargs,\n    ) -&gt; RunnableResult:\n        \"\"\"\n        Run the node synchronously with given input data and configuration.\n\n        Args:\n            input_data (Any): Input data for the node.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            depends_result (dict, optional): Results of already executed nodes. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: Result of the node execution.\n        \"\"\"\n        from dynamiq.nodes.agents.exceptions import RecoverableAgentException\n\n        logger.info(f\"Node {self.name} - {self.id}: execution started.\")\n        transformed_input = input_data\n        time_start = datetime.now()\n\n        config = ensure_config(config)\n\n        run_id = uuid4()\n        merged_kwargs = merge(kwargs, {\"run_id\": run_id, \"parent_run_id\": kwargs.get(\"parent_run_id\", None)})\n        if depends_result is None:\n            depends_result = {}\n\n        try:\n            try:\n                self.validate_depends(depends_result)\n                input_data = self.get_approved_data_or_origin(input_data, config=config, **merged_kwargs)\n            except NodeException as e:\n                transformed_input = input_data | {\n                    k: result.to_tracing_depend_dict() for k, result in depends_result.items()\n                }\n                skip_data = {\"failed_dependency\": e.failed_depend.to_dict(for_tracing=True)}\n                self.run_on_node_skip(\n                    callbacks=config.callbacks,\n                    skip_data=skip_data,\n                    input_data=transformed_input,\n                    **merged_kwargs,\n                )\n                logger.info(f\"Node {self.name} - {self.id}: execution skipped.\")\n                return RunnableResult(\n                    status=RunnableStatus.SKIP,\n                    input=transformed_input,\n                    output=None,\n                    error=RunnableResultError.from_exception(e, recoverable=e.recoverable),\n                )\n\n            transformed_input = self.validate_input_schema(\n                self.transform_input(input_data=input_data, depends_result=depends_result, config=config, **kwargs),\n                **kwargs,\n            )\n            self.run_on_node_start(config.callbacks, dict(transformed_input), **merged_kwargs)\n            cache = cache_wf_entity(\n                entity_id=self.id,\n                cache_enabled=self.caching.enabled,\n                cache_config=config.cache,\n            )\n\n            output, from_cache = cache(self.execute_with_retry)(transformed_input, config, **merged_kwargs)\n\n            merged_kwargs[\"is_output_from_cache\"] = from_cache\n            transformed_output = self.transform_output(output, config=config, **kwargs)\n\n            self.run_on_node_end(config.callbacks, transformed_output, **merged_kwargs)\n\n            logger.info(\n                f\"Node {self.name} - {self.id}: execution succeeded in \"\n                f\"{format_duration(time_start, datetime.now())}.\"\n            )\n            return RunnableResult(\n                status=RunnableStatus.SUCCESS, input=dict(transformed_input), output=transformed_output\n            )\n        except Exception as e:\n            self.run_on_node_error(callbacks=config.callbacks, error=e, input_data=transformed_input, **merged_kwargs)\n            logger.error(\n                f\"Node {self.name} - {self.id}: execution failed in {e}\"\n                f\"{format_duration(time_start, datetime.now())}.\"\n            )\n\n            recoverable = isinstance(e, RecoverableAgentException)\n            result = RunnableResult(\n                status=RunnableStatus.FAILURE,\n                input=transformed_input,\n                output=None,\n                error=RunnableResultError.from_exception(e, recoverable=recoverable),\n            )\n            return result\n\n    async def run_async(\n        self,\n        input_data: dict,\n        config: RunnableConfig = None,\n        depends_result: dict = None,\n        **kwargs,\n    ) -&gt; RunnableResult:\n        \"\"\"\n        Run the node asynchronously with given input data and configuration.\n        This runs the synchronous implementation in a thread pool to avoid blocking the event loop.\n\n        Args:\n            input_data (Any): Input data for the node.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            depends_result (dict, optional): Results of dependent nodes. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: Result of the node execution.\n        \"\"\"\n        return await asyncio.to_thread(\n            self.run_sync, input_data=input_data, config=config, depends_result=depends_result, **kwargs\n        )\n\n    def execute_with_retry(self, input_data: dict[str, Any] | BaseModel, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the node with retry logic.\n\n        Args:\n            input_data (dict[str, Any]): Input data for the node.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Any: Result of the node execution.\n\n        Raises:\n            Exception: If all retry attempts fail.\n        \"\"\"\n        config = ensure_config(config)\n        timeout = self.error_handling.timeout_seconds\n\n        error = None\n        n_attempt = self.error_handling.max_retries + 1\n        executor = None\n\n        try:\n            if timeout is not None:\n                executor = ThreadPoolExecutor()\n\n            for attempt in range(n_attempt):\n                merged_kwargs = merge(kwargs, {\"execution_run_id\": uuid4()})\n\n                self.run_on_node_execute_start(config.callbacks, input_data, **merged_kwargs)\n\n                try:\n                    if executor and timeout is not None:\n                        output = self.execute_with_timeout(\n                            executor=executor,\n                            timeout=timeout,\n                            input_data=input_data,\n                            config=config,\n                            **merged_kwargs,\n                        )\n                    else:\n                        output = self.execute(input_data=input_data, config=config, **merged_kwargs)\n\n                    self.run_on_node_execute_end(config.callbacks, output, **merged_kwargs)\n                    return output\n                except TimeoutError as e:\n                    error = e\n                    self.run_on_node_execute_error(config.callbacks, error, **merged_kwargs)\n                    logger.warning(f\"Node {self.name} - {self.id}: timeout.\")\n                except Exception as e:\n                    error = e\n                    self.run_on_node_execute_error(config.callbacks, error, **merged_kwargs)\n                    logger.error(f\"Node {self.name} - {self.id}: execution error: {e}\")\n\n                # do not sleep after the last attempt\n                if attempt &lt; n_attempt - 1:\n                    time_to_sleep = self.error_handling.retry_interval_seconds * (\n                        self.error_handling.backoff_rate**attempt\n                    )\n                    logger.info(f\"Node {self.name} - {self.id}: retrying in {time_to_sleep} seconds.\")\n                    time.sleep(time_to_sleep)\n\n            logger.error(f\"Node {self.name} - {self.id}: execution failed after {n_attempt} attempts.\")\n            raise error\n        finally:\n            if executor is not None:\n                executor.shutdown()\n\n    def execute_with_timeout(\n        self,\n        executor: ThreadPoolExecutor,\n        timeout: float | None,\n        input_data: dict[str, Any] | BaseModel,\n        config: RunnableConfig = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Execute the node with a timeout.\n\n        Args:\n            executor (ThreadPoolExecutor): Thread pool executor to use.\n            timeout (float | None): Timeout duration in seconds.\n            input_data (dict[str, Any]): Input data for the node.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Any: Result of the execution.\n\n        Raises:\n            Exception: If execution fails or times out.\n        \"\"\"\n        future = executor.submit(self.execute, input_data, config=config, **kwargs)\n\n        try:\n            result = future.result(timeout=timeout)\n        except Exception as e:\n            raise e\n\n        return result\n\n    def get_context_for_input_schema(self) -&gt; dict:\n        \"\"\"Provides context for input schema that is required for proper validation.\"\"\"\n        return {}\n\n    def get_input_streaming_event(\n        self,\n        event_msg_type: \"type[StreamingEventMessage]\" = StreamingEventMessage,\n        event: str | None = None,\n        config: RunnableConfig = None,\n    ) -&gt; StreamingEventMessage:\n        \"\"\"\n        Get the input streaming event from the input streaming.\n\n        Args:\n            event_msg_type (Type[StreamingEventMessage], optional): The event message type to use.\n            event (str, optional): The event to use for the message.\n            config (RunnableConfig, optional): Configuration for the runnable.\n        \"\"\"\n        # Use runnable streaming configuration. If not found use node streaming configuration\n        streaming = getattr(config.nodes_override.get(self.id), \"streaming\", None) or self.streaming\n        if streaming.input_streaming_enabled:\n            while not streaming.input_queue_done_event or not streaming.input_queue_done_event.is_set():\n                try:\n                    data = streaming.input_queue.get(timeout=streaming.timeout)\n                except Empty:\n                    raise ValueError(f\"Input streaming timeout: {streaming.timeout} exceeded.\")\n\n                try:\n                    event_msg = event_msg_type.model_validate_json(data)\n                    if event and event_msg.event != event:\n                        raise ValueError()\n                except ValueError:\n                    logger.error(\n                        f\"Invalid streaming event data: {data}. \"\n                        f\"Allowed event: {event}, event_msg_type: {event_msg_type}\"\n                    )\n                    continue\n\n                return event_msg\n\n        raise ValueError(\"Input streaming is not enabled.\")\n\n    def run_on_node_start(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        input_data: dict[str, Any],\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node start.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                    input_data = input_data.to_dict(for_tracing=True) if hasattr(input_data, \"to_dict\") else input_data\n                callback.on_node_start(self.to_dict(**dict_kwargs), input_data, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    def run_on_node_end(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        output_data: dict[str, Any],\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node end.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            output_data (dict[str, Any]): Output data from the node.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                    output_data = (\n                        output_data.to_dict(for_tracing=True) if hasattr(output_data, \"to_dict\") else output_data\n                    )\n                callback.on_node_end(self.to_dict(**dict_kwargs), output_data, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    def run_on_node_error(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        error: BaseException,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node error.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            error (BaseException): The error that occurred.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_node_error(self.to_dict(**dict_kwargs), error, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    def run_on_node_skip(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        skip_data: dict[str, Any],\n        input_data: dict[str, Any],\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node skip.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            skip_data (dict[str, Any]): Data related to the skip.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                    input_data = input_data.to_dict(for_tracing=True) if hasattr(input_data, \"to_dict\") else input_data\n                callback.on_node_skip(self.to_dict(**dict_kwargs), skip_data, input_data, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    def run_on_node_execute_start(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        input_data: dict[str, Any] | BaseModel,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node execute start.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            input_data (dict[str, Any]): Input data for the node.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if isinstance(input_data, BaseModel):\n            input_data = dict(input_data)\n\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                    input_data = input_data.to_dict(for_tracing=True) if hasattr(input_data, \"to_dict\") else input_data\n                callback.on_node_execute_start(self.to_dict(**dict_kwargs), input_data, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    def run_on_node_execute_end(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        output_data: dict[str, Any],\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node execute end.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            output_data (dict[str, Any]): Output data from the node.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                    output_data = (\n                        output_data.to_dict(for_tracing=True) if hasattr(output_data, \"to_dict\") else output_data\n                    )\n                callback.on_node_execute_end(self.to_dict(**dict_kwargs), output_data, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    def run_on_node_execute_error(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        error: BaseException,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node execute error.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            error (BaseException): The error that occurred.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_node_execute_error(self.to_dict(**dict_kwargs), error, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    def run_on_node_execute_run(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node execute run.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_node_execute_run(self.to_dict(**dict_kwargs), **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    def run_on_node_execute_stream(\n        self,\n        callbacks: list[BaseCallbackHandler],\n        chunk: dict[str, Any] | None = None,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Run callbacks on node execute stream.\n\n        Args:\n            callbacks (list[BaseCallbackHandler]): List of callback handlers.\n            chunk (dict[str, Any]): Chunk of streaming data.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        for callback in callbacks + self.callbacks:\n            try:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                    chunk = chunk.to_dict(for_tracing=True) if hasattr(chunk, \"to_dict\") else chunk\n                callback.on_node_execute_stream(self.to_dict(**dict_kwargs), chunk, **kwargs)\n            except Exception as e:\n                logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n\n    @abstractmethod\n    def execute(self, input_data: dict[str, Any] | BaseModel, config: RunnableConfig = None, **kwargs) -&gt; Any:\n        \"\"\"\n        Execute the node with the given input.\n        Args:\n            input_data (dict[str, Any]): Input data for the node.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Any: Result of the execution.\n        \"\"\"\n        pass\n\n    def depends_on(self, nodes: Union[\"Node\", list[\"Node\"]], condition: ChoiceCondition | None = None) -&gt; \"Node\":\n        \"\"\"\n        Add dependencies for this node. Accepts either a single node or a list of nodes.\n\n        Args:\n            nodes (Node or list[Node]): A single node or list of nodes this node depends on.\n            condition (ChoiceCondition, optional): The condition for the dependency.\n\n        Raises:\n            TypeError: If the input is neither a Node nor a list of Node instances.\n            ValueError: If an empty list is provided.\n\n        Returns:\n            self: Enables method chaining.\n        \"\"\"\n\n        if nodes is None:\n            raise ValueError(\"Nodes cannot be None.\")\n\n        if isinstance(nodes, Node):\n            nodes = [nodes]\n\n        if not isinstance(nodes, list) or not all(isinstance(node, Node) for node in nodes):\n            raise TypeError(f\"Expected a Node or a list of Node instances, but got {type(nodes).__name__}.\")\n\n        if not nodes:\n            raise ValueError(\"Cannot add an empty list of dependencies.\")\n\n        for node in nodes:\n            self.depends.append(NodeDependency(node=node, condition=condition))\n\n        return self\n\n    def enable_streaming(self, event: str = STREAMING_EVENT):\n        \"\"\"\n        Enable streaming for the node and optionally set the event name.\n\n        Args:\n            event (str): The event name for streaming. Defaults to 'streaming'.\n\n        Returns:\n            self: Enables method chaining.\n        \"\"\"\n        self.streaming.enabled = True\n        self.streaming.event = event\n        return self\n\n    @property\n    def outputs(self):\n        \"\"\"\n        Provide the output references for the node.\n        \"\"\"\n        return self._output_references\n\n    def inputs(self, **kwargs):\n        \"\"\"\n        Add input mappings for the node.\n\n        Returns:\n            self: Enables method chaining.\n\n        Examples:\n            from dynamiq.nodes.llms import OpenAI\n\n            openai_1_node = OpenAI(...)\n            openai_2_node = OpenAI(...)\n            openai_3_node = OpenAI(...)\n\n            def merge_and_short_content(inputs: dict, outputs: dict[str, dict]):\n                return (\n                    f\"- {outputs[openai_1_node.id]['content'][:200]} \\n - {outputs[openai_2_node.id]['content'][:200]}\"\n                )\n\n            openai_4_node = (\n                OpenAI(\n                    ...\n                    prompt=prompts.Prompt(\n                        messages=[\n                            prompts.Message(\n                                role=\"user\",\n                                content=(\n                                    \"Please simplify that information for {{purpose}}:\\n\"\n                                    \"{{extra_instructions}}\\n\"\n                                    \"{{content}}\\n\"\n                                    \"{{extra_content}}\"\n                                ),\n                            )\n                        ],\n                    ),\n                )\n                .inputs(\n                    purpose=\"10 years old kids\",\n                    extra_instructions=\"Please return information in readable format.\",\n                    content=merge_and_short_content,\n                    extra_content=openai_3_node.outputs.content,\n                )\n                .depends_on([openai_1_node, openai_2_node, openai_3_node])\n            )\n        \"\"\"\n        for key, value in kwargs.items():\n            if callable(value):\n                self._validate_input_mapping_value_func(value)\n\n            self.input_mapping[key] = value\n        return self\n\n    def deep_merge(self, source: dict, destination: dict) -&gt; dict:\n        \"\"\"\n        Recursively merge dictionaries with proper override behavior.\n\n        Args:\n            source: Source dictionary with higher priority values\n            destination: Destination dictionary with lower priority values\n\n        Returns:\n            dict: Merged dictionary where source values override destination values,\n                  and lists are concatenated when both source and destination have lists\n        \"\"\"\n        result = destination.copy()\n        for key, value in source.items():\n            if key in result:\n                if isinstance(value, dict) and isinstance(result[key], dict):\n                    result[key] = self.deep_merge(value, result[key])\n                elif isinstance(value, list) and isinstance(result[key], list):\n                    result[key] = result[key] + value\n                else:\n                    result[key] = value\n            else:\n                result[key] = value\n        return result\n\n    def dry_run_cleanup(self, dry_run_config: DryRunConfig | None = None) -&gt; None:\n        \"\"\"Clean up resources created during dry run.\n        This method provides a default implementation that nodes can override\n        to perform specific cleanup operations. By default, it does nothing\n        but provides the interface for node-level cleanup.\n\n        Args:\n            dry_run_config: Configuration for dry run behavior.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.outputs","title":"<code>outputs</code>  <code>property</code>","text":"<p>Provide the output references for the node.</p>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.clone","title":"<code>clone()</code>","text":"<p>Create a safe clone of the node.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def clone(self) -&gt; \"Node\":\n    \"\"\"Create a safe clone of the node.\"\"\"\n    cloned_node = self.model_copy(deep=False)\n\n    def _clone_nested(value: Any) -&gt; Any:\n        # Do not attempt to copy modules/functions/classes or other callables\n        if isinstance(value, (ModuleType, FunctionType)) or isinstance(value, type) or callable(value):\n            return value\n        if isinstance(value, Node):\n            return value.clone()\n        elif isinstance(value, BaseModel):\n            try:\n                bm_copy = value.model_copy(deep=False)\n                for fname in getattr(value, \"model_fields\", {}):\n                    try:\n                        setattr(bm_copy, fname, _clone_nested(getattr(value, fname)))\n                    except Exception as e:\n                        logger.warning(f\"Clone: failed to clone BaseModel field '{fname}': {e}\")\n\n                return bm_copy\n            except Exception as e:\n                logger.warning(f\"Clone: BaseModel copy failed, falling back to shallow copy: {e}\")\n                return copy.copy(value)\n        elif isinstance(value, list):\n            return [_clone_nested(v) for v in value]\n        elif isinstance(value, dict):\n            return {k: _clone_nested(v) for k, v in value.items()}\n        try:\n            return copy.copy(value)\n        except Exception as e:\n            logger.warning(f\"Clone: failed to clone field '{value}': {e}\")\n            return value\n\n    for _field_name in getattr(cloned_node, \"model_fields\", {}):\n        _val = getattr(cloned_node, _field_name)\n        _new_val = _clone_nested(_val)\n        if _new_val is not _val:\n            try:\n                setattr(cloned_node, _field_name, _new_val)\n            except Exception as e:\n                logger.warning(f\"Clone: unable to set field '{_field_name}' during nested clone: {e}\")\n\n    init_map = self.get_clone_attr_initializers()\n    for attr_name, init_fn in init_map.items():\n        try:\n            if hasattr(cloned_node, attr_name):\n                value = init_fn(cloned_node) if callable(init_fn) else None\n                if value is not None:\n                    setattr(cloned_node, attr_name, value)\n                else:\n                    try:\n                        setattr(cloned_node, attr_name, None)\n                    except Exception as e:\n                        logger.warning(f\"Clone: failed to set attr '{attr_name}': {e}\")\n        except Exception as e:\n            logger.warning(f\"Clone: initializer for attr '{attr_name}' failed: {e}\")\n\n    for method_name in self.get_clone_init_methods_names():\n        try:\n            method = getattr(cloned_node, method_name, None)\n            if callable(method):\n                method()\n        except Exception as e:\n            logger.warning(f\"Clone: method '{method_name}' invocation failed: {e}\")\n\n    return cloned_node\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.deep_merge","title":"<code>deep_merge(source, destination)</code>","text":"<p>Recursively merge dictionaries with proper override behavior.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>dict</code> <p>Source dictionary with higher priority values</p> required <code>destination</code> <code>dict</code> <p>Destination dictionary with lower priority values</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Merged dictionary where source values override destination values,   and lists are concatenated when both source and destination have lists</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def deep_merge(self, source: dict, destination: dict) -&gt; dict:\n    \"\"\"\n    Recursively merge dictionaries with proper override behavior.\n\n    Args:\n        source: Source dictionary with higher priority values\n        destination: Destination dictionary with lower priority values\n\n    Returns:\n        dict: Merged dictionary where source values override destination values,\n              and lists are concatenated when both source and destination have lists\n    \"\"\"\n    result = destination.copy()\n    for key, value in source.items():\n        if key in result:\n            if isinstance(value, dict) and isinstance(result[key], dict):\n                result[key] = self.deep_merge(value, result[key])\n            elif isinstance(value, list) and isinstance(result[key], list):\n                result[key] = result[key] + value\n            else:\n                result[key] = value\n        else:\n            result[key] = value\n    return result\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.depends_on","title":"<code>depends_on(nodes, condition=None)</code>","text":"<p>Add dependencies for this node. Accepts either a single node or a list of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>Node or list[Node]</code> <p>A single node or list of nodes this node depends on.</p> required <code>condition</code> <code>ChoiceCondition</code> <p>The condition for the dependency.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input is neither a Node nor a list of Node instances.</p> <code>ValueError</code> <p>If an empty list is provided.</p> <p>Returns:</p> Name Type Description <code>self</code> <code>Node</code> <p>Enables method chaining.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def depends_on(self, nodes: Union[\"Node\", list[\"Node\"]], condition: ChoiceCondition | None = None) -&gt; \"Node\":\n    \"\"\"\n    Add dependencies for this node. Accepts either a single node or a list of nodes.\n\n    Args:\n        nodes (Node or list[Node]): A single node or list of nodes this node depends on.\n        condition (ChoiceCondition, optional): The condition for the dependency.\n\n    Raises:\n        TypeError: If the input is neither a Node nor a list of Node instances.\n        ValueError: If an empty list is provided.\n\n    Returns:\n        self: Enables method chaining.\n    \"\"\"\n\n    if nodes is None:\n        raise ValueError(\"Nodes cannot be None.\")\n\n    if isinstance(nodes, Node):\n        nodes = [nodes]\n\n    if not isinstance(nodes, list) or not all(isinstance(node, Node) for node in nodes):\n        raise TypeError(f\"Expected a Node or a list of Node instances, but got {type(nodes).__name__}.\")\n\n    if not nodes:\n        raise ValueError(\"Cannot add an empty list of dependencies.\")\n\n    for node in nodes:\n        self.depends.append(NodeDependency(node=node, condition=condition))\n\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.dry_run_cleanup","title":"<code>dry_run_cleanup(dry_run_config=None)</code>","text":"<p>Clean up resources created during dry run. This method provides a default implementation that nodes can override to perform specific cleanup operations. By default, it does nothing but provides the interface for node-level cleanup.</p> <p>Parameters:</p> Name Type Description Default <code>dry_run_config</code> <code>DryRunConfig | None</code> <p>Configuration for dry run behavior.</p> <code>None</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def dry_run_cleanup(self, dry_run_config: DryRunConfig | None = None) -&gt; None:\n    \"\"\"Clean up resources created during dry run.\n    This method provides a default implementation that nodes can override\n    to perform specific cleanup operations. By default, it does nothing\n    but provides the interface for node-level cleanup.\n\n    Args:\n        dry_run_config: Configuration for dry run behavior.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.enable_streaming","title":"<code>enable_streaming(event=STREAMING_EVENT)</code>","text":"<p>Enable streaming for the node and optionally set the event name.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>str</code> <p>The event name for streaming. Defaults to 'streaming'.</p> <code>STREAMING_EVENT</code> <p>Returns:</p> Name Type Description <code>self</code> <p>Enables method chaining.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def enable_streaming(self, event: str = STREAMING_EVENT):\n    \"\"\"\n    Enable streaming for the node and optionally set the event name.\n\n    Args:\n        event (str): The event name for streaming. Defaults to 'streaming'.\n\n    Returns:\n        self: Enables method chaining.\n    \"\"\"\n    self.streaming.enabled = True\n    self.streaming.event = event\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Execute the node with the given input. Args:     input_data (dict[str, Any]): Input data for the node.     config (RunnableConfig, optional): Configuration for the runnable.     **kwargs: Additional keyword arguments.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Result of the execution.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>@abstractmethod\ndef execute(self, input_data: dict[str, Any] | BaseModel, config: RunnableConfig = None, **kwargs) -&gt; Any:\n    \"\"\"\n    Execute the node with the given input.\n    Args:\n        input_data (dict[str, Any]): Input data for the node.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Any: Result of the execution.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.execute_with_retry","title":"<code>execute_with_retry(input_data, config=None, **kwargs)</code>","text":"<p>Execute the node with retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>Result of the node execution.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If all retry attempts fail.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def execute_with_retry(self, input_data: dict[str, Any] | BaseModel, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the node with retry logic.\n\n    Args:\n        input_data (dict[str, Any]): Input data for the node.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Any: Result of the node execution.\n\n    Raises:\n        Exception: If all retry attempts fail.\n    \"\"\"\n    config = ensure_config(config)\n    timeout = self.error_handling.timeout_seconds\n\n    error = None\n    n_attempt = self.error_handling.max_retries + 1\n    executor = None\n\n    try:\n        if timeout is not None:\n            executor = ThreadPoolExecutor()\n\n        for attempt in range(n_attempt):\n            merged_kwargs = merge(kwargs, {\"execution_run_id\": uuid4()})\n\n            self.run_on_node_execute_start(config.callbacks, input_data, **merged_kwargs)\n\n            try:\n                if executor and timeout is not None:\n                    output = self.execute_with_timeout(\n                        executor=executor,\n                        timeout=timeout,\n                        input_data=input_data,\n                        config=config,\n                        **merged_kwargs,\n                    )\n                else:\n                    output = self.execute(input_data=input_data, config=config, **merged_kwargs)\n\n                self.run_on_node_execute_end(config.callbacks, output, **merged_kwargs)\n                return output\n            except TimeoutError as e:\n                error = e\n                self.run_on_node_execute_error(config.callbacks, error, **merged_kwargs)\n                logger.warning(f\"Node {self.name} - {self.id}: timeout.\")\n            except Exception as e:\n                error = e\n                self.run_on_node_execute_error(config.callbacks, error, **merged_kwargs)\n                logger.error(f\"Node {self.name} - {self.id}: execution error: {e}\")\n\n            # do not sleep after the last attempt\n            if attempt &lt; n_attempt - 1:\n                time_to_sleep = self.error_handling.retry_interval_seconds * (\n                    self.error_handling.backoff_rate**attempt\n                )\n                logger.info(f\"Node {self.name} - {self.id}: retrying in {time_to_sleep} seconds.\")\n                time.sleep(time_to_sleep)\n\n        logger.error(f\"Node {self.name} - {self.id}: execution failed after {n_attempt} attempts.\")\n        raise error\n    finally:\n        if executor is not None:\n            executor.shutdown()\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.execute_with_timeout","title":"<code>execute_with_timeout(executor, timeout, input_data, config=None, **kwargs)</code>","text":"<p>Execute the node with a timeout.</p> <p>Parameters:</p> Name Type Description Default <code>executor</code> <code>ThreadPoolExecutor</code> <p>Thread pool executor to use.</p> required <code>timeout</code> <code>float | None</code> <p>Timeout duration in seconds.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>Result of the execution.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If execution fails or times out.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def execute_with_timeout(\n    self,\n    executor: ThreadPoolExecutor,\n    timeout: float | None,\n    input_data: dict[str, Any] | BaseModel,\n    config: RunnableConfig = None,\n    **kwargs,\n):\n    \"\"\"\n    Execute the node with a timeout.\n\n    Args:\n        executor (ThreadPoolExecutor): Thread pool executor to use.\n        timeout (float | None): Timeout duration in seconds.\n        input_data (dict[str, Any]): Input data for the node.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Any: Result of the execution.\n\n    Raises:\n        Exception: If execution fails or times out.\n    \"\"\"\n    future = executor.submit(self.execute, input_data, config=config, **kwargs)\n\n    try:\n        result = future.result(timeout=timeout)\n    except Exception as e:\n        raise e\n\n    return result\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.get_approved_data_or_origin","title":"<code>get_approved_data_or_origin(input_data, config=None, **kwargs)</code>","text":"<p>Approves or disapproves (cancels) Node execution by requesting feedback. Updates input data according to the feedback or leaves it the same. Raises NodeException if execution was canceled by feedback.</p> <p>Parameters:</p> Name Type Description Default <code>input_data(dict[str,</code> <code>Any]</code> <p>Input data.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Updated input data.</p> <p>Raises:</p> Type Description <code>NodeException</code> <p>If Node execution was canceled by feedback.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def get_approved_data_or_origin(\n    self, input_data: dict[str, Any], config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Approves or disapproves (cancels) Node execution by requesting feedback.\n    Updates input data according to the feedback or leaves it the same.\n    Raises NodeException if execution was canceled by feedback.\n\n    Args:\n        input_data(dict[str, Any]): Input data.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: Updated input data.\n\n    Raises:\n        NodeException: If Node execution was canceled by feedback.\n    \"\"\"\n    if self.approval.enabled:\n        approval_result = self.send_approval_message(self.approval, input_data, config=config, **kwargs)\n        if not approval_result.is_approved:\n            raise NodeException(\n                message=f\"Execution was canceled by human with feedback {approval_result.feedback}\",\n                recoverable=True,\n                failed_depend=NodeDependency(self, option=\"Execution was canceled.\"),\n            )\n        return approval_result.data\n\n    return input_data\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.get_clone_attr_initializers","title":"<code>get_clone_attr_initializers()</code>","text":"<p>Mapping of attribute name -&gt; initializer callable(node) -&gt; value.</p> <p>Default: provides streaming isolation so clones do not share runtime state.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def get_clone_attr_initializers(self) -&gt; dict[str, Callable[[\"Node\"], Any]]:\n    \"\"\"Mapping of attribute name -&gt; initializer callable(node) -&gt; value.\n\n    Default: provides streaming isolation so clones do not share runtime state.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.get_clone_init_methods_names","title":"<code>get_clone_init_methods_names()</code>","text":"<p>List of method names to call on the clone to reset per-run state.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def get_clone_init_methods_names(self) -&gt; list[str]:\n    \"\"\"List of method names to call on the clone to reset per-run state.\"\"\"\n    return list(self._clone_init_methods_names)\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.get_context_for_input_schema","title":"<code>get_context_for_input_schema()</code>","text":"<p>Provides context for input schema that is required for proper validation.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def get_context_for_input_schema(self) -&gt; dict:\n    \"\"\"Provides context for input schema that is required for proper validation.\"\"\"\n    return {}\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.get_input_streaming_event","title":"<code>get_input_streaming_event(event_msg_type=StreamingEventMessage, event=None, config=None)</code>","text":"<p>Get the input streaming event from the input streaming.</p> <p>Parameters:</p> Name Type Description Default <code>event_msg_type</code> <code>Type[StreamingEventMessage]</code> <p>The event message type to use.</p> <code>StreamingEventMessage</code> <code>event</code> <code>str</code> <p>The event to use for the message.</p> <code>None</code> <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def get_input_streaming_event(\n    self,\n    event_msg_type: \"type[StreamingEventMessage]\" = StreamingEventMessage,\n    event: str | None = None,\n    config: RunnableConfig = None,\n) -&gt; StreamingEventMessage:\n    \"\"\"\n    Get the input streaming event from the input streaming.\n\n    Args:\n        event_msg_type (Type[StreamingEventMessage], optional): The event message type to use.\n        event (str, optional): The event to use for the message.\n        config (RunnableConfig, optional): Configuration for the runnable.\n    \"\"\"\n    # Use runnable streaming configuration. If not found use node streaming configuration\n    streaming = getattr(config.nodes_override.get(self.id), \"streaming\", None) or self.streaming\n    if streaming.input_streaming_enabled:\n        while not streaming.input_queue_done_event or not streaming.input_queue_done_event.is_set():\n            try:\n                data = streaming.input_queue.get(timeout=streaming.timeout)\n            except Empty:\n                raise ValueError(f\"Input streaming timeout: {streaming.timeout} exceeded.\")\n\n            try:\n                event_msg = event_msg_type.model_validate_json(data)\n                if event and event_msg.event != event:\n                    raise ValueError()\n            except ValueError:\n                logger.error(\n                    f\"Invalid streaming event data: {data}. \"\n                    f\"Allowed event: {event}, event_msg_type: {event_msg_type}\"\n                )\n                continue\n\n            return event_msg\n\n    raise ValueError(\"Input streaming is not enabled.\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize node components.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager.</p> <code>None</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize node components.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager.\n    \"\"\"\n    self.is_postponed_component_init = False\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.inputs","title":"<code>inputs(**kwargs)</code>","text":"<pre><code>    Add input mappings for the node.\n\n    Returns:\n        self: Enables method chaining.\n\n    Examples:\n        from dynamiq.nodes.llms import OpenAI\n\n        openai_1_node = OpenAI(...)\n        openai_2_node = OpenAI(...)\n        openai_3_node = OpenAI(...)\n\n        def merge_and_short_content(inputs: dict, outputs: dict[str, dict]):\n            return (\n                f\"- {outputs[openai_1_node.id]['content'][:200]}\n</code></pre> <ul> <li>{outputsopenai_2_node.id[:200]}\"                 )<pre><code>    openai_4_node = (\n        OpenAI(\n            ...\n            prompt=prompts.Prompt(\n                messages=[\n                    prompts.Message(\n                        role=\"user\",\n                        content=(\n                            \"Please simplify that information for {{purpose}}:\n</code></pre> <p>\"                                 \"{{extra_instructions}} \"                                 \"{{content}} \"                                 \"{{extra_content}}\"                             ),                         )                     ],                 ),             )             .inputs(                 purpose=\"10 years old kids\",                 extra_instructions=\"Please return information in readable format.\",                 content=merge_and_short_content,                 extra_content=openai_3_node.outputs.content,             )             .depends_on([openai_1_node, openai_2_node, openai_3_node])         )</p> </li> </ul> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def inputs(self, **kwargs):\n    \"\"\"\n    Add input mappings for the node.\n\n    Returns:\n        self: Enables method chaining.\n\n    Examples:\n        from dynamiq.nodes.llms import OpenAI\n\n        openai_1_node = OpenAI(...)\n        openai_2_node = OpenAI(...)\n        openai_3_node = OpenAI(...)\n\n        def merge_and_short_content(inputs: dict, outputs: dict[str, dict]):\n            return (\n                f\"- {outputs[openai_1_node.id]['content'][:200]} \\n - {outputs[openai_2_node.id]['content'][:200]}\"\n            )\n\n        openai_4_node = (\n            OpenAI(\n                ...\n                prompt=prompts.Prompt(\n                    messages=[\n                        prompts.Message(\n                            role=\"user\",\n                            content=(\n                                \"Please simplify that information for {{purpose}}:\\n\"\n                                \"{{extra_instructions}}\\n\"\n                                \"{{content}}\\n\"\n                                \"{{extra_content}}\"\n                            ),\n                        )\n                    ],\n                ),\n            )\n            .inputs(\n                purpose=\"10 years old kids\",\n                extra_instructions=\"Please return information in readable format.\",\n                content=merge_and_short_content,\n                extra_content=openai_3_node.outputs.content,\n            )\n            .depends_on([openai_1_node, openai_2_node, openai_3_node])\n        )\n    \"\"\"\n    for key, value in kwargs.items():\n        if callable(value):\n            self._validate_input_mapping_value_func(value)\n\n        self.input_mapping[key] = value\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_async","title":"<code>run_async(input_data, config=None, depends_result=None, **kwargs)</code>  <code>async</code>","text":"<p>Run the node asynchronously with given input data and configuration. This runs the synchronous implementation in a thread pool to avoid blocking the event loop.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the node.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>depends_result</code> <code>dict</code> <p>Results of dependent nodes. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>RunnableResult</code> <code>RunnableResult</code> <p>Result of the node execution.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>async def run_async(\n    self,\n    input_data: dict,\n    config: RunnableConfig = None,\n    depends_result: dict = None,\n    **kwargs,\n) -&gt; RunnableResult:\n    \"\"\"\n    Run the node asynchronously with given input data and configuration.\n    This runs the synchronous implementation in a thread pool to avoid blocking the event loop.\n\n    Args:\n        input_data (Any): Input data for the node.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        depends_result (dict, optional): Results of dependent nodes. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        RunnableResult: Result of the node execution.\n    \"\"\"\n    return await asyncio.to_thread(\n        self.run_sync, input_data=input_data, config=config, depends_result=depends_result, **kwargs\n    )\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_end","title":"<code>run_on_node_end(callbacks, output_data, **kwargs)</code>","text":"<p>Run callbacks on node end.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the node.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_end(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    output_data: dict[str, Any],\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node end.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        output_data (dict[str, Any]): Output data from the node.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n                output_data = (\n                    output_data.to_dict(for_tracing=True) if hasattr(output_data, \"to_dict\") else output_data\n                )\n            callback.on_node_end(self.to_dict(**dict_kwargs), output_data, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_error","title":"<code>run_on_node_error(callbacks, error, **kwargs)</code>","text":"<p>Run callbacks on node error.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>error</code> <code>BaseException</code> <p>The error that occurred.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_error(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    error: BaseException,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node error.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        error (BaseException): The error that occurred.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_node_error(self.to_dict(**dict_kwargs), error, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_execute_end","title":"<code>run_on_node_execute_end(callbacks, output_data, **kwargs)</code>","text":"<p>Run callbacks on node execute end.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>output_data</code> <code>dict[str, Any]</code> <p>Output data from the node.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_execute_end(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    output_data: dict[str, Any],\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node execute end.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        output_data (dict[str, Any]): Output data from the node.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n                output_data = (\n                    output_data.to_dict(for_tracing=True) if hasattr(output_data, \"to_dict\") else output_data\n                )\n            callback.on_node_execute_end(self.to_dict(**dict_kwargs), output_data, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_execute_error","title":"<code>run_on_node_execute_error(callbacks, error, **kwargs)</code>","text":"<p>Run callbacks on node execute error.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>error</code> <code>BaseException</code> <p>The error that occurred.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_execute_error(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    error: BaseException,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node execute error.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        error (BaseException): The error that occurred.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_node_execute_error(self.to_dict(**dict_kwargs), error, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_execute_run","title":"<code>run_on_node_execute_run(callbacks, **kwargs)</code>","text":"<p>Run callbacks on node execute run.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_execute_run(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node execute run.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_node_execute_run(self.to_dict(**dict_kwargs), **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_execute_start","title":"<code>run_on_node_execute_start(callbacks, input_data, **kwargs)</code>","text":"<p>Run callbacks on node execute start.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_execute_start(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    input_data: dict[str, Any] | BaseModel,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node execute start.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if isinstance(input_data, BaseModel):\n        input_data = dict(input_data)\n\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n                input_data = input_data.to_dict(for_tracing=True) if hasattr(input_data, \"to_dict\") else input_data\n            callback.on_node_execute_start(self.to_dict(**dict_kwargs), input_data, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_execute_stream","title":"<code>run_on_node_execute_stream(callbacks, chunk=None, **kwargs)</code>","text":"<p>Run callbacks on node execute stream.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>chunk</code> <code>dict[str, Any]</code> <p>Chunk of streaming data.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_execute_stream(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    chunk: dict[str, Any] | None = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node execute stream.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        chunk (dict[str, Any]): Chunk of streaming data.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n                chunk = chunk.to_dict(for_tracing=True) if hasattr(chunk, \"to_dict\") else chunk\n            callback.on_node_execute_stream(self.to_dict(**dict_kwargs), chunk, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_skip","title":"<code>run_on_node_skip(callbacks, skip_data, input_data, **kwargs)</code>","text":"<p>Run callbacks on node skip.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>skip_data</code> <code>dict[str, Any]</code> <p>Data related to the skip.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_skip(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    skip_data: dict[str, Any],\n    input_data: dict[str, Any],\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node skip.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        skip_data (dict[str, Any]): Data related to the skip.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n                input_data = input_data.to_dict(for_tracing=True) if hasattr(input_data, \"to_dict\") else input_data\n            callback.on_node_skip(self.to_dict(**dict_kwargs), skip_data, input_data, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_on_node_start","title":"<code>run_on_node_start(callbacks, input_data, **kwargs)</code>","text":"<p>Run callbacks on node start.</p> <p>Parameters:</p> Name Type Description Default <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the node.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_on_node_start(\n    self,\n    callbacks: list[BaseCallbackHandler],\n    input_data: dict[str, Any],\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Run callbacks on node start.\n\n    Args:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        input_data (dict[str, Any]): Input data for the node.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n\n    for callback in callbacks + self.callbacks:\n        try:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n                input_data = input_data.to_dict(for_tracing=True) if hasattr(input_data, \"to_dict\") else input_data\n            callback.on_node_start(self.to_dict(**dict_kwargs), input_data, **kwargs)\n        except Exception as e:\n            logger.error(f\"Error running callback {callback.__class__.__name__}: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.run_sync","title":"<code>run_sync(input_data, config=None, depends_result=None, **kwargs)</code>","text":"<p>Run the node synchronously with given input data and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the node.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>depends_result</code> <code>dict</code> <p>Results of already executed nodes. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>RunnableResult</code> <code>RunnableResult</code> <p>Result of the node execution.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def run_sync(\n    self,\n    input_data: dict,\n    config: RunnableConfig = None,\n    depends_result: dict = None,\n    **kwargs,\n) -&gt; RunnableResult:\n    \"\"\"\n    Run the node synchronously with given input data and configuration.\n\n    Args:\n        input_data (Any): Input data for the node.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        depends_result (dict, optional): Results of already executed nodes. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        RunnableResult: Result of the node execution.\n    \"\"\"\n    from dynamiq.nodes.agents.exceptions import RecoverableAgentException\n\n    logger.info(f\"Node {self.name} - {self.id}: execution started.\")\n    transformed_input = input_data\n    time_start = datetime.now()\n\n    config = ensure_config(config)\n\n    run_id = uuid4()\n    merged_kwargs = merge(kwargs, {\"run_id\": run_id, \"parent_run_id\": kwargs.get(\"parent_run_id\", None)})\n    if depends_result is None:\n        depends_result = {}\n\n    try:\n        try:\n            self.validate_depends(depends_result)\n            input_data = self.get_approved_data_or_origin(input_data, config=config, **merged_kwargs)\n        except NodeException as e:\n            transformed_input = input_data | {\n                k: result.to_tracing_depend_dict() for k, result in depends_result.items()\n            }\n            skip_data = {\"failed_dependency\": e.failed_depend.to_dict(for_tracing=True)}\n            self.run_on_node_skip(\n                callbacks=config.callbacks,\n                skip_data=skip_data,\n                input_data=transformed_input,\n                **merged_kwargs,\n            )\n            logger.info(f\"Node {self.name} - {self.id}: execution skipped.\")\n            return RunnableResult(\n                status=RunnableStatus.SKIP,\n                input=transformed_input,\n                output=None,\n                error=RunnableResultError.from_exception(e, recoverable=e.recoverable),\n            )\n\n        transformed_input = self.validate_input_schema(\n            self.transform_input(input_data=input_data, depends_result=depends_result, config=config, **kwargs),\n            **kwargs,\n        )\n        self.run_on_node_start(config.callbacks, dict(transformed_input), **merged_kwargs)\n        cache = cache_wf_entity(\n            entity_id=self.id,\n            cache_enabled=self.caching.enabled,\n            cache_config=config.cache,\n        )\n\n        output, from_cache = cache(self.execute_with_retry)(transformed_input, config, **merged_kwargs)\n\n        merged_kwargs[\"is_output_from_cache\"] = from_cache\n        transformed_output = self.transform_output(output, config=config, **kwargs)\n\n        self.run_on_node_end(config.callbacks, transformed_output, **merged_kwargs)\n\n        logger.info(\n            f\"Node {self.name} - {self.id}: execution succeeded in \"\n            f\"{format_duration(time_start, datetime.now())}.\"\n        )\n        return RunnableResult(\n            status=RunnableStatus.SUCCESS, input=dict(transformed_input), output=transformed_output\n        )\n    except Exception as e:\n        self.run_on_node_error(callbacks=config.callbacks, error=e, input_data=transformed_input, **merged_kwargs)\n        logger.error(\n            f\"Node {self.name} - {self.id}: execution failed in {e}\"\n            f\"{format_duration(time_start, datetime.now())}.\"\n        )\n\n        recoverable = isinstance(e, RecoverableAgentException)\n        result = RunnableResult(\n            status=RunnableStatus.FAILURE,\n            input=transformed_input,\n            output=None,\n            error=RunnableResultError.from_exception(e, recoverable=recoverable),\n        )\n        return result\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.send_approval_message","title":"<code>send_approval_message(approval_config, input_data, config=None, **kwargs)</code>","text":"<p>Sends approval message and determines if it was approved or disapproved (canceled).</p> <p>Parameters:</p> Name Type Description Default <code>approval_config</code> <code>ApprovalConfig</code> <p>Configuration for the approval.</p> required <code>input_data</code> <code>dict</code> <p>Data that will be sent.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>ApprovalInputData</code> <code>ApprovalInputData</code> <p>Result of approval.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def send_approval_message(\n    self, approval_config: ApprovalConfig, input_data: dict, config: RunnableConfig = None, **kwargs\n) -&gt; ApprovalInputData:\n    \"\"\"\n    Sends approval message and determines if it was approved or disapproved (canceled).\n\n    Args:\n        approval_config (ApprovalConfig): Configuration for the approval.\n        input_data (dict): Data that will be sent.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        ApprovalInputData: Result of approval.\n    \"\"\"\n\n    message = Template(approval_config.msg_template).render(self.to_dict(), input_data=input_data)\n    match approval_config.feedback_method:\n        case FeedbackMethod.STREAM:\n            approval_result = self.send_streaming_approval_message(\n                message, input_data, approval_config, config=config, **kwargs\n            )\n        case FeedbackMethod.CONSOLE:\n            approval_result = self.send_console_approval_message(message)\n        case _:\n            raise ValueError(f\"Error: Incorrect feedback method is chosen {approval_config.feedback_method}.\")\n\n    update_params = {\n        feature_name: approval_result.data[feature_name]\n        for feature_name in approval_config.mutable_data_params\n        if feature_name in approval_result.data\n    }\n    approval_result.data = {**input_data, **update_params}\n\n    if approval_result.is_approved is None:\n        if approval_result.feedback == approval_config.accept_pattern:\n            logger.info(\n                f\"Node {self.name} action was approved by human \"\n                f\"with provided feedback '{approval_result.feedback}'.\"\n            )\n            approval_result.is_approved = True\n\n        else:\n            approval_result.is_approved = False\n            logger.info(\n                f\"Node {self.name} action was canceled by human\"\n                f\"with provided feedback '{approval_result.feedback}'.\"\n            )\n\n    return approval_result\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.send_console_approval_message","title":"<code>send_console_approval_message(template)</code>","text":"<p>Sends approval message in console and waits for response.</p> <p>Parameters:</p> Name Type Description Default <code>template</code> <code>dict</code> <p>Template to send.</p> required <p>Returns:     ApprovalInputData: Response to approval message.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def send_console_approval_message(self, template: str) -&gt; ApprovalInputData:\n    \"\"\"\n    Sends approval message in console and waits for response.\n\n    Args:\n        template (dict): Template to send.\n    Returns:\n        ApprovalInputData: Response to approval message.\n    \"\"\"\n    feedback = input(template)\n    return ApprovalInputData(feedback=feedback)\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.send_streaming_approval_message","title":"<code>send_streaming_approval_message(template, input_data, approval_config, config=None, **kwargs)</code>","text":"<p>Sends approval message and waits for response.</p> <p>Parameters:</p> Name Type Description Default <code>template</code> <code>str</code> <p>Template to send.</p> required <code>input_data</code> <code>dict</code> <p>Data that will be sent.</p> required <code>approval_config</code> <code>ApprovalConfig</code> <p>Configuration for approval.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Return <p>ApprovalInputData: Response to approval message.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def send_streaming_approval_message(\n    self, template: str, input_data: dict, approval_config: ApprovalConfig, config: RunnableConfig = None, **kwargs\n) -&gt; ApprovalInputData:\n    \"\"\"\n    Sends approval message and waits for response.\n\n    Args:\n        template (str): Template to send.\n        input_data (dict): Data that will be sent.\n        approval_config (ApprovalConfig): Configuration for approval.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Return:\n        ApprovalInputData: Response to approval message.\n\n    \"\"\"\n    event = ApprovalStreamingOutputEventMessage(\n        wf_run_id=config.run_id,\n        entity_id=self.id,\n        data={\"template\": template, \"data\": input_data, \"mutable_data_params\": approval_config.mutable_data_params},\n        event=approval_config.event,\n    )\n\n    logger.info(f\"Node {self.name} - {self.id}: sending approval.\")\n\n    self.run_on_node_execute_stream(callbacks=config.callbacks, event=event, **kwargs)\n\n    output: ApprovalInputData = self.get_input_streaming_event(\n        event=approval_config.event, event_msg_type=ApprovalStreamingInputEventMessage, config=config\n    ).data\n\n    return output\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.to_dict","title":"<code>to_dict(include_secure_params=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    for_tracing: bool = kwargs.pop(\"for_tracing\", False)\n    exclude = kwargs.pop(\n        \"exclude\", self.to_dict_exclude_params if include_secure_params else self.to_dict_exclude_secure_params\n    )\n    data = self.model_dump(\n        exclude=exclude,\n        serialize_as_any=kwargs.pop(\"serialize_as_any\", True),\n        **kwargs,\n    )\n\n    it = self.input_transformer.to_dict(for_tracing=for_tracing, **kwargs)\n    if it is not None:\n        data[\"input_transformer\"] = it\n    ot = self.output_transformer.to_dict(for_tracing=for_tracing, **kwargs)\n    if ot is not None:\n        data[\"output_transformer\"] = ot\n    data[\"caching\"] = self.caching.to_dict(for_tracing=for_tracing, **kwargs)\n    data[\"streaming\"] = self.streaming.to_dict(for_tracing=for_tracing, **kwargs)\n    data[\"approval\"] = self.approval.to_dict(for_tracing=for_tracing, **kwargs)\n\n    data[\"depends\"] = [depend.to_dict(for_tracing=for_tracing, **kwargs) for depend in self.depends]\n    data[\"input_mapping\"] = format_value(self.input_mapping)\n\n    if getattr(self, \"connection\", None):\n        data[\"connection\"] = self.connection.to_dict(for_tracing=for_tracing, **kwargs)\n\n    if for_tracing:\n        data = {k: v for k, v in data.items() if v is not None or k in (\"input\", \"output\")}\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.transform","title":"<code>transform(data, transformer)</code>  <code>staticmethod</code>","text":"<p>Apply transformation to data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Input data to transform.</p> required <code>transformer</code> <code>Transformer</code> <p>Transformer to apply.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Transformed data.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>@staticmethod\ndef transform(data: Any, transformer: Transformer) -&gt; Any:\n    \"\"\"\n    Apply transformation to data.\n\n    Args:\n        data (Any): Input data to transform.\n        transformer (Transformer): Transformer to apply.\n\n    Returns:\n        Any: Transformed data.\n    \"\"\"\n    output = jsonpath_filter(data, transformer.path)\n    output = jsonpath_mapper(output, transformer.selector)\n    return output\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.transform_input","title":"<code>transform_input(input_data, depends_result, use_input_transformer=True, **kwargs)</code>","text":"<p>Transform input data for the node.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict</code> <p>Input data for the node.</p> required <code>depends_result</code> <code>dict</code> <p>Results of dependent nodes.</p> required <code>use_input_transformer</code> <code>bool</code> <p>Determines if InputTransformer will be applied to the input.</p> <code>True</code> <p>Raises:</p> Type Description <code>NodeException</code> <p>If a dependency result is missing or input mapping fails.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Transformed input data.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def transform_input(\n    self, input_data: dict, depends_result: dict[Any, RunnableResult], use_input_transformer: bool = True, **kwargs\n) -&gt; dict:\n    \"\"\"\n    Transform input data for the node.\n\n    Args:\n        input_data (dict): Input data for the node.\n        depends_result (dict): Results of dependent nodes.\n        use_input_transformer (bool): Determines if InputTransformer will be applied to the input.\n\n    Raises:\n        NodeException: If a dependency result is missing or input mapping fails.\n\n    Returns:\n        dict: Transformed input data.\n    \"\"\"\n    # Apply input transformer\n    if (self.input_transformer.path or self.input_transformer.selector) and use_input_transformer:\n        depends_result_as_dict = {k: result.to_depend_dict() for k, result in depends_result.items()}\n        inputs = self.transform(input_data | depends_result_as_dict, self.input_transformer)\n    else:\n        inputs = input_data | {k: result.to_tracing_depend_dict() for k, result in depends_result.items()}\n\n    # Apply input bindings\n    for key, value in self.input_mapping.items():\n        if isinstance(value, NodeOutputReference):\n            depend_result = depends_result.get(value.node.id)\n            if not depend_result:\n                raise NodeException(message=f\"Dependency {value.node.id}: result not found.\")\n            if value.output_key not in depend_result.output:\n                raise NodeException(message=f\"Dependency {value.node.id} output {value.output_key}: not found.\")\n\n            inputs[key] = depend_result.output[value.output_key]\n\n        elif callable(value):\n            try:\n                inputs[key] = value(inputs, {d_id: result.output for d_id, result in depends_result.items()})\n            except Exception:\n                raise NodeException(message=f\"Input mapping {key}: failed.\")\n        else:\n            inputs[key] = value\n\n    return inputs\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.transform_output","title":"<code>transform_output(output_data, **kwargs)</code>","text":"<p>Transform output data from the node.</p> <p>Parameters:</p> Name Type Description Default <code>output_data</code> <code>Any</code> <p>Output data to transform.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Transformed output data.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def transform_output(self, output_data: Any, **kwargs) -&gt; Any:\n    \"\"\"\n    Transform output data from the node.\n\n    Args:\n        output_data (Any): Output data to transform.\n\n    Returns:\n        Any: Transformed output data.\n    \"\"\"\n    return self.transform(output_data, self.output_transformer)\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.validate_depends","title":"<code>validate_depends(depends_result)</code>","text":"<p>Validate all dependencies of the node.</p> <p>Parameters:</p> Name Type Description Default <code>depends_result</code> <code>dict</code> <p>Results of dependent nodes.</p> required <code>input_data</code> <code>dict</code> <p>Input data for the node.</p> required Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def validate_depends(self, depends_result: dict[str, RunnableResult]):\n    \"\"\"\n    Validate all dependencies of the node.\n\n    Args:\n        depends_result (dict): Results of dependent nodes.\n        input_data (dict): Input data for the node.\n\n    Raises:\n        Various exceptions based on dependency validation results.\n    \"\"\"\n    for dep in self.depends:\n        self._validate_dependency_status(depend=dep, depends_result=depends_result)\n        if dep.condition:\n            self._validate_dependency_condition(depend=dep, depends_result=depends_result)\n        if dep.option:\n            self._validate_dependency_option(depend=dep, depends_result=depends_result)\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Node.validate_input_schema","title":"<code>validate_input_schema(input_data, **kwargs)</code>","text":"<p>Validate input data against the input schema. Returns instance of input_schema if it is provided.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data to validate.</p> required <p>Raises:</p> Type Description <code>NodeException</code> <p>If input data does not match the input schema.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def validate_input_schema(self, input_data: dict[str, Any], **kwargs) -&gt; dict[str, Any] | BaseModel:\n    \"\"\"\n    Validate input data against the input schema. Returns instance of input_schema if it is provided.\n\n    Args:\n        input_data (Any): Input data to validate.\n\n    Raises:\n        NodeException: If input data does not match the input schema.\n    \"\"\"\n    from dynamiq.nodes.agents.exceptions import RecoverableAgentException\n\n    if self.input_schema:\n        try:\n            return self.input_schema.model_validate(\n                input_data, context=kwargs | self.get_context_for_input_schema()\n            )\n        except Exception as e:\n            if kwargs.get(\"recoverable_error\", False):\n                raise RecoverableAgentException(f\"Input data validation failed: {e}\")\n            raise e\n\n    return input_data\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.NodeDependency","title":"<code>NodeDependency</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a dependency between nodes.</p> <p>Attributes:</p> Name Type Description <code>node</code> <code>Node</code> <p>The dependent node.</p> <code>option</code> <code>str | None</code> <p>Optional condition for the dependency.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class NodeDependency(BaseModel):\n    \"\"\"\n    Represents a dependency between nodes.\n\n    Attributes:\n        node (Node): The dependent node.\n        option (str | None): Optional condition for the dependency.\n    \"\"\"\n    node: \"Node\"\n    option: str | None = None\n    condition: ChoiceCondition | None = None\n\n    def __init__(self, node: \"Node\", option: str | None = None, condition: ChoiceCondition | None = None):\n        super().__init__(node=node, option=option, condition=condition)\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        for_tracing: bool = kwargs.get(\"for_tracing\", False)\n        node_value: dict\n        if for_tracing:\n            node_value = {\"id\": self.node.id, \"name\": self.node.name, \"type\": self.node.type}\n        else:\n            node_value = self.node.to_dict(**kwargs)\n\n        return {\n            \"node\": node_value,\n            \"option\": self.option,\n            \"condition\": self.condition.model_dump() if self.condition else None,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.NodeDependency.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    for_tracing: bool = kwargs.get(\"for_tracing\", False)\n    node_value: dict\n    if for_tracing:\n        node_value = {\"id\": self.node.id, \"name\": self.node.name, \"type\": self.node.type}\n    else:\n        node_value = self.node.to_dict(**kwargs)\n\n    return {\n        \"node\": node_value,\n        \"option\": self.option,\n        \"condition\": self.condition.model_dump() if self.condition else None,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.NodeMetadata","title":"<code>NodeMetadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata for a node.</p> <p>Attributes:</p> Name Type Description <code>label</code> <code>str | None</code> <p>Optional label for the node.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class NodeMetadata(BaseModel):\n    \"\"\"\n    Metadata for a node.\n\n    Attributes:\n        label (str | None): Optional label for the node.\n    \"\"\"\n    label: str | None = None\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.NodeOutputReference","title":"<code>NodeOutputReference</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a reference to a node output.</p> <p>Attributes:</p> Name Type Description <code>node</code> <code>Node</code> <p>The node to reference.</p> <code>output_key</code> <code>str</code> <p>Key for the output.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class NodeOutputReference(BaseModel):\n    \"\"\"\n    Represents a reference to a node output.\n\n    Attributes:\n        node (Node): The node to reference.\n        output_key (str): Key for the output.\n    \"\"\"\n\n    node: \"Node\"\n    output_key: str\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.NodeOutputReferences","title":"<code>NodeOutputReferences</code>","text":"<p>Provides output references for a node.</p> <p>Attributes:</p> Name Type Description <code>node</code> <code>Node</code> <p>The node to provide output references for.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class NodeOutputReferences:\n    \"\"\"\n    Provides output references for a node.\n\n    Attributes:\n        node (Node): The node to provide output references for.\n    \"\"\"\n\n    def __init__(self, node: \"Node\"):\n        self.node = node\n\n    def __getattr__(self, key: Any):\n        return NodeOutputReference(node=self.node, output_key=key)\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.NodeReadyToRun","title":"<code>NodeReadyToRun</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a node ready to run with its input data and dependencies.</p> <p>Attributes:</p> Name Type Description <code>node</code> <code>Node</code> <p>The node to be run.</p> <code>is_ready</code> <code>bool</code> <p>Whether the node is ready to run.</p> <code>input_data</code> <code>Any</code> <p>Input data for the node.</p> <code>depends_result</code> <code>dict[str, Any]</code> <p>Results of dependent nodes.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class NodeReadyToRun(BaseModel):\n    \"\"\"\n    Represents a node ready to run with its input data and dependencies.\n\n    Attributes:\n        node (Node): The node to be run.\n        is_ready (bool): Whether the node is ready to run.\n        input_data (Any): Input data for the node.\n        depends_result (dict[str, Any]): Results of dependent nodes.\n    \"\"\"\n    node: \"Node\"\n    is_ready: bool\n    input_data: Any = None\n    depends_result: dict[str, Any] = {}\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.OutputTransformer","title":"<code>OutputTransformer</code>","text":"<p>               Bases: <code>InputTransformer</code></p> <p>Output transformer for nodes.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class OutputTransformer(InputTransformer):\n    \"\"\"Output transformer for nodes.\"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.Transformer","title":"<code>Transformer</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base class for input and output transformers.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>str | None</code> <p>JSONPath for data selection.</p> <code>selector</code> <code>dict[str, str] | None</code> <p>Mapping for data transformation.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class Transformer(BaseModel):\n    \"\"\"\n    Base class for input and output transformers.\n\n    Attributes:\n        path (str | None): JSONPath for data selection.\n        selector (dict[str, str] | None): Mapping for data transformation.\n    \"\"\"\n    path: str | None = None\n    selector: dict[str, str] | None = None\n\n    def to_dict(self, for_tracing: bool = False, **kwargs) -&gt; dict | None:\n        if for_tracing and self.path is None and self.selector is None:\n            return None\n        return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.VectorStoreNode","title":"<code>VectorStoreNode</code>","text":"<p>               Bases: <code>ConnectionNode</code>, <code>BaseVectorStoreParams</code>, <code>ABC</code></p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>class VectorStoreNode(ConnectionNode, BaseVectorStoreParams, ABC):\n    vector_store: Any | None = None\n\n    @model_validator(mode=\"after\")\n    def validate_connection_client(self):\n        if not self.vector_store and not self.connection:\n            raise ValueError(\"'connection' or 'vector_store' should be specified\")\n        return self\n\n    @property\n    @abstractmethod\n    def vector_store_cls(self):\n        raise NotImplementedError\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(BaseVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def connect_to_vector_store(self):\n        vector_store_params = self.vector_store_params\n        vector_store = self.vector_store_cls(**vector_store_params)\n\n        logger.debug(\n            f\"Node {self.name} - {self.id}: connected to {self.vector_store_cls.__name__} vector store with\"\n            f\" {vector_store_params}\"\n        )\n\n        return vector_store\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize components for the node.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        # Use vector_store client if it is already initialized\n        if self.vector_store:\n            self.client = self.vector_store.client\n\n        super().init_components(connection_manager)\n\n        if self.vector_store is None:\n            self.vector_store = self.connect_to_vector_store()\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.VectorStoreNode.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize components for the node.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize components for the node.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    # Use vector_store client if it is already initialized\n    if self.vector_store:\n        self.client = self.vector_store.client\n\n    super().init_components(connection_manager)\n\n    if self.vector_store is None:\n        self.vector_store = self.connect_to_vector_store()\n</code></pre>"},{"location":"dynamiq/nodes/node/#dynamiq.nodes.node.ensure_config","title":"<code>ensure_config(config=None)</code>","text":"<p>Ensure that a valid RunnableConfig is provided.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>RunnableConfig</code> <p>The input configuration. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>RunnableConfig</code> <code>RunnableConfig</code> <p>A valid RunnableConfig object.</p> Source code in <code>dynamiq/nodes/node.py</code> <pre><code>def ensure_config(config: RunnableConfig = None) -&gt; RunnableConfig:\n    \"\"\"\n    Ensure that a valid RunnableConfig is provided.\n\n    Args:\n        config (RunnableConfig, optional): The input configuration. Defaults to None.\n\n    Returns:\n        RunnableConfig: A valid RunnableConfig object.\n    \"\"\"\n    if config is None:\n        return RunnableConfig(callbacks=[])\n\n    return config\n</code></pre>"},{"location":"dynamiq/nodes/types/","title":"Types","text":""},{"location":"dynamiq/nodes/types/#dynamiq.nodes.types.ChoiceCondition","title":"<code>ChoiceCondition</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a condition.</p> Source code in <code>dynamiq/nodes/types.py</code> <pre><code>class ChoiceCondition(BaseModel):\n    \"\"\"Represents a condition.\"\"\"\n\n    variable: str | None = None\n    operator: ConditionOperator | None = None\n    value: Any = None\n    is_not: bool = False\n    operands: list[\"ChoiceCondition\"] | None = None\n</code></pre>"},{"location":"dynamiq/nodes/types/#dynamiq.nodes.types.ConditionOperator","title":"<code>ConditionOperator</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum representing various condition operators.</p> Source code in <code>dynamiq/nodes/types.py</code> <pre><code>class ConditionOperator(str, Enum):\n    \"\"\"Enum representing various condition operators.\"\"\"\n\n    OR = \"or\"\n    AND = \"and\"\n    BOOLEAN_EQUALS = \"boolean-equals\"\n    BOOLEAN_EQUALS_PATH = \"boolean-equals-path\"\n    NUMERIC_EQUALS = \"numeric-equals\"\n    NUMERIC_EQUALS_PATH = \"numeric-equals-path\"\n    NUMERIC_GREATER_THAN = \"numeric-greater-than\"\n    NUMERIC_GREATER_THAN_PATH = \"numeric-greater-than-path\"\n    NUMERIC_GREATER_THAN_OR_EQUALS = \"numeric-greater-than-or-equals\"\n    NUMERIC_GREATER_THAN_OR_EQUALS_PATH = \"numeric-greater-than-or-equals-path\"\n    NUMERIC_LESS_THAN = \"numeric-less-than\"\n    NUMERIC_LESS_THAN_PATH = \"numeric-less-than-path\"\n    NUMERIC_LESS_THAN_OR_EQUALS = \"numeric-less-than-or-equals\"\n    NUMERIC_LESS_THAN_OR_EQUALS_PATH = \"numeric-less-than-or-equals-path\"\n    STRING_EQUALS = \"string-equals\"\n    STRING_EQUALS_PATH = \"string-equals-path\"\n    STRING_GREATER_THAN = \"string-greater-than\"\n    STRING_GREATER_THAN_PATH = \"string-greater-than-path\"\n    STRING_GREATER_THAN_OR_EQUALS = \"string-greater-than-or-equals\"\n    STRING_GREATER_THAN_OR_EQUALS_PATH = \"string-greater-than-or-equals-path\"\n    STRING_LESS_THAN = \"string-less-than\"\n    STRING_LESS_THAN_PATH = \"string-less-than-path\"\n    STRING_LESS_THAN_OR_EQUALS = \"string-less-than-or-equals\"\n    STRING_LESS_THAN_OR_EQUALS_PATH = \"string-less-than-or-equals-path\"\n    STRING_STARTS_WITH = \"string-starts-with\"\n    STRING_ENDS_WITH = \"string-ends-with\"\n    STRING_CONTAINS = \"string-contains\"\n    STRING_REGEXP = \"string-regexp\"\n</code></pre>"},{"location":"dynamiq/nodes/types/#dynamiq.nodes.types.InferenceMode","title":"<code>InferenceMode</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of inference types.</p> Source code in <code>dynamiq/nodes/types.py</code> <pre><code>class InferenceMode(str, Enum):\n    \"\"\"\n    Enumeration of inference types.\n    \"\"\"\n\n    DEFAULT = \"DEFAULT\"\n    XML = \"XML\"\n    FUNCTION_CALLING = \"FUNCTION_CALLING\"\n    STRUCTURED_OUTPUT = \"STRUCTURED_OUTPUT\"\n</code></pre>"},{"location":"dynamiq/nodes/types/#dynamiq.nodes.types.NodeGroup","title":"<code>NodeGroup</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of node groups that categorize different types of nodes.</p> <p>Each group represents a collection of related node types, providing a higher-level classification of the system's components.</p> Source code in <code>dynamiq/nodes/types.py</code> <pre><code>class NodeGroup(str, Enum):\n    \"\"\"\n    Enumeration of node groups that categorize different types of nodes.\n\n    Each group represents a collection of related node types, providing a higher-level\n    classification of the system's components.\n    \"\"\"\n\n    LLMS = \"llms\"\n    OPERATORS = \"operators\"\n    EMBEDDERS = \"embedders\"\n    RANKERS = \"rankers\"\n    CONVERTERS = \"converters\"\n    RETRIEVERS = \"retrievers\"\n    SPLITTERS = \"splitters\"\n    WRITERS = \"writers\"\n    UTILS = \"utils\"\n    TOOLS = \"tools\"\n    AGENTS = \"agents\"\n    AUDIO = \"audio\"\n    VALIDATORS = \"validators\"\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/","title":"Agent","text":""},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent","title":"<code>Agent</code>","text":"<p>               Bases: <code>Agent</code></p> <p>Unified Agent that uses a ReAct-style strategy for processing tasks by interacting with tools in a loop.</p> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>class Agent(BaseAgent):\n    \"\"\"Unified Agent that uses a ReAct-style strategy for processing tasks by interacting with tools in a loop.\"\"\"\n\n    name: str = \"Agent\"\n    max_loops: int = Field(default=15, ge=2)\n    inference_mode: InferenceMode = Field(default=InferenceMode.DEFAULT)\n    behaviour_on_max_loops: Behavior = Field(\n        default=Behavior.RAISE,\n        description=\"Define behavior when max loops are exceeded. Options are 'raise' or 'return'.\",\n    )\n    parallel_tool_calls_enabled: bool = Field(\n        default=False,\n        description=\"Enable multi-tool execution in a single step. \"\n        \"When True, the agent can call multiple tools in parallel.\",\n    )\n    direct_tool_output_enabled: bool = Field(\n        default=False,\n        description=\"Allow agent to return raw tool outputs as final answers. \"\n        \"When True, agent can use special XML format to return tool outputs directly.\",\n    )\n\n    format_schema: list = Field(default_factory=list)\n    summarization_config: SummarizationConfig = Field(default_factory=SummarizationConfig)\n\n    _tools: list[Tool] = []\n    _response_format: dict[str, Any] | None = None\n\n    def log_reasoning(self, thought: str, action: str, action_input: str, loop_num: int) -&gt; None:\n        \"\"\"\n        Logs reasoning step of agent.\n\n        Args:\n            thought (str): Reasoning about next step.\n            action (str): Chosen action.\n            action_input (str): Input to the tool chosen by action.\n            loop_num (int): Number of reasoning loop.\n        \"\"\"\n        logger.info(\n            \"\\n------------------------------------------\\n\"\n            f\"Agent {self.name}: Loop {loop_num}:\\n\"\n            f\"Thought: {thought}\\n\"\n            f\"Action: {action}\\n\"\n            f\"Action Input: {action_input}\"\n            \"\\n------------------------------------------\"\n        )\n\n    def log_final_output(self, thought: str, final_output: str, loop_num: int) -&gt; None:\n        \"\"\"\n        Logs final output of the agent.\n\n        Args:\n            final_output (str): Final output of agent.\n            loop_num (int): Number of reasoning loop\n        \"\"\"\n        logger.info(\n            \"\\n------------------------------------------\\n\"\n            f\"Agent {self.name}: Loop {loop_num}\\n\"\n            f\"Thought: {thought}\\n\"\n            f\"Final answer: {final_output}\"\n            \"\\n------------------------------------------\\n\"\n        )\n\n    @model_validator(mode=\"after\")\n    def validate_inference_mode(self):\n        \"\"\"Validate whether specified model can be inferenced in provided mode.\"\"\"\n        match self.inference_mode:\n            case InferenceMode.FUNCTION_CALLING:\n                if not supports_function_calling(model=self.llm.model):\n                    raise ValueError(f\"Model {self.llm.model} does not support function calling\")\n\n            case InferenceMode.STRUCTURED_OUTPUT:\n                params = get_supported_openai_params(model=self.llm.model)\n                if \"response_format\" not in params:\n                    raise ValueError(f\"Model {self.llm.model} does not support structured output\")\n\n        return self\n\n    @model_validator(mode=\"after\")\n    def _ensure_context_manager_tool(self):\n        \"\"\"Automatically add ContextManagerTool when summarization is enabled.\"\"\"\n        try:\n            if self.summarization_config.enabled:\n                has_context_tool = any(isinstance(t, ContextManagerTool) for t in self.tools)\n                if not has_context_tool:\n                    # Add with a stable name for addressing from the agent\n                    self.tools.append(ContextManagerTool(llm=self.llm, name=\"context-manager\"))\n        except Exception as e:\n            logger.error(f\"Failed to ensure ContextManagerTool: {e}\")\n        return self\n\n    def _parse_thought(self, output: str) -&gt; tuple[str | None, str | None]:\n        \"\"\"Extracts thought from the output string.\"\"\"\n        thought_match = re.search(\n            r\"Thought:\\s*(.*?)Action\",\n            output,\n            re.DOTALL,\n        )\n\n        if thought_match:\n            return thought_match.group(1).strip()\n\n        return \"\"\n\n    def _parse_action(self, output: str) -&gt; tuple[str | None, str | None, dict | list | None]:\n        \"\"\"\n        Parses the action(s), input(s),\n        and thought from the output string.\n        Supports both single tool actions\n        and multiple sequential tool calls when multi-tool is enabled.\n\n        Args:\n            output (str): The output string from the LLM containing Thought, Action, and Action Input.\n\n        Returns:\n            tuple: (thought, action_type, actions_data) where:\n                - thought is the extracted reasoning\n                - action_type is either a tool name (for single tool) or \"multiple_tools\" (for multiple tools)\n                - actions_data is either a dict (for single tool) or a list of dicts (for multiple tools)\n        \"\"\"\n        try:\n            thought_pattern = r\"Thought:\\s*(.*?)(?:Action:|$)\"\n            thought_match = re.search(thought_pattern, output, re.DOTALL)\n            thought = thought_match.group(1).strip() if thought_match else None\n\n            action_pattern = r\"Action:\\s*(.*?)\\nAction Input:\\s*(\\{(?:[^{}]|(?R))*\\})\"\n\n            remaining_text = output\n            actions = []\n\n            while \"Action:\" in remaining_text:\n                action_match = regex.search(action_pattern, remaining_text, re.DOTALL)\n                if not action_match:\n                    break\n\n                action_name = action_match.group(1).strip()\n                raw_input = action_match.group(2).strip()\n\n                for marker in [\"```json\", \"```JSON\", \"```\"]:\n                    raw_input = raw_input.replace(marker, \"\").strip()\n\n                try:\n                    action_input = json.loads(raw_input.strip())\n                    actions.append({\"tool_name\": action_name, \"tool_input\": action_input})\n                except json.JSONDecodeError as e:\n                    raise ActionParsingException(\n                        f\"Invalid JSON in Action Input for {action_name}: {str(e)} : {raw_input}\",\n                        recoverable=True,\n                    )\n\n                end_pos = action_match.end()\n                remaining_text = remaining_text[end_pos:]\n\n            if not actions:\n                logger.info(\"No valid Action and Action Input pairs found in the output \")\n                raise ActionParsingException(\n                    \"No valid Action and Action Input pairs found in the output.\",\n                    recoverable=True,\n                )\n\n            if not self.parallel_tool_calls_enabled or len(actions) == 1:\n                action = actions[0][\"tool_name\"]\n                action_input = actions[0][\"tool_input\"]\n                return thought, action, action_input\n            else:\n                return thought, \"multiple_tools\", actions\n\n        except Exception as e:\n            logger.error(f\"Error: {e}\")\n            if isinstance(e, ActionParsingException):\n                raise\n            raise ActionParsingException(\n                f\"Error parsing action(s): {str(e)}. \"\n                f\"Please ensure the output follows the format 'Thought: &lt;text&gt; \"\n                f\"Action: &lt;action&gt; Action Input: &lt;valid JSON&gt;' \"\n                f\"{'with possible multiple Action/Action Input pairs.' if self.parallel_tool_calls_enabled else ''}\",\n                recoverable=True,\n            )\n\n    def tracing_final(self, loop_num, final_answer, config, kwargs):\n        self._intermediate_steps[loop_num][\"final_answer\"] = final_answer\n\n    def tracing_intermediate(self, loop_num, formatted_prompt, llm_generated_output):\n        self._intermediate_steps[loop_num] = AgentIntermediateStep(\n            input_data={\"prompt\": formatted_prompt},\n            model_observation=AgentIntermediateStepModelObservation(\n                initial=llm_generated_output,\n            ),\n        ).model_dump(by_alias=True)\n\n    def _append_recovery_instruction(\n        self,\n        *,\n        error_label: str,\n        error_detail: str,\n        llm_generated_output: str | None,\n        extra_guidance: str | None = None,\n    ) -&gt; None:\n        \"\"\"Append a correction instruction to prompt for recoverable agent errors.\"\"\"\n\n        error_context = llm_generated_output if llm_generated_output else \"No response generated\"\n\n        self._prompt.messages.append(\n            Message(role=MessageRole.ASSISTANT, content=f\"Previous response:\\n{error_context}\", static=True)\n        )\n\n        guidance_suffix = f\" {extra_guidance.strip()}\" if extra_guidance else \"\"\n\n        correction_message = (\n            \"Correction Instruction: The previous response could not be parsed due to the \"\n            f\"following error: '{error_label}: {error_detail}'. Please regenerate the response \"\n            \"strictly following the required format, ensuring all tags or labeled sections are \"\n            \"present and correctly structured, and that any JSON content is valid.\" + guidance_suffix\n        )\n\n        self._prompt.messages.append(\n            Message(role=MessageRole.USER, content=correction_message, static=True)\n        )\n\n    def _extract_final_answer(self, output: str) -&gt; str:\n        \"\"\"Extracts the final thought and answer as a tuple from the output string.\"\"\"\n        match = re.search(r\"Thought:\\s*(.*?)\\s*Answer:\\s*(.*)\", output, re.DOTALL)\n        if match:\n            thought = match.group(1).strip()\n            answer = match.group(2).strip()\n            return thought, answer\n        else:\n            return \"\", \"\"\n\n    def _process_direct_tool_output_return_xml(self, final_answer: str) -&gt; str:\n        \"\"\"\n        Process direct tool output return format.\n        Looks for XML format: &lt;answer type=\"tool_output\" action=\"tool_name\" action_input=\"tool_input\"&gt;\n\n        Args:\n            final_answer (str): The final answer to process\n\n        Returns:\n            str: Either the raw tool output or the original final answer\n        \"\"\"\n\n        tool_output_match = re.search(\n            r'&lt;answer\\s+type=\"tool_output\"\\s+action=\"([^\"]+)\"\\s+action_input\\s*=[\\'\"](.*?)[\\'\"]\\s*(?:&gt;&lt;/answer&gt;|&gt;)',\n            final_answer,\n            re.IGNORECASE | re.DOTALL,\n        )\n\n        if tool_output_match:\n            action = tool_output_match.group(1)\n            action_input = tool_output_match.group(2)\n\n            try:\n                parsed_action_input = json.loads(action_input)\n            except json.JSONDecodeError as e:\n                raise RecoverableAgentException(f\"Invalid JSON in Action Input for {action}: {str(e)}\")\n\n            cache_entry = ToolCacheEntry(action=action, action_input=parsed_action_input)\n            tool_output = self._tool_cache.get(cache_entry)\n\n            if tool_output is not None:\n                logger.info(f\"Found tool output for action='{action}' action_input='{action_input}'\")\n                return str(tool_output)\n            else:\n                available_tools = [(entry.action, entry.action_input) for entry in self._tool_cache.keys()]\n                logger.warning(\n                    f\"Tool output not found for action='{action}' input='{action_input}'. \"\n                    f\"Available tools: {available_tools}\"\n                )\n                logger.debug(f\"Cache entry created: {cache_entry}\")\n                return final_answer\n\n        return final_answer\n\n    def stream_reasoning(self, content: dict[str, Any], config: RunnableConfig, **kwargs) -&gt; None:\n        \"\"\"\n        Streams intermediate reasoning of the Agent.\n\n        Args:\n            content (dict[str, Any]): Content that will be sent.\n            config (RunnableConfig | None): Configuration for the agent run.\n            **kwargs: Additional parameters for running the agent.\n        \"\"\"\n        if self.streaming.enabled and self.streaming.mode == StreamingMode.ALL:\n            self.stream_content(\n                content=content,\n                source=self.name,\n                step=\"reasoning\",\n                config=config,\n                **kwargs,\n            )\n\n    def is_token_limit_exceeded(self) -&gt; bool:\n        \"\"\"Check whether token limit for summarization is exceeded.\n\n        Returns:\n            bool: Whether token limit is exceeded.\n        \"\"\"\n        prompt_tokens = self._prompt.count_tokens(self.llm.model)\n\n        return (\n            self.summarization_config.max_token_context_length\n            and prompt_tokens &gt; self.summarization_config.max_token_context_length\n        ) or (prompt_tokens / self.llm.get_token_limit() &gt; self.summarization_config.context_usage_ratio)\n\n    def summarize_history(\n        self,\n        input_message,\n        summary_offset: int,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; int:\n        \"\"\"\n        Summarizes history and saves relevant information in the context\n\n        Args:\n            input_message (Message | VisionMessage): User request message.\n            summary_offset (int): Offset to the position of the first message in prompt that was not summarized.\n            config (RunnableConfig | None): Configuration for the agent run.\n            **kwargs: Additional parameters for running the agent.\n\n        Returns:\n            int: Number of summarized messages.\n        \"\"\"\n        logger.info(f\"Agent {self.name} - {self.id}: Summarization of tool output started.\")\n        messages_history = \"\\nHistory to extract information from: \\n\"\n        summary_sections = []\n\n        offset = max(self._history_offset, summary_offset - self.summarization_config.context_history_length)\n        for index, message in enumerate(self._prompt.messages[offset:]):\n            if message.role == MessageRole.USER:\n                if (index + offset &gt;= summary_offset) and (\"Observation:\" in message.content):\n                    messages_history += (\n                        f\"=== TOOL_OUTPUT: {index + offset} === \\n {message.content}\"\n                        f\"\\n === TOOL_OUTPUT: {index + offset} === \\n\"\n                    )\n                    summary_sections.append(index + offset)\n            else:\n                messages_history += f\"\\n{message.content}\\n\"\n\n        messages_history = (\n            messages_history + f\"\\n Required tags in the output {[f'tool_output{index}' for index in summary_sections]}\"\n        )\n\n        summary_messages = [\n            Message(content=HISTORY_SUMMARIZATION_PROMPT, role=MessageRole.SYSTEM, static=True),\n            input_message,\n            Message(content=messages_history, role=MessageRole.USER, static=True),\n        ]\n\n        summary_tags = [f\"tool_output{index}\" for index in summary_sections]\n\n        for _ in range(self.max_loops):\n            llm_result = self._run_llm(\n                messages=summary_messages,\n                config=config,\n                **kwargs,\n            )\n\n            output = llm_result.output[\"content\"]\n            summary_messages.append(Message(content=output, role=MessageRole.ASSISTANT, static=True))\n            try:\n                parsed_data = XMLParser.parse(\n                    f\"&lt;root&gt;{output}&lt;/root&gt;\",\n                    required_tags=summary_tags,\n                    optional_tags=[],\n                )\n            except ParsingError as e:\n                logger.error(f\"Error: {e}. Make sure you have provided all tags at once: {summary_tags}\")\n                summary_messages.append(Message(content=str(e), role=MessageRole.USER, static=True))\n                continue\n\n            for summary_index, message_index in enumerate(summary_sections[:-1]):\n                self._prompt.messages[message_index].content = (\n                    f\"Observation (shortened): \\n{parsed_data.get(summary_tags[summary_index])}\"\n                )\n\n            if self.is_token_limit_exceeded():\n                self._prompt.messages[summary_sections[-1]].content = (\n                    f\"Observation (shortened): \\n{parsed_data.get(summary_tags[-1])}\"\n                )\n                summary_offset = len(self._prompt.messages)\n            else:\n                summary_offset = len(self._prompt.messages) - 2\n\n            logger.info(f\"Agent {self.name} - {self.id}: Summarization of tool output finished.\")\n            return summary_offset\n\n    def get_clone_attr_initializers(self) -&gt; dict[str, Callable[[Node], Any]]:\n        base = super().get_clone_attr_initializers()\n        base.update(\n            {\n                \"_tool_cache\": lambda _: {},\n            }\n        )\n        return base\n\n    def _run_agent(\n        self,\n        input_message: Message | VisionMessage,\n        history_messages: list[Message] | None = None,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; str:\n        \"\"\"\n        Executes the ReAct strategy by iterating through thought, action, and observation cycles.\n        Args:\n            config (RunnableConfig | None): Configuration for the agent run.\n            **kwargs: Additional parameters for running the agent.\n        Returns:\n            str: Final answer provided by the agent.\n        Raises:\n            RuntimeError: If the maximum number of loops is reached without finding a final answer.\n            Exception: If an error occurs during execution.\n        \"\"\"\n        if self.verbose:\n            logger.info(f\"Agent {self.name} - {self.id}: Running ReAct strategy\")\n\n        system_message = Message(\n            role=MessageRole.SYSTEM,\n            content=self.generate_prompt(\n                tools_name=self.tool_names, input_formats=self.generate_input_formats(self.tools)\n            ),\n            static=True,\n        )\n\n        if history_messages:\n            self._prompt.messages = [system_message, *history_messages, input_message]\n        else:\n            self._prompt.messages = [system_message, input_message]\n\n        summary_offset = self._history_offset = len(self._prompt.messages)\n\n        stop_sequences = []\n        if self.inference_mode == InferenceMode.DEFAULT:\n            stop_sequences.extend([\"Observation: \", \"\\nObservation:\"])\n        elif self.inference_mode == InferenceMode.XML:\n            stop_sequences.extend([\n                \"\\nObservation:\",\n                \"Observation:\",\n                \"&lt;/output&gt;\\n&lt;\",\n                \"&lt;/output&gt;&lt;\",\n            ])\n        self.llm.stop = stop_sequences\n\n        for loop_num in range(1, self.max_loops + 1):\n            try:\n                streaming_callback = None\n                original_streaming_enabled = self.llm.streaming.enabled\n\n                if self.streaming.enabled:\n                    streaming_callback = AgentStreamingParserCallback(\n                        agent=self,\n                        config=config,\n                        loop_num=loop_num,\n                        **kwargs,\n                    )\n\n                    if not original_streaming_enabled:\n                        self.llm.streaming.enabled = True\n\n                    llm_config = config.model_copy(deep=False)\n                    llm_config.callbacks = [\n                        callback\n                        for callback in llm_config.callbacks\n                        if not isinstance(callback, StreamingQueueCallbackHandler)\n                    ]\n                    llm_config.callbacks.append(streaming_callback)\n\n                try:\n                    llm_result = self._run_llm(\n                        messages=self._prompt.messages,\n                        tools=self._tools,\n                        response_format=self._response_format,\n                        config=(llm_config if streaming_callback else config),\n                        **kwargs,\n                    )\n                finally:\n                    if not original_streaming_enabled:\n                        try:\n                            self.llm.streaming.enabled = original_streaming_enabled\n                        except Exception:\n                            logger.error(\"Failed to restore llm.streaming.enabled state\")\n\n                action, action_input = None, None\n                llm_generated_output = \"\"\n\n                if streaming_callback and streaming_callback.accumulated_content:\n                    llm_generated_output = streaming_callback.accumulated_content\n                else:\n                    llm_generated_output = llm_result.output.get(\"content\", \"\")\n\n                llm_reasoning = (\n                    llm_generated_output[:200]\n                    if llm_generated_output\n                    else str(llm_result.output.get(\"tool_calls\", \"\"))[:200]\n                )\n                logger.info(f\"Agent {self.name} - {self.id}: Loop {loop_num}, \" f\"reasoning:\\n{llm_reasoning}...\")\n\n                match self.inference_mode:\n                    case InferenceMode.DEFAULT:\n\n                        self.tracing_intermediate(loop_num, self._prompt.messages, llm_generated_output)\n\n                        if not llm_generated_output or not llm_generated_output.strip():\n                            self._append_recovery_instruction(\n                                error_label=\"EmptyResponse\",\n                                error_detail=\"The model returned an empty reply while using the Thought/Action format.\",\n                                llm_generated_output=llm_generated_output,\n                                extra_guidance=(\n                                    \"Re-evaluate the latest observation and respond with 'Thought:' followed by either \"\n                                    \"an 'Action:' plus JSON 'Action Input:' or a final 'Answer:' section.\"\n                                ),\n                            )\n                            continue\n\n                        if \"Answer:\" in llm_generated_output:\n                            thought, final_answer = self._extract_final_answer(llm_generated_output)\n\n                            if self.direct_tool_output_enabled:\n                                final_answer = self._process_direct_tool_output_return_xml(final_answer)\n\n                            self.log_final_output(thought, final_answer, loop_num)\n                            self.tracing_final(loop_num, final_answer, config, kwargs)\n                            return final_answer\n\n                        thought, action, action_input = self._parse_action(llm_generated_output)\n                        self.log_reasoning(thought, action, action_input, loop_num)\n\n                    case InferenceMode.FUNCTION_CALLING:\n                        if self.verbose:\n                            logger.info(f\"Agent {self.name} - {self.id}: using function calling inference mode\")\n                        if \"tool_calls\" not in dict(llm_result.output):\n                            logger.error(\"Error: No function called.\")\n                            raise ActionParsingException(\n                                \"Error: No function called, you need to call the correct function.\"\n                            )\n\n                        action = list(llm_result.output[\"tool_calls\"].values())[0][\"function\"][\"name\"].strip()\n                        llm_generated_output_json = list(llm_result.output[\"tool_calls\"].values())[0][\"function\"][\n                            \"arguments\"\n                        ]\n\n                        llm_generated_output = json.dumps(llm_generated_output_json)\n\n                        self.tracing_intermediate(loop_num, self._prompt.messages, llm_generated_output)\n                        thought = llm_generated_output_json[\"thought\"]\n                        if action == \"provide_final_answer\":\n                            final_answer = llm_generated_output_json[\"answer\"]\n                            self.log_final_output(thought, final_answer, loop_num)\n                            self.tracing_final(loop_num, final_answer, config, kwargs)\n                            return final_answer\n\n                        action_input = llm_generated_output_json[\"action_input\"]\n\n                        if isinstance(action_input, str):\n                            try:\n                                action_input = json.loads(action_input)\n                            except json.JSONDecodeError as e:\n                                raise ActionParsingException(\n                                    f\"Error parsing action_input string. {e}\", recoverable=True\n                                )\n\n                        self.log_reasoning(thought, action, action_input, loop_num)\n\n                    case InferenceMode.STRUCTURED_OUTPUT:\n                        if self.verbose:\n                            logger.info(f\"Agent {self.name} - {self.id}: using structured output inference mode\")\n\n                        self.tracing_intermediate(loop_num, self._prompt.messages, llm_generated_output)\n                        try:\n                            if isinstance(llm_generated_output, str):\n                                llm_generated_output_json = json.loads(llm_generated_output)\n                            else:\n                                llm_generated_output_json = llm_generated_output\n                        except json.JSONDecodeError as e:\n                            raise ActionParsingException(f\"Error parsing action. {e}\", recoverable=True)\n\n                        if \"action\" not in llm_generated_output_json or \"thought\" not in llm_generated_output_json:\n                            raise ActionParsingException(\"No action or thought provided.\", recoverable=True)\n\n                        thought = llm_generated_output_json[\"thought\"]\n                        action = llm_generated_output_json[\"action\"]\n                        action_input = llm_generated_output_json[\"action_input\"]\n\n                        if action == \"finish\":\n                            self.log_final_output(thought, action_input, loop_num)\n                            self.tracing_final(loop_num, action_input, config, kwargs)\n                            return action_input\n\n                        try:\n                            if isinstance(action_input, str):\n                                action_input = json.loads(action_input)\n                        except json.JSONDecodeError as e:\n                            raise ActionParsingException(f\"Error parsing action_input string. {e}\", recoverable=True)\n\n                        self.log_reasoning(thought, action, action_input, loop_num)\n\n                    case InferenceMode.XML:\n                        if self.verbose:\n                            logger.info(f\"Agent {self.name} - {self.id}: using XML inference mode\")\n\n                        self.tracing_intermediate(loop_num, self._prompt.messages, llm_generated_output)\n\n                        if not llm_generated_output or not llm_generated_output.strip():\n                            self._append_recovery_instruction(\n                                error_label=\"EmptyResponse\",\n                                error_detail=\"The model returned an empty reply while XML format was required.\",\n                                llm_generated_output=llm_generated_output,\n                                extra_guidance=(\n                                    \"Respond with &lt;thought&gt;...&lt;/thought&gt; and \"\n                                    \"either &lt;action&gt;/&lt;action_input&gt; or &lt;answer&gt; tags, \"\n                                    \"making sure to address the latest observation.\"\n                                ),\n                            )\n                            continue\n\n                        if self.parallel_tool_calls_enabled:\n                            try:\n                                parsed_result = XMLParser.parse_unified_xml_format(llm_generated_output)\n\n                                thought = parsed_result.get(\"thought\", \"\")\n\n                                if parsed_result.get(\"is_final\", False):\n                                    final_answer = parsed_result.get(\"answer\", \"\")\n                                    if self.direct_tool_output_enabled:\n                                        final_answer = self._process_direct_tool_output_return_xml(final_answer)\n                                    self.log_final_output(thought, final_answer, loop_num)\n                                    self.tracing_final(loop_num, final_answer, config, kwargs)\n                                    return final_answer\n\n                                tools_data = parsed_result.get(\"tools\", [])\n                                action = tools_data\n\n                                if len(tools_data) == 1:\n                                    self.log_reasoning(\n                                        thought,\n                                        tools_data[0].get(\"name\", \"unknown_tool\"),\n                                        tools_data[0].get(\"input\", {}),\n                                        loop_num,\n                                    )\n                                else:\n                                    self.log_reasoning(thought, \"multiple_tools\", str(tools_data), loop_num)\n\n                                tools_data_for_streaming = [\n                                    {\n                                        \"name\": tool.get(\"name\", \"\"),\n                                        \"type\": self.tool_by_names.get(tool.get(\"name\", \"\")).type,\n                                    }\n                                    for tool in tools_data\n                                    if tool.get(\"name\", \"\") and self.tool_by_names.get(tool.get(\"name\", \"\"))\n                                ]\n\n                                self.stream_reasoning(\n                                    {\n                                        \"thought\": thought,\n                                        \"tools\": tools_data_for_streaming,\n                                        \"loop_num\": loop_num,\n                                    },\n                                    config,\n                                    **kwargs,\n                                )\n\n                            except (XMLParsingError, TagNotFoundError, JSONParsingError) as e:\n                                self._append_recovery_instruction(\n                                    error_label=type(e).__name__,\n                                    error_detail=str(e),\n                                    llm_generated_output=llm_generated_output,\n                                    extra_guidance=(\n                                        \"Return &lt;thought&gt; with the resolved plan and list tool calls inside &lt;tools&gt;, \"\n                                        \"or mark the run as final with &lt;answer&gt;.\"\n                                    ),\n                                )\n                                continue\n                        else:\n                            try:\n                                parsed_data = XMLParser.parse(\n                                    llm_generated_output, required_tags=[\"thought\", \"answer\"], optional_tags=[\"output\"]\n                                )\n                                thought = parsed_data.get(\"thought\")\n                                final_answer = parsed_data.get(\"answer\")\n                                if self.direct_tool_output_enabled:\n                                    final_answer = self._process_direct_tool_output_return_xml(final_answer)\n                                self.log_final_output(thought, final_answer, loop_num)\n                                self.tracing_final(loop_num, final_answer, config, kwargs)\n                                return final_answer\n\n                            except TagNotFoundError:\n                                logger.debug(\"XMLParser: Not a final answer structure, trying action structure.\")\n                                try:\n                                    parsed_data = XMLParser.parse(\n                                        llm_generated_output,\n                                        required_tags=[\"thought\", \"action\", \"action_input\"],\n                                        optional_tags=[\"output\"],\n                                        json_fields=[\"action_input\"],\n                                    )\n                                    thought = parsed_data.get(\"thought\")\n                                    action = parsed_data.get(\"action\")\n                                    action_input = parsed_data.get(\"action_input\")\n                                    self.log_reasoning(thought, action, action_input, loop_num)\n                                except ParsingError as e:\n                                    logger.error(f\"XMLParser: Empty or invalid XML response for action parsing: {e}\")\n                                    raise ActionParsingException(\n                                        \"The previous response was empty or invalid. \"\n                                        \"Provide &lt;thought&gt; with either &lt;action&gt;/&lt;action_input&gt; or &lt;answer&gt;.\",\n                                        recoverable=True,\n                                    )\n                                except (XMLParsingError, TagNotFoundError, JSONParsingError) as e:\n                                    logger.error(f\"XMLParser: Failed to parse XML for action or answer: {e}\")\n                                    raise ActionParsingException(f\"Error parsing LLM output: {e}\", recoverable=True)\n\n                            except ParsingError as e:\n                                logger.error(f\"XMLParser: Empty or invalid XML response: {e}\")\n                                raise ActionParsingException(\n                                    \"The previous response was empty or invalid. \"\n                                    \"Please provide the required XML tags.\",\n                                    recoverable=True,\n                                )\n\n                            except (XMLParsingError, JSONParsingError) as e:\n                                logger.error(f\"XMLParser: Error parsing potential final answer XML: {e}\")\n                                raise ActionParsingException(f\"Error parsing LLM output: {e}\", recoverable=True)\n\n                self._prompt.messages.append(\n                    Message(role=MessageRole.ASSISTANT, content=llm_generated_output, static=True)\n                )\n\n                if action and self.tools:\n                    tool_result = None\n                    tool_files: Any = []\n                    tool = None\n\n                    if self.inference_mode == InferenceMode.XML and self.parallel_tool_calls_enabled:\n                        execution_output = self._execute_tools(tools_data, config, **kwargs)\n                        tool_result, tool_files = self._separate_tool_result_and_files(execution_output)\n\n                    elif self.inference_mode == InferenceMode.DEFAULT and self.parallel_tool_calls_enabled:\n                        if action == \"multiple_tools\":\n                            tools_data = []\n                            for tool_call in action_input:\n                                if (\n                                    not isinstance(tool_call, dict)\n                                    or \"tool_name\" not in tool_call\n                                    or \"tool_input\" not in tool_call\n                                ):\n                                    raise ActionParsingException(\n                                        \"Invalid tool call format. \"\n                                        \"Each tool call must have 'tool_name' and 'tool_input'.\",\n                                        recoverable=True,\n                                    )\n\n                                tools_data.append({\"name\": tool_call[\"tool_name\"], \"input\": tool_call[\"tool_input\"]})\n\n                            self.stream_reasoning(\n                                {\n                                    \"thought\": thought,\n                                    \"action\": \"multiple_tools\",\n                                    \"tools\": tools_data,\n                                    \"loop_num\": loop_num,\n                                },\n                                config,\n                                **kwargs,\n                            )\n\n                            execution_output = self._execute_tools(tools_data, config, **kwargs)\n                            tool_result, tool_files = self._separate_tool_result_and_files(execution_output)\n\n                            action_input_json = json.dumps(action_input)\n\n                            step_observation = AgentIntermediateStepModelObservation(\n                                tool_using=\"multiple_tools\",\n                                tool_input=str(action_input_json),\n                                tool_output=str(tool_result),\n                                updated=llm_generated_output,\n                            )\n\n                            self._intermediate_steps[loop_num][\"model_observation\"].update(\n                                step_observation.model_dump()\n                            )\n                        else:\n                            try:\n                                tool = self.tool_by_names.get(self.sanitize_tool_name(action))\n                                if not tool:\n                                    raise AgentUnknownToolException(\n                                        f\"Unknown tool: {action}.\"\n                                        \"Use only available tools and provide \"\n                                        \"only the tool's name in the action field. \"\n                                        \"Do not include any additional reasoning. \"\n                                        \"Please correct the action field or state that you cannot answer the question. \"\n                                    )\n\n                                self.stream_reasoning(\n                                    {\n                                        \"thought\": thought,\n                                        \"action\": action,\n                                        \"tool\": {\"name\": tool.name, \"type\": tool.type},\n                                        \"action_input\": action_input,\n                                        \"loop_num\": loop_num,\n                                    },\n                                    config,\n                                    **kwargs,\n                                )\n\n                                tool_result, tool_files = self._run_tool(tool, action_input, config, **kwargs)\n\n                            except RecoverableAgentException as e:\n                                tool_result = f\"{type(e).__name__}: {e}\"\n                    else:\n                        try:\n                            tool = self.tool_by_names.get(self.sanitize_tool_name(action))\n                            if not tool:\n                                raise AgentUnknownToolException(\n                                    f\"Unknown tool: {action}.\"\n                                    \"Use only available tools and provide only the tool's name in the action field. \"\n                                    \"Do not include any additional reasoning. \"\n                                    \"Please correct the action field or state that you cannot answer the question.\"\n                                )\n\n                            self.stream_reasoning(\n                                {\n                                    \"thought\": thought,\n                                    \"action\": action,\n                                    \"tool\": {\"name\": tool.name, \"type\": tool.type},\n                                    \"action_input\": action_input,\n                                    \"loop_num\": loop_num,\n                                },\n                                config,\n                                **kwargs,\n                            )\n\n                            tool_cache_entry = ToolCacheEntry(action=action, action_input=action_input)\n                            tool_result = self._tool_cache.get(tool_cache_entry, None)\n                            if not tool_result:\n                                tool_result, tool_files = self._run_tool(tool, action_input, config, **kwargs)\n\n                            else:\n                                logger.info(f\"Agent {self.name} - {self.id}: Cached output of {action} found.\")\n\n                        except RecoverableAgentException as e:\n                            tool_result = f\"{type(e).__name__}: {e}\"\n\n                    if isinstance(tool, ContextManagerTool):\n                        _apply_context_manager_tool_effect(self._prompt, tool_result, self._history_offset)\n\n                    observation = f\"\\nObservation: {tool_result}\\n\"\n                    self._prompt.messages.append(Message(role=MessageRole.USER, content=observation, static=True))\n\n                    if self.streaming.enabled and self.streaming.mode == StreamingMode.ALL:\n                        if tool is not None:\n                            source_name = tool_name = tool.name\n                        elif isinstance(action, list):\n                            tool_names = [\n                                (\n                                    tool_data[\"name\"]\n                                    if isinstance(tool_data, dict) and \"name\" in tool_data\n                                    else UNKNOWN_TOOL_NAME\n                                )\n                                for tool_data in action\n                            ]\n\n                            if len(tool_names) == 1:\n                                source_name = tool_name = tool_names[0]\n                            else:\n                                unique_tools = list(set(tool_names))\n                                if len(unique_tools) == 1:\n                                    source_name = tool_name = f\"{unique_tools[0]} (parallel)\"\n                                else:\n                                    source_name = tool_name = \" + \".join(unique_tools)\n                        else:\n                            source_name = tool_name = str(action)\n\n                        self.stream_content(\n                            content={\n                                \"name\": tool_name,\n                                \"input\": action_input,\n                                \"result\": tool_result,\n                                \"files\": tool_files,\n                            },\n                            source=source_name,\n                            step=\"tool\",\n                            config=config,\n                            **kwargs,\n                        )\n\n                    step_observation = AgentIntermediateStepModelObservation(\n                        tool_using=action,\n                        tool_input=action_input,\n                        tool_output=tool_result,\n                        updated=llm_generated_output,\n                    )\n\n                    self._intermediate_steps[loop_num][\"model_observation\"].update(step_observation.model_dump())\n                else:\n                    self.stream_reasoning(\n                        {\n                            \"thought\": thought,\n                            \"action\": action,\n                            \"action_input\": action_input,\n                            \"loop_num\": loop_num,\n                        },\n                        config,\n                        **kwargs,\n                    )\n            except ActionParsingException as e:\n                extra_guidance = None\n                if self.inference_mode == InferenceMode.XML:\n                    extra_guidance = (\n                        \"Ensure the reply contains &lt;thought&gt; along \"\n                        \"with either &lt;action&gt;/&lt;action_input&gt; or a final \"\n                        \"&lt;answer&gt; tag.\"\n                    )\n                elif self.inference_mode == InferenceMode.DEFAULT:\n                    extra_guidance = (\n                        \"Provide 'Thought:' and either 'Action:' \"\n                        \"with a JSON 'Action Input:' or a final 'Answer:' section.\"\n                    )\n\n                self._append_recovery_instruction(\n                    error_label=type(e).__name__,\n                    error_detail=str(e),\n                    llm_generated_output=llm_generated_output,\n                    extra_guidance=extra_guidance,\n                )\n                continue\n\n            if self.summarization_config.enabled:\n                if self.is_token_limit_exceeded():\n                    summary_offset = self.summarize_history(input_message, summary_offset, config=config, **kwargs)\n\n        if self.behaviour_on_max_loops == Behavior.RAISE:\n            error_message = (\n                f\"Agent {self.name} (ID: {self.id}) \"\n                f\"has reached the maximum loop limit of {self.max_loops} \"\n                f\"without finding a final answer. \"\n                f\"Last response: {self._prompt.messages[-1].content}\\n\"\n                f\"Consider increasing the maximum number of loops or \"\n                f\"reviewing the task complexity to ensure completion.\"\n            )\n            raise MaxLoopsExceededException(message=error_message)\n        else:\n            max_loop_final_answer = self._handle_max_loops_exceeded(input_message, config, **kwargs)\n            if self.streaming.enabled:\n                self.stream_content(\n                    content=max_loop_final_answer,\n                    source=self.name,\n                    step=\"answer\",\n                    config=config,\n                    **kwargs,\n                )\n            return max_loop_final_answer\n\n    def aggregate_history(self, messages: list[Message, VisionMessage]) -&gt; str:\n        \"\"\"\n        Concatenates multiple history messages into one unified string.\n\n        Args:\n            messages (list[Message, VisionMessage]): List of messages to aggregate.\n\n        Returns:\n            str: Aggregated content.\n        \"\"\"\n\n        history = \"\"\n\n        for message in messages:\n            if isinstance(message, VisionMessage):\n                for content in message.content:\n                    if isinstance(content, VisionMessageTextContent):\n                        history += content.text\n            else:\n                if message.role == MessageRole.ASSISTANT:\n                    history += f\"-TOOL DESCRIPTION START-\\n{message.content}\\n-TOOL DESCRIPTION END-\\n\"\n                elif message.role == MessageRole.USER:\n                    history += f\"-TOOL OUTPUT START-\\n{message.content}\\n-TOOL OUTPUT END-\\n\"\n\n        return history\n\n    def _handle_max_loops_exceeded(\n        self, input_message: Message | VisionMessage, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; str:\n        \"\"\"\n        Handle the case where max loops are exceeded by crafting a thoughtful response.\n        Uses XMLParser to extract the final answer from the LLM's last attempt.\n\n        Args:\n            input_message (Message | VisionMessage): Initial user message.\n            config (RunnableConfig | None): Configuration for the agent run.\n            **kwargs: Additional parameters for running the agent.\n\n        Returns:\n            str: Final answer provided by the agent.\n        \"\"\"\n        system_message = Message(content=REACT_MAX_LOOPS_PROMPT, role=MessageRole.SYSTEM, static=True)\n        conversation_history = Message(\n            content=self.aggregate_history(self._prompt.messages), role=MessageRole.USER, static=True\n        )\n        llm_final_attempt_result = self._run_llm(\n            [system_message, input_message, conversation_history], config=config, **kwargs\n        )\n        llm_final_attempt = llm_final_attempt_result.output[\"content\"]\n        self._run_depends = [NodeDependency(node=self.llm).to_dict()]\n\n        try:\n            final_answer = XMLParser.extract_first_tag_lxml(llm_final_attempt, [\"answer\"])\n            if final_answer is None:\n                logger.warning(\"Max loops handler: lxml failed to extract &lt;answer&gt;, falling back to regex.\")\n                final_answer = XMLParser.extract_first_tag_regex(llm_final_attempt, [\"answer\"])\n\n            if final_answer is None:\n                logger.error(\n                    \"Max loops handler: Failed to extract &lt;answer&gt; tag even with fallbacks. Returning raw output.\"\n                )\n                final_answer = llm_final_attempt\n\n        except Exception as e:\n            logger.error(f\"Max loops handler: Error during final answer extraction: {e}. Returning raw output.\")\n            final_answer = llm_final_attempt\n\n        return f\"{final_answer}\"\n\n    def generate_input_formats(self, tools: list[Node]) -&gt; str:\n        \"\"\"Generate formatted input descriptions for each tool.\"\"\"\n        input_formats = []\n        for tool in tools:\n            params = []\n            for name, field in tool.input_schema.model_fields.items():\n                if not field.json_schema_extra or field.json_schema_extra.get(\"is_accessible_to_agent\", True):\n                    if get_origin(field.annotation) in (Union, types.UnionType):\n                        type_str = str(field.annotation)\n                    else:\n                        type_str = getattr(field.annotation, \"__name__\", str(field.annotation))\n\n                    if field.json_schema_extra and field.json_schema_extra.get(\"map_from_storage\", False):\n                        type_str = \"tuple[str, ...]\"\n\n                    description = field.description or \"No description\"\n                    params.append(f\"{name} ({type_str}): {description}\")\n            if params:\n                input_formats.append(f\" - {self.sanitize_tool_name(tool.name)}\\n \\t* \" + \"\\n\\t* \".join(params))\n        return \"\\n\".join(input_formats)\n\n    def generate_structured_output_schemas(self):\n        tool_names = [self.sanitize_tool_name(tool.name) for tool in self.tools]\n\n        schema = {\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": \"plan_next_action\",\n                \"strict\": True,\n                \"schema\": {\n                    \"type\": \"object\",\n                    \"required\": [\"thought\", \"action\", \"action_input\"],\n                    \"properties\": {\n                        \"thought\": {\n                            \"type\": \"string\",\n                            \"description\": \"Your reasoning about the next step.\",\n                        },\n                        \"action\": {\n                            \"type\": \"string\",\n                            \"description\": f\"Next action to make (choose from [{tool_names}, finish]).\",\n                        },\n                        \"action_input\": {\n                            \"type\": \"string\",\n                            \"description\": \"Input for chosen action.\",\n                        },\n                    },\n                    \"additionalProperties\": False,\n                },\n            },\n        }\n\n        self._response_format = schema\n\n    @staticmethod\n    def filter_format_type(param_annotation: Any) -&gt; list[str]:\n        \"\"\"\n        Filters proper type for a function calling schema.\n\n        Args:\n            param_annotation (Any): Parameter annotation.\n        Returns:\n            list[str]: List of parameter types that describe provided annotation.\n        \"\"\"\n\n        if get_origin(param_annotation) in (Union, types.UnionType):\n            return get_args(param_annotation)\n\n        return [param_annotation]\n\n    def generate_property_schema(self, properties, name, field):\n        if not field.json_schema_extra or field.json_schema_extra.get(\"is_accessible_to_agent\", True):\n            description = field.description or \"No description.\"\n\n            description += f\" Defaults to: {field.default}.\" if field.default and not field.is_required() else \"\"\n            params = self.filter_format_type(field.annotation)\n\n            properties[name] = {\"description\": description}\n            types = []\n\n            for param in params:\n                if param is type(None):\n                    types.append(\"null\")\n\n                elif param_type := TYPE_MAPPING.get(param):\n                    types.append(param_type)\n\n                elif issubclass(param, Enum):\n                    element_type = TYPE_MAPPING.get(\n                        self.filter_format_type(type(list(param.__members__.values())[0].value))[0]\n                    )\n                    types.append(element_type)\n                    properties[name][\"enum\"] = [field.value for field in param.__members__.values()]\n\n                elif getattr(param, \"__origin__\", None) is list:\n                    types.append(\"array\")\n                    properties[name][\"items\"] = {\"type\": TYPE_MAPPING.get(param.__args__[0])}\n\n                elif getattr(param, \"__origin__\", None) is dict:\n                    types.append(\"object\")\n\n            if len(types) == 1:\n                properties[name][\"type\"] = types[0]\n            elif len(types) &gt; 1:\n                properties[name][\"type\"] = types\n            else:\n                properties[name][\"type\"] = \"string\"\n\n    def generate_function_calling_schemas(self):\n        \"\"\"Generate schemas for function calling.\"\"\"\n        self._tools.append(final_answer_function_schema)\n        for tool in self.tools:\n            properties = {}\n            input_params = tool.input_schema.model_fields.items()\n            if list(input_params) and not isinstance(self.llm, Gemini):\n                for name, field in tool.input_schema.model_fields.items():\n                    self.generate_property_schema(properties, name, field)\n\n                schema = {\n                    \"type\": \"function\",\n                    \"function\": {\n                        \"name\": self.sanitize_tool_name(tool.name),\n                        \"description\": tool.description[:1024],\n                        \"parameters\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"thought\": {\n                                    \"type\": \"string\",\n                                    \"description\": \"Your reasoning about using this tool.\",\n                                },\n                                \"action_input\": {\n                                    \"type\": \"object\",\n                                    \"description\": \"Input for the selected tool\",\n                                    \"properties\": properties,\n                                    \"required\": list(properties.keys()),\n                                    \"additionalProperties\": False,\n                                },\n                            },\n                            \"additionalProperties\": False,\n                            \"required\": [\"thought\", \"action_input\"],\n                        },\n                        \"strict\": True,\n                    },\n                }\n\n                self._tools.append(schema)\n\n            else:\n                schema = {\n                    \"type\": \"function\",\n                    \"function\": {\n                        \"name\": self.sanitize_tool_name(tool.name),\n                        \"description\": tool.description[:1024],\n                        \"parameters\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"thought\": {\n                                    \"type\": \"string\",\n                                    \"description\": \"Your reasoning about using this tool.\",\n                                },\n                                \"action_input\": {\n                                    \"type\": \"string\",\n                                    \"description\": \"Input for the selected tool in JSON string format.\",\n                                },\n                            },\n                            \"additionalProperties\": False,\n                            \"required\": [\"thought\", \"action_input\"],\n                        },\n                        \"strict\": True,\n                    },\n                }\n\n                self._tools.append(schema)\n\n    def _init_prompt_blocks(self):\n        \"\"\"Initialize the prompt blocks required for the ReAct strategy.\"\"\"\n        super()._init_prompt_blocks()\n\n        if self.parallel_tool_calls_enabled:\n            instructions_default = REACT_BLOCK_INSTRUCTIONS_MULTI\n            instructions_xml = REACT_BLOCK_XML_INSTRUCTIONS_MULTI\n        else:\n            instructions_default = REACT_BLOCK_INSTRUCTIONS_SINGLE\n            instructions_xml = REACT_BLOCK_XML_INSTRUCTIONS_SINGLE\n\n        if self.direct_tool_output_enabled:\n            instructions_default += \"\\n\" + DEFAULT_DIRECT_OUTPUT_CAPABILITIES\n            instructions_xml += \"\\n\" + XML_DIRECT_OUTPUT_CAPABILITIES\n\n        prompt_blocks = {\n            \"tools\": \"\" if not self.tools else REACT_BLOCK_TOOLS,\n            \"instructions\": REACT_BLOCK_INSTRUCTIONS_NO_TOOLS if not self.tools else instructions_default,\n            \"output_format\": REACT_BLOCK_OUTPUT_FORMAT,\n        }\n\n        match self.inference_mode:\n            case InferenceMode.FUNCTION_CALLING:\n                self.generate_function_calling_schemas()\n                prompt_blocks[\"instructions\"] = REACT_BLOCK_INSTRUCTIONS_FUNCTION_CALLING\n                if self.tools:\n                    prompt_blocks[\"tools\"] = REACT_BLOCK_TOOLS_NO_FORMATS\n\n            case InferenceMode.STRUCTURED_OUTPUT:\n                self.generate_structured_output_schemas()\n                prompt_blocks[\"instructions\"] = REACT_BLOCK_INSTRUCTIONS_STRUCTURED_OUTPUT\n\n            case InferenceMode.XML:\n                prompt_blocks[\"instructions\"] = (\n                    REACT_BLOCK_XML_INSTRUCTIONS_NO_TOOLS if not self.tools else instructions_xml\n                )\n\n        self._prompt_blocks.update(prompt_blocks)\n\n    @staticmethod\n    def _build_unique_file_key(files_map: dict[str, Any], base: str) -&gt; str:\n        key = base or \"file\"\n        if key not in files_map:\n            return key\n        suffix = 1\n        while f\"{key}_{suffix}\" in files_map:\n            suffix += 1\n        return f\"{key}_{suffix}\"\n\n    def _merge_tool_files(self, aggregated: dict[str, Any], tool_name: str, files: Any) -&gt; None:\n        if not files:\n            return\n\n        sanitized_name = self.sanitize_tool_name(tool_name) or \"tool\"\n\n        if isinstance(files, dict):\n            for key, value in files.items():\n                base_key = key or sanitized_name\n                unique_key = self._build_unique_file_key(aggregated, base_key)\n                aggregated[unique_key] = value\n        elif isinstance(files, (list, tuple)):\n            for idx, file_obj in enumerate(files):\n                base_key = getattr(file_obj, \"name\", None) or f\"{sanitized_name}_{idx}\"\n                unique_key = self._build_unique_file_key(aggregated, base_key)\n                aggregated[unique_key] = file_obj\n        else:\n            unique_key = self._build_unique_file_key(aggregated, sanitized_name)\n            aggregated[unique_key] = files\n\n    @staticmethod\n    def _separate_tool_result_and_files(execution_result: Any) -&gt; tuple[Any, dict[str, Any]]:\n        if isinstance(execution_result, dict):\n            content = execution_result.get(\"content\", \"\")\n            files = execution_result.get(\"files\", {})\n            if isinstance(files, dict):\n                return content, files\n            if isinstance(files, (list, tuple)):\n                return content, {str(index): file for index, file in enumerate(files)}\n            if files:\n                return content, {\"result\": files}\n            return content, {}\n        return execution_result, {}\n\n    def _run_single_tool(\n        self,\n        tool_name: str,\n        tool_input: dict[str, Any],\n        config: RunnableConfig,\n        update_run_depends: bool = True,\n        **kwargs,\n    ) -&gt; dict[str, Any]:\n        tool = self.tool_by_names.get(self.sanitize_tool_name(tool_name))\n        if not tool:\n            return {\n                \"tool_name\": tool_name,\n                \"success\": False,\n                \"tool_input\": tool_input,\n                \"result\": f\"Unknown tool: {tool_name}. Please use only available tools.\",\n                \"files\": {},\n                \"dependency\": None,\n            }\n\n        try:\n            tool_result, tool_files, dependency = self._run_tool(\n                tool,\n                tool_input,\n                config,\n                update_run_depends=update_run_depends,\n                collect_dependency=True,\n                **kwargs,\n            )\n            return {\n                \"tool_name\": tool.name,\n                \"success\": True,\n                \"tool_input\": tool_input,\n                \"result\": tool_result,\n                \"files\": tool_files,\n                \"dependency\": dependency,\n            }\n        except RecoverableAgentException as e:\n            error_message = f\"{type(e).__name__}: {e}\"\n            logger.error(error_message)\n            return {\n                \"tool_name\": tool.name,\n                \"success\": False,\n                \"tool_input\": tool_input,\n                \"result\": error_message,\n                \"files\": {},\n                \"dependency\": None,\n            }\n\n    def _stream_tool_result(self, result: dict[str, Any], config: RunnableConfig, **kwargs) -&gt; None:\n        if self.streaming.enabled and self.streaming.mode == StreamingMode.ALL:\n            try:\n                self.stream_content(\n                    content={\n                        \"name\": result.get(\"tool_name\"),\n                        \"input\": result.get(\"tool_input\"),\n                        \"result\": result.get(\"result\"),\n                        \"files\": result.get(\"files\"),\n                    },\n                    source=str(result.get(\"tool_name\")),\n                    step=\"tool\",\n                    config=config,\n                    **kwargs,\n                )\n            except Exception as stream_err:\n                logger.error(f\"Streaming error for tool {result.get('tool_name')}: {stream_err}\")\n\n    def _execute_tools(\n        self, tools_data: list[dict[str, Any]], config: RunnableConfig, **kwargs\n    ) -&gt; str | dict[str, Any]:\n        \"\"\"\n        Execute one or more tools and gather their results.\n\n        Args:\n            tools_data (list): List of dictionaries containing name and input for each tool\n            config (RunnableConfig): Configuration for the runnable\n            **kwargs: Additional arguments for tool execution\n\n        Returns:\n            str | dict[str, Any]: Combined observation string with all tool results and optional files\n        \"\"\"\n        all_results: list[dict[str, Any]] = []\n\n        if not tools_data:\n            return \"\"\n\n        prepared_tools: list[dict[str, Any]] = []\n\n        for idx, td in enumerate(tools_data):\n            tool_name = td.get(\"name\")\n            tool_input = td.get(\"input\")\n            if tool_name is None or tool_input is None:\n                error_message = \"Invalid tool payload: missing 'name' or 'input'\"\n                logger.error(error_message)\n                all_results.append(\n                    {\n                        \"order\": idx,\n                        \"tool_name\": tool_name or UNKNOWN_TOOL_NAME,\n                        \"success\": False,\n                        \"tool_input\": tool_input,\n                        \"result\": error_message,\n                        \"files\": {},\n                        \"dependency\": None,\n                    }\n                )\n                continue\n            prepared_tools.append({\"order\": idx, \"name\": tool_name, \"input\": tool_input})\n\n        if prepared_tools:\n            if len(prepared_tools) == 1:\n                tool_payload = prepared_tools[0]\n                res = self._run_single_tool(\n                    tool_payload[\"name\"],\n                    tool_payload[\"input\"],\n                    config,\n                    update_run_depends=True,\n                    **kwargs,\n                )\n                res[\"order\"] = tool_payload[\"order\"]\n                all_results.append(res)\n                self._stream_tool_result(res, config, **kwargs)\n            else:\n                max_workers = len(prepared_tools)\n                with ThreadPoolExecutor(max_workers=max_workers) as executor:\n                    future_map = {}\n                    for tool_payload in prepared_tools:\n                        future = executor.submit(\n                            self._run_single_tool,\n                            tool_payload[\"name\"],\n                            tool_payload[\"input\"],\n                            config,\n                            False,\n                            **kwargs,\n                        )\n                        future_map[future] = tool_payload\n\n                    for future in as_completed(future_map.keys()):\n                        tool_payload = future_map[future]\n                        tool_name = tool_payload[\"name\"]\n                        tool_input = tool_payload[\"input\"]\n                        try:\n                            res = future.result()\n                        except Exception as e:\n                            error_message = f\"Error executing tool {tool_name}: {str(e)}\"\n                            logger.error(error_message)\n                            res = {\n                                \"tool_name\": tool_name,\n                                \"success\": False,\n                                \"tool_input\": tool_input,\n                                \"result\": error_message,\n                                \"files\": {},\n                                \"dependency\": None,\n                            }\n                        res[\"order\"] = tool_payload[\"order\"]\n                        all_results.append(res)\n                        self._stream_tool_result(res, config, **kwargs)\n\n        observation_parts: list[str] = []\n        aggregated_files: dict[str, Any] = {}\n\n        ordered_results = sorted(all_results, key=lambda r: r.get(\"order\", 0))\n\n        for result in ordered_results:\n            tool_name = result.get(\"tool_name\", UNKNOWN_TOOL_NAME)\n            result_content = result.get(\"result\", \"\")\n            success_status = \"SUCCESS\" if result.get(\"success\") else \"ERROR\"\n            observation_parts.append(f\"--- {tool_name} has resulted in {success_status} ---\\n{result_content}\")\n\n            self._merge_tool_files(aggregated_files, tool_name, result.get(\"files\"))\n\n        dependencies = [result.get(\"dependency\") for result in ordered_results if result.get(\"dependency\")]\n        if dependencies:\n            self._run_depends = dependencies\n\n        combined_observation = \"\\n\\n\".join(observation_parts)\n\n        if aggregated_files:\n            return {\"content\": combined_observation, \"files\": aggregated_files}\n        return combined_observation\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.aggregate_history","title":"<code>aggregate_history(messages)</code>","text":"<p>Concatenates multiple history messages into one unified string.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list[Message, VisionMessage]</code> <p>List of messages to aggregate.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Aggregated content.</p> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>def aggregate_history(self, messages: list[Message, VisionMessage]) -&gt; str:\n    \"\"\"\n    Concatenates multiple history messages into one unified string.\n\n    Args:\n        messages (list[Message, VisionMessage]): List of messages to aggregate.\n\n    Returns:\n        str: Aggregated content.\n    \"\"\"\n\n    history = \"\"\n\n    for message in messages:\n        if isinstance(message, VisionMessage):\n            for content in message.content:\n                if isinstance(content, VisionMessageTextContent):\n                    history += content.text\n        else:\n            if message.role == MessageRole.ASSISTANT:\n                history += f\"-TOOL DESCRIPTION START-\\n{message.content}\\n-TOOL DESCRIPTION END-\\n\"\n            elif message.role == MessageRole.USER:\n                history += f\"-TOOL OUTPUT START-\\n{message.content}\\n-TOOL OUTPUT END-\\n\"\n\n    return history\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.filter_format_type","title":"<code>filter_format_type(param_annotation)</code>  <code>staticmethod</code>","text":"<p>Filters proper type for a function calling schema.</p> <p>Parameters:</p> Name Type Description Default <code>param_annotation</code> <code>Any</code> <p>Parameter annotation.</p> required <p>Returns:     list[str]: List of parameter types that describe provided annotation.</p> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>@staticmethod\ndef filter_format_type(param_annotation: Any) -&gt; list[str]:\n    \"\"\"\n    Filters proper type for a function calling schema.\n\n    Args:\n        param_annotation (Any): Parameter annotation.\n    Returns:\n        list[str]: List of parameter types that describe provided annotation.\n    \"\"\"\n\n    if get_origin(param_annotation) in (Union, types.UnionType):\n        return get_args(param_annotation)\n\n    return [param_annotation]\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.generate_function_calling_schemas","title":"<code>generate_function_calling_schemas()</code>","text":"<p>Generate schemas for function calling.</p> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>def generate_function_calling_schemas(self):\n    \"\"\"Generate schemas for function calling.\"\"\"\n    self._tools.append(final_answer_function_schema)\n    for tool in self.tools:\n        properties = {}\n        input_params = tool.input_schema.model_fields.items()\n        if list(input_params) and not isinstance(self.llm, Gemini):\n            for name, field in tool.input_schema.model_fields.items():\n                self.generate_property_schema(properties, name, field)\n\n            schema = {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": self.sanitize_tool_name(tool.name),\n                    \"description\": tool.description[:1024],\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"thought\": {\n                                \"type\": \"string\",\n                                \"description\": \"Your reasoning about using this tool.\",\n                            },\n                            \"action_input\": {\n                                \"type\": \"object\",\n                                \"description\": \"Input for the selected tool\",\n                                \"properties\": properties,\n                                \"required\": list(properties.keys()),\n                                \"additionalProperties\": False,\n                            },\n                        },\n                        \"additionalProperties\": False,\n                        \"required\": [\"thought\", \"action_input\"],\n                    },\n                    \"strict\": True,\n                },\n            }\n\n            self._tools.append(schema)\n\n        else:\n            schema = {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": self.sanitize_tool_name(tool.name),\n                    \"description\": tool.description[:1024],\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"thought\": {\n                                \"type\": \"string\",\n                                \"description\": \"Your reasoning about using this tool.\",\n                            },\n                            \"action_input\": {\n                                \"type\": \"string\",\n                                \"description\": \"Input for the selected tool in JSON string format.\",\n                            },\n                        },\n                        \"additionalProperties\": False,\n                        \"required\": [\"thought\", \"action_input\"],\n                    },\n                    \"strict\": True,\n                },\n            }\n\n            self._tools.append(schema)\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.generate_input_formats","title":"<code>generate_input_formats(tools)</code>","text":"<p>Generate formatted input descriptions for each tool.</p> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>def generate_input_formats(self, tools: list[Node]) -&gt; str:\n    \"\"\"Generate formatted input descriptions for each tool.\"\"\"\n    input_formats = []\n    for tool in tools:\n        params = []\n        for name, field in tool.input_schema.model_fields.items():\n            if not field.json_schema_extra or field.json_schema_extra.get(\"is_accessible_to_agent\", True):\n                if get_origin(field.annotation) in (Union, types.UnionType):\n                    type_str = str(field.annotation)\n                else:\n                    type_str = getattr(field.annotation, \"__name__\", str(field.annotation))\n\n                if field.json_schema_extra and field.json_schema_extra.get(\"map_from_storage\", False):\n                    type_str = \"tuple[str, ...]\"\n\n                description = field.description or \"No description\"\n                params.append(f\"{name} ({type_str}): {description}\")\n        if params:\n            input_formats.append(f\" - {self.sanitize_tool_name(tool.name)}\\n \\t* \" + \"\\n\\t* \".join(params))\n    return \"\\n\".join(input_formats)\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.is_token_limit_exceeded","title":"<code>is_token_limit_exceeded()</code>","text":"<p>Check whether token limit for summarization is exceeded.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether token limit is exceeded.</p> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>def is_token_limit_exceeded(self) -&gt; bool:\n    \"\"\"Check whether token limit for summarization is exceeded.\n\n    Returns:\n        bool: Whether token limit is exceeded.\n    \"\"\"\n    prompt_tokens = self._prompt.count_tokens(self.llm.model)\n\n    return (\n        self.summarization_config.max_token_context_length\n        and prompt_tokens &gt; self.summarization_config.max_token_context_length\n    ) or (prompt_tokens / self.llm.get_token_limit() &gt; self.summarization_config.context_usage_ratio)\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.log_final_output","title":"<code>log_final_output(thought, final_output, loop_num)</code>","text":"<p>Logs final output of the agent.</p> <p>Parameters:</p> Name Type Description Default <code>final_output</code> <code>str</code> <p>Final output of agent.</p> required <code>loop_num</code> <code>int</code> <p>Number of reasoning loop</p> required Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>def log_final_output(self, thought: str, final_output: str, loop_num: int) -&gt; None:\n    \"\"\"\n    Logs final output of the agent.\n\n    Args:\n        final_output (str): Final output of agent.\n        loop_num (int): Number of reasoning loop\n    \"\"\"\n    logger.info(\n        \"\\n------------------------------------------\\n\"\n        f\"Agent {self.name}: Loop {loop_num}\\n\"\n        f\"Thought: {thought}\\n\"\n        f\"Final answer: {final_output}\"\n        \"\\n------------------------------------------\\n\"\n    )\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.log_reasoning","title":"<code>log_reasoning(thought, action, action_input, loop_num)</code>","text":"<p>Logs reasoning step of agent.</p> <p>Parameters:</p> Name Type Description Default <code>thought</code> <code>str</code> <p>Reasoning about next step.</p> required <code>action</code> <code>str</code> <p>Chosen action.</p> required <code>action_input</code> <code>str</code> <p>Input to the tool chosen by action.</p> required <code>loop_num</code> <code>int</code> <p>Number of reasoning loop.</p> required Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>def log_reasoning(self, thought: str, action: str, action_input: str, loop_num: int) -&gt; None:\n    \"\"\"\n    Logs reasoning step of agent.\n\n    Args:\n        thought (str): Reasoning about next step.\n        action (str): Chosen action.\n        action_input (str): Input to the tool chosen by action.\n        loop_num (int): Number of reasoning loop.\n    \"\"\"\n    logger.info(\n        \"\\n------------------------------------------\\n\"\n        f\"Agent {self.name}: Loop {loop_num}:\\n\"\n        f\"Thought: {thought}\\n\"\n        f\"Action: {action}\\n\"\n        f\"Action Input: {action_input}\"\n        \"\\n------------------------------------------\"\n    )\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.stream_reasoning","title":"<code>stream_reasoning(content, config, **kwargs)</code>","text":"<p>Streams intermediate reasoning of the Agent.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>dict[str, Any]</code> <p>Content that will be sent.</p> required <code>config</code> <code>RunnableConfig | None</code> <p>Configuration for the agent run.</p> required <code>**kwargs</code> <p>Additional parameters for running the agent.</p> <code>{}</code> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>def stream_reasoning(self, content: dict[str, Any], config: RunnableConfig, **kwargs) -&gt; None:\n    \"\"\"\n    Streams intermediate reasoning of the Agent.\n\n    Args:\n        content (dict[str, Any]): Content that will be sent.\n        config (RunnableConfig | None): Configuration for the agent run.\n        **kwargs: Additional parameters for running the agent.\n    \"\"\"\n    if self.streaming.enabled and self.streaming.mode == StreamingMode.ALL:\n        self.stream_content(\n            content=content,\n            source=self.name,\n            step=\"reasoning\",\n            config=config,\n            **kwargs,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.summarize_history","title":"<code>summarize_history(input_message, summary_offset, config=None, **kwargs)</code>","text":"<p>Summarizes history and saves relevant information in the context</p> <p>Parameters:</p> Name Type Description Default <code>input_message</code> <code>Message | VisionMessage</code> <p>User request message.</p> required <code>summary_offset</code> <code>int</code> <p>Offset to the position of the first message in prompt that was not summarized.</p> required <code>config</code> <code>RunnableConfig | None</code> <p>Configuration for the agent run.</p> <code>None</code> <code>**kwargs</code> <p>Additional parameters for running the agent.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of summarized messages.</p> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>def summarize_history(\n    self,\n    input_message,\n    summary_offset: int,\n    config: RunnableConfig | None = None,\n    **kwargs,\n) -&gt; int:\n    \"\"\"\n    Summarizes history and saves relevant information in the context\n\n    Args:\n        input_message (Message | VisionMessage): User request message.\n        summary_offset (int): Offset to the position of the first message in prompt that was not summarized.\n        config (RunnableConfig | None): Configuration for the agent run.\n        **kwargs: Additional parameters for running the agent.\n\n    Returns:\n        int: Number of summarized messages.\n    \"\"\"\n    logger.info(f\"Agent {self.name} - {self.id}: Summarization of tool output started.\")\n    messages_history = \"\\nHistory to extract information from: \\n\"\n    summary_sections = []\n\n    offset = max(self._history_offset, summary_offset - self.summarization_config.context_history_length)\n    for index, message in enumerate(self._prompt.messages[offset:]):\n        if message.role == MessageRole.USER:\n            if (index + offset &gt;= summary_offset) and (\"Observation:\" in message.content):\n                messages_history += (\n                    f\"=== TOOL_OUTPUT: {index + offset} === \\n {message.content}\"\n                    f\"\\n === TOOL_OUTPUT: {index + offset} === \\n\"\n                )\n                summary_sections.append(index + offset)\n        else:\n            messages_history += f\"\\n{message.content}\\n\"\n\n    messages_history = (\n        messages_history + f\"\\n Required tags in the output {[f'tool_output{index}' for index in summary_sections]}\"\n    )\n\n    summary_messages = [\n        Message(content=HISTORY_SUMMARIZATION_PROMPT, role=MessageRole.SYSTEM, static=True),\n        input_message,\n        Message(content=messages_history, role=MessageRole.USER, static=True),\n    ]\n\n    summary_tags = [f\"tool_output{index}\" for index in summary_sections]\n\n    for _ in range(self.max_loops):\n        llm_result = self._run_llm(\n            messages=summary_messages,\n            config=config,\n            **kwargs,\n        )\n\n        output = llm_result.output[\"content\"]\n        summary_messages.append(Message(content=output, role=MessageRole.ASSISTANT, static=True))\n        try:\n            parsed_data = XMLParser.parse(\n                f\"&lt;root&gt;{output}&lt;/root&gt;\",\n                required_tags=summary_tags,\n                optional_tags=[],\n            )\n        except ParsingError as e:\n            logger.error(f\"Error: {e}. Make sure you have provided all tags at once: {summary_tags}\")\n            summary_messages.append(Message(content=str(e), role=MessageRole.USER, static=True))\n            continue\n\n        for summary_index, message_index in enumerate(summary_sections[:-1]):\n            self._prompt.messages[message_index].content = (\n                f\"Observation (shortened): \\n{parsed_data.get(summary_tags[summary_index])}\"\n            )\n\n        if self.is_token_limit_exceeded():\n            self._prompt.messages[summary_sections[-1]].content = (\n                f\"Observation (shortened): \\n{parsed_data.get(summary_tags[-1])}\"\n            )\n            summary_offset = len(self._prompt.messages)\n        else:\n            summary_offset = len(self._prompt.messages) - 2\n\n        logger.info(f\"Agent {self.name} - {self.id}: Summarization of tool output finished.\")\n        return summary_offset\n</code></pre>"},{"location":"dynamiq/nodes/agents/agent/#dynamiq.nodes.agents.agent.Agent.validate_inference_mode","title":"<code>validate_inference_mode()</code>","text":"<p>Validate whether specified model can be inferenced in provided mode.</p> Source code in <code>dynamiq/nodes/agents/agent.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_inference_mode(self):\n    \"\"\"Validate whether specified model can be inferenced in provided mode.\"\"\"\n    match self.inference_mode:\n        case InferenceMode.FUNCTION_CALLING:\n            if not supports_function_calling(model=self.llm.model):\n                raise ValueError(f\"Model {self.llm.model} does not support function calling\")\n\n        case InferenceMode.STRUCTURED_OUTPUT:\n            params = get_supported_openai_params(model=self.llm.model)\n            if \"response_format\" not in params:\n                raise ValueError(f\"Model {self.llm.model} does not support structured output\")\n\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/","title":"Base","text":""},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent","title":"<code>Agent</code>","text":"<p>               Bases: <code>Node</code></p> <p>Base class for an AI Agent that interacts with a Language Model and tools.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>class Agent(Node):\n    \"\"\"Base class for an AI Agent that interacts with a Language Model and tools.\"\"\"\n\n    AGENT_PROMPT_TEMPLATE: ClassVar[str] = AGENT_PROMPT_TEMPLATE\n\n    llm: BaseLLM = Field(..., description=\"LLM used by the agent.\")\n    group: NodeGroup = NodeGroup.AGENTS\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=3600))\n    tools: list[Node] = []\n    files: list[io.BytesIO | bytes] | None = None\n    images: list[str | bytes | io.BytesIO] = None\n    name: str = \"Agent\"\n    max_loops: int = 1\n    tool_output_max_length: int = TOOL_MAX_TOKENS\n    tool_output_truncate_enabled: bool = True\n    memory: Memory | None = Field(None, description=\"Memory node for the agent.\")\n    memory_limit: int = Field(100, description=\"Maximum number of messages to retrieve from memory\")\n    memory_retrieval_strategy: MemoryRetrievalStrategy | None = MemoryRetrievalStrategy.ALL\n    verbose: bool = Field(False, description=\"Whether to print verbose logs.\")\n    file_store: FileStoreConfig = Field(\n        default_factory=lambda: FileStoreConfig(enabled=False, backend=InMemoryFileStore()),\n        description=\"Configuration for file storage used by the agent.\",\n    )\n\n    input_message: Message | VisionMessage | None = None\n    role: str | None = Field(\n        default=None,\n        description=\"\"\"Agent basic instructions.\n            Can be used to provide additional context or instructions to the agent.\n            Accepts Jinja templates to provide additional parameters.\"\"\",\n    )\n    description: str | None = Field(default=None, description=\"Short human-readable description of the agent.\")\n    _prompt_blocks: dict[str, str] = PrivateAttr(default_factory=dict)\n    _prompt_variables: dict[str, Any] = PrivateAttr(default_factory=dict)\n    _mcp_servers: list[MCPServer] = PrivateAttr(default_factory=list)\n    _mcp_server_tool_ids: list[str] = PrivateAttr(default_factory=list)\n    _tool_cache: dict[ToolCacheEntry, Any] = {}\n    _history_offset: int = PrivateAttr(\n        default=2,  # Offset to the first message (default: 2 \u2014 system and initial user messages).\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[AgentInputSchema]] = AgentInputSchema\n    _json_schema_fields: ClassVar[list[str]] = [\"role\", \"description\"]\n\n    @classmethod\n    def _generate_json_schema(\n        cls, llms: dict[type[BaseLLM], list[str]] = {}, tools=list[type[Node]], **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Generates full json schema for Agent with provided llms and tools.\n        This schema is designed for compatibility with the WorkflowYamlParser,\n        containing enough partial information to instantiate an Agent.\n        Parameters name to be included in the schema are either defined in the _json_schema_fields class variable or\n        passed via the fields parameter.\n\n        It generates a schema using the provided LLMs and tools.\n\n        Args:\n            llms (dict[type[BaseLLM], list[str]]): Available llm providers and models.\n            tools (list[type[Node]]): List of tools.\n\n        Returns:\n            dict[str, Any]: Generated json schema.\n        \"\"\"\n        schema = super()._generate_json_schema(**kwargs)\n        schema[\"properties\"][\"llm\"] = {\n            \"anyOf\": [\n                {\n                    \"type\": \"object\",\n                    **llm._generate_json_schema(models=models, fields=[\"model\", \"temperature\", \"max_tokens\"]),\n                }\n                for llm, models in llms.items()\n            ],\n            \"additionalProperties\": False,\n        }\n\n        schema[\"properties\"][\"tools\"] = {\n            \"type\": \"array\",\n            \"items\": {\"anyOf\": [{\"type\": \"object\", **tool._generate_json_schema()} for tool in tools]},\n        }\n\n        schema[\"required\"] += [\"tools\", \"llm\"]\n        return schema\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._intermediate_steps: dict[int, dict] = {}\n        self._run_depends: list[dict] = []\n        self._prompt = Prompt(messages=[])\n\n        expanded_tools = []\n        for tool in self.tools:\n            if isinstance(tool, MCPServer):\n                self._mcp_servers.append(tool)\n                subtools = tool.get_mcp_tools()\n                expanded_tools.extend(subtools)\n                self._mcp_server_tool_ids.extend([subtool.id for subtool in subtools])\n            else:\n                expanded_tools.append(tool)\n\n        self.tools = expanded_tools\n\n        if self.file_store_backend:\n            if self.file_store.agent_file_write_enabled:\n                self.tools.append(FileWriteTool(file_store=self.file_store_backend))\n\n            self.tools.append(FileReadTool(file_store=self.file_store_backend, llm=self.llm))\n            self.tools.append(FileListTool(file_store=self.file_store_backend))\n\n        self._init_prompt_blocks()\n\n    @model_validator(mode=\"after\")\n    def validate_input_fields(self):\n        if self.input_message:\n            self.input_message.role = MessageRole.USER\n\n        return self\n\n    def get_context_for_input_schema(self) -&gt; dict:\n        \"\"\"Provides context for input schema that is required for proper validation.\"\"\"\n        role_for_validation = self.role or \"\"\n        if role_for_validation and (\n            \"{% raw %}\" not in role_for_validation and \"{% endraw %}\" not in role_for_validation\n        ):\n            role_for_validation = f\"{{% raw %}}{role_for_validation}{{% endraw %}}\"\n        return {\"input_message\": self.input_message, \"role\": role_for_validation}\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\n            \"llm\": True,\n            \"tools\": True,\n            \"memory\": True,\n            \"files\": True,\n            \"images\": True,\n            \"file_store\": True,\n        }\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"llm\"] = self.llm.to_dict(**kwargs)\n\n        data[\"tools\"] = [tool.to_dict(**kwargs) for tool in self.tools if tool.id not in self._mcp_server_tool_ids]\n        data[\"tools\"] = data[\"tools\"] + [mcp_server.to_dict(**kwargs) for mcp_server in self._mcp_servers]\n\n        data[\"memory\"] = self.memory.to_dict(**kwargs) if self.memory else None\n        if self.files:\n            data[\"files\"] = [{\"name\": getattr(f, \"name\", f\"file_{i}\")} for i, f in enumerate(self.files)]\n        if self.images:\n            data[\"images\"] = [{\"name\": getattr(f, \"name\", f\"image_{i}\")} for i, f in enumerate(self.images)]\n\n        data[\"file_store\"] = self.file_store.to_dict(**kwargs) if self.file_store else None\n\n        return data\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize components for the manager and agents.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.llm.is_postponed_component_init:\n            self.llm.init_components(connection_manager)\n\n        for tool in self.tools:\n            if tool.is_postponed_component_init:\n                tool.init_components(connection_manager)\n            tool.is_optimized_for_agents = True\n\n    def sanitize_tool_name(self, s: str):\n        \"\"\"Sanitize tool name to follow [^a-zA-Z0-9_-].\"\"\"\n        s = s.replace(\" \", \"-\")\n        sanitized = re.sub(r\"[^a-zA-Z0-9_-]\", \"\", s)\n        return sanitized\n\n    def _init_prompt_blocks(self):\n        \"\"\"Initializes default prompt blocks and variables.\"\"\"\n        self._prompt_blocks = {\n            \"date\": \"{{ date }}\",\n            \"tools\": \"{{ tool_description }}\",\n            \"instructions\": \"\",\n            \"context\": \"{{ context }}\",\n        }\n        self._prompt_variables = {\n            \"tool_description\": self.tool_description,\n            \"date\": datetime.now().strftime(\"%d %B %Y\"),\n        }\n\n    def set_block(self, block_name: str, content: str):\n        \"\"\"Adds or updates a prompt block.\"\"\"\n        self._prompt_blocks[block_name] = content\n\n    def set_prompt_variable(self, variable_name: str, value: Any):\n        \"\"\"Sets or updates a prompt variable.\"\"\"\n        self._prompt_variables[variable_name] = value\n\n    def _prepare_metadata(self, input_data: dict) -&gt; dict:\n        \"\"\"\n        Prepare metadata from input data.\n\n        Args:\n            input_data (dict): Input data containing user information\n\n        Returns:\n            dict: Processed metadata\n        \"\"\"\n        EXCLUDED_KEYS = {\"user_id\", \"session_id\", \"input\", \"metadata\", \"files\", \"images\", \"tool_params\"}\n        custom_metadata = input_data.get(\"metadata\", {}).copy()\n        custom_metadata.update({k: v for k, v in input_data.items() if k not in EXCLUDED_KEYS})\n\n        if \"files\" in custom_metadata:\n            del custom_metadata[\"files\"]\n        if \"images\" in custom_metadata:\n            del custom_metadata[\"images\"]\n        if \"tool_params\" in custom_metadata:\n            del custom_metadata[\"tool_params\"]\n\n        user_id = input_data.get(\"user_id\")\n        session_id = input_data.get(\"session_id\")\n\n        if user_id:\n            custom_metadata[\"user_id\"] = user_id\n        if session_id:\n            custom_metadata[\"session_id\"] = session_id\n\n        return custom_metadata\n\n    def execute(\n        self,\n        input_data: AgentInputSchema,\n        input_message: Message | VisionMessage | None = None,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the agent with the given input data.\n        \"\"\"\n        log_data = dict(input_data).copy()\n\n        if log_data.get(\"images\"):\n            log_data[\"images\"] = [f\"image_{i}\" for i in range(len(log_data[\"images\"]))]\n\n        if log_data.get(\"files\"):\n            log_data[\"files\"] = [f\"file_{i}\" for i in range(len(log_data[\"files\"]))]\n\n        logger.info(f\"Agent {self.name} - {self.id}: started with input {log_data}\")\n        self.reset_run_state()\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        custom_metadata = self._prepare_metadata(dict(input_data))\n\n        input_message = input_message or self.input_message or Message(role=MessageRole.USER, content=input_data.input)\n        input_message = input_message.format_message(**dict(input_data))\n\n        use_memory = self.memory and (dict(input_data).get(\"user_id\") or dict(input_data).get(\"session_id\"))\n\n        if use_memory:\n            history_messages = self._retrieve_memory(dict(input_data))\n            if len(history_messages) &gt; 0:\n                history_messages.insert(\n                    0,\n                    Message(\n                        role=MessageRole.SYSTEM,\n                        content=\"Below is the previous conversation history. \"\n                        \"Use this context to inform your response.\",\n                    ),\n                )\n            if isinstance(input_message, Message):\n                memory_content = input_message.content\n            else:\n                text_parts = [\n                    content.text for content in input_message.content if isinstance(content, VisionMessageTextContent)\n                ]\n                memory_content = \" \".join(text_parts) if text_parts else \"Image input\"\n            self.memory.add(role=MessageRole.USER, content=memory_content, metadata=custom_metadata)\n        else:\n            history_messages = None\n\n        if self.role:\n            # Only auto-wrap the entire role in a raw block if the user did not\n            # provide explicit raw/endraw markers. This allows roles to mix\n            # literal sections (via raw) with Jinja variables like {{ input }}\n            # without creating nested raw blocks.\n            if (\"{% raw %}\" in self.role) or (\"{% endraw %}\" in self.role):\n                self._prompt_blocks[\"role\"] = self.role\n            else:\n                self._prompt_blocks[\"role\"] = f\"{{% raw %}}{self.role}{{% endraw %}}\"\n\n        files = input_data.files\n        if files:\n            if not self.file_store_backend:\n                self.file_store = FileStoreConfig(enabled=True, backend=InMemoryFileStore())\n                self.tools.append(FileReadTool(file_store=self.file_store.backend, llm=self.llm))\n                self.tools.append(FileListTool(file_store=self.file_store.backend))\n                self._init_prompt_blocks()\n            self._ensure_named_files(files)\n\n        if input_data.tool_params:\n            kwargs[\"tool_params\"] = input_data.tool_params\n\n        self._prompt_variables.update(dict(input_data))\n        kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n        kwargs.pop(\"run_depends\", None)\n\n        result = self._run_agent(input_message, history_messages, config=config, **kwargs)\n\n        if use_memory:\n            self.memory.add(role=MessageRole.ASSISTANT, content=result, metadata=custom_metadata)\n\n        execution_result = {\n            \"content\": result,\n        }\n\n        if self.file_store_backend and not self.file_store_backend.is_empty():\n            execution_result[\"files\"] = self.file_store_backend.list_files_bytes()\n            logger.info(\n                f\"Agent {self.name} - {self.id}: returning {len(execution_result['files'])}\"\n                \" accumulated file(s) in FileStore\"\n            )\n\n        logger.info(f\"Node {self.name} - {self.id}: finished with RESULT:\\n{str(result)[:200]}...\")\n\n        return execution_result\n\n    def retrieve_conversation_history(\n        self,\n        user_query: str = None,\n        user_id: str = None,\n        session_id: str = None,\n        limit: int = None,\n        strategy: MemoryRetrievalStrategy = MemoryRetrievalStrategy.ALL,\n    ) -&gt; list[Message]:\n        \"\"\"\n        Retrieves conversation history for the agent using the specified strategy.\n\n        Args:\n            user_query: Current user input to find relevant context (for RELEVANT/HYBRID strategies)\n            user_id: Optional user identifier\n            session_id: Optional session identifier\n            limit: Maximum number of messages to return (defaults to memory_limit)\n            strategy: Which retrieval strategy to use (ALL, RELEVANT, or HYBRID)\n\n        Returns:\n            List of messages forming a valid conversation context\n        \"\"\"\n        if not self.memory or not (user_id or session_id):\n            return []\n\n        filters = {}\n        if user_id:\n            filters[\"user_id\"] = user_id\n        if session_id:\n            filters[\"session_id\"] = session_id\n\n        limit = limit or self.memory_limit\n\n        if strategy == MemoryRetrievalStrategy.RELEVANT and not user_query:\n            logger.warning(\"RELEVANT strategy selected but no user_query provided - falling back to ALL\")\n            strategy = MemoryRetrievalStrategy.ALL\n\n        conversation = self.memory.get_agent_conversation(\n            query=user_query,\n            limit=limit,\n            filters=filters,\n            strategy=strategy,\n        )\n        return conversation\n\n    def _retrieve_memory(self, input_data: dict) -&gt; list[Message]:\n        \"\"\"\n        Retrieves memory messages when user_id and/or session_id are provided.\n        \"\"\"\n        user_id = input_data.get(\"user_id\")\n        session_id = input_data.get(\"session_id\")\n\n        user_query = input_data.get(\"input\", \"\")\n        history_messages = self.retrieve_conversation_history(\n            user_query=user_query,\n            user_id=user_id,\n            session_id=session_id,\n            strategy=self.memory_retrieval_strategy,\n        )\n        logger.info(\"Agent %s - %s: retrieved %d messages from memory\", self.name, self.id, len(history_messages))\n        return history_messages\n\n    def _run_llm(\n        self, messages: list[Message | VisionMessage], config: RunnableConfig | None = None, **kwargs\n    ) -&gt; RunnableResult:\n        \"\"\"Runs the LLM with a given prompt and handles streaming or full responses.\n\n        Args:\n            messages (list[Message | VisionMessage]): Input messages for llm.\n            config (Optional[RunnableConfig]): Configuration for the runnable.\n            kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: Generated response.\n        \"\"\"\n        try:\n            llm_result = self.llm.run(\n                input_data={},\n                config=config,\n                prompt=Prompt(messages=messages),\n                run_depends=deepcopy(self._run_depends),\n                **kwargs,\n            )\n            self._run_depends = [NodeDependency(node=self.llm).to_dict(for_tracing=True)]\n            if llm_result.status != RunnableStatus.SUCCESS:\n                error_message = f\"LLM '{self.llm.name}' failed: {llm_result.error.message}\"\n                raise ValueError({error_message})\n\n            return llm_result\n\n        except Exception as e:\n            raise e\n\n    def stream_content(\n        self,\n        content: str | dict,\n        source: str,\n        step: str,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; str | dict:\n        \"\"\"\n        Streams data.\n\n        Args:\n            content (str | dict): Data that will be streamed.\n            source (str): Source of the content.\n            step (str): Description of the step.\n            config (Optional[RunnableConfig]): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            str | dict: Streamed data.\n        \"\"\"\n        if not isinstance(source, str):\n            raise ValueError(\n                f\"stream_content source parameter must be a string, got {type(source).__name__}: {source}. \"\n                f\"This likely indicates incorrect parameter passing from the calling code.\"\n            )\n\n        return self.stream_response(content=content, source=source, step=step, config=config, **kwargs)\n\n    def stream_response(\n        self, content: str | dict, source: str, step: str, config: RunnableConfig | None = None, **kwargs\n    ):\n        if not isinstance(source, str):\n            raise ValueError(\n                f\"stream_response source parameter must be a string, got {type(source).__name__}: {source}. \"\n                f\"This likely indicates a parameter ordering issue in the calling code.\"\n            )\n\n        response_for_stream = StreamChunk(\n            choices=[StreamChunkChoice(delta=StreamChunkChoiceDelta(content=content, source=source, step=step))]\n        )\n\n        self.run_on_node_execute_stream(\n            callbacks=config.callbacks,\n            chunk=response_for_stream.model_dump(),\n            **kwargs,\n        )\n        return content\n\n    def _run_agent(\n        self,\n        input_message: Message | VisionMessage,\n        history_messages: list[Message] | None = None,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; str:\n        \"\"\"Runs the agent with the generated prompt and handles exceptions.\"\"\"\n        formatted_prompt = self.generate_prompt()\n        system_message = Message(role=MessageRole.SYSTEM, content=formatted_prompt)\n        if history_messages:\n            self._prompt.messages = [system_message, *history_messages, input_message]\n        else:\n            self._prompt.messages = [system_message, input_message]\n\n        try:\n            llm_result = self._run_llm(self._prompt.messages, config=config, **kwargs).output[\"content\"]\n            self._prompt.messages.append(Message(role=MessageRole.ASSISTANT, content=llm_result))\n\n            if self.streaming.enabled:\n                return self.stream_content(\n                    content=llm_result,\n                    source=self.name,\n                    step=\"answer\",\n                    config=config,\n                    **kwargs,\n                )\n            return llm_result\n\n        except Exception as e:\n            raise e\n\n    def _get_tool(self, action: str) -&gt; Node:\n        \"\"\"Retrieves the tool corresponding to the given action.\"\"\"\n        tool = self.tool_by_names.get(self.sanitize_tool_name(action))\n        if not tool:\n            raise AgentUnknownToolException(\n                f\"Unknown tool: {action}.\"\n                \"Use only available tools and provide only the tool's name in the action field. \"\n                \"Do not include any additional reasoning. \"\n                \"Please correct the action field or state that you cannot answer the question.\"\n            )\n        return tool\n\n    def _apply_parameters(self, merged_input: dict, params: dict, source: str, debug_info: list = None):\n        \"\"\"Apply parameters from the specified source to the merged input.\"\"\"\n        if debug_info is None:\n            debug_info = []\n        for key, value in params.items():\n            if key in merged_input and isinstance(value, dict) and isinstance(merged_input[key], dict):\n                merged_nested = merged_input[key].copy()\n                merged_input[key] = deep_merge(value, merged_nested)\n                debug_info.append(f\"  - From {source}: Merged nested {key}\")\n            else:\n                merged_input[key] = value\n                debug_info.append(f\"  - From {source}: Set {key}={value}\")\n\n    def _regenerate_node_ids(self, obj: Any) -&gt; Any:\n        \"\"\"Recursively assign new IDs to cloned nodes and nested models.\"\"\"\n        if isinstance(obj, BaseModel):\n            if hasattr(obj, \"id\"):\n                setattr(obj, \"id\", str(uuid4()))\n\n            for field_name in getattr(obj, \"model_fields\", {}):\n                value = getattr(obj, field_name)\n                if isinstance(value, list):\n                    setattr(obj, field_name, [self._regenerate_node_ids(item) for item in value])\n                elif isinstance(value, dict):\n                    setattr(obj, field_name, {k: self._regenerate_node_ids(v) for k, v in value.items()})\n                else:\n                    setattr(obj, field_name, self._regenerate_node_ids(value))\n            return obj\n        if isinstance(obj, list):\n            return [self._regenerate_node_ids(item) for item in obj]\n        if isinstance(obj, dict):\n            return {k: self._regenerate_node_ids(v) for k, v in obj.items()}\n        return obj\n\n    def _clone_tool_for_execution(self, tool: Node, config: RunnableConfig | None) -&gt; tuple[Node, RunnableConfig]:\n        \"\"\"Clone tool and align config overrides so each execution is isolated.\"\"\"\n        base_config = ensure_config(config)\n        try:\n            tool_copy = self._regenerate_node_ids(tool.clone())\n        except Exception as e:\n            logger.warning(f\"Agent {self.name} - {self.id}: failed to clone tool {tool.name}: {e}\")\n            return tool, base_config\n\n        local_config = base_config\n        try:\n            local_config = base_config.model_copy(deep=False)\n            original_override = base_config.nodes_override.get(tool.id)\n            if original_override:\n                local_config.nodes_override[tool_copy.id] = original_override\n        except Exception as e:\n            logger.warning(\n                f\"Agent {self.name} - {self.id}: failed to prepare config override for cloned tool {tool.name}: {e}\"\n            )\n            local_config = base_config\n\n        return tool_copy, local_config\n\n    def _run_tool(\n        self,\n        tool: Node,\n        tool_input: dict,\n        config,\n        update_run_depends: bool = True,\n        collect_dependency: bool = False,\n        **kwargs,\n    ) -&gt; Any:\n        \"\"\"Runs a specific tool with the given input.\"\"\"\n        merged_input = tool_input.copy() if isinstance(tool_input, dict) else {\"input\": tool_input}\n\n        if isinstance(tool, ContextManagerTool):\n            merged_input[\"history\"] = self._prompt.messages[self._history_offset :]\n\n        raw_tool_params = kwargs.get(\"tool_params\", ToolParams())\n        tool_params = (\n            ToolParams.model_validate(raw_tool_params) if isinstance(raw_tool_params, dict) else raw_tool_params\n        )\n\n        if self.file_store_backend and tool.is_files_allowed:\n            for field_name, field in tool.input_schema.model_fields.items():\n                if field.json_schema_extra and field.json_schema_extra.get(\"map_from_storage\", False):\n                    if field_name in merged_input:\n                        merged_input[field_name] = FileMappedInput(\n                            input=merged_input[field_name], files=self.file_store_backend.list_files_bytes()\n                        )\n                    else:\n                        merged_input[field_name] = self.file_store_backend.list_files_bytes()\n            if isinstance(tool, Python):\n                merged_input[\"files\"] = self.file_store_backend.list_files_bytes()\n\n        if tool_params:\n            debug_info = []\n            if self.verbose:\n                debug_info.append(f\"Tool parameter merging for {tool.name} (ID: {tool.id}):\")\n                debug_info.append(f\"Starting with input: {merged_input}\")\n\n            # 1. Apply global parameters (lowest priority)\n            global_params = tool_params.global_params\n            if global_params:\n                self._apply_parameters(merged_input, global_params, \"global\", debug_info)\n\n            # 2. Apply parameters by tool name (medium priority)\n            name_params_any = tool_params.by_name_params.get(tool.name) or tool_params.by_name_params.get(\n                self.sanitize_tool_name(tool.name)\n            )\n            if name_params_any:\n                if isinstance(name_params_any, ToolParams):\n                    if self.verbose:\n                        debug_info.append(\n                            f\"  - From name:{tool.name}: encountered nested ToolParams (ignored for non-agent tool)\"\n                        )\n                elif isinstance(name_params_any, dict):\n                    self._apply_parameters(merged_input, name_params_any, f\"name:{tool.name}\", debug_info)\n\n            # 3. Apply parameters by tool ID (highest priority)\n            id_params_any = tool_params.by_id_params.get(tool.id)\n            if id_params_any:\n                if isinstance(id_params_any, ToolParams):\n                    if self.verbose:\n                        debug_info.append(\n                            f\"  - From id:{tool.id}: encountered nested ToolParams (ignored for non-agent tool)\"\n                        )\n                elif isinstance(id_params_any, dict):\n                    self._apply_parameters(merged_input, id_params_any, f\"id:{tool.id}\", debug_info)\n\n            if self.verbose and debug_info:\n                logger.debug(\"\\n\".join(debug_info))\n\n        child_kwargs = kwargs | {\"recoverable_error\": True}\n        is_child_agent = isinstance(tool, Agent)\n\n        if is_child_agent and tool_params:\n            nested_any = (\n                tool_params.by_id_params.get(getattr(tool, \"id\", \"\"))\n                or tool_params.by_name_params.get(getattr(tool, \"name\", \"\"))\n                or tool_params.by_name_params.get(self.sanitize_tool_name(getattr(tool, \"name\", \"\")))\n            )\n            if nested_any:\n                if isinstance(nested_any, ToolParams):\n                    nested_tp = nested_any\n                elif isinstance(nested_any, dict):\n                    nested_tp = ToolParams.model_validate(nested_any)\n                else:\n                    nested_tp = None\n                if nested_tp:\n                    child_kwargs = child_kwargs | {\"tool_params\": nested_tp}\n\n        tool_to_run = tool\n        tool_config = ensure_config(config)\n        if getattr(self, \"parallel_tool_calls_enabled\", False):\n            tool_to_run, tool_config = self._clone_tool_for_execution(tool, tool_config)\n\n        tool_result = tool_to_run.run(\n            input_data=merged_input,\n            config=tool_config,\n            run_depends=deepcopy(self._run_depends),\n            **child_kwargs,\n        )\n        dependency_node = tool_to_run if tool_to_run is not tool else tool\n        dependency_dict = NodeDependency(node=dependency_node).to_dict(for_tracing=True)\n        if update_run_depends:\n            self._run_depends = [dependency_dict]\n        if tool_result.status != RunnableStatus.SUCCESS:\n            error_message = f\"Tool '{tool.name}' failed: {tool_result.error.to_dict()}\"\n            if tool_result.error.recoverable:\n                raise ToolExecutionException({error_message})\n            else:\n                raise ValueError({error_message})\n        tool_result_output_content = tool_result.output.get(\"content\")\n\n        self._handle_tool_generated_files(tool, tool_result)\n\n        tool_result_content_processed = process_tool_output_for_agent(\n            content=tool_result_output_content,\n            max_tokens=self.tool_output_max_length,\n            truncate=self.tool_output_truncate_enabled,\n        )\n\n        self._tool_cache[ToolCacheEntry(action=tool.name, action_input=tool_input)] = tool_result_content_processed\n\n        output_files = tool_result.output.get(\"files\", [])\n        if collect_dependency:\n            return tool_result_content_processed, output_files, dependency_dict\n\n        return tool_result_content_processed, output_files\n\n    def _ensure_named_files(self, files: list[io.BytesIO | bytes]) -&gt; None:\n        \"\"\"Ensure all uploaded files have name and description attributes and store them in file_store if available.\"\"\"\n        named = []\n        for i, f in enumerate(files):\n            if isinstance(f, bytes):\n                bio = io.BytesIO(f)\n                bio.name = f\"file_{i}.bin\"\n                bio.description = \"User-provided file\"\n\n                if self.file_store_backend:\n                    try:\n                        self.file_store_backend.store(\n                            file_path=bio.name,\n                            content=f,\n                            content_type=\"application/octet-stream\",\n                            metadata={\"description\": bio.description, \"source\": \"user_upload\"},\n                            overwrite=True,\n                        )\n                    except Exception as e:\n                        logger.warning(f\"Failed to store file {bio.name} in file_store: {e}\")\n\n                named.append(bio)\n            elif isinstance(f, io.BytesIO):\n                if not hasattr(f, \"name\"):\n                    f.name = f\"file_{i}\"\n                if not hasattr(f, \"description\"):\n                    f.description = \"User-provided file\"\n\n                if self.file_store_backend:\n                    try:\n                        content = f.read()\n                        f.seek(0)\n\n                        self.file_store_backend.store(\n                            file_path=f.name,\n                            content=content,\n                            content_type=\"application/octet-stream\",\n                            metadata={\"description\": f.description, \"source\": \"user_upload\"},\n                            overwrite=True,\n                        )\n                    except Exception as e:\n                        logger.warning(f\"Failed to store file {f.name} in file_store: {e}\")\n\n                named.append(f)\n            else:\n                named.append(f)\n        return named\n\n    def _handle_tool_generated_files(self, tool: Node, tool_result: RunnableResult) -&gt; None:\n        \"\"\"\n        Handle files generated by tools and store them in the file store.\n\n        Args:\n            tool: The tool that generated the files\n            tool_result: The result from the tool execution\n        \"\"\"\n        if not self.file_store_backend:\n            return\n\n        if isinstance(tool_result.output, dict) and \"files\" in tool_result.output:\n            tool_files = tool_result.output.get(\"files\", [])\n            if tool_files:\n                stored_files = []\n                for file in tool_files:\n                    if isinstance(file, io.BytesIO):\n                        file_name = getattr(file, \"name\", f\"file_{id(file)}.bin\")\n                        file_description = getattr(file, \"description\", \"Tool-generated file\")\n                        content_type = getattr(file, \"content_type\", \"application/octet-stream\")\n\n                        content = file.read()\n                        file.seek(0)\n\n                        self.file_store_backend.store(\n                            file_path=file_name,\n                            content=content,\n                            content_type=content_type,\n                            metadata={\"description\": file_description, \"source\": \"tool_generated\"},\n                            overwrite=True,\n                        )\n                        stored_files.append(file_name)\n                    elif isinstance(file, bytes):\n                        file_name = f\"file_{id(file)}.bin\"\n                        file_description = f\"Tool-{tool.name}-generated file\"\n                        content_type = \"application/octet-stream\"\n                        self.file_store_backend.store(\n                            file_path=file_name,\n                            content=file,\n                            content_type=content_type,\n                            metadata={\"description\": file_description, \"source\": \"tool_generated\"},\n                            overwrite=True,\n                        )\n                        stored_files.append(file_name)\n                    else:\n                        logger.warning(f\"Unsupported file type from tool '{tool.name}': {type(file)}\")\n\n                logger.info(f\"Tool '{tool.name}' generated {len(stored_files)} file(s): {stored_files}\")\n\n    @property\n    def file_store_backend(self) -&gt; FileStore | None:\n        \"\"\"Get the file store backend from the configuration if enabled.\"\"\"\n        return self.file_store.backend if self.file_store.enabled else None\n\n    @property\n    def tool_description(self) -&gt; str:\n        \"\"\"Returns a description of the tools available to the agent.\"\"\"\n        return (\n            \"\\n\".join(\n                [\n                    f\"{tool.name}:\\n &lt;{tool.name}_description&gt;\\n{tool.description.strip()}\\n&lt;\\\\{tool.name}_description&gt;\"\n                    for tool in self.tools\n                ]\n            )\n            if self.tools\n            else \"\"\n        )\n\n    @property\n    def tool_names(self) -&gt; str:\n        \"\"\"Returns a comma-separated list of tool names available to the agent.\"\"\"\n        return \",\".join([self.sanitize_tool_name(tool.name) for tool in self.tools])\n\n    @property\n    def tool_by_names(self) -&gt; dict[str, Node]:\n        \"\"\"Returns a dictionary mapping tool names to their corresponding Node objects.\"\"\"\n        return {self.sanitize_tool_name(tool.name): tool for tool in self.tools}\n\n    def reset_run_state(self):\n        \"\"\"Resets the agent's run state.\"\"\"\n        self._intermediate_steps = {}\n        self._run_depends = []\n        self._tool_cache: dict[ToolCacheEntry, Any] = {}\n\n    def generate_prompt(self, block_names: list[str] | None = None, **kwargs) -&gt; str:\n        \"\"\"Generates the prompt using specified blocks and variables.\"\"\"\n        temp_variables = self._prompt_variables.copy()\n        temp_variables.update(kwargs)\n\n        formatted_prompt_blocks = {}\n        for block, content in self._prompt_blocks.items():\n            if block_names is None or block in block_names:\n                formatted_content = Template(content).render(**temp_variables)\n                if content:\n                    formatted_prompt_blocks[block] = formatted_content\n\n        prompt = Template(self.AGENT_PROMPT_TEMPLATE).render(formatted_prompt_blocks).strip()\n        prompt = self._clean_prompt(prompt)\n        return textwrap.dedent(prompt)\n\n    def _clean_prompt(self, prompt_text):\n        cleaned = re.sub(r\"\\n{3,}\", \"\\n\\n\", prompt_text)\n        return cleaned.strip()\n\n    def get_clone_attr_initializers(self) -&gt; dict[str, Callable[[Node], Any]]:\n        base = super().get_clone_attr_initializers()\n        from dynamiq.prompts import Prompt\n\n        base.update(\n            {\n                \"_prompt\": (lambda _self: Prompt(messages=[]) if Prompt else None),\n            }\n        )\n        return base\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.file_store_backend","title":"<code>file_store_backend: FileStore | None</code>  <code>property</code>","text":"<p>Get the file store backend from the configuration if enabled.</p>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.tool_by_names","title":"<code>tool_by_names: dict[str, Node]</code>  <code>property</code>","text":"<p>Returns a dictionary mapping tool names to their corresponding Node objects.</p>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.tool_description","title":"<code>tool_description: str</code>  <code>property</code>","text":"<p>Returns a description of the tools available to the agent.</p>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.tool_names","title":"<code>tool_names: str</code>  <code>property</code>","text":"<p>Returns a comma-separated list of tool names available to the agent.</p>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.execute","title":"<code>execute(input_data, input_message=None, config=None, **kwargs)</code>","text":"<p>Executes the agent with the given input data.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def execute(\n    self,\n    input_data: AgentInputSchema,\n    input_message: Message | VisionMessage | None = None,\n    config: RunnableConfig | None = None,\n    **kwargs,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the agent with the given input data.\n    \"\"\"\n    log_data = dict(input_data).copy()\n\n    if log_data.get(\"images\"):\n        log_data[\"images\"] = [f\"image_{i}\" for i in range(len(log_data[\"images\"]))]\n\n    if log_data.get(\"files\"):\n        log_data[\"files\"] = [f\"file_{i}\" for i in range(len(log_data[\"files\"]))]\n\n    logger.info(f\"Agent {self.name} - {self.id}: started with input {log_data}\")\n    self.reset_run_state()\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    custom_metadata = self._prepare_metadata(dict(input_data))\n\n    input_message = input_message or self.input_message or Message(role=MessageRole.USER, content=input_data.input)\n    input_message = input_message.format_message(**dict(input_data))\n\n    use_memory = self.memory and (dict(input_data).get(\"user_id\") or dict(input_data).get(\"session_id\"))\n\n    if use_memory:\n        history_messages = self._retrieve_memory(dict(input_data))\n        if len(history_messages) &gt; 0:\n            history_messages.insert(\n                0,\n                Message(\n                    role=MessageRole.SYSTEM,\n                    content=\"Below is the previous conversation history. \"\n                    \"Use this context to inform your response.\",\n                ),\n            )\n        if isinstance(input_message, Message):\n            memory_content = input_message.content\n        else:\n            text_parts = [\n                content.text for content in input_message.content if isinstance(content, VisionMessageTextContent)\n            ]\n            memory_content = \" \".join(text_parts) if text_parts else \"Image input\"\n        self.memory.add(role=MessageRole.USER, content=memory_content, metadata=custom_metadata)\n    else:\n        history_messages = None\n\n    if self.role:\n        # Only auto-wrap the entire role in a raw block if the user did not\n        # provide explicit raw/endraw markers. This allows roles to mix\n        # literal sections (via raw) with Jinja variables like {{ input }}\n        # without creating nested raw blocks.\n        if (\"{% raw %}\" in self.role) or (\"{% endraw %}\" in self.role):\n            self._prompt_blocks[\"role\"] = self.role\n        else:\n            self._prompt_blocks[\"role\"] = f\"{{% raw %}}{self.role}{{% endraw %}}\"\n\n    files = input_data.files\n    if files:\n        if not self.file_store_backend:\n            self.file_store = FileStoreConfig(enabled=True, backend=InMemoryFileStore())\n            self.tools.append(FileReadTool(file_store=self.file_store.backend, llm=self.llm))\n            self.tools.append(FileListTool(file_store=self.file_store.backend))\n            self._init_prompt_blocks()\n        self._ensure_named_files(files)\n\n    if input_data.tool_params:\n        kwargs[\"tool_params\"] = input_data.tool_params\n\n    self._prompt_variables.update(dict(input_data))\n    kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n    kwargs.pop(\"run_depends\", None)\n\n    result = self._run_agent(input_message, history_messages, config=config, **kwargs)\n\n    if use_memory:\n        self.memory.add(role=MessageRole.ASSISTANT, content=result, metadata=custom_metadata)\n\n    execution_result = {\n        \"content\": result,\n    }\n\n    if self.file_store_backend and not self.file_store_backend.is_empty():\n        execution_result[\"files\"] = self.file_store_backend.list_files_bytes()\n        logger.info(\n            f\"Agent {self.name} - {self.id}: returning {len(execution_result['files'])}\"\n            \" accumulated file(s) in FileStore\"\n        )\n\n    logger.info(f\"Node {self.name} - {self.id}: finished with RESULT:\\n{str(result)[:200]}...\")\n\n    return execution_result\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.generate_prompt","title":"<code>generate_prompt(block_names=None, **kwargs)</code>","text":"<p>Generates the prompt using specified blocks and variables.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def generate_prompt(self, block_names: list[str] | None = None, **kwargs) -&gt; str:\n    \"\"\"Generates the prompt using specified blocks and variables.\"\"\"\n    temp_variables = self._prompt_variables.copy()\n    temp_variables.update(kwargs)\n\n    formatted_prompt_blocks = {}\n    for block, content in self._prompt_blocks.items():\n        if block_names is None or block in block_names:\n            formatted_content = Template(content).render(**temp_variables)\n            if content:\n                formatted_prompt_blocks[block] = formatted_content\n\n    prompt = Template(self.AGENT_PROMPT_TEMPLATE).render(formatted_prompt_blocks).strip()\n    prompt = self._clean_prompt(prompt)\n    return textwrap.dedent(prompt)\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.get_context_for_input_schema","title":"<code>get_context_for_input_schema()</code>","text":"<p>Provides context for input schema that is required for proper validation.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def get_context_for_input_schema(self) -&gt; dict:\n    \"\"\"Provides context for input schema that is required for proper validation.\"\"\"\n    role_for_validation = self.role or \"\"\n    if role_for_validation and (\n        \"{% raw %}\" not in role_for_validation and \"{% endraw %}\" not in role_for_validation\n    ):\n        role_for_validation = f\"{{% raw %}}{role_for_validation}{{% endraw %}}\"\n    return {\"input_message\": self.input_message, \"role\": role_for_validation}\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize components for the manager and agents.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize components for the manager and agents.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.llm.is_postponed_component_init:\n        self.llm.init_components(connection_manager)\n\n    for tool in self.tools:\n        if tool.is_postponed_component_init:\n            tool.init_components(connection_manager)\n        tool.is_optimized_for_agents = True\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Resets the agent's run state.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"Resets the agent's run state.\"\"\"\n    self._intermediate_steps = {}\n    self._run_depends = []\n    self._tool_cache: dict[ToolCacheEntry, Any] = {}\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.retrieve_conversation_history","title":"<code>retrieve_conversation_history(user_query=None, user_id=None, session_id=None, limit=None, strategy=MemoryRetrievalStrategy.ALL)</code>","text":"<p>Retrieves conversation history for the agent using the specified strategy.</p> <p>Parameters:</p> Name Type Description Default <code>user_query</code> <code>str</code> <p>Current user input to find relevant context (for RELEVANT/HYBRID strategies)</p> <code>None</code> <code>user_id</code> <code>str</code> <p>Optional user identifier</p> <code>None</code> <code>session_id</code> <code>str</code> <p>Optional session identifier</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum number of messages to return (defaults to memory_limit)</p> <code>None</code> <code>strategy</code> <code>MemoryRetrievalStrategy</code> <p>Which retrieval strategy to use (ALL, RELEVANT, or HYBRID)</p> <code>ALL</code> <p>Returns:</p> Type Description <code>list[Message]</code> <p>List of messages forming a valid conversation context</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def retrieve_conversation_history(\n    self,\n    user_query: str = None,\n    user_id: str = None,\n    session_id: str = None,\n    limit: int = None,\n    strategy: MemoryRetrievalStrategy = MemoryRetrievalStrategy.ALL,\n) -&gt; list[Message]:\n    \"\"\"\n    Retrieves conversation history for the agent using the specified strategy.\n\n    Args:\n        user_query: Current user input to find relevant context (for RELEVANT/HYBRID strategies)\n        user_id: Optional user identifier\n        session_id: Optional session identifier\n        limit: Maximum number of messages to return (defaults to memory_limit)\n        strategy: Which retrieval strategy to use (ALL, RELEVANT, or HYBRID)\n\n    Returns:\n        List of messages forming a valid conversation context\n    \"\"\"\n    if not self.memory or not (user_id or session_id):\n        return []\n\n    filters = {}\n    if user_id:\n        filters[\"user_id\"] = user_id\n    if session_id:\n        filters[\"session_id\"] = session_id\n\n    limit = limit or self.memory_limit\n\n    if strategy == MemoryRetrievalStrategy.RELEVANT and not user_query:\n        logger.warning(\"RELEVANT strategy selected but no user_query provided - falling back to ALL\")\n        strategy = MemoryRetrievalStrategy.ALL\n\n    conversation = self.memory.get_agent_conversation(\n        query=user_query,\n        limit=limit,\n        filters=filters,\n        strategy=strategy,\n    )\n    return conversation\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.sanitize_tool_name","title":"<code>sanitize_tool_name(s)</code>","text":"<p>Sanitize tool name to follow [^a-zA-Z0-9_-].</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def sanitize_tool_name(self, s: str):\n    \"\"\"Sanitize tool name to follow [^a-zA-Z0-9_-].\"\"\"\n    s = s.replace(\" \", \"-\")\n    sanitized = re.sub(r\"[^a-zA-Z0-9_-]\", \"\", s)\n    return sanitized\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.set_block","title":"<code>set_block(block_name, content)</code>","text":"<p>Adds or updates a prompt block.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def set_block(self, block_name: str, content: str):\n    \"\"\"Adds or updates a prompt block.\"\"\"\n    self._prompt_blocks[block_name] = content\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.set_prompt_variable","title":"<code>set_prompt_variable(variable_name, value)</code>","text":"<p>Sets or updates a prompt variable.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def set_prompt_variable(self, variable_name: str, value: Any):\n    \"\"\"Sets or updates a prompt variable.\"\"\"\n    self._prompt_variables[variable_name] = value\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.stream_content","title":"<code>stream_content(content, source, step, config=None, **kwargs)</code>","text":"<p>Streams data.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str | dict</code> <p>Data that will be streamed.</p> required <code>source</code> <code>str</code> <p>Source of the content.</p> required <code>step</code> <code>str</code> <p>Description of the step.</p> required <code>config</code> <code>Optional[RunnableConfig]</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str | dict</code> <p>str | dict: Streamed data.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def stream_content(\n    self,\n    content: str | dict,\n    source: str,\n    step: str,\n    config: RunnableConfig | None = None,\n    **kwargs,\n) -&gt; str | dict:\n    \"\"\"\n    Streams data.\n\n    Args:\n        content (str | dict): Data that will be streamed.\n        source (str): Source of the content.\n        step (str): Description of the step.\n        config (Optional[RunnableConfig]): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        str | dict: Streamed data.\n    \"\"\"\n    if not isinstance(source, str):\n        raise ValueError(\n            f\"stream_content source parameter must be a string, got {type(source).__name__}: {source}. \"\n            f\"This likely indicates incorrect parameter passing from the calling code.\"\n        )\n\n    return self.stream_response(content=content, source=source, step=step, config=config, **kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.Agent.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"llm\"] = self.llm.to_dict(**kwargs)\n\n    data[\"tools\"] = [tool.to_dict(**kwargs) for tool in self.tools if tool.id not in self._mcp_server_tool_ids]\n    data[\"tools\"] = data[\"tools\"] + [mcp_server.to_dict(**kwargs) for mcp_server in self._mcp_servers]\n\n    data[\"memory\"] = self.memory.to_dict(**kwargs) if self.memory else None\n    if self.files:\n        data[\"files\"] = [{\"name\": getattr(f, \"name\", f\"file_{i}\")} for i, f in enumerate(self.files)]\n    if self.images:\n        data[\"images\"] = [{\"name\": getattr(f, \"name\", f\"image_{i}\")} for i, f in enumerate(self.images)]\n\n    data[\"file_store\"] = self.file_store.to_dict(**kwargs) if self.file_store else None\n\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.AgentManager","title":"<code>AgentManager</code>","text":"<p>               Bases: <code>Agent</code></p> <p>Manager class that extends the Agent class to include specific actions.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>class AgentManager(Agent):\n    \"\"\"Manager class that extends the Agent class to include specific actions.\"\"\"\n\n    _actions: dict[str, Callable] = PrivateAttr(default_factory=dict)\n    name: str = \"Agent Manager\"\n    input_schema: ClassVar[type[AgentManagerInputSchema]] = AgentManagerInputSchema\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._init_actions()\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"_actions\"] = {\n            k: getattr(action, \"__name__\", str(action))\n            for k, action in self._actions.items()\n        }\n        return data\n\n    def _init_actions(self):\n        \"\"\"Initializes the default actions for the manager.\"\"\"\n        self._actions = {\n            \"plan\": self._plan,\n            \"assign\": self._assign,\n            \"final\": self._final,\n            \"handle_input\": self._handle_input,\n        }\n\n    def add_action(self, name: str, action: Callable):\n        \"\"\"Adds a custom action to the manager.\"\"\"\n        self._actions[name] = action\n\n    def get_context_for_input_schema(self) -&gt; dict:\n        \"\"\"Provides context for input schema that is required for proper validation.\"\"\"\n        return {\"actions\": list(self._actions.keys())}\n\n    def execute(\n        self, input_data: AgentManagerInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"Executes the manager agent with the given input data and action.\"\"\"\n        log_data = dict(input_data).copy()\n\n        if log_data.get(\"images\"):\n            log_data[\"images\"] = [f\"image_{i}\" for i in range(len(log_data[\"images\"]))]\n\n        if log_data.get(\"files\"):\n            log_data[\"files\"] = [f\"file_{i}\" for i in range(len(log_data[\"files\"]))]\n\n        logger.info(f\"Agent {self.name} - {self.id}: started with input {log_data}\")\n        self.reset_run_state()\n        config = config or RunnableConfig()\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        action = input_data.action\n\n        self._prompt_variables.update(dict(input_data))\n\n        kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n        kwargs.pop(\"run_depends\", None)\n        _result_llm = self._actions[action](config=config, **kwargs)\n        result = {\"action\": action, \"result\": _result_llm}\n\n        execution_result = {\n            \"content\": result,\n        }\n        logger.info(f\"Agent {self.name} - {self.id}: finished with RESULT:\\n{str(result)[:200]}...\")\n\n        return execution_result\n\n    def _plan(self, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"Executes the 'plan' action.\"\"\"\n        prompt = Template(self._prompt_blocks.get(\"plan\")).render(**(self._prompt_variables | kwargs))\n        llm_result = self._run_llm([Message(role=MessageRole.USER, content=prompt)], config, **kwargs).output[\"content\"]\n\n        return llm_result\n\n    def _assign(self, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"Executes the 'assign' action.\"\"\"\n        prompt = Template(self._prompt_blocks.get(\"assign\")).render(**(self._prompt_variables | kwargs))\n        llm_result = self._run_llm([Message(role=MessageRole.USER, content=prompt)], config, **kwargs).output[\"content\"]\n\n        return llm_result\n\n    def _final(self, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"Executes the 'final' action.\"\"\"\n        prompt = Template(self._prompt_blocks.get(\"final\")).render(**(self._prompt_variables | kwargs))\n        llm_result = self._run_llm([Message(role=MessageRole.USER, content=prompt)], config, **kwargs).output[\"content\"]\n        if self.streaming.enabled:\n            return self.stream_content(\n                content=llm_result,\n                step=\"manager_final_output\",\n                source=self.name,\n                config=config,\n                **kwargs,\n            )\n        return llm_result\n\n    def _handle_input(self, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"\n        Executes the single 'handle_input' action to either respond or plan\n        based on user request complexity.\n        \"\"\"\n        prompt = Template(self._prompt_blocks.get(\"handle_input\")).render(**(self._prompt_variables | kwargs))\n        llm_result = self._run_llm([Message(role=MessageRole.USER, content=prompt)], config, **kwargs).output[\"content\"]\n        return llm_result\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.AgentManager.add_action","title":"<code>add_action(name, action)</code>","text":"<p>Adds a custom action to the manager.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def add_action(self, name: str, action: Callable):\n    \"\"\"Adds a custom action to the manager.\"\"\"\n    self._actions[name] = action\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.AgentManager.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the manager agent with the given input data and action.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def execute(\n    self, input_data: AgentManagerInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"Executes the manager agent with the given input data and action.\"\"\"\n    log_data = dict(input_data).copy()\n\n    if log_data.get(\"images\"):\n        log_data[\"images\"] = [f\"image_{i}\" for i in range(len(log_data[\"images\"]))]\n\n    if log_data.get(\"files\"):\n        log_data[\"files\"] = [f\"file_{i}\" for i in range(len(log_data[\"files\"]))]\n\n    logger.info(f\"Agent {self.name} - {self.id}: started with input {log_data}\")\n    self.reset_run_state()\n    config = config or RunnableConfig()\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    action = input_data.action\n\n    self._prompt_variables.update(dict(input_data))\n\n    kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n    kwargs.pop(\"run_depends\", None)\n    _result_llm = self._actions[action](config=config, **kwargs)\n    result = {\"action\": action, \"result\": _result_llm}\n\n    execution_result = {\n        \"content\": result,\n    }\n    logger.info(f\"Agent {self.name} - {self.id}: finished with RESULT:\\n{str(result)[:200]}...\")\n\n    return execution_result\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.AgentManager.get_context_for_input_schema","title":"<code>get_context_for_input_schema()</code>","text":"<p>Provides context for input schema that is required for proper validation.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def get_context_for_input_schema(self) -&gt; dict:\n    \"\"\"Provides context for input schema that is required for proper validation.\"\"\"\n    return {\"actions\": list(self._actions.keys())}\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.AgentManager.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"_actions\"] = {\n        k: getattr(action, \"__name__\", str(action))\n        for k, action in self._actions.items()\n    }\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.AgentStatus","title":"<code>AgentStatus</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Represents the status of an agent's execution.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>class AgentStatus(str, Enum):\n    \"\"\"Represents the status of an agent's execution.\"\"\"\n\n    SUCCESS = \"success\"\n    FAIL = \"fail\"\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.StreamChunk","title":"<code>StreamChunk</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model for streaming chunks with choices containing delta updates.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>class StreamChunk(BaseModel):\n    \"\"\"Model for streaming chunks with choices containing delta updates.\"\"\"\n\n    choices: list[StreamChunkChoice]\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.StreamChunkChoice","title":"<code>StreamChunkChoice</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Stream chunk choice model.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>class StreamChunkChoice(BaseModel):\n    \"\"\"Stream chunk choice model.\"\"\"\n\n    delta: StreamChunkChoiceDelta\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.StreamChunkChoiceDelta","title":"<code>StreamChunkChoiceDelta</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Delta model for content chunks.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>class StreamChunkChoiceDelta(BaseModel):\n    \"\"\"Delta model for content chunks.\"\"\"\n    content: str | dict\n    source: str\n    step: str\n\n    @field_validator('source')\n    @classmethod\n    def validate_source(cls, v):\n        \"\"\"Ensure source is always a string.\"\"\"\n        if not isinstance(v, str):\n            raise ValueError(f\"source must be a string, got {type(v).__name__}: {v}\")\n        return v\n\n    def _recursive_serialize(self, obj, key_path: str = \"\", index: int = None):\n        \"\"\"Recursively serialize an object, converting any BytesIO objects to FileInfo objects.\"\"\"\n        if isinstance(obj, io.BytesIO):\n            return convert_bytesio_to_file_info(obj, key_path, index).model_dump()\n\n        elif isinstance(obj, dict):\n            result = {}\n            for k, v in obj.items():\n                new_key_path = f\"{key_path}.{k}\" if key_path else k\n                result[k] = self._recursive_serialize(v, new_key_path)\n            return result\n\n        elif isinstance(obj, list):\n            result = []\n\n            for i, item in enumerate(obj):\n                new_key_path = f\"{key_path}[{i}]\" if key_path else f\"item_{i}\"\n                result.append(self._recursive_serialize(item, new_key_path, i))\n            return result\n\n        else:\n            return obj\n\n    @model_serializer\n    def serialize_content(self):\n        \"\"\"Serialize content dict, converting any BytesIO objects to base64 strings while preserving key structure.\"\"\"\n        if self.content is None or not isinstance(self.content, dict):\n            return {\"content\": self.content, \"source\": self.source, \"step\": self.step}\n\n        serialized_content = self._recursive_serialize(self.content)\n\n        result = {\n            \"content\": serialized_content,\n            \"source\": self.source,\n            \"step\": self.step,\n        }\n\n        return result\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.StreamChunkChoiceDelta.serialize_content","title":"<code>serialize_content()</code>","text":"<p>Serialize content dict, converting any BytesIO objects to base64 strings while preserving key structure.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>@model_serializer\ndef serialize_content(self):\n    \"\"\"Serialize content dict, converting any BytesIO objects to base64 strings while preserving key structure.\"\"\"\n    if self.content is None or not isinstance(self.content, dict):\n        return {\"content\": self.content, \"source\": self.source, \"step\": self.step}\n\n    serialized_content = self._recursive_serialize(self.content)\n\n    result = {\n        \"content\": serialized_content,\n        \"source\": self.source,\n        \"step\": self.step,\n    }\n\n    return result\n</code></pre>"},{"location":"dynamiq/nodes/agents/base/#dynamiq.nodes.agents.base.StreamChunkChoiceDelta.validate_source","title":"<code>validate_source(v)</code>  <code>classmethod</code>","text":"<p>Ensure source is always a string.</p> Source code in <code>dynamiq/nodes/agents/base.py</code> <pre><code>@field_validator('source')\n@classmethod\ndef validate_source(cls, v):\n    \"\"\"Ensure source is always a string.\"\"\"\n    if not isinstance(v, str):\n        raise ValueError(f\"source must be a string, got {type(v).__name__}: {v}\")\n    return v\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/","title":"Exceptions","text":""},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.ActionParsingException","title":"<code>ActionParsingException</code>","text":"<p>               Bases: <code>RecoverableAgentException</code></p> <p>Exception raised when an action cannot be parsed. Raising this exeption will allow Agent to reiterate.</p> <p>This exception is a subclass of AgentException and inherits its attributes and methods.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class ActionParsingException(RecoverableAgentException):\n    \"\"\"\n    Exception raised when an action cannot be parsed. Raising this exeption will allow Agent to reiterate.\n\n    This exception is a subclass of AgentException and inherits its attributes and methods.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.AgentUnknownToolException","title":"<code>AgentUnknownToolException</code>","text":"<p>               Bases: <code>RecoverableAgentException</code></p> <p>Exception raised when a unknown tool is requested. Raising this exeption will allow Agent to reiterate.</p> <p>This exception is a subclass of AgentException and inherits its attributes and methods.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class AgentUnknownToolException(RecoverableAgentException):\n    \"\"\"\n    Exception raised when a unknown tool is requested. Raising this exeption will allow Agent to reiterate.\n\n    This exception is a subclass of AgentException and inherits its attributes and methods.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.InvalidActionException","title":"<code>InvalidActionException</code>","text":"<p>               Bases: <code>RecoverableAgentException</code></p> <p>Exception raised when invalid action is chosen. Raising this exeption will allow Agent to reiterate.</p> <p>This exception is a subclass of AgentException and inherits its attributes and methods.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class InvalidActionException(RecoverableAgentException):\n    \"\"\"\n    Exception raised when invalid action is chosen. Raising this exeption will allow Agent to reiterate.\n\n    This exception is a subclass of AgentException and inherits its attributes and methods.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.JSONParsingError","title":"<code>JSONParsingError</code>","text":"<p>               Bases: <code>ParsingError</code></p> <p>Exception raised when expected JSON content within XML is invalid.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class JSONParsingError(ParsingError):\n    \"\"\"Exception raised when expected JSON content within XML is invalid.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.MaxLoopsExceededException","title":"<code>MaxLoopsExceededException</code>","text":"<p>               Bases: <code>RecoverableAgentException</code></p> <p>Exception raised when the agent exceeds the maximum number of allowed loops.</p> <p>This exception is recoverable, meaning the agent can continue after catching this exception.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class MaxLoopsExceededException(RecoverableAgentException):\n    \"\"\"\n    Exception raised when the agent exceeds the maximum number of allowed loops.\n\n    This exception is recoverable, meaning the agent can continue after catching this exception.\n    \"\"\"\n\n    def __init__(\n        self, message: str = \"Maximum number of loops reached without finding a final answer.\", recoverable: bool = True\n    ):\n        super().__init__(message, recoverable=recoverable)\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.ParsingError","title":"<code>ParsingError</code>","text":"<p>               Bases: <code>RecoverableAgentException</code></p> <p>Base class for parsing errors.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class ParsingError(RecoverableAgentException):\n    \"\"\"Base class for parsing errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.RecoverableAgentException","title":"<code>RecoverableAgentException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for recoverable agent errors.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class RecoverableAgentException(Exception):\n    \"\"\"\n    Base exception class for recoverable agent errors.\n    \"\"\"\n\n    def __init__(self, *args, recoverable: bool = True, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.recoverable = recoverable\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.TagNotFoundError","title":"<code>TagNotFoundError</code>","text":"<p>               Bases: <code>ParsingError</code></p> <p>Exception raised when required XML tags are missing.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class TagNotFoundError(ParsingError):\n    \"\"\"Exception raised when required XML tags are missing.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.ToolExecutionException","title":"<code>ToolExecutionException</code>","text":"<p>               Bases: <code>RecoverableAgentException</code></p> <p>Exception raised when a tools fails to execute. Raising this exeption will allow Agent to reiterate.</p> <p>This exception is a subclass of AgentException and inherits its attributes and methods.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class ToolExecutionException(RecoverableAgentException):\n    \"\"\"\n    Exception raised when a tools fails to execute. Raising this exeption will allow Agent to reiterate.\n\n    This exception is a subclass of AgentException and inherits its attributes and methods.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/exceptions/#dynamiq.nodes.agents.exceptions.XMLParsingError","title":"<code>XMLParsingError</code>","text":"<p>               Bases: <code>ParsingError</code></p> <p>Exception raised when XML structure is invalid or cannot be parsed.</p> Source code in <code>dynamiq/nodes/agents/exceptions.py</code> <pre><code>class XMLParsingError(ParsingError):\n    \"\"\"Exception raised when XML structure is invalid or cannot be parsed.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/","title":"Utils","text":""},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.FileMappedInput","title":"<code>FileMappedInput</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Structure for storing file mapped inputs.</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>class FileMappedInput(BaseModel):\n    \"\"\"Structure for storing file mapped inputs.\"\"\"\n\n    input: Any\n    files: list[io.BytesIO]  # List of BytesIO objects or FileInfo objects\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @field_serializer(\"files\")\n    def serialize_files(self, files: list[io.BytesIO]) -&gt; list[str]:\n        return [getattr(file, \"name\", f\"file_{i}\") for i, file in enumerate(files)]\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.SummarizationConfig","title":"<code>SummarizationConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for agent history summarization.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether streaming is enabled. Defaults to False.</p> <code>max_token_context_length</code> <code>int | None</code> <p>Maximum number of tokens in prompt after which summarization will be applied. Defaults to None.</p> <code>context_usage_ratio</code> <code>float</code> <p>Relative percentage of tokens in prompt after which summarization will be applied.</p> <code>context_history_length</code> <code>int</code> <p>Number of history messages that will be prepended.</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>class SummarizationConfig(BaseModel):\n    \"\"\"Configuration for agent history summarization.\n\n    Attributes:\n        enabled (bool): Whether streaming is enabled. Defaults to False.\n        max_token_context_length (int | None): Maximum number of tokens in prompt after\n          which summarization will be applied. Defaults to None.\n        context_usage_ratio (float): Relative percentage of tokens in prompt after which summarization will be applied.\n        context_history_length (int): Number of history messages that will be prepended.\n    \"\"\"\n\n    enabled: bool = False\n    max_token_context_length: int | None = None\n    context_usage_ratio: float = 0.8\n    context_history_length: int = 4\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.ToolCacheEntry","title":"<code>ToolCacheEntry</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Single key entry in tool cache.</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>class ToolCacheEntry(BaseModel):\n    \"\"\"Single key entry in tool cache.\"\"\"\n\n    action: str\n    action_input: dict | str\n\n    model_config = ConfigDict(frozen=True)\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def convert_to_str(cls, data):\n        if isinstance(data, dict):\n            data[\"action_input\"] = json.dumps(data.get('action_input'), sort_keys=True)\n        return data\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.XMLParser","title":"<code>XMLParser</code>","text":"<p>Utility class for parsing XML-like output, often generated by LLMs. Prioritizes lxml for robustness, with fallbacks for common issues.</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>class XMLParser:\n    \"\"\"\n    Utility class for parsing XML-like output, often generated by LLMs.\n    Prioritizes lxml for robustness, with fallbacks for common issues.\n    \"\"\"\n\n    DEFAULT_PRESERVE_TAGS = [\"answer\", \"thought\"]\n\n    @staticmethod\n    def _clean_content(text: str) -&gt; str:\n        \"\"\"\n        Cleans the input string to remove common LLM artifacts and isolate XML.\n\n        Args:\n            text (str): The input string to be cleaned\n\n        Returns:\n            str: Cleaned string containing only the XML content\n        \"\"\"\n        if not isinstance(text, str):\n            return \"\"\n\n        cleaned = text.strip()\n\n        if cleaned.startswith(\"```\") and cleaned.endswith(\"```\"):\n            cleaned = re.sub(r\"^```.*?\\n\", \"\", cleaned)\n            cleaned = re.sub(r\"\\n```$\", \"\", cleaned)\n\n        xml_matches = list(re.finditer(r\"&lt;(\\w+)\\b[^&gt;]*&gt;.*?&lt;/\\1&gt;\", cleaned, re.DOTALL))\n        if xml_matches:\n            for match in reversed(xml_matches):\n                candidate = match.group(0)\n                if \"&lt;answer\" in candidate:\n                    cleaned = candidate\n                    break\n            else:\n                cleaned = xml_matches[-1].group(0)\n\n        return cleaned\n\n    @staticmethod\n    def extract_content_with_regex_fallback(text: str, tag_name: str) -&gt; str | None:\n        \"\"\"\n        Extract tag content using regex as a fallback when XML parsing fails.\n        Works with both complete and incomplete tags.\n\n        Args:\n            text (str): The XML-like text to extract content from\n            tag_name (str): The name of the tag to extract content from\n\n        Returns:\n            str | None: The extracted content if found, None otherwise\n        \"\"\"\n        complete_pattern = f\"&lt;{tag_name}[^&gt;]*&gt;(.*?)&lt;/{tag_name}&gt;\"\n        complete_match = re.search(complete_pattern, text, re.DOTALL)\n\n        if complete_match:\n            content = complete_match.group(1).strip()\n            if content:\n                return content\n            return None\n\n        incomplete_pattern = f\"&lt;{tag_name}[^&gt;]*&gt;(.*?)(?=&lt;(?!/{tag_name})|$)\"\n        incomplete_match = re.search(incomplete_pattern, text, re.DOTALL)\n\n        if incomplete_match:\n            content = incomplete_match.group(1).strip()\n            if content:\n                return content\n\n        return None\n\n    @staticmethod\n    def preprocess_xml_content(\n        text: str, required_tags: Sequence[str] = None, optional_tags: Sequence[str] = None\n    ) -&gt; dict[str, tuple[str, str]]:\n        \"\"\"\n        Extract raw content for all tags that need special handling before parsing.\n        Filters tags based on required and optional tags if provided.\n\n        Args:\n            text (str): The XML-like text to preprocess\n            required_tags (Sequence[str], optional): List of tags that must be present\n            optional_tags (Sequence[str], optional): List of tags that may be present\n\n        Returns:\n            dict[str, tuple[str, str]]: Dictionary mapping tag names to (modified_text, raw_content) tuples\n        \"\"\"\n        extracted_contents = {}\n        tags_to_process = set(XMLParser.DEFAULT_PRESERVE_TAGS)\n\n        # Add required and optional tags to the set if provided\n        if required_tags:\n            tags_to_process.update(required_tags)\n        if optional_tags:\n            tags_to_process.update(optional_tags)\n\n        text = XMLParser._escape_unbalanced_reserved_tags(text, tags_to_process)\n\n        for tag in tags_to_process:\n            content = XMLParser.extract_content_with_regex_fallback(text, tag)\n            if content:\n                tag_pattern = f\"&lt;{tag}[^&gt;]*&gt;.*?(?=&lt;(?!/{tag})|$)|&lt;{tag}[^&gt;]*&gt;.*?&lt;/{tag}&gt;\"\n                modified_text = re.sub(tag_pattern, f\"&lt;{tag}&gt;CONTENT_PLACEHOLDER_{tag}&lt;/{tag}&gt;\", text, flags=re.DOTALL)\n                extracted_contents[tag] = (modified_text, content)\n                text = modified_text\n\n        return extracted_contents\n\n    @staticmethod\n    def _escape_unbalanced_reserved_tags(text: str, tags: Sequence[str]) -&gt; str:\n        \"\"\"Escape reserved tag tokens that appear in prose instead of well-formed XML.\"\"\"\n\n        if not text:\n            return text\n\n        for tag in tags:\n            open_tag = f\"&lt;{tag}&gt;\"\n            close_tag = f\"&lt;/{tag}&gt;\"\n\n            # Replace stray closing tags without matching opening tags\n            search_start = 0\n            while True:\n                close_index = text.find(close_tag, search_start)\n                if close_index == -1:\n                    break\n\n                opening_index = text.rfind(open_tag, 0, close_index)\n                if opening_index == -1:\n                    text = text[:close_index] + f\"&amp;lt;/{tag}&amp;gt;\" + text[close_index + len(close_tag) :]\n                    search_start = close_index + len(f\"&amp;lt;/{tag}&amp;gt;\")\n                else:\n                    search_start = close_index + len(close_tag)\n\n            # Replace stray opening tags without matching closing tags\n            search_start = 0\n            while True:\n                open_index = text.find(open_tag, search_start)\n                if open_index == -1:\n                    break\n\n                closing_index = text.find(close_tag, open_index + len(open_tag))\n                if closing_index == -1:\n                    text = text[:open_index] + f\"&amp;lt;{tag}&amp;gt;\" + text[open_index + len(open_tag) :]\n                    search_start = open_index + len(f\"&amp;lt;{tag}&amp;gt;\")\n                else:\n                    search_start = open_index + len(open_tag)\n\n        return text\n\n    @staticmethod\n    def _parse_with_lxml(cleaned_text: str) -&gt; LET._Element | None:\n        \"\"\"\n        Attempts to parse the cleaned text using lxml with recovery.\n\n        Args:\n            cleaned_text (str): The cleaned XML text to parse\n\n        Returns:\n            LET._Element | None: The parsed XML element if successful, None otherwise\n        \"\"\"\n        if not cleaned_text:\n            return None\n        try:\n            tags_to_check = [\"thought\", \"answer\", \"action\", \"action_input\", \"output\"]\n            fixed_text = cleaned_text\n\n            for tag in tags_to_check:\n                opening_count = len(re.findall(f\"&lt;{tag}[^&gt;]*&gt;\", fixed_text))\n                closing_count = len(re.findall(f\"&lt;/{tag}&gt;\", fixed_text))\n\n                if opening_count &gt; closing_count:\n                    logger.debug(f\"XMLParser: Adding missing &lt;/{tag}&gt; tags\")\n                    if tag == \"output\":\n                        fixed_text += f\"&lt;/{tag}&gt;\"\n                    else:\n                        pos = fixed_text.find(f\"&lt;{tag}\")\n                        if pos &gt;= 0:\n                            next_tag_pos = fixed_text.find(\"&lt;\", pos + 1)\n                            if next_tag_pos &gt; 0 and f\"&lt;/{tag}&gt;\" not in fixed_text[pos:next_tag_pos]:\n                                fixed_text = fixed_text[:next_tag_pos] + f\"&lt;/{tag}&gt;\" + fixed_text[next_tag_pos:]\n\n            parser = LET.XMLParser(recover=True, encoding=\"utf-8\")\n            root = LET.fromstring(fixed_text.encode(\"utf-8\"), parser=parser)  # nosec: B320\n            return root\n        except LET.XMLSyntaxError as e:\n            logger.warning(f\"XMLParser: lxml parsing failed with recovery: {e}. Content: {cleaned_text[:200]}...\")\n            return None\n        except Exception as e:\n            logger.error(f\"XMLParser: Unexpected error during parsing: {e}. Content: {cleaned_text[:200]}...\")\n            return None\n\n    @staticmethod\n    def _extract_data_lxml(\n        root: LET._Element,\n        required_tags: Sequence[str],\n        optional_tags: Sequence[str] = None,\n        preserve_format_tags: Sequence[str] = None,\n    ) -&gt; dict[str, str]:\n        \"\"\"\n        Extracts text content from specified tags using XPath.\n\n        Args:\n            root (LET._Element): The root XML element to extract data from\n            required_tags (Sequence[str]): Tags that must be present in the output\n            optional_tags (Sequence[str], optional): Tags to extract if present\n            preserve_format_tags (Sequence[str], optional): Tags where original formatting should be preserved\n\n        Returns:\n            dict[str, str]: Dictionary mapping tag names to their extracted content\n\n        Raises:\n            TagNotFoundError: If a required tag is missing or empty\n        \"\"\"\n        data = {}\n        optional_tags = optional_tags or []\n        preserve_format_tags = list(preserve_format_tags or [])\n\n        for tag in XMLParser.DEFAULT_PRESERVE_TAGS:\n            if tag not in preserve_format_tags:\n                preserve_format_tags.append(tag)\n\n        all_tags = list(required_tags) + list(optional_tags)\n\n        for tag in all_tags:\n            tag_content = None\n            element_found = False\n            elements = root.xpath(f\".//{tag}\")\n            if elements:\n                element_found = True\n                for elem in elements:\n                    if tag in preserve_format_tags:\n                        xml_content = LET.tostring(elem, encoding=\"unicode\", method=\"xml\")\n                        tag_pattern = re.compile(f\"&lt;{tag}[^&gt;]*&gt;(.*?)&lt;/{tag}&gt;\", re.DOTALL)\n                        match = tag_pattern.search(xml_content)\n                        text = match.group(1) if match else \"\"\n                    else:\n                        text = \"\".join(elem.itertext()).strip()\n\n                    if not text and tag in required_tags:\n                        raise TagNotFoundError(f\"Required tag &lt;{tag}&gt; found but contains no text content.\")\n\n                    if text:\n                        if text.startswith(\"CONTENT_PLACEHOLDER_\"):\n                            continue\n                        tag_content = text\n                        break\n\n            if not element_found:\n                try:\n                    if root.getparent() is not None:\n                        parent_elements = root.xpath(f\"../{tag}\")\n                        if parent_elements:\n                            element_found = True\n                            for elem in parent_elements:\n                                text_parent_child = \"\".join(elem.itertext()).strip()\n                                if text_parent_child:\n                                    tag_content = text_parent_child\n                                    break\n                except (AttributeError, Exception) as e:\n                    logger.debug(f\"XMLParser: Error checking parent for tag '{tag}': {e}\")\n                    pass\n\n            if tag_content is not None:\n                data[tag] = tag_content\n            elif element_found and tag in required_tags and tag_content is None:\n                raise TagNotFoundError(f\"Required tag &lt;{tag}&gt; found but contains no text content.\")\n            elif not element_found and tag in required_tags:\n                raise TagNotFoundError(\n                    f\"Required tag &lt;{tag}&gt; not found in the XML structure \"\n                    f\"relative to the parsed root element ('{root.tag}') or its parent.\"\n                )\n\n        missing_required_after_all = [tag for tag in required_tags if tag not in data]\n        if missing_required_after_all:\n            raise TagNotFoundError(f\"Required tags missing after extraction: {', '.join(missing_required_after_all)}\")\n\n        return data\n\n    @staticmethod\n    def _parse_json_fields(data: dict[str, str], json_fields: Sequence[str]) -&gt; dict[str, Any]:\n        \"\"\"\n        Parses specified fields in the data dictionary as JSON.\n\n        Args:\n            data (dict[str, str]): Dictionary of extracted tag contents\n            json_fields (Sequence[str]): List of field names to parse as JSON\n\n        Returns:\n            dict[str, Any]: Dictionary with specified fields parsed as JSON objects\n\n        Raises:\n            JSONParsingError: If a JSON field cannot be parsed correctly\n        \"\"\"\n        parsed_data = data.copy()\n        for field in json_fields:\n            if field in parsed_data:\n                try:\n                    json_string = re.sub(r\"^```(?:json)?\\s*|```$\", \"\", parsed_data[field].strip())\n                    parsed_data[field] = json.loads(json_string)\n                except json.JSONDecodeError as e:\n                    error_message = (\n                        f\"Failed to parse JSON content for field '{field}'. \"\n                        f\"Error: {e}. Original content: '{parsed_data[field][:100]}...'\"\n                    )\n                    guidance = (\n                        \" Ensure the value is valid JSON with double quotes for keys and strings, \"\n                        'and proper escaping for special characters (e.g., \\\\n for newlines, \\\\\" for quotes).'\n                    )\n                    raise JSONParsingError(error_message + guidance)\n                except Exception as e:\n                    raise JSONParsingError(f\"Unexpected error parsing JSON for field '{field}': {e}\")\n        return parsed_data\n\n    @staticmethod\n    def parse(\n        text: str,\n        required_tags: Sequence[str],\n        optional_tags: Sequence[str] = None,\n        json_fields: Sequence[str] = None,\n        preserve_format_tags: Sequence[str] = None,\n        attempt_wrap: bool = True,\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Parse XML-like text to extract structured data from specified tags.\n\n        This function employs a multi-stage parsing strategy:\n        1. First cleans and preprocesses the input text\n        2. Attempts extraction using regex for tags needing special handling\n        3. Tries robust XML parsing with lxml (with auto-repair capabilities)\n        4. Falls back to regex extraction for any remaining tags\n        5. Processes JSON fields if specified\n\n        Each stage has fallback mechanisms to handle various edge cases commonly\n        seen in LLM-generated XML, including malformed tags, missing closing tags,\n        and inconsistent formatting.\n\n        Args:\n            text (str): The XML-like text to parse\n            required_tags (Sequence[str]): Tags that must be present in the output\n            optional_tags (Sequence[str], optional): Tags to extract if present\n            json_fields (Sequence[str], optional): Fields to parse as JSON objects\n            preserve_format_tags (Sequence[str], optional): Tags where original formatting\n                                                           should be preserved\n            attempt_wrap (bool, optional): Whether to try wrapping content in a root tag\n                                          if initial parsing fails\n\n        Returns:\n            dict[str, Any]: Dictionary mapping tag names to their extracted content\n\n        Raises:\n            ParsingError: If the input is empty or invalid\n            TagNotFoundError: If a required tag is missing or empty\n            JSONParsingError: If a JSON field cannot be parsed\n        \"\"\"\n        optional_tags = optional_tags or []\n        json_fields = json_fields or []\n        preserve_format_tags = list(preserve_format_tags or [])\n\n        required_optional_set = set(required_tags) | set(optional_tags)\n\n        for tag in XMLParser.DEFAULT_PRESERVE_TAGS:\n            if tag not in preserve_format_tags:\n                preserve_format_tags.append(tag)\n        cleaned_text = XMLParser._clean_content(text)\n        if not cleaned_text:\n            if text and text.strip():\n                cleaned_text = text.strip()\n            else:\n                if required_tags:\n                    raise ParsingError(\"Input text is empty or became empty after cleaning.\")\n                else:\n                    return {}\n\n        tags_to_process = set(XMLParser.DEFAULT_PRESERVE_TAGS)\n        if required_tags:\n            tags_to_process.update(required_tags)\n        if optional_tags:\n            tags_to_process.update(optional_tags)\n\n        extracted_contents = XMLParser.preprocess_xml_content(cleaned_text, required_tags, optional_tags)\n\n        modified_text = cleaned_text\n        if extracted_contents:\n            for tag, (tag_modified_text, _) in extracted_contents.items():\n                modified_text = tag_modified_text\n\n        result = {}\n        for tag, (_, content) in extracted_contents.items():\n            if tag in required_optional_set:\n                result[tag] = content\n\n        remaining_required = [tag for tag in required_tags if tag not in result]\n        remaining_optional = [tag for tag in optional_tags if tag not in result]\n\n        try:\n            root = XMLParser._parse_with_lxml(modified_text)\n\n            if root is None and attempt_wrap:\n                wrapped_text = f\"&lt;root&gt;{modified_text}&lt;/root&gt;\"\n                root = XMLParser._parse_with_lxml(wrapped_text)\n\n            if root is not None and (remaining_required or remaining_optional):\n                xml_data = XMLParser._extract_data_lxml(\n                    root, remaining_required, remaining_optional, preserve_format_tags\n                )\n                result.update(xml_data)\n                remaining_required = [tag for tag in remaining_required if tag not in result]\n                remaining_optional = [tag for tag in remaining_optional if tag not in result]\n        except TagNotFoundError as e:\n            logger.debug(\n                \"XMLParser: lxml extraction missing tag (will retry via fallback): %s\",\n                e,\n            )\n        except Exception as e:\n            logger.warning(f\"XMLParser: XML parsing failed: {e}\")\n\n        for tag in remaining_required:\n            content = XMLParser.extract_content_with_regex_fallback(text, tag)\n            if content:\n                result[tag] = content\n            else:\n                empty_tag_pattern = f\"&lt;{tag}[^&gt;]*&gt;\\\\s*&lt;/{tag}&gt;\"\n                if re.search(empty_tag_pattern, text):\n                    raise TagNotFoundError(f\"Required tag &lt;{tag}&gt; found but contains no text content.\")\n                else:\n                    raise TagNotFoundError(f\"Required tag &lt;{tag}&gt; not found even with fallback methods\")\n\n        for tag in remaining_optional:\n            content = XMLParser.extract_content_with_regex_fallback(text, tag)\n            if content:\n                result[tag] = content\n\n        if result:\n            result = XMLParser._restore_placeholder_mentions(result, tags_to_process)\n\n        if json_fields and result:\n            result = XMLParser._parse_json_fields(result, json_fields)\n\n        return result\n\n    @staticmethod\n    def _restore_placeholder_mentions(data: dict[str, Any], tags: Sequence[str]) -&gt; dict[str, Any]:\n        \"\"\"Replace placeholder artifacts with escaped tag mentions.\"\"\"\n\n        restored = {}\n        for key, value in data.items():\n            if isinstance(value, str):\n                for tag in tags:\n                    placeholder = f\"&lt;{tag}&gt;CONTENT_PLACEHOLDER_{tag}&lt;/{tag}&gt;\"\n                    if placeholder in value:\n                        value = value.replace(placeholder, f\"&amp;lt;{tag}&amp;gt;\")\n                    # Escape any remaining raw occurrences of reserved tags\n                    value = value.replace(f\"&lt;{tag}&gt;\", f\"&amp;lt;{tag}&amp;gt;\")\n                    value = value.replace(f\"&lt;/{tag}&gt;\", f\"&amp;lt;/{tag}&amp;gt;\")\n                restored[key] = value\n            else:\n                restored[key] = value\n\n        return restored\n\n    @staticmethod\n    def extract_first_tag_lxml(text: str, tags: Sequence[str]) -&gt; str | None:\n        \"\"\"\n        Extracts the text content of the first tag found from the list using lxml.\n        Useful for simple cases like extracting just the final answer.\n\n        Args:\n            text (str): The XML-like text to extract content from\n            tags (Sequence[str]): Ordered list of tags to look for\n\n        Returns:\n            str | None: Content of the first found tag, or None if no tags are found\n        \"\"\"\n        cleaned_text = XMLParser._clean_content(text)\n        if not cleaned_text:\n            return None\n\n        root = XMLParser._parse_with_lxml(cleaned_text)\n\n        if root is None:\n            wrapped_text = f\"&lt;root&gt;{cleaned_text}&lt;/root&gt;\"\n            root = XMLParser._parse_with_lxml(wrapped_text)\n\n        if root is None:\n            logger.warning(f\"XMLParser: extract_first_tag_lxml failed to parse: {cleaned_text[:200]}...\")\n            return None\n\n        for tag in tags:\n            elements = root.xpath(f\".//{tag}\")\n            if elements:\n                for elem in elements:\n                    content = \"\".join(elem.itertext()).strip()\n                    if content:\n                        return content\n        return None\n\n    @staticmethod\n    def extract_first_tag_regex(text: str, tags: Sequence[str]) -&gt; str | None:\n        \"\"\"\n        Fallback method: Extracts the text content of the first tag found using regex.\n        Less reliable than lxml, use only when lxml fails completely.\n\n        Args:\n            text (str): The XML-like text to extract content from\n            tags (Sequence[str]): Ordered list of tags to look for\n\n        Returns:\n            str | None: Content of the first found tag, or None if no tags are found\n        \"\"\"\n        if not isinstance(text, str):\n            return None\n\n        for tag in tags:\n            match = re.search(f\"&lt;{tag}\\\\b[^&gt;]*&gt;(.*?)&lt;/{tag}&gt;\", text, re.DOTALL | re.IGNORECASE)\n            if match:\n                content = match.group(1).strip()\n                if content:\n                    return content\n        return None\n\n    @staticmethod\n    def parse_unified_xml_format(text: str) -&gt; dict[str, Any]:\n        \"\"\"\n        Parse XML content using a unified structure for both tool calls and final answers.\n\n        Args:\n            text (str): The XML content to parse\n\n        Returns:\n            dict: A dictionary containing parsed data with the following structure:\n                For tool calls:\n                {\n                    \"is_final\": False,\n                    \"thought\": \"extracted thought text\",\n                    \"tools\": [\n                        {\"name\": \"tool name\", \"input\": parsed_json_input},\n                        {\"name\": \"tool name\", \"input\": parsed_json_input},\n                        ...\n                    ]\n                }\n\n                For final answer:\n                {\n                    \"is_final\": True,\n                    \"thought\": \"extracted thought text\",\n                    \"answer\": \"final answer text\"\n                }\n\n        Raises:\n            XMLParsingError: If the XML cannot be parsed\n            TagNotFoundError: If required tags are missing\n        \"\"\"\n        try:\n            cleaned_text = XMLParser._clean_content(text)\n            if not cleaned_text:\n                raise XMLParsingError(\"Empty or invalid XML content\")\n\n            try:\n                parsed_data = XMLParser.parse(cleaned_text, required_tags=[\"thought\", \"answer\"], optional_tags=[\"o\"])\n                return {\"is_final\": True, \"thought\": parsed_data.get(\"thought\"), \"answer\": parsed_data.get(\"answer\")}\n            except TagNotFoundError:\n                pass\n\n            root = XMLParser._parse_with_lxml(cleaned_text)\n            if root is None:\n\n                wrapped_text = f\"&lt;root&gt;{cleaned_text}&lt;/root&gt;\"\n                root = XMLParser._parse_with_lxml(wrapped_text)\n\n            if root is None:\n                raise XMLParsingError(\"Failed to parse XML content with lxml\")\n\n            thought_elems = root.xpath(\".//thought\")\n            if not thought_elems:\n                raise TagNotFoundError(\"Required tag &lt;thought&gt; not found\")\n\n            thought = \"\".join(thought_elems[0].itertext()).strip()\n\n            tool_calls_elem = None\n            for tag_name in [\"tool_calls\", \"tools\"]:\n                elems = root.xpath(f\".//{tag_name}\")\n                if elems:\n                    tool_calls_elem = elems[0]\n                    break\n\n            if tool_calls_elem is None:\n                raise TagNotFoundError(\"Required tag &lt;tool_calls&gt; or &lt;tools&gt; not found\")\n\n            tools = []\n            for tool_elem in tool_calls_elem.xpath(\".//tool\"):\n\n                name_elem = None\n                for name_tag in [\"n\", \"name\", \"tool_name\"]:\n                    name_elems = tool_elem.xpath(f\".//{name_tag}\")\n                    if name_elems:\n                        name_elem = name_elems[0]\n                        break\n\n                if name_elem is None:\n                    continue\n\n                input_elem = None\n                for input_tag in [\"input\", \"tool_input\"]:\n                    input_elems = tool_elem.xpath(f\".//{input_tag}\")\n                    if input_elems:\n                        input_elem = input_elems[0]\n                        break\n\n                if input_elem is None:\n                    continue\n\n                tool_name = \"\".join(name_elem.itertext()).strip()\n                input_json_str = \"\".join(input_elem.itertext()).strip()\n\n                try:\n\n                    input_json_str = re.sub(r\"^```(?:json)?\\s*|```$\", \"\", input_json_str.strip())\n                    tool_input = json.loads(input_json_str)\n                except json.JSONDecodeError as e:\n                    logger.warning(f\"Failed to parse JSON for tool {tool_name}: {e}\")\n                    continue\n\n                tools.append({\"name\": tool_name, \"input\": tool_input})\n\n            if not tools:\n                raise TagNotFoundError(\"No valid tool elements found with both name and input tags\")\n\n            return {\"is_final\": False, \"thought\": thought, \"tools\": tools}\n\n        except (XMLParsingError, TagNotFoundError):\n            raise\n        except Exception as e:\n            raise XMLParsingError(f\"Error parsing XML: {str(e)}\")\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.XMLParser.extract_content_with_regex_fallback","title":"<code>extract_content_with_regex_fallback(text, tag_name)</code>  <code>staticmethod</code>","text":"<p>Extract tag content using regex as a fallback when XML parsing fails. Works with both complete and incomplete tags.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The XML-like text to extract content from</p> required <code>tag_name</code> <code>str</code> <p>The name of the tag to extract content from</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: The extracted content if found, None otherwise</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>@staticmethod\ndef extract_content_with_regex_fallback(text: str, tag_name: str) -&gt; str | None:\n    \"\"\"\n    Extract tag content using regex as a fallback when XML parsing fails.\n    Works with both complete and incomplete tags.\n\n    Args:\n        text (str): The XML-like text to extract content from\n        tag_name (str): The name of the tag to extract content from\n\n    Returns:\n        str | None: The extracted content if found, None otherwise\n    \"\"\"\n    complete_pattern = f\"&lt;{tag_name}[^&gt;]*&gt;(.*?)&lt;/{tag_name}&gt;\"\n    complete_match = re.search(complete_pattern, text, re.DOTALL)\n\n    if complete_match:\n        content = complete_match.group(1).strip()\n        if content:\n            return content\n        return None\n\n    incomplete_pattern = f\"&lt;{tag_name}[^&gt;]*&gt;(.*?)(?=&lt;(?!/{tag_name})|$)\"\n    incomplete_match = re.search(incomplete_pattern, text, re.DOTALL)\n\n    if incomplete_match:\n        content = incomplete_match.group(1).strip()\n        if content:\n            return content\n\n    return None\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.XMLParser.extract_first_tag_lxml","title":"<code>extract_first_tag_lxml(text, tags)</code>  <code>staticmethod</code>","text":"<p>Extracts the text content of the first tag found from the list using lxml. Useful for simple cases like extracting just the final answer.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The XML-like text to extract content from</p> required <code>tags</code> <code>Sequence[str]</code> <p>Ordered list of tags to look for</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: Content of the first found tag, or None if no tags are found</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>@staticmethod\ndef extract_first_tag_lxml(text: str, tags: Sequence[str]) -&gt; str | None:\n    \"\"\"\n    Extracts the text content of the first tag found from the list using lxml.\n    Useful for simple cases like extracting just the final answer.\n\n    Args:\n        text (str): The XML-like text to extract content from\n        tags (Sequence[str]): Ordered list of tags to look for\n\n    Returns:\n        str | None: Content of the first found tag, or None if no tags are found\n    \"\"\"\n    cleaned_text = XMLParser._clean_content(text)\n    if not cleaned_text:\n        return None\n\n    root = XMLParser._parse_with_lxml(cleaned_text)\n\n    if root is None:\n        wrapped_text = f\"&lt;root&gt;{cleaned_text}&lt;/root&gt;\"\n        root = XMLParser._parse_with_lxml(wrapped_text)\n\n    if root is None:\n        logger.warning(f\"XMLParser: extract_first_tag_lxml failed to parse: {cleaned_text[:200]}...\")\n        return None\n\n    for tag in tags:\n        elements = root.xpath(f\".//{tag}\")\n        if elements:\n            for elem in elements:\n                content = \"\".join(elem.itertext()).strip()\n                if content:\n                    return content\n    return None\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.XMLParser.extract_first_tag_regex","title":"<code>extract_first_tag_regex(text, tags)</code>  <code>staticmethod</code>","text":"<p>Fallback method: Extracts the text content of the first tag found using regex. Less reliable than lxml, use only when lxml fails completely.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The XML-like text to extract content from</p> required <code>tags</code> <code>Sequence[str]</code> <p>Ordered list of tags to look for</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: Content of the first found tag, or None if no tags are found</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>@staticmethod\ndef extract_first_tag_regex(text: str, tags: Sequence[str]) -&gt; str | None:\n    \"\"\"\n    Fallback method: Extracts the text content of the first tag found using regex.\n    Less reliable than lxml, use only when lxml fails completely.\n\n    Args:\n        text (str): The XML-like text to extract content from\n        tags (Sequence[str]): Ordered list of tags to look for\n\n    Returns:\n        str | None: Content of the first found tag, or None if no tags are found\n    \"\"\"\n    if not isinstance(text, str):\n        return None\n\n    for tag in tags:\n        match = re.search(f\"&lt;{tag}\\\\b[^&gt;]*&gt;(.*?)&lt;/{tag}&gt;\", text, re.DOTALL | re.IGNORECASE)\n        if match:\n            content = match.group(1).strip()\n            if content:\n                return content\n    return None\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.XMLParser.parse","title":"<code>parse(text, required_tags, optional_tags=None, json_fields=None, preserve_format_tags=None, attempt_wrap=True)</code>  <code>staticmethod</code>","text":"<p>Parse XML-like text to extract structured data from specified tags.</p> <p>This function employs a multi-stage parsing strategy: 1. First cleans and preprocesses the input text 2. Attempts extraction using regex for tags needing special handling 3. Tries robust XML parsing with lxml (with auto-repair capabilities) 4. Falls back to regex extraction for any remaining tags 5. Processes JSON fields if specified</p> <p>Each stage has fallback mechanisms to handle various edge cases commonly seen in LLM-generated XML, including malformed tags, missing closing tags, and inconsistent formatting.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The XML-like text to parse</p> required <code>required_tags</code> <code>Sequence[str]</code> <p>Tags that must be present in the output</p> required <code>optional_tags</code> <code>Sequence[str]</code> <p>Tags to extract if present</p> <code>None</code> <code>json_fields</code> <code>Sequence[str]</code> <p>Fields to parse as JSON objects</p> <code>None</code> <code>preserve_format_tags</code> <code>Sequence[str]</code> <p>Tags where original formatting                                            should be preserved</p> <code>None</code> <code>attempt_wrap</code> <code>bool</code> <p>Whether to try wrapping content in a root tag                           if initial parsing fails</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary mapping tag names to their extracted content</p> <p>Raises:</p> Type Description <code>ParsingError</code> <p>If the input is empty or invalid</p> <code>TagNotFoundError</code> <p>If a required tag is missing or empty</p> <code>JSONParsingError</code> <p>If a JSON field cannot be parsed</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>@staticmethod\ndef parse(\n    text: str,\n    required_tags: Sequence[str],\n    optional_tags: Sequence[str] = None,\n    json_fields: Sequence[str] = None,\n    preserve_format_tags: Sequence[str] = None,\n    attempt_wrap: bool = True,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Parse XML-like text to extract structured data from specified tags.\n\n    This function employs a multi-stage parsing strategy:\n    1. First cleans and preprocesses the input text\n    2. Attempts extraction using regex for tags needing special handling\n    3. Tries robust XML parsing with lxml (with auto-repair capabilities)\n    4. Falls back to regex extraction for any remaining tags\n    5. Processes JSON fields if specified\n\n    Each stage has fallback mechanisms to handle various edge cases commonly\n    seen in LLM-generated XML, including malformed tags, missing closing tags,\n    and inconsistent formatting.\n\n    Args:\n        text (str): The XML-like text to parse\n        required_tags (Sequence[str]): Tags that must be present in the output\n        optional_tags (Sequence[str], optional): Tags to extract if present\n        json_fields (Sequence[str], optional): Fields to parse as JSON objects\n        preserve_format_tags (Sequence[str], optional): Tags where original formatting\n                                                       should be preserved\n        attempt_wrap (bool, optional): Whether to try wrapping content in a root tag\n                                      if initial parsing fails\n\n    Returns:\n        dict[str, Any]: Dictionary mapping tag names to their extracted content\n\n    Raises:\n        ParsingError: If the input is empty or invalid\n        TagNotFoundError: If a required tag is missing or empty\n        JSONParsingError: If a JSON field cannot be parsed\n    \"\"\"\n    optional_tags = optional_tags or []\n    json_fields = json_fields or []\n    preserve_format_tags = list(preserve_format_tags or [])\n\n    required_optional_set = set(required_tags) | set(optional_tags)\n\n    for tag in XMLParser.DEFAULT_PRESERVE_TAGS:\n        if tag not in preserve_format_tags:\n            preserve_format_tags.append(tag)\n    cleaned_text = XMLParser._clean_content(text)\n    if not cleaned_text:\n        if text and text.strip():\n            cleaned_text = text.strip()\n        else:\n            if required_tags:\n                raise ParsingError(\"Input text is empty or became empty after cleaning.\")\n            else:\n                return {}\n\n    tags_to_process = set(XMLParser.DEFAULT_PRESERVE_TAGS)\n    if required_tags:\n        tags_to_process.update(required_tags)\n    if optional_tags:\n        tags_to_process.update(optional_tags)\n\n    extracted_contents = XMLParser.preprocess_xml_content(cleaned_text, required_tags, optional_tags)\n\n    modified_text = cleaned_text\n    if extracted_contents:\n        for tag, (tag_modified_text, _) in extracted_contents.items():\n            modified_text = tag_modified_text\n\n    result = {}\n    for tag, (_, content) in extracted_contents.items():\n        if tag in required_optional_set:\n            result[tag] = content\n\n    remaining_required = [tag for tag in required_tags if tag not in result]\n    remaining_optional = [tag for tag in optional_tags if tag not in result]\n\n    try:\n        root = XMLParser._parse_with_lxml(modified_text)\n\n        if root is None and attempt_wrap:\n            wrapped_text = f\"&lt;root&gt;{modified_text}&lt;/root&gt;\"\n            root = XMLParser._parse_with_lxml(wrapped_text)\n\n        if root is not None and (remaining_required or remaining_optional):\n            xml_data = XMLParser._extract_data_lxml(\n                root, remaining_required, remaining_optional, preserve_format_tags\n            )\n            result.update(xml_data)\n            remaining_required = [tag for tag in remaining_required if tag not in result]\n            remaining_optional = [tag for tag in remaining_optional if tag not in result]\n    except TagNotFoundError as e:\n        logger.debug(\n            \"XMLParser: lxml extraction missing tag (will retry via fallback): %s\",\n            e,\n        )\n    except Exception as e:\n        logger.warning(f\"XMLParser: XML parsing failed: {e}\")\n\n    for tag in remaining_required:\n        content = XMLParser.extract_content_with_regex_fallback(text, tag)\n        if content:\n            result[tag] = content\n        else:\n            empty_tag_pattern = f\"&lt;{tag}[^&gt;]*&gt;\\\\s*&lt;/{tag}&gt;\"\n            if re.search(empty_tag_pattern, text):\n                raise TagNotFoundError(f\"Required tag &lt;{tag}&gt; found but contains no text content.\")\n            else:\n                raise TagNotFoundError(f\"Required tag &lt;{tag}&gt; not found even with fallback methods\")\n\n    for tag in remaining_optional:\n        content = XMLParser.extract_content_with_regex_fallback(text, tag)\n        if content:\n            result[tag] = content\n\n    if result:\n        result = XMLParser._restore_placeholder_mentions(result, tags_to_process)\n\n    if json_fields and result:\n        result = XMLParser._parse_json_fields(result, json_fields)\n\n    return result\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.XMLParser.parse_unified_xml_format","title":"<code>parse_unified_xml_format(text)</code>  <code>staticmethod</code>","text":"<p>Parse XML content using a unified structure for both tool calls and final answers.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The XML content to parse</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>A dictionary containing parsed data with the following structure: For tool calls: {     \"is_final\": False,     \"thought\": \"extracted thought text\",     \"tools\": [         {\"name\": \"tool name\", \"input\": parsed_json_input},         {\"name\": \"tool name\", \"input\": parsed_json_input},         ...     ] }</p> <p>For final answer: {     \"is_final\": True,     \"thought\": \"extracted thought text\",     \"answer\": \"final answer text\" }</p> <p>Raises:</p> Type Description <code>XMLParsingError</code> <p>If the XML cannot be parsed</p> <code>TagNotFoundError</code> <p>If required tags are missing</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>@staticmethod\ndef parse_unified_xml_format(text: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Parse XML content using a unified structure for both tool calls and final answers.\n\n    Args:\n        text (str): The XML content to parse\n\n    Returns:\n        dict: A dictionary containing parsed data with the following structure:\n            For tool calls:\n            {\n                \"is_final\": False,\n                \"thought\": \"extracted thought text\",\n                \"tools\": [\n                    {\"name\": \"tool name\", \"input\": parsed_json_input},\n                    {\"name\": \"tool name\", \"input\": parsed_json_input},\n                    ...\n                ]\n            }\n\n            For final answer:\n            {\n                \"is_final\": True,\n                \"thought\": \"extracted thought text\",\n                \"answer\": \"final answer text\"\n            }\n\n    Raises:\n        XMLParsingError: If the XML cannot be parsed\n        TagNotFoundError: If required tags are missing\n    \"\"\"\n    try:\n        cleaned_text = XMLParser._clean_content(text)\n        if not cleaned_text:\n            raise XMLParsingError(\"Empty or invalid XML content\")\n\n        try:\n            parsed_data = XMLParser.parse(cleaned_text, required_tags=[\"thought\", \"answer\"], optional_tags=[\"o\"])\n            return {\"is_final\": True, \"thought\": parsed_data.get(\"thought\"), \"answer\": parsed_data.get(\"answer\")}\n        except TagNotFoundError:\n            pass\n\n        root = XMLParser._parse_with_lxml(cleaned_text)\n        if root is None:\n\n            wrapped_text = f\"&lt;root&gt;{cleaned_text}&lt;/root&gt;\"\n            root = XMLParser._parse_with_lxml(wrapped_text)\n\n        if root is None:\n            raise XMLParsingError(\"Failed to parse XML content with lxml\")\n\n        thought_elems = root.xpath(\".//thought\")\n        if not thought_elems:\n            raise TagNotFoundError(\"Required tag &lt;thought&gt; not found\")\n\n        thought = \"\".join(thought_elems[0].itertext()).strip()\n\n        tool_calls_elem = None\n        for tag_name in [\"tool_calls\", \"tools\"]:\n            elems = root.xpath(f\".//{tag_name}\")\n            if elems:\n                tool_calls_elem = elems[0]\n                break\n\n        if tool_calls_elem is None:\n            raise TagNotFoundError(\"Required tag &lt;tool_calls&gt; or &lt;tools&gt; not found\")\n\n        tools = []\n        for tool_elem in tool_calls_elem.xpath(\".//tool\"):\n\n            name_elem = None\n            for name_tag in [\"n\", \"name\", \"tool_name\"]:\n                name_elems = tool_elem.xpath(f\".//{name_tag}\")\n                if name_elems:\n                    name_elem = name_elems[0]\n                    break\n\n            if name_elem is None:\n                continue\n\n            input_elem = None\n            for input_tag in [\"input\", \"tool_input\"]:\n                input_elems = tool_elem.xpath(f\".//{input_tag}\")\n                if input_elems:\n                    input_elem = input_elems[0]\n                    break\n\n            if input_elem is None:\n                continue\n\n            tool_name = \"\".join(name_elem.itertext()).strip()\n            input_json_str = \"\".join(input_elem.itertext()).strip()\n\n            try:\n\n                input_json_str = re.sub(r\"^```(?:json)?\\s*|```$\", \"\", input_json_str.strip())\n                tool_input = json.loads(input_json_str)\n            except json.JSONDecodeError as e:\n                logger.warning(f\"Failed to parse JSON for tool {tool_name}: {e}\")\n                continue\n\n            tools.append({\"name\": tool_name, \"input\": tool_input})\n\n        if not tools:\n            raise TagNotFoundError(\"No valid tool elements found with both name and input tags\")\n\n        return {\"is_final\": False, \"thought\": thought, \"tools\": tools}\n\n    except (XMLParsingError, TagNotFoundError):\n        raise\n    except Exception as e:\n        raise XMLParsingError(f\"Error parsing XML: {str(e)}\")\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.XMLParser.preprocess_xml_content","title":"<code>preprocess_xml_content(text, required_tags=None, optional_tags=None)</code>  <code>staticmethod</code>","text":"<p>Extract raw content for all tags that need special handling before parsing. Filters tags based on required and optional tags if provided.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The XML-like text to preprocess</p> required <code>required_tags</code> <code>Sequence[str]</code> <p>List of tags that must be present</p> <code>None</code> <code>optional_tags</code> <code>Sequence[str]</code> <p>List of tags that may be present</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, tuple[str, str]]</code> <p>dict[str, tuple[str, str]]: Dictionary mapping tag names to (modified_text, raw_content) tuples</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>@staticmethod\ndef preprocess_xml_content(\n    text: str, required_tags: Sequence[str] = None, optional_tags: Sequence[str] = None\n) -&gt; dict[str, tuple[str, str]]:\n    \"\"\"\n    Extract raw content for all tags that need special handling before parsing.\n    Filters tags based on required and optional tags if provided.\n\n    Args:\n        text (str): The XML-like text to preprocess\n        required_tags (Sequence[str], optional): List of tags that must be present\n        optional_tags (Sequence[str], optional): List of tags that may be present\n\n    Returns:\n        dict[str, tuple[str, str]]: Dictionary mapping tag names to (modified_text, raw_content) tuples\n    \"\"\"\n    extracted_contents = {}\n    tags_to_process = set(XMLParser.DEFAULT_PRESERVE_TAGS)\n\n    # Add required and optional tags to the set if provided\n    if required_tags:\n        tags_to_process.update(required_tags)\n    if optional_tags:\n        tags_to_process.update(optional_tags)\n\n    text = XMLParser._escape_unbalanced_reserved_tags(text, tags_to_process)\n\n    for tag in tags_to_process:\n        content = XMLParser.extract_content_with_regex_fallback(text, tag)\n        if content:\n            tag_pattern = f\"&lt;{tag}[^&gt;]*&gt;.*?(?=&lt;(?!/{tag})|$)|&lt;{tag}[^&gt;]*&gt;.*?&lt;/{tag}&gt;\"\n            modified_text = re.sub(tag_pattern, f\"&lt;{tag}&gt;CONTENT_PLACEHOLDER_{tag}&lt;/{tag}&gt;\", text, flags=re.DOTALL)\n            extracted_contents[tag] = (modified_text, content)\n            text = modified_text\n\n    return extracted_contents\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.bytes_to_data_url","title":"<code>bytes_to_data_url(image_bytes)</code>","text":"<p>Convert image bytes to a data URL</p> <p>Parameters:</p> Name Type Description Default <code>image_bytes</code> <code>bytes</code> <p>Raw image bytes</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Data URL string (format: data:image/jpeg;base64,...)</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>def bytes_to_data_url(image_bytes: bytes) -&gt; str:\n    \"\"\"\n    Convert image bytes to a data URL\n\n    Args:\n        image_bytes (bytes): Raw image bytes\n\n    Returns:\n        str: Data URL string (format: data:image/jpeg;base64,...)\n    \"\"\"\n    try:\n        mime_type = filetype.guess_mime(image_bytes)\n        if not mime_type:\n            if image_bytes[:2] == b\"\\xff\\xd8\":\n                mime_type = \"image/jpeg\"\n            elif image_bytes[:8] == b\"\\x89PNG\\r\\n\\x1a\\n\":\n                mime_type = \"image/png\"\n            elif image_bytes[:6] in (b\"GIF87a\", b\"GIF89a\"):\n                mime_type = \"image/gif\"\n            else:\n                mime_type = \"application/octet-stream\"\n\n        encoded = base64.b64encode(image_bytes).decode(\"utf-8\")\n        return f\"data:{mime_type};base64,{encoded}\"\n    except Exception as e:\n        logger.error(f\"Error converting image to data URL: {str(e)}\")\n        raise ValueError(f\"Failed to convert image to data URL: {str(e)}\")\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.convert_bytesio_to_file_info","title":"<code>convert_bytesio_to_file_info(bytesio_obj, key, index=None)</code>","text":"<p>Convert a BytesIO object to a FileInfo object with base64 encoded content.</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>def convert_bytesio_to_file_info(bytesio_obj: io.BytesIO, key: str, index: int = None) -&gt; FileInfo:\n    \"\"\"Convert a BytesIO object to a FileInfo object with base64 encoded content.\"\"\"\n    content_bytes = bytesio_obj.getvalue()\n\n    encoded = base64.b64encode(content_bytes).decode(\"utf-8\")\n\n    name = getattr(bytesio_obj, \"name\", f\"file_{key}\" if index is None else f\"file_{key}_{index}\")\n    content_type = getattr(bytesio_obj, \"content_type\", \"unknown\")\n    description = getattr(bytesio_obj, \"description\", \"\")\n\n    # Create a path based on the name\n    path = f\"/{name}\" if not name.startswith(\"/\") else name\n\n    return FileInfo(\n        content=encoded,\n        path=path,\n        name=name,\n        content_type=content_type,\n        metadata={\"description\": description},\n        size=len(content_bytes),\n    )\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.create_message_from_input","title":"<code>create_message_from_input(input_data)</code>","text":"<p>Create appropriate message type based on input data, automatically detecting and handling images from either images or files fields</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict</code> <p>Input data dictionary containing: - 'input': Text input string - 'images': List of image data (URLs, bytes, or BytesIO objects) - 'files': List of file data (bytes or BytesIO objects)</p> required <p>Returns:</p> Type Description <code>Message | VisionMessage</code> <p>Message or VisionMessage: Appropriate message type for the input</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>def create_message_from_input(input_data: dict) -&gt; Message | VisionMessage:\n    \"\"\"\n    Create appropriate message type based on input data,\n    automatically detecting and handling images from either images or files fields\n\n    Args:\n        input_data (dict): Input data dictionary containing:\n            - 'input': Text input string\n            - 'images': List of image data (URLs, bytes, or BytesIO objects)\n            - 'files': List of file data (bytes or BytesIO objects)\n\n    Returns:\n        Message or VisionMessage: Appropriate message type for the input\n    \"\"\"\n    text_input = input_data.get(\"input\", \"\")\n    images = input_data.get(\"images\", []) or []\n    files = input_data.get(\"files\", []) or []\n\n    if not isinstance(images, list):\n        images = [images]\n    else:\n        images = list(images)\n\n    for file in files:\n        if is_image_file(file):\n            logger.debug(f\"File detected as image, adding to vision processing: {getattr(file, 'name', 'unnamed')}\")\n            images.append(file)\n\n    if not images:\n        return Message(role=MessageRole.USER, content=text_input)\n\n    content = []\n\n    if text_input:\n        content.append(VisionMessageTextContent(text=text_input))\n\n    for image in images:\n        try:\n            if isinstance(image, str):\n                if image.startswith((\"http://\", \"https://\", \"data:\")):\n                    image_url = image\n                else:\n                    with open(image, \"rb\") as file:\n                        image_bytes = file.read()\n                        image_url = bytes_to_data_url(image_bytes)\n            else:\n                if isinstance(image, io.BytesIO):\n                    image_bytes = image.getvalue()\n                else:\n                    image_bytes = image\n                image_url = bytes_to_data_url(image_bytes)\n\n            content.append(VisionMessageImageContent(image_url=VisionMessageImageURL(url=image_url)))\n        except Exception as e:\n            logger.error(f\"Error processing image: {str(e)}\")\n\n    return VisionMessage(content=content, role=MessageRole.USER)\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.extract_thought_from_intermediate_steps","title":"<code>extract_thought_from_intermediate_steps(intermediate_steps)</code>","text":"<p>Extract thought process from the intermediate steps structure.</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>def extract_thought_from_intermediate_steps(intermediate_steps):\n    \"\"\"Extract thought process from the intermediate steps structure.\"\"\"\n    if not intermediate_steps:\n        return None\n\n    for step_key, step_value in intermediate_steps.items():\n        if isinstance(step_value, dict) and \"model_observation\" in step_value:\n            model_obs = step_value[\"model_observation\"]\n\n            if isinstance(model_obs, dict):\n                if \"initial\" in model_obs:\n                    initial = model_obs[\"initial\"]\n\n                    if initial.startswith(\"{\") and '\"thought\"' in initial:\n                        try:\n                            json_data = json.loads(initial)\n                            if \"thought\" in json_data:\n                                return json_data[\"thought\"]\n                        except json.JSONDecodeError:\n                            pass\n\n                    if \"&lt;thought&gt;\" in initial:\n                        thought_match = re.search(r\"&lt;thought&gt;\\s*(.*?)\\s*&lt;/thought&gt;\", initial, re.DOTALL)\n                        if thought_match:\n                            return thought_match.group(1)\n\n                    thought_match = re.search(r\"Thought:\\s*(.*?)(?:\\n\\n|\\nAnswer:)\", initial, re.DOTALL)\n                    if thought_match:\n                        return thought_match.group(1)\n\n    return None\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.is_image_file","title":"<code>is_image_file(file)</code>","text":"<p>Determine if a file is an image by examining its content</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <p>File-like object or bytes</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the file is an image, False otherwise</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>def is_image_file(file) -&gt; bool:\n    \"\"\"\n    Determine if a file is an image by examining its content\n\n    Args:\n        file: File-like object or bytes\n\n    Returns:\n        bool: True if the file is an image, False otherwise\n    \"\"\"\n    try:\n        if isinstance(file, io.BytesIO):\n            pos = file.tell()\n            file.seek(0)\n            file_bytes = file.read(32)\n            file.seek(pos)\n        elif isinstance(file, bytes):\n            file_bytes = file[:32]\n        else:\n            return False\n\n        signatures = {\n            b\"\\xff\\xd8\\xff\": \"jpg/jpeg\",  # JPEG\n            b\"\\x89PNG\\r\\n\\x1a\\n\": \"png\",  # PNG\n            b\"GIF87a\": \"gif\",  # GIF87a\n            b\"GIF89a\": \"gif\",  # GIF89a\n            b\"RIFF\": \"webp\",  # WebP\n            b\"MM\\x00*\": \"tiff\",  # TIFF (big endian)\n            b\"II*\\x00\": \"tiff\",  # TIFF (little endian)\n            b\"BM\": \"bmp\",  # BMP\n        }\n\n        for sig, fmt in signatures.items():\n            if file_bytes.startswith(sig):\n                return True\n\n        if isinstance(file, io.BytesIO):\n            pos = file.tell()\n            file.seek(0)\n            mime = filetype.guess_mime(file.read(4096))\n            file.seek(pos)\n            return mime is not None and mime.startswith(\"image/\")\n        elif isinstance(file, bytes):\n            mime = filetype.guess_mime(file)\n            return mime is not None and mime.startswith(\"image/\")\n\n        return False\n    except Exception as e:\n        logger.error(f\"Error checking if file is an image: {str(e)}\")\n        return False\n</code></pre>"},{"location":"dynamiq/nodes/agents/utils/#dynamiq.nodes.agents.utils.process_tool_output_for_agent","title":"<code>process_tool_output_for_agent(content, max_tokens=TOOL_MAX_TOKENS, truncate=True)</code>","text":"<p>Process tool output for agent consumption.</p> <p>This function converts various types of tool outputs into a string representation. It handles dictionaries (with or without a 'content' key), lists, tuples, and other types by converting them to a string. If the resulting string exceeds the maximum allowed length, it truncates the content.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>Any</code> <p>The output from tool execution, which can be of various types.</p> required <code>max_tokens</code> <code>int</code> <p>Maximum allowed token count for the content. The effective character limit is computed as max_tokens * CHARS_PER_TOKEN (assuming ~4 characters per token).</p> <code>TOOL_MAX_TOKENS</code> <code>truncate</code> <code>bool</code> <p>Whether to truncate the content if it exceeds the maximum length.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A processed string suitable for agent consumption.</p> Source code in <code>dynamiq/nodes/agents/utils.py</code> <pre><code>def process_tool_output_for_agent(content: Any, max_tokens: int = TOOL_MAX_TOKENS, truncate: bool = True) -&gt; str:\n    \"\"\"\n    Process tool output for agent consumption.\n\n    This function converts various types of tool outputs into a string representation.\n    It handles dictionaries (with or without a 'content' key), lists, tuples, and other\n    types by converting them to a string. If the resulting string exceeds the maximum\n    allowed length, it truncates the content.\n\n    Args:\n        content: The output from tool execution, which can be of various types.\n        max_tokens: Maximum allowed token count for the content. The effective character\n            limit is computed as max_tokens * CHARS_PER_TOKEN (assuming ~4 characters per token).\n        truncate: Whether to truncate the content if it exceeds the maximum length.\n\n    Returns:\n        A processed string suitable for agent consumption.\n    \"\"\"\n    if not isinstance(content, str):\n        if isinstance(content, dict):\n            filtered_content = {k: v for k, v in content.items() if k != \"files\"}\n\n            if \"content\" in filtered_content:\n                inner_content = filtered_content[\"content\"]\n                content = inner_content if isinstance(inner_content, str) else json.dumps(inner_content, indent=2)\n            else:\n                content = json.dumps(filtered_content, indent=2) if filtered_content else \"\"\n        elif isinstance(content, (list, tuple)):\n            content = \"\\n\".join(str(item) for item in content)\n        else:\n            content = str(content)\n\n    max_len_in_char: int = max_tokens * CHARS_PER_TOKEN\n    content = re.sub(r\"\\{\\{\\s*(.*?)\\s*\\}\\}\", r\"\\1\", content)\n\n    if len(content) &gt; max_len_in_char and truncate:\n        half_length: int = (max_len_in_char - 100) // 2\n        truncation_message: str = \"\\n...[Content truncated]...\\n\"\n        content = content[:half_length] + truncation_message + content[-half_length:]\n\n    return content\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/","title":"Adaptive","text":""},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AdaptiveOrchestrator","title":"<code>AdaptiveOrchestrator</code>","text":"<p>               Bases: <code>Orchestrator</code></p> <p>Orchestrates the execution of complex tasks using multiple specialized agents.</p> <p>This class manages the breakdown of a main objective into subtasks, delegates these subtasks to appropriate agents, and synthesizes the results into a final answer.</p> <p>Attributes:</p> Name Type Description <code>manager</code> <code>ManagerAgent</code> <p>The managing agent responsible for overseeing the orchestration process.</p> <code>agents</code> <code>List[Agent]</code> <p>List of specialized agents available for task execution.</p> <code>objective</code> <code>Optional[str]</code> <p>The main objective of the orchestration.</p> <code>max_loops</code> <code>Optional[int]</code> <p>Maximum number of actions.</p> <code>reflection_enabled</code> <code>Optional[bool]</code> <p>Enable reflection mode</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive.py</code> <pre><code>class AdaptiveOrchestrator(Orchestrator):\n    \"\"\"\n    Orchestrates the execution of complex tasks using multiple specialized agents.\n\n    This class manages the breakdown of a main objective into subtasks,\n    delegates these subtasks to appropriate agents, and synthesizes the results\n    into a final answer.\n\n    Attributes:\n        manager (ManagerAgent): The managing agent responsible for overseeing the orchestration process.\n        agents (List[BaseAgent]): List of specialized agents available for task execution.\n        objective (Optional[str]): The main objective of the orchestration.\n        max_loops (Optional[int]): Maximum number of actions.\n        reflection_enabled (Optional[bool]): Enable reflection mode\n    \"\"\"\n\n    name: str | None = \"AdaptiveOrchestrator\"\n    group: NodeGroup = NodeGroup.AGENTS\n    manager: AdaptiveAgentManager\n    agents: list[Agent] = []\n    max_loops: int = 15\n    reflection_enabled: bool = False\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"manager\": True, \"agents\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"manager\"] = self.manager.to_dict(**kwargs)\n        data[\"agents\"] = [agent.to_dict(**kwargs) for agent in self.agents]\n        return data\n\n    def reset_run_state(self):\n        self._chat_history = []\n        self._run_depends = []\n\n    def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n        \"\"\"\n        Initialize components of the orchestrator.\n\n        Args:\n            connection_manager (ConnectionManager | None): The connection manager. Defaults to None.\n        \"\"\"\n        super().init_components(connection_manager)\n        if self.manager.is_postponed_component_init:\n            self.manager.init_components(connection_manager)\n\n        for agent in self.agents:\n            if agent.is_postponed_component_init:\n                agent.init_components(connection_manager)\n\n    @property\n    def agents_descriptions(self) -&gt; str:\n        \"\"\"Get a formatted string of agent descriptions.\"\"\"\n        return \"\\n\".join([f\"{i}. {agent.name}\" for i, agent in enumerate(self.agents)]) if self.agents else \"\"\n\n    def _handle_next_action(self, content: str, config: RunnableConfig | None = None, **kwargs) -&gt; Action:\n        \"\"\"\n        Parse XML content to extract action details. Streams action if streaming is enabled.\n\n        Args:\n            content (str): XML formatted content from LLM response\n\n        Returns:\n            Action: Parsed action object\n        \"\"\"\n        action = self._parse_xml_content(content)\n        if self.manager.streaming.enabled and self.streaming.mode == StreamingMode.ALL:\n            self.manager.stream_content(\n                content={\"next_action\": action},\n                step=\"manager_planning\",\n                source=self.name,\n                config=config,\n                **kwargs,\n            )\n        return action\n\n    def get_next_action(self, config: RunnableConfig = None, **kwargs) -&gt; Action:\n        \"\"\"\n        Determine the next action based on the current state and LLM output.\n\n        Returns:\n            Action: The next action to be taken.\n\n        Raises:\n            ActionParseError: If there is an error parsing the action from the LLM response.\n        \"\"\"\n\n        manager_result = self.manager.run(\n            input_data={\n                \"action\": \"plan\",\n                \"agents\": self.agents_descriptions,\n                \"chat_history\": format_chat_history(self._chat_history),\n            },\n            config=config,\n            run_depends=self._run_depends,\n            **kwargs,\n        )\n        self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n        if manager_result.status != RunnableStatus.SUCCESS:\n            error_message = f\"Agent '{self.manager.name}' failed: {manager_result.error.message}\"\n            raise ActionParseError(f\"Unable to retrieve the next action from Agent Manager, Error: {error_message}\")\n\n        manager_content = manager_result.output.get(\"content\").get(\"result\")\n\n        if self.reflection_enabled:\n            reflect_result = self.manager.run(\n                input_data={\n                    \"action\": \"reflect\",\n                    \"agents\": self.agents_descriptions,\n                    \"chat_history\": format_chat_history(self._chat_history),\n                    \"plan\": manager_content,\n                    \"agent_output\": \"\",\n                },\n                config=config,\n                run_depends=self._run_depends,\n                **kwargs,\n            )\n            self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n            if reflect_result.status != RunnableStatus.SUCCESS:\n                error_message = f\"Agent '{self.manager.name}' failed on reflection: {reflect_result.error.message}\"\n                logger.error(error_message)\n                return self._handle_next_action(manager_content, config=config, **kwargs)\n            else:\n                reflect_content = reflect_result.output.get(\"content\").get(\"result\")\n                try:\n                    return self._handle_next_action(reflect_content, config=config, **kwargs)\n                except ActionParseError as e:\n                    logger.error(f\"Agent '{self.manager.name}' failed on reflection parsing: {str(e)}\")\n                    return self._handle_next_action(manager_content, config=config, **kwargs)\n\n        return self._handle_next_action(manager_content, config=config, **kwargs)\n\n    def run_flow(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Process the given task using the manager agent logic.\n\n        Args:\n            input_task (str): The task to be processed.\n            config (RunnableConfig): Configuration for the runnable.\n\n        Returns:\n            dict[str, Any]: The final output generated after processing the task.\n        \"\"\"\n\n        analysis = self._analyze_user_input(input_task, self.agents_descriptions, config=config, **kwargs)\n        decision = analysis.decision\n        message = analysis.message\n\n        if decision == Decision.RESPOND:\n            return {\"content\": message}\n        else:\n            self._chat_history.append({\"role\": \"user\", \"content\": input_task})\n\n            for i in range(self.max_loops):\n                action = self.get_next_action(config=config, **kwargs)\n                logger.info(f\"Orchestrator {self.name} - {self.id}: Loop {i + 1} - Action: {action.dict()}\")\n                if action.command == ActionCommand.DELEGATE:\n                    self._handle_delegation(action=action, config=config, **kwargs)\n\n                elif action.command == ActionCommand.RESPOND:\n                    respond_result = self._handle_respond(action=action)\n                    respond_final_result = self.parse_xml_final_answer(respond_result)\n                    return {\"content\": respond_final_result}\n\n                elif action.command == ActionCommand.FINAL_ANSWER:\n                    manager_final_result = self.get_final_result(\n                        {\n                            \"input_task\": input_task,\n                            \"chat_history\": format_chat_history(self._chat_history),\n                            \"preliminary_answer\": action.answer,\n                        },\n                        config=config,\n                        **kwargs,\n                    )\n                    final_result = self.parse_xml_final_answer(manager_final_result)\n                    return {\"content\": final_result}\n\n    def _handle_delegation(self, action: Action, config: RunnableConfig = None, **kwargs) -&gt; None:\n        \"\"\"\n        Handle task delegation to a specialized agent.\n\n        Args:\n            action (Action): The action containing the delegation command and details.\n        \"\"\"\n        agent = next((a for a in self.agents if a.name == action.agent), None)\n        if agent:\n            result = agent.run(\n                input_data={\"input\": action.task},\n                config=config,\n                run_depends=self._run_depends,\n                **kwargs,\n            )\n            self._run_depends = [NodeDependency(node=agent).to_dict(for_tracing=True)]\n            if result.status != RunnableStatus.SUCCESS:\n                error_message = f\"Agent '{agent.name}' failed: {result.error.message}\"\n                raise OrchestratorError(f\"Failed to execute Agent {agent.name}, due to error: {error_message}\")\n\n            self._chat_history.append(\n                {\n                    \"role\": \"system\",\n                    \"content\": f\"Agent {action.agent} result: {result.output.get('content')}\",\n                }\n            )\n        else:\n            result = self.manager.run(\n                input_data={\n                    \"action\": \"respond\",\n                    \"task\": action.task,\n                    \"agents\": self.agents_descriptions,\n                    \"chat_history\": format_chat_history(self._chat_history),\n                },\n                config=config,\n                run_depends=self._run_depends,\n                **kwargs,\n            )\n            self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n            if result.status != RunnableStatus.SUCCESS:\n                content = result.error.message\n                logger.error(\n                    f\"Orchestrator {self.name} - {self.id}: \" f\"Error executing {self.manager.name}:\" f\"{content}\"\n                )\n            else:\n                content = result.output.get(\"content\")\n\n            self._chat_history.append(\n                {\n                    \"role\": \"system\",\n                    \"content\": f\"LLM result: {content}\",\n                }\n            )\n\n    def _handle_respond(self, action: Action, config: RunnableConfig = None, **kwargs) -&gt; str:\n        \"\"\"\n        Handle a direct response from the Manager.\n\n        Args:\n            action (Action): The action to handle.\n            config (RunnableConfig | None): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            str: The manager's response content.\n\n        Raises:\n            OrchestratorError: If the manager fails to execute the respond action.\n        \"\"\"\n        manager_result = self.manager.run(\n            input_data={\n                \"action\": \"respond\",\n                \"task\": action.task,\n                \"agents\": self.agents_descriptions,\n                \"chat_history\": format_chat_history(self._chat_history),\n            },\n            config=config,\n            run_depends=self._run_depends,\n            **kwargs,\n        )\n        self._run_depends = [NodeDependency(node=self.manager).to_dict()]\n\n        if manager_result.status != RunnableStatus.SUCCESS:\n            error_message = f\"Manager agent '{self.manager.name}' failed: {manager_result.error.message}\"\n            raise OrchestratorError(f\"Failed to execute respond action with manager, due to error: {error_message}\")\n\n        manager_result_content = manager_result.output.get(\"content\").get(\"result\")\n\n        self._chat_history.append(\n            {\n                \"role\": \"system\",\n                \"content\": f\"[Manager agent '{self.manager.name} - quick response]: {manager_result_content}\",\n            }\n        )\n        return manager_result_content\n\n    def setup_streaming(self) -&gt; None:\n        \"\"\"Setups streaming for orchestrator.\"\"\"\n        self.manager.streaming = self.streaming\n        for agent in self.agents:\n            agent.streaming = self.streaming\n\n    def _parse_xml_content(self, content: str) -&gt; Action:\n        \"\"\"\n        Parse XML content to extract action details.\n\n        Args:\n            content (str): XML formatted content from LLM response\n\n        Returns:\n            Action: Parsed action object\n\n        Raises:\n            ActionParseError: If XML parsing fails or required tags are missing\n        \"\"\"\n\n        if \"&lt;action&gt;\" not in content.lower():\n            logger.info(\"No &lt;action&gt; tag found in content, applying fallback wrapping for XML parsing.\")\n            content = f\"&lt;root&gt;&lt;action&gt;respond&lt;/action&gt;&lt;task&gt;{content.strip()}&lt;/task&gt;&lt;/root&gt;\"\n        try:\n            root = self._clean_content(content=content)\n        except Exception as e:\n            error_message = f\"XML parsing error: {str(e)} in content: {content}\"\n            logger.error(error_message)\n            raise ActionParseError(error_message)\n\n        try:\n            action_elem = root.find(\".//action\")\n            if action_elem is None or not action_elem.text:\n                error_message = (\n                    f\"Orchestrator {self.name} - {self.id}: XML parsing error: No &lt;action&gt; tag found in the response\"\n                )\n                raise ActionParseError(error_message)\n\n            action_type = action_elem.text.strip().lower()\n\n            if action_type == \"delegate\":\n                agent_elem = root.find(\".//agent\")\n                task_elem = root.find(\".//task\")\n                task_data_elem = root.find(\".//task_data\")\n\n                if agent_elem is None or task_elem is None:\n                    error_message = (\n                        f\"Orchestrator {self.name} - {self.id}: XML parsing error: \"\n                        f\"Delegate action missing required &lt;agent&gt; or &lt;task&gt; tags\"\n                    )\n                    raise ActionParseError(error_message)\n\n                return Action(\n                    command=ActionCommand.DELEGATE,\n                    agent=agent_elem.text.strip(),\n                    task=task_elem.text.strip()\n                    + (f\" {task_data_elem.text.strip()}\" if task_data_elem is not None and task_data_elem.text else \"\"),\n                )\n\n            elif action_type == \"final_answer\":\n                answer_elem = root.find(\".//final_answer\")\n                if answer_elem is None or not answer_elem.text:\n                    error_message = (\n                        f\"Orchestrator {self.name} - {self.id}: XML parsing error: \"\n                        f\"Final answer action missing &lt;final_answer&gt; tag\"\n                    )\n                    raise ActionParseError(error_message)\n                return Action(command=ActionCommand.FINAL_ANSWER, answer=answer_elem.text.strip())\n\n            elif action_type == \"respond\":\n                task_elem = root.find(\".//task\")\n                if task_elem is None or not task_elem.text:\n                    error_message = (\n                        f\"Orchestrator {self.name} - {self.id}: XML parsing error: Respond action missing &lt;task&gt; tag\"\n                    )\n                    raise ActionParseError(error_message)\n                return Action(\n                    command=ActionCommand.RESPOND,\n                    task=task_elem.text.strip(),\n                )\n            else:\n                raise ActionParseError(f\"Unknown action type: {action_type}\")\n\n        except LET.ParseError as e:\n            error_message = f\"Orchestrator {self.name} - {self.id}: XML parsing error: {str(e)}\"\n            raise ActionParseError(error_message)\n        except Exception as e:\n            error_message = f\"Orchestrator {self.name} - {self.id}: Error parsing action: {str(e)}\"\n            raise ActionParseError(error_message)\n\n    def parse_xml_final_answer(self, content: str) -&gt; str:\n        \"\"\"\n        Parses XML content to extract the final answer from either 'output' or 'final_answer' tags.\n\n        This method attempts to extract content using XML parsing first, and if that fails,\n        falls back to regex pattern matching. If both methods fail, it returns the original content.\n\n        Args:\n            content (str): The XML-formatted string containing the answer.\n\n        Returns:\n            str: The extracted answer from either the 'output' or 'final_answer' tags.\n                If parsing fails, returns the original content.\n\n        Raises:\n            ActionParseError: When XML parsing fails and neither 'output' nor 'final_answer' tags\n                contain valid content.\n        \"\"\"\n        try:\n            root = self._clean_content(content=content)\n            for tag in [\"output\", \"final_answer\"]:\n                elem = root.find(f\".//{tag}\")\n                if elem is not None and elem.text and elem.text.strip():\n                    return elem.text.strip()\n            error_message = (\n                f\"Error parsing final answer: {str(content)[:100]}...\"\n                f\" Neither &lt;output&gt; nor &lt;final_answer&gt; tag found with valid content.\"\n            )\n            raise ActionParseError(error_message)\n        except Exception as e:\n            logger.info(\"Error parsing final answer using XML: %s. Falling back to regex extraction.\", e)\n            for tag in [\"output\", \"final_answer\"]:\n                pattern = rf\"&lt;{tag}&gt;(.*?)&lt;/{tag}&gt;\"\n                match = re.search(pattern, content, re.DOTALL)\n                if match:\n                    extracted = match.group(1).strip()\n                    if extracted:\n                        return extracted\n            logger.info(\"Regex extraction failed. Returning original content as fallback.\")\n            return content\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AdaptiveOrchestrator.agents_descriptions","title":"<code>agents_descriptions: str</code>  <code>property</code>","text":"<p>Get a formatted string of agent descriptions.</p>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AdaptiveOrchestrator.get_next_action","title":"<code>get_next_action(config=None, **kwargs)</code>","text":"<p>Determine the next action based on the current state and LLM output.</p> <p>Returns:</p> Name Type Description <code>Action</code> <code>Action</code> <p>The next action to be taken.</p> <p>Raises:</p> Type Description <code>ActionParseError</code> <p>If there is an error parsing the action from the LLM response.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive.py</code> <pre><code>def get_next_action(self, config: RunnableConfig = None, **kwargs) -&gt; Action:\n    \"\"\"\n    Determine the next action based on the current state and LLM output.\n\n    Returns:\n        Action: The next action to be taken.\n\n    Raises:\n        ActionParseError: If there is an error parsing the action from the LLM response.\n    \"\"\"\n\n    manager_result = self.manager.run(\n        input_data={\n            \"action\": \"plan\",\n            \"agents\": self.agents_descriptions,\n            \"chat_history\": format_chat_history(self._chat_history),\n        },\n        config=config,\n        run_depends=self._run_depends,\n        **kwargs,\n    )\n    self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n    if manager_result.status != RunnableStatus.SUCCESS:\n        error_message = f\"Agent '{self.manager.name}' failed: {manager_result.error.message}\"\n        raise ActionParseError(f\"Unable to retrieve the next action from Agent Manager, Error: {error_message}\")\n\n    manager_content = manager_result.output.get(\"content\").get(\"result\")\n\n    if self.reflection_enabled:\n        reflect_result = self.manager.run(\n            input_data={\n                \"action\": \"reflect\",\n                \"agents\": self.agents_descriptions,\n                \"chat_history\": format_chat_history(self._chat_history),\n                \"plan\": manager_content,\n                \"agent_output\": \"\",\n            },\n            config=config,\n            run_depends=self._run_depends,\n            **kwargs,\n        )\n        self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n        if reflect_result.status != RunnableStatus.SUCCESS:\n            error_message = f\"Agent '{self.manager.name}' failed on reflection: {reflect_result.error.message}\"\n            logger.error(error_message)\n            return self._handle_next_action(manager_content, config=config, **kwargs)\n        else:\n            reflect_content = reflect_result.output.get(\"content\").get(\"result\")\n            try:\n                return self._handle_next_action(reflect_content, config=config, **kwargs)\n            except ActionParseError as e:\n                logger.error(f\"Agent '{self.manager.name}' failed on reflection parsing: {str(e)}\")\n                return self._handle_next_action(manager_content, config=config, **kwargs)\n\n    return self._handle_next_action(manager_content, config=config, **kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AdaptiveOrchestrator.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize components of the orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager | None</code> <p>The connection manager. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n    \"\"\"\n    Initialize components of the orchestrator.\n\n    Args:\n        connection_manager (ConnectionManager | None): The connection manager. Defaults to None.\n    \"\"\"\n    super().init_components(connection_manager)\n    if self.manager.is_postponed_component_init:\n        self.manager.init_components(connection_manager)\n\n    for agent in self.agents:\n        if agent.is_postponed_component_init:\n            agent.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AdaptiveOrchestrator.parse_xml_final_answer","title":"<code>parse_xml_final_answer(content)</code>","text":"<p>Parses XML content to extract the final answer from either 'output' or 'final_answer' tags.</p> <p>This method attempts to extract content using XML parsing first, and if that fails, falls back to regex pattern matching. If both methods fail, it returns the original content.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The XML-formatted string containing the answer.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The extracted answer from either the 'output' or 'final_answer' tags. If parsing fails, returns the original content.</p> <p>Raises:</p> Type Description <code>ActionParseError</code> <p>When XML parsing fails and neither 'output' nor 'final_answer' tags contain valid content.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive.py</code> <pre><code>def parse_xml_final_answer(self, content: str) -&gt; str:\n    \"\"\"\n    Parses XML content to extract the final answer from either 'output' or 'final_answer' tags.\n\n    This method attempts to extract content using XML parsing first, and if that fails,\n    falls back to regex pattern matching. If both methods fail, it returns the original content.\n\n    Args:\n        content (str): The XML-formatted string containing the answer.\n\n    Returns:\n        str: The extracted answer from either the 'output' or 'final_answer' tags.\n            If parsing fails, returns the original content.\n\n    Raises:\n        ActionParseError: When XML parsing fails and neither 'output' nor 'final_answer' tags\n            contain valid content.\n    \"\"\"\n    try:\n        root = self._clean_content(content=content)\n        for tag in [\"output\", \"final_answer\"]:\n            elem = root.find(f\".//{tag}\")\n            if elem is not None and elem.text and elem.text.strip():\n                return elem.text.strip()\n        error_message = (\n            f\"Error parsing final answer: {str(content)[:100]}...\"\n            f\" Neither &lt;output&gt; nor &lt;final_answer&gt; tag found with valid content.\"\n        )\n        raise ActionParseError(error_message)\n    except Exception as e:\n        logger.info(\"Error parsing final answer using XML: %s. Falling back to regex extraction.\", e)\n        for tag in [\"output\", \"final_answer\"]:\n            pattern = rf\"&lt;{tag}&gt;(.*?)&lt;/{tag}&gt;\"\n            match = re.search(pattern, content, re.DOTALL)\n            if match:\n                extracted = match.group(1).strip()\n                if extracted:\n                    return extracted\n        logger.info(\"Regex extraction failed. Returning original content as fallback.\")\n        return content\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AdaptiveOrchestrator.run_flow","title":"<code>run_flow(input_task, config=None, **kwargs)</code>","text":"<p>Process the given task using the manager agent logic.</p> <p>Parameters:</p> Name Type Description Default <code>input_task</code> <code>str</code> <p>The task to be processed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: The final output generated after processing the task.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive.py</code> <pre><code>def run_flow(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Process the given task using the manager agent logic.\n\n    Args:\n        input_task (str): The task to be processed.\n        config (RunnableConfig): Configuration for the runnable.\n\n    Returns:\n        dict[str, Any]: The final output generated after processing the task.\n    \"\"\"\n\n    analysis = self._analyze_user_input(input_task, self.agents_descriptions, config=config, **kwargs)\n    decision = analysis.decision\n    message = analysis.message\n\n    if decision == Decision.RESPOND:\n        return {\"content\": message}\n    else:\n        self._chat_history.append({\"role\": \"user\", \"content\": input_task})\n\n        for i in range(self.max_loops):\n            action = self.get_next_action(config=config, **kwargs)\n            logger.info(f\"Orchestrator {self.name} - {self.id}: Loop {i + 1} - Action: {action.dict()}\")\n            if action.command == ActionCommand.DELEGATE:\n                self._handle_delegation(action=action, config=config, **kwargs)\n\n            elif action.command == ActionCommand.RESPOND:\n                respond_result = self._handle_respond(action=action)\n                respond_final_result = self.parse_xml_final_answer(respond_result)\n                return {\"content\": respond_final_result}\n\n            elif action.command == ActionCommand.FINAL_ANSWER:\n                manager_final_result = self.get_final_result(\n                    {\n                        \"input_task\": input_task,\n                        \"chat_history\": format_chat_history(self._chat_history),\n                        \"preliminary_answer\": action.answer,\n                    },\n                    config=config,\n                    **kwargs,\n                )\n                final_result = self.parse_xml_final_answer(manager_final_result)\n                return {\"content\": final_result}\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AdaptiveOrchestrator.setup_streaming","title":"<code>setup_streaming()</code>","text":"<p>Setups streaming for orchestrator.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive.py</code> <pre><code>def setup_streaming(self) -&gt; None:\n    \"\"\"Setups streaming for orchestrator.\"\"\"\n    self.manager.streaming = self.streaming\n    for agent in self.agents:\n        agent.streaming = self.streaming\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AdaptiveOrchestrator.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"manager\"] = self.manager.to_dict(**kwargs)\n    data[\"agents\"] = [agent.to_dict(**kwargs) for agent in self.agents]\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive/#dynamiq.nodes.agents.orchestrators.adaptive.AgentNotFoundError","title":"<code>AgentNotFoundError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Raised when a specified agent is not found.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive.py</code> <pre><code>class AgentNotFoundError(OrchestratorError):\n    \"\"\"Raised when a specified agent is not found.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive_manager/","title":"Adaptive manager","text":""},{"location":"dynamiq/nodes/agents/orchestrators/adaptive_manager/#dynamiq.nodes.agents.orchestrators.adaptive_manager.AdaptiveAgentManager","title":"<code>AdaptiveAgentManager</code>","text":"<p>               Bases: <code>AgentManager</code></p> <p>An adaptive agent manager that coordinates specialized agents to complete complex tasks.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive_manager.py</code> <pre><code>class AdaptiveAgentManager(AgentManager):\n    \"\"\"An adaptive agent manager that coordinates specialized agents to complete complex tasks.\"\"\"\n\n    name: str = \"Adaptive Manager\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the AdaptiveAgentManager and set up prompt templates.\"\"\"\n        super().__init__(**kwargs)\n        self._init_prompt_blocks()\n\n    def _init_actions(self):\n        \"\"\"Extend the default actions with 'respond'.\"\"\"\n        super()._init_actions()  #\n        self._actions[\"respond\"] = self._respond\n        self._actions[\"reflect\"] = self._reflect\n\n    def _init_prompt_blocks(self):\n        \"\"\"Initialize the prompt blocks with adaptive plan and final prompts.\"\"\"\n        super()._init_prompt_blocks()\n        self._prompt_blocks.update(\n            {\n                \"plan\": self._get_adaptive_plan_prompt(),\n                \"final\": self._get_adaptive_final_prompt(),\n                \"respond\": self._get_adaptive_respond_prompt(),\n                \"reflect\": self._get_adaptive_reflect_prompt(),\n                \"handle_input\": self._get_adaptive_handle_input_prompt(),\n            }\n        )\n\n    @staticmethod\n    def _get_adaptive_plan_prompt() -&gt; str:\n        \"\"\"Return the adaptive plan prompt template.\"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_PLAN\n\n    @staticmethod\n    def _get_adaptive_handle_input_prompt() -&gt; str:\n        \"\"\"Determines how to handle input, either by continuing the flow or providing a direct response.\"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_HANDLE_INPUT\n\n    @staticmethod\n    def _get_adaptive_final_prompt() -&gt; str:\n        \"\"\"Return the adaptive final answer prompt template.\"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_FINAL_ANSWER\n\n    @staticmethod\n    def _get_adaptive_respond_prompt() -&gt; str:\n        \"\"\"Return the adaptive clarify prompt template.\"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_RESPOND\n\n    @staticmethod\n    def _get_adaptive_reflect_prompt() -&gt; str:\n        \"\"\"Return the adaptive reflect prompt template.\"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_REFLECT\n\n    def _reflect(self, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"Executes the 'reflect' action.\"\"\"\n        prompt = Template(self._prompt_blocks.get(\"reflect\")).render(**(self._prompt_variables | kwargs))\n        llm_result = self._run_llm([Message(role=MessageRole.USER, content=prompt)], config, **kwargs).output[\"content\"]\n        if self.streaming.enabled and self.streaming.mode == StreamingMode.ALL:\n            return self.stream_content(\n                content=llm_result,\n                step=\"manager_reflection\",\n                source=self.name,\n                config=config,\n                **kwargs\n            )\n        return llm_result\n\n    def _respond(self, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"Executes the 'respond' action.\"\"\"\n        prompt = Template(self._prompt_blocks.get(\"respond\")).render(**(self._prompt_variables | kwargs))\n        llm_result = self._run_llm([Message(role=MessageRole.USER, content=prompt)], config, **kwargs).output[\"content\"]\n        if self.streaming.enabled and self.streaming.mode == StreamingMode.ALL:\n            return self.stream_content(\n                content=llm_result, step=\"manager_response\", source=self.name, config=config, **kwargs\n            )\n        return llm_result\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/adaptive_manager/#dynamiq.nodes.agents.orchestrators.adaptive_manager.AdaptiveAgentManager.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the AdaptiveAgentManager and set up prompt templates.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/adaptive_manager.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the AdaptiveAgentManager and set up prompt templates.\"\"\"\n    super().__init__(**kwargs)\n    self._init_prompt_blocks()\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/","title":"Graph","text":""},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator","title":"<code>GraphOrchestrator</code>","text":"<p>               Bases: <code>Orchestrator</code></p> <p>Orchestrates the execution of complex tasks, interconnected within the graph structure.</p> <p>This class manages the execution by following structure of directed graph. When finished synthesizes the results into a final answer.</p> <p>Attributes:</p> Name Type Description <code>manager</code> <code>ManagerAgent</code> <p>The managing agent responsible for overseeing the orchestration process.</p> <code>context</code> <code>Dict[str, Any]</code> <p>Context of the orchestrator.</p> <code>states</code> <code>List[GraphState]</code> <p>List of states within orchestrator.</p> <code>initial_state</code> <code>str</code> <p>State to start from.</p> <code>objective</code> <code>Optional[str]</code> <p>The main objective of the orchestration.</p> <code>max_loops</code> <code>Optional[int]</code> <p>Maximum number of transition between states.</p> <code>input_analysis_enabled</code> <code>bool</code> <p>Enables initial input analysis.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>class GraphOrchestrator(Orchestrator):\n    \"\"\"\n    Orchestrates the execution of complex tasks, interconnected within the graph structure.\n\n    This class manages the execution by following structure of directed graph. When finished synthesizes the results\n    into a final answer.\n\n    Attributes:\n        manager (ManagerAgent): The managing agent responsible for overseeing the orchestration process.\n        context (Dict[str, Any]): Context of the orchestrator.\n        states (List[GraphState]): List of states within orchestrator.\n        initial_state (str): State to start from.\n        objective (Optional[str]): The main objective of the orchestration.\n        max_loops (Optional[int]): Maximum number of transition between states.\n        input_analysis_enabled (bool): Enables initial input analysis.\n    \"\"\"\n\n    name: str | None = \"GraphOrchestrator\"\n    manager: GraphAgentManager\n    initial_state: str = START\n    context: dict[str, Any] = {}\n    states: list[GraphState] = []\n    max_loops: int = 15\n    input_analysis_enabled: bool = False\n\n    def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n        \"\"\"\n        Initialize components of the orchestrator.\n\n        Args:\n            connection_manager (Optional[ConnectionManager]): The connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        super().init_components(connection_manager)\n\n        if self.manager.is_postponed_component_init:\n            self.manager.init_components(connection_manager)\n\n        for state in self.states:\n            if state.is_postponed_component_init:\n                state.init_components(connection_manager)\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._state_by_id = {state.id: state for state in self.states}\n\n        if START not in self._state_by_id:\n            start_state = GraphState(id=START, description=\"Initial state\")\n            self._state_by_id[START] = start_state\n            self.states.append(start_state)\n\n        if END not in self._state_by_id:\n            end_state = GraphState(id=END, description=\"Final state\")\n            self._state_by_id[END] = end_state\n            self.states.append(end_state)\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"manager\": True, \"states\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"manager\"] = self.manager.to_dict(**kwargs)\n        data[\"states\"] = [state.to_dict(**kwargs) for state in self.states]\n        return data\n\n    def add_state_by_tasks(\n        self, state_id: str, tasks: list[Node | Callable], callbacks: list[NodeCallbackHandler] = []\n    ) -&gt; None:\n        \"\"\"\n        Adds state to the graph based on tasks.\n\n        Args:\n            state_id (str): Id of the state.\n            tasks (list[Node | Callable]): List of tasks that have to be executed when running this state.\n            callbacks: list[NodeCallbackHandler]: List of callbacks.\n        Raises:\n            ValueError: If state with specified id already exists.\n        \"\"\"\n        if state_id in self._state_by_id:\n            raise ValueError(f\"Error: State with id {state_id} already exists.\")\n\n        filtered_tasks = []\n\n        has_agent = False\n        for task in tasks:\n            if isinstance(task, Node):\n                if isinstance(task, Agent):\n                    has_agent = True\n                filtered_tasks.append(task)\n            elif isinstance(task, Callable):\n                filtered_tasks.append(function_tool(task)())\n            else:\n                raise OrchestratorError(\"Error: Task must be either a Node or a Callable.\")\n\n        state = GraphState(\n            id=state_id,\n            name=state_id,\n            manager=self.manager if has_agent else None,\n            tasks=filtered_tasks,\n            callbacks=callbacks,\n        )\n        self.states.append(state)\n        self._state_by_id[state.id] = state\n\n    def add_state(self, state: GraphState) -&gt; None:\n        \"\"\"\n        Adds state to the graph.\n\n        Args:\n            state (State): State to add to the graph.\n\n        Raises:\n            ValueError: If state with specified id already exists.\n        \"\"\"\n        if state.id in self._state_by_id:\n            raise ValueError(f\"Error: State with id {state.id} already exists.\")\n\n        self.states.append(state)\n        self._state_by_id[state.id] = state\n\n    def add_edge(self, source_id: str, destination_id: str) -&gt; None:\n        \"\"\"\n        Adds edge to the graph. When source state finishes execution, destination state will be executed next.\n\n        Args:\n            source_id (str): Id of source state.\n            destination_id (str): Id of destination state.\n\n        Raises:\n            ValueError: If state with specified id does not exist.\n        \"\"\"\n        self.validate_states([source_id, destination_id])\n        self._state_by_id[source_id].next_states = [destination_id]\n\n    def validate_states(self, ids: list[str]) -&gt; None:\n        \"\"\"\n        Check if the provided state ids are valid.\n\n        Args:\n            ids (list[str]): State ids to validate.\n\n        Raises:\n            ValueError: If state with specified id does not exist.\n        \"\"\"\n        for state_id in ids:\n            if state_id not in self._state_by_id:\n                raise ValueError(f\"State with id {state_id} does not exist\")\n\n    def add_conditional_edge(\n        self,\n        source_id: str,\n        destination_ids: list[str],\n        condition: Callable | Python,\n        callbacks: list[NodeCallbackHandler] = [],\n    ) -&gt; None:\n        \"\"\"\n        Adds conditional edge to the graph.\n        Conditional edge provides opportunity to choose between destination states based on condition.\n\n        Args:\n            source_id (str): Id of the source state.\n            destination_ids (list[str]): Ids of destination states.\n            condition (Callable | Python): Condition that will determine next state.\n            callbacks: list[NodeCallbackHandler]: List of callbacks.\n        Raises:\n            ValueError: If state with specified id is not present.\n        \"\"\"\n        self.validate_states(destination_ids + [source_id])\n\n        if isinstance(condition, Python):\n            condition.callbacks.extend(callbacks)\n            self._state_by_id[source_id].condition = condition\n        elif isinstance(condition, Callable):\n            tool = function_tool(condition)()\n            tool.callbacks = callbacks\n            self._state_by_id[source_id].condition = tool\n        else:\n            raise OrchestratorError(\"Error: Conditional edge must be either a Python Node or a Callable.\")\n\n        self._state_by_id[source_id].next_states = destination_ids\n\n    def get_next_state_by_manager(self, state: GraphState, config: RunnableConfig, **kwargs) -&gt; GraphState:\n        \"\"\"\n        Determine the next state based on the current state and history. Uses GraphAgentManager.\n\n        Args:\n            state (State): Current state.\n            config (Optional[RunnableConfig]): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            State: Next state to execute.\n\n        Raises:\n            OrchestratorError: If there is an error parsing the action from the LLM response.\n            StateNotFoundError: If the state is invalid or not found.\n        \"\"\"\n        manager_result = self.manager.run(\n            input_data={\n                \"action\": \"plan\",\n                \"states_description\": self.states_descriptions(state.next_states),\n                \"chat_history\": self._chat_history,\n            },\n            config=config,\n            run_depends=self._run_depends,\n            **kwargs,\n        )\n        self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n        if manager_result.status != RunnableStatus.SUCCESS:\n            error = manager_result.error.to_dict()\n            logger.error(f\"GraphOrchestrator {self.id}: Error generating final answer: {error}\")\n            raise OrchestratorError(\"Failed to generate final answer\")\n\n        try:\n            next_state = json.loads(\n                manager_result.output.get(\"content\").get(\"result\").replace(\"json\", \"\").replace(\"```\", \"\").strip()\n            )[\"state\"]\n\n            if self.manager.streaming.enabled and self.manager.streaming.mode == StreamingMode.ALL:\n                self.manager.stream_content(\n                    content={\"next_state\": next_state},\n                    step=\"manager_planning\",\n                    source=self.name,\n                    config=config,\n                    **kwargs,\n                )\n\n        except Exception as e:\n            logger.error(\"GraphOrchestrator: Error when parsing response about next state.\")\n            raise OrchestratorError(f\"Error when parsing response about next state {e}\")\n\n        if next_state in self._state_by_id:\n            return self._state_by_id[next_state]\n        else:\n            logger.error(f\"GraphOrchestrator: State with id {next_state} was not found.\")\n            raise StateNotFoundError(f\"State with id {next_state} was not found.\")\n\n    def _get_next_state(self, state: GraphState, config: RunnableConfig = None, **kwargs) -&gt; GraphState:\n        \"\"\"\n        Determine the next state based on the current state and chat history.\n\n        Returns:\n            state (State): Current state.\n\n        Raises:\n            OrchestratorError: If there is an error parsing output of conditional edge.\n            StateNotFoundError: If the state is invalid or not found.\n        \"\"\"\n        prompt = \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in self._chat_history])\n\n        logger.debug(f\"GraphOrchestrator {self.id}: PROMPT {prompt}\")\n\n        if len(state.next_states) &gt; 1:\n            if condition := state.condition:\n                if isinstance(condition, Python):\n                    input_data = {**self.context, \"history\": self._chat_history}\n                else:\n                    input_data = {\"context\": self.context | {\"history\": self._chat_history}}\n\n                next_state = condition.run(\n                    input_data=input_data, config=config, run_depends=self._run_depends, **kwargs\n                ).output.get(\"content\")\n\n                self._run_depends = [NodeDependency(node=condition).to_dict(for_tracing=True)]\n\n                if not isinstance(next_state, str):\n                    raise OrchestratorError(\n                        f\"Error: Condition return invalid type. Expected a string got {type(next_state)} \"\n                    )\n\n                if next_state not in self._state_by_id:\n                    raise StateNotFoundError(f\"State with id {next_state} was not found.\")\n\n                return self._state_by_id[next_state]\n            else:\n                return self.get_next_state_by_manager(state, config)\n        else:\n            return self._state_by_id[state.next_states[0]]\n\n    def states_descriptions(self, states: list[str]) -&gt; str:\n        \"\"\"Get a formatted string of states descriptions.\"\"\"\n        return \"\\n\".join(\n            [f\"'{self._state_by_id[state].name}': {self._state_by_id[state].description}\" for state in states]\n        )\n\n    def run_flow(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Process the graph workflow.\n\n        Args:\n            input_task (str): The task to be processed.\n            config (RunnableConfig): Configuration for the runnable.\n\n        Returns:\n            dict[str, Any]: The final output generated after processing the task and inner context of orchestrator.\n        \"\"\"\n        if self.input_analysis_enabled:\n            analysis = self._analyze_user_input(\n                input_task, self.states_descriptions(list(self._state_by_id.keys())), config=config, **kwargs\n            )\n            decision = analysis.decision\n            message = analysis.message\n        else:\n            decision = Decision.PLAN\n\n        if decision == Decision.RESPOND:\n            return {\"content\": message}\n        else:\n            self._chat_history.append({\"role\": \"user\", \"content\": input_task})\n            state = self._state_by_id[self.initial_state]\n\n            for _ in range(self.max_loops):\n                logger.info(f\"GraphOrchestrator {self.id}: Next state: {state.id}\")\n\n                if state.id == END:\n                    final_output = self._chat_history[-1][\"content\"] if self._chat_history else \"\"\n                    return {\"content\": final_output, \"context\": self.context | {\"history\": self._chat_history}}\n\n                elif state.id != START:\n\n                    output = state.run(\n                        input_data={\"context\": self.context, \"chat_history\": self._chat_history},\n                        config=config,\n                        run_depends=self._run_depends,\n                        **kwargs,\n                    )\n                    if output.status != RunnableStatus.SUCCESS:\n                        raise OrchestratorError(output.error.message)\n\n                    output = output.output\n                    self.context = self.context | output[\"context\"]\n                    self._run_depends = [NodeDependency(node=state).to_dict(for_tracing=True)]\n                    self._chat_history = self._chat_history + output[\"history_messages\"]\n\n                state = self._get_next_state(state, config=config, **kwargs)\n\n    def setup_streaming(self) -&gt; None:\n        \"\"\"Setups streaming for orchestrator.\"\"\"\n        self.manager.streaming = self.streaming\n        for state in self.states:\n            for task in state.tasks:\n                task.streaming = self.streaming\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.add_conditional_edge","title":"<code>add_conditional_edge(source_id, destination_ids, condition, callbacks=[])</code>","text":"<p>Adds conditional edge to the graph. Conditional edge provides opportunity to choose between destination states based on condition.</p> <p>Parameters:</p> Name Type Description Default <code>source_id</code> <code>str</code> <p>Id of the source state.</p> required <code>destination_ids</code> <code>list[str]</code> <p>Ids of destination states.</p> required <code>condition</code> <code>Callable | Python</code> <p>Condition that will determine next state.</p> required <code>callbacks</code> <code>list[NodeCallbackHandler]</code> <p>list[NodeCallbackHandler]: List of callbacks.</p> <code>[]</code> <p>Raises:     ValueError: If state with specified id is not present.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def add_conditional_edge(\n    self,\n    source_id: str,\n    destination_ids: list[str],\n    condition: Callable | Python,\n    callbacks: list[NodeCallbackHandler] = [],\n) -&gt; None:\n    \"\"\"\n    Adds conditional edge to the graph.\n    Conditional edge provides opportunity to choose between destination states based on condition.\n\n    Args:\n        source_id (str): Id of the source state.\n        destination_ids (list[str]): Ids of destination states.\n        condition (Callable | Python): Condition that will determine next state.\n        callbacks: list[NodeCallbackHandler]: List of callbacks.\n    Raises:\n        ValueError: If state with specified id is not present.\n    \"\"\"\n    self.validate_states(destination_ids + [source_id])\n\n    if isinstance(condition, Python):\n        condition.callbacks.extend(callbacks)\n        self._state_by_id[source_id].condition = condition\n    elif isinstance(condition, Callable):\n        tool = function_tool(condition)()\n        tool.callbacks = callbacks\n        self._state_by_id[source_id].condition = tool\n    else:\n        raise OrchestratorError(\"Error: Conditional edge must be either a Python Node or a Callable.\")\n\n    self._state_by_id[source_id].next_states = destination_ids\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.add_edge","title":"<code>add_edge(source_id, destination_id)</code>","text":"<p>Adds edge to the graph. When source state finishes execution, destination state will be executed next.</p> <p>Parameters:</p> Name Type Description Default <code>source_id</code> <code>str</code> <p>Id of source state.</p> required <code>destination_id</code> <code>str</code> <p>Id of destination state.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If state with specified id does not exist.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def add_edge(self, source_id: str, destination_id: str) -&gt; None:\n    \"\"\"\n    Adds edge to the graph. When source state finishes execution, destination state will be executed next.\n\n    Args:\n        source_id (str): Id of source state.\n        destination_id (str): Id of destination state.\n\n    Raises:\n        ValueError: If state with specified id does not exist.\n    \"\"\"\n    self.validate_states([source_id, destination_id])\n    self._state_by_id[source_id].next_states = [destination_id]\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.add_state","title":"<code>add_state(state)</code>","text":"<p>Adds state to the graph.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>State</code> <p>State to add to the graph.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If state with specified id already exists.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def add_state(self, state: GraphState) -&gt; None:\n    \"\"\"\n    Adds state to the graph.\n\n    Args:\n        state (State): State to add to the graph.\n\n    Raises:\n        ValueError: If state with specified id already exists.\n    \"\"\"\n    if state.id in self._state_by_id:\n        raise ValueError(f\"Error: State with id {state.id} already exists.\")\n\n    self.states.append(state)\n    self._state_by_id[state.id] = state\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.add_state_by_tasks","title":"<code>add_state_by_tasks(state_id, tasks, callbacks=[])</code>","text":"<p>Adds state to the graph based on tasks.</p> <p>Parameters:</p> Name Type Description Default <code>state_id</code> <code>str</code> <p>Id of the state.</p> required <code>tasks</code> <code>list[Node | Callable]</code> <p>List of tasks that have to be executed when running this state.</p> required <code>callbacks</code> <code>list[NodeCallbackHandler]</code> <p>list[NodeCallbackHandler]: List of callbacks.</p> <code>[]</code> <p>Raises:     ValueError: If state with specified id already exists.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def add_state_by_tasks(\n    self, state_id: str, tasks: list[Node | Callable], callbacks: list[NodeCallbackHandler] = []\n) -&gt; None:\n    \"\"\"\n    Adds state to the graph based on tasks.\n\n    Args:\n        state_id (str): Id of the state.\n        tasks (list[Node | Callable]): List of tasks that have to be executed when running this state.\n        callbacks: list[NodeCallbackHandler]: List of callbacks.\n    Raises:\n        ValueError: If state with specified id already exists.\n    \"\"\"\n    if state_id in self._state_by_id:\n        raise ValueError(f\"Error: State with id {state_id} already exists.\")\n\n    filtered_tasks = []\n\n    has_agent = False\n    for task in tasks:\n        if isinstance(task, Node):\n            if isinstance(task, Agent):\n                has_agent = True\n            filtered_tasks.append(task)\n        elif isinstance(task, Callable):\n            filtered_tasks.append(function_tool(task)())\n        else:\n            raise OrchestratorError(\"Error: Task must be either a Node or a Callable.\")\n\n    state = GraphState(\n        id=state_id,\n        name=state_id,\n        manager=self.manager if has_agent else None,\n        tasks=filtered_tasks,\n        callbacks=callbacks,\n    )\n    self.states.append(state)\n    self._state_by_id[state.id] = state\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.get_next_state_by_manager","title":"<code>get_next_state_by_manager(state, config, **kwargs)</code>","text":"<p>Determine the next state based on the current state and history. Uses GraphAgentManager.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>State</code> <p>Current state.</p> required <code>config</code> <code>Optional[RunnableConfig]</code> <p>Configuration for the runnable.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>State</code> <code>GraphState</code> <p>Next state to execute.</p> <p>Raises:</p> Type Description <code>OrchestratorError</code> <p>If there is an error parsing the action from the LLM response.</p> <code>StateNotFoundError</code> <p>If the state is invalid or not found.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def get_next_state_by_manager(self, state: GraphState, config: RunnableConfig, **kwargs) -&gt; GraphState:\n    \"\"\"\n    Determine the next state based on the current state and history. Uses GraphAgentManager.\n\n    Args:\n        state (State): Current state.\n        config (Optional[RunnableConfig]): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        State: Next state to execute.\n\n    Raises:\n        OrchestratorError: If there is an error parsing the action from the LLM response.\n        StateNotFoundError: If the state is invalid or not found.\n    \"\"\"\n    manager_result = self.manager.run(\n        input_data={\n            \"action\": \"plan\",\n            \"states_description\": self.states_descriptions(state.next_states),\n            \"chat_history\": self._chat_history,\n        },\n        config=config,\n        run_depends=self._run_depends,\n        **kwargs,\n    )\n    self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n    if manager_result.status != RunnableStatus.SUCCESS:\n        error = manager_result.error.to_dict()\n        logger.error(f\"GraphOrchestrator {self.id}: Error generating final answer: {error}\")\n        raise OrchestratorError(\"Failed to generate final answer\")\n\n    try:\n        next_state = json.loads(\n            manager_result.output.get(\"content\").get(\"result\").replace(\"json\", \"\").replace(\"```\", \"\").strip()\n        )[\"state\"]\n\n        if self.manager.streaming.enabled and self.manager.streaming.mode == StreamingMode.ALL:\n            self.manager.stream_content(\n                content={\"next_state\": next_state},\n                step=\"manager_planning\",\n                source=self.name,\n                config=config,\n                **kwargs,\n            )\n\n    except Exception as e:\n        logger.error(\"GraphOrchestrator: Error when parsing response about next state.\")\n        raise OrchestratorError(f\"Error when parsing response about next state {e}\")\n\n    if next_state in self._state_by_id:\n        return self._state_by_id[next_state]\n    else:\n        logger.error(f\"GraphOrchestrator: State with id {next_state} was not found.\")\n        raise StateNotFoundError(f\"State with id {next_state} was not found.\")\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize components of the orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>Optional[ConnectionManager]</code> <p>The connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n    \"\"\"\n    Initialize components of the orchestrator.\n\n    Args:\n        connection_manager (Optional[ConnectionManager]): The connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    super().init_components(connection_manager)\n\n    if self.manager.is_postponed_component_init:\n        self.manager.init_components(connection_manager)\n\n    for state in self.states:\n        if state.is_postponed_component_init:\n            state.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.run_flow","title":"<code>run_flow(input_task, config=None, **kwargs)</code>","text":"<p>Process the graph workflow.</p> <p>Parameters:</p> Name Type Description Default <code>input_task</code> <code>str</code> <p>The task to be processed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: The final output generated after processing the task and inner context of orchestrator.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def run_flow(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Process the graph workflow.\n\n    Args:\n        input_task (str): The task to be processed.\n        config (RunnableConfig): Configuration for the runnable.\n\n    Returns:\n        dict[str, Any]: The final output generated after processing the task and inner context of orchestrator.\n    \"\"\"\n    if self.input_analysis_enabled:\n        analysis = self._analyze_user_input(\n            input_task, self.states_descriptions(list(self._state_by_id.keys())), config=config, **kwargs\n        )\n        decision = analysis.decision\n        message = analysis.message\n    else:\n        decision = Decision.PLAN\n\n    if decision == Decision.RESPOND:\n        return {\"content\": message}\n    else:\n        self._chat_history.append({\"role\": \"user\", \"content\": input_task})\n        state = self._state_by_id[self.initial_state]\n\n        for _ in range(self.max_loops):\n            logger.info(f\"GraphOrchestrator {self.id}: Next state: {state.id}\")\n\n            if state.id == END:\n                final_output = self._chat_history[-1][\"content\"] if self._chat_history else \"\"\n                return {\"content\": final_output, \"context\": self.context | {\"history\": self._chat_history}}\n\n            elif state.id != START:\n\n                output = state.run(\n                    input_data={\"context\": self.context, \"chat_history\": self._chat_history},\n                    config=config,\n                    run_depends=self._run_depends,\n                    **kwargs,\n                )\n                if output.status != RunnableStatus.SUCCESS:\n                    raise OrchestratorError(output.error.message)\n\n                output = output.output\n                self.context = self.context | output[\"context\"]\n                self._run_depends = [NodeDependency(node=state).to_dict(for_tracing=True)]\n                self._chat_history = self._chat_history + output[\"history_messages\"]\n\n            state = self._get_next_state(state, config=config, **kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.setup_streaming","title":"<code>setup_streaming()</code>","text":"<p>Setups streaming for orchestrator.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def setup_streaming(self) -&gt; None:\n    \"\"\"Setups streaming for orchestrator.\"\"\"\n    self.manager.streaming = self.streaming\n    for state in self.states:\n        for task in state.tasks:\n            task.streaming = self.streaming\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.states_descriptions","title":"<code>states_descriptions(states)</code>","text":"<p>Get a formatted string of states descriptions.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def states_descriptions(self, states: list[str]) -&gt; str:\n    \"\"\"Get a formatted string of states descriptions.\"\"\"\n    return \"\\n\".join(\n        [f\"'{self._state_by_id[state].name}': {self._state_by_id[state].description}\" for state in states]\n    )\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"manager\"] = self.manager.to_dict(**kwargs)\n    data[\"states\"] = [state.to_dict(**kwargs) for state in self.states]\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.GraphOrchestrator.validate_states","title":"<code>validate_states(ids)</code>","text":"<p>Check if the provided state ids are valid.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str]</code> <p>State ids to validate.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If state with specified id does not exist.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>def validate_states(self, ids: list[str]) -&gt; None:\n    \"\"\"\n    Check if the provided state ids are valid.\n\n    Args:\n        ids (list[str]): State ids to validate.\n\n    Raises:\n        ValueError: If state with specified id does not exist.\n    \"\"\"\n    for state_id in ids:\n        if state_id not in self._state_by_id:\n            raise ValueError(f\"State with id {state_id} does not exist\")\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph/#dynamiq.nodes.agents.orchestrators.graph.StateNotFoundError","title":"<code>StateNotFoundError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Raised when next state was not found.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph.py</code> <pre><code>class StateNotFoundError(OrchestratorError):\n    \"\"\"Raised when next state was not found.\"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_manager/","title":"Graph manager","text":""},{"location":"dynamiq/nodes/agents/orchestrators/graph_manager/#dynamiq.nodes.agents.orchestrators.graph_manager.GraphAgentManager","title":"<code>GraphAgentManager</code>","text":"<p>               Bases: <code>AgentManager</code></p> <p>A graph agent manager that coordinates graph flow execution.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_manager.py</code> <pre><code>class GraphAgentManager(AgentManager):\n    \"\"\"A graph agent manager that coordinates graph flow execution.\"\"\"\n\n    name: str = \"Graph Manager\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the GraphAgentManager and set up prompt templates.\"\"\"\n        super().__init__(**kwargs)\n        self._init_prompt_blocks()\n\n    def _init_prompt_blocks(self):\n        \"\"\"Initialize the prompt blocks with finding next state, actions and final answer prompts.\"\"\"\n        super()._init_prompt_blocks()\n        self._prompt_blocks.update(\n            {\n                \"plan\": self._get_next_state_prompt(),\n                \"assign\": self._get_actions_prompt(),\n                \"handle_input\": self._get_graph_handle_input_prompt(),\n            }\n        )\n\n    @staticmethod\n    def _get_graph_handle_input_prompt() -&gt; str:\n        \"\"\"Determines how to handle input, either by continuing the flow or providing a direct response.\"\"\"\n        return PROMPT_TEMPLATE_GRAPH_AGENT_MANAGER_HANDLE_INPUT\n\n    @staticmethod\n    def _get_next_state_prompt() -&gt; str:\n        \"\"\"Return next step prompt template.\"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_NEXT_STATE\n\n    @staticmethod\n    def _get_actions_prompt() -&gt; str:\n        \"\"\"Return actions prompt template.\"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_ACTIONS\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_manager/#dynamiq.nodes.agents.orchestrators.graph_manager.GraphAgentManager.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the GraphAgentManager and set up prompt templates.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_manager.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the GraphAgentManager and set up prompt templates.\"\"\"\n    super().__init__(**kwargs)\n    self._init_prompt_blocks()\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_state/","title":"Graph state","text":""},{"location":"dynamiq/nodes/agents/orchestrators/graph_state/#dynamiq.nodes.agents.orchestrators.graph_state.GraphState","title":"<code>GraphState</code>","text":"<p>               Bases: <code>Node</code></p> <p>Represents single state of graph flow</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the state.</p> <code>name</code> <code>str</code> <p>Name of the state</p> <code>description</code> <code>str</code> <p>Description of the state.</p> <code>next_states</code> <code>list[str]</code> <p>List of adjacent node</p> <code>tasks</code> <code>list[Node]</code> <p>List of tasks that have to be executed in this state.</p> <code>condition</code> <code>Python | FunctionTool</code> <p>Condition that determines next state to execute.</p> <code>manager</code> <code>GraphAgentManager</code> <p>The managing agent responsible for overseeing state execution.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_state.py</code> <pre><code>class GraphState(Node):\n    \"\"\"Represents single state of graph flow\n\n    Attributes:\n        id (str): Unique identifier for the state.\n        name (str): Name of the state\n        description (str): Description of the state.\n        next_states (list[str]): List of adjacent node\n        tasks (list[Node]): List of tasks that have to be executed in this state.\n        condition (Python | FunctionTool): Condition that determines next state to execute.\n        manager (GraphAgentManager): The managing agent responsible for overseeing state execution.\n    \"\"\"\n\n    id: str\n    name: str = \"State\"\n    group: NodeGroup = NodeGroup.UTILS\n    input_schema: ClassVar[type[StateInputSchema]] = StateInputSchema\n    description: str = \"\"\n    next_states: list[str] = []\n    tasks: list[Node] = []\n    condition: Python | FunctionTool | None = None\n    manager: GraphAgentManager | None = None\n\n    @model_validator(mode=\"after\")\n    def validate_manager(self):\n        for task in self.tasks:\n            if isinstance(task, Agent) and not self.manager:\n                raise ValueError(\"Error: Provide manager to state to execute agent tasks.\")\n\n        return self\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"manager\": True, \"tasks\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        if self.manager:\n            data[\"manager\"] = self.manager.to_dict(**kwargs)\n        else:\n            data[\"manager\"] = None\n        data[\"tasks\"] = [task.to_dict(**kwargs) for task in self.tasks]\n        return data\n\n    def merge_contexts(self, context_list: list[dict[str, Any]]) -&gt; dict:\n        \"\"\"\n        Merges contexts. Raises error when lossless merging is not possible.\n\n        Args:\n            context_list (list[dict[str, Any]]): List of contexts to merge.\n        Raises:\n            OrchestratorError: If multiple changes of the same context variable are detected.\n        \"\"\"\n        merged_dict = {}\n\n        for d in context_list:\n            for key, value in d.items():\n                if key in merged_dict:\n                    if merged_dict[key] != value:\n                        raise OrchestratorError(f\"Error: multiple changes of context variable {key} are detected.\")\n                merged_dict[key] = value\n\n        return merged_dict\n\n    def agent_description(self, agent: Agent) -&gt; str:\n        \"\"\"\n        Creates agent description.\n\n        Args:\n            agent (Agent): Agent for which to provide a description.\n\n        Return:\n            str: Description of the agent.\n        \"\"\"\n        return f\"Name: {agent.name}. Role: {agent.role}\"\n\n    def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n        \"\"\"\n        Initialize components of the orchestrator.\n\n        Args:\n            connection_manager (Optional[ConnectionManager]): The connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        super().init_components(connection_manager)\n        if self.manager and self.manager.is_postponed_component_init:\n            self.manager.init_components(connection_manager)\n\n        for task in self.tasks:\n            if task.is_postponed_component_init:\n                task.init_components(connection_manager)\n\n    def validate_input_transformer(self, task: Node, input_data: dict[str, Any], **kwargs) -&gt; bool:\n        \"\"\"\n        Validates whether input data after transformation is a correct input for the task.\n\n        Args:\n            task (Node): Task that have to be executed.\n            input_data (dict[str, Any]): Original input to the task.\n\n        Return:\n            bool: Whether input data is correct.\n        \"\"\"\n\n        try:\n            if task.input_transformer and (task.input_transformer.path or task.input_transformer.selector):\n                output = task.transform(input_data, task.input_transformer)\n                task.validate_input_schema(output, **kwargs)\n                return True\n            else:\n                return False\n\n        except Exception as e:\n            logger.error(f\"Error occurred while applying the InputTransformer to the {task.name} Node. {e}\")\n            return False\n\n    def _submit_task(\n        self,\n        task: Node,\n        global_context: dict[str, Any],\n        chat_history: list[dict[str, str]],\n        config: RunnableConfig,\n        **kwargs,\n    ) -&gt; tuple[str, dict[str, Any]]:\n        \"\"\"Executes single task.\n\n        Args:\n            task (Node): Task to be executed.\n            global_context (dict[str, Any]): Current context of the execution.\n            chat_history (list[dict[str, str]]): List of history messages.\n            config (Optional[RunnableConfig]): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            str: The result of the task execution.\n            dict[str, Any]: Updates to the context.\n\n        Raises:\n            OrchestratorError: If an error occurs during the execution process.\n\n        \"\"\"\n\n        run_depends = []\n\n        if isinstance(task, Agent):\n            agent_input = {\"context\": global_context | {\"history\": chat_history}}\n            is_input_correct = self.validate_input_transformer(task, agent_input, **kwargs)\n            if not is_input_correct:\n                manager_result = self.manager.run(\n                    input_data={\n                        \"action\": \"assign\",\n                        \"task\": self.agent_description(task),\n                        \"chat_history\": chat_history,\n                    },\n                    run_depends=run_depends,\n                    config=config,\n                    **kwargs,\n                )\n\n                run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n                if manager_result.status != RunnableStatus.SUCCESS:\n                    result = manager_result.to_dict()\n                    logger.error(f\"GraphOrchestrator: Error generating actions for state: {result}\")\n                    raise OrchestratorError(f\"GraphOrchestrator: Error generating actions for state: {result}\")\n\n                try:\n                    agent_input = {\n                        \"input\": json.loads(\n                            manager_result.output.get(\"content\")\n                            .get(\"result\")\n                            .replace(\"json\", \"\")\n                            .replace(\"```\", \"\")\n                            .strip()\n                        )[\"input\"]\n                    }\n                except Exception as e:\n                    logger.error(f\"GraphOrchestrator: Error when parsing response about next state {e}\")\n                    raise OrchestratorError(f\"Error when parsing response about next state {e}\")\n\n            response = task.run(\n                input_data=agent_input,\n                config=config,\n                run_depends=run_depends,\n                use_input_transformer=is_input_correct,\n                **kwargs,\n            )\n\n            if response.status != RunnableStatus.SUCCESS:\n                error_msg = response.error.message\n                logger.error(f\"GraphOrchestrator: Failed to execute Agent {task.name} with Error: {error_msg}\")\n                raise OrchestratorError(f\"Failed to execute Agent {task.name} with Error: {error_msg}\")\n\n            result = response.output.get(\"content\")\n            return result, {}\n\n        elif isinstance(task, FunctionTool):\n            input_data = {\"context\": global_context | {\"history\": chat_history}}\n        else:\n            input_data = {**global_context, \"history\": chat_history}\n\n        response = task.run(input_data=input_data, config=config, run_depends=run_depends, **kwargs)\n\n        if response.status != RunnableStatus.SUCCESS:\n            error_msg = response.error.message\n            logger.error(f\"GraphOrchestrator: Failed to execute {task.name} with Error: {error_msg}\")\n            raise OrchestratorError(f\"Failed to execute {task.name} with Error: {error_msg}\")\n\n        context = response.output.get(\"content\")\n\n        if isinstance(task, FunctionTool) or isinstance(task, Python):\n            if not isinstance(context, dict):\n                raise OrchestratorError(\n                    f\"Error: Task returned invalid data format. Expected a dictionary got {type(context)}\"\n                )\n\n            if \"result\" not in context:\n                raise OrchestratorError(\"Error: Task returned dictionary with no 'result' key in it.\")\n        else:\n            return context, {}\n\n        context.pop(\"history\", None)\n\n        result = context.pop(\"result\")\n\n        return result, context\n\n    def execute(self, input_data: StateInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict:\n        \"\"\"\n        Execute the State.\n\n        Args:\n            input_data (StateInputSchema): The input data containing context and chat history.\n            config (Optional[RunnableConfig]): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: The result of the state execution (updated context and chat history).\n        \"\"\"\n        logger.debug(f\"State {self.id}: starting the flow with input_task:\\n```{input_data}```\")\n        kwargs.pop(\"run_depends\", None)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n        kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n\n        global_context = input_data.context\n        chat_history = input_data.chat_history\n\n        history_messages = []\n\n        if len(self.tasks) == 1:\n            result, context = self._submit_task(\n                self.tasks[0],\n                global_context,\n                chat_history,\n                config=config,\n                **kwargs,\n            )\n\n            history_messages.append(\n                {\n                    \"role\": MessageRole.ASSISTANT,\n                    \"content\": result,\n                }\n            )\n\n            global_context = global_context | context\n\n        elif len(self.tasks) &gt; 1:\n\n            contexts = []\n\n            for task in self.tasks:\n\n                result, context = self._submit_task(\n                    task, copy.deepcopy(global_context), copy.deepcopy(chat_history), config=config, **kwargs\n                )\n\n                history_messages.append(\n                    {\n                        \"role\": MessageRole.ASSISTANT,\n                        \"content\": result,\n                    }\n                )\n\n                contexts.append(context)\n            global_context = global_context | self.merge_contexts(contexts)\n\n        return {\"context\": global_context, \"history_messages\": history_messages}\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_state/#dynamiq.nodes.agents.orchestrators.graph_state.GraphState.agent_description","title":"<code>agent_description(agent)</code>","text":"<p>Creates agent description.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>Agent</code> <p>Agent for which to provide a description.</p> required Return <p>str: Description of the agent.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_state.py</code> <pre><code>def agent_description(self, agent: Agent) -&gt; str:\n    \"\"\"\n    Creates agent description.\n\n    Args:\n        agent (Agent): Agent for which to provide a description.\n\n    Return:\n        str: Description of the agent.\n    \"\"\"\n    return f\"Name: {agent.name}. Role: {agent.role}\"\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_state/#dynamiq.nodes.agents.orchestrators.graph_state.GraphState.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the State.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>StateInputSchema</code> <p>The input data containing context and chat history.</p> required <code>config</code> <code>Optional[RunnableConfig]</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dict[str, Any]: The result of the state execution (updated context and chat history).</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_state.py</code> <pre><code>def execute(self, input_data: StateInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict:\n    \"\"\"\n    Execute the State.\n\n    Args:\n        input_data (StateInputSchema): The input data containing context and chat history.\n        config (Optional[RunnableConfig]): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: The result of the state execution (updated context and chat history).\n    \"\"\"\n    logger.debug(f\"State {self.id}: starting the flow with input_task:\\n```{input_data}```\")\n    kwargs.pop(\"run_depends\", None)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n    kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n\n    global_context = input_data.context\n    chat_history = input_data.chat_history\n\n    history_messages = []\n\n    if len(self.tasks) == 1:\n        result, context = self._submit_task(\n            self.tasks[0],\n            global_context,\n            chat_history,\n            config=config,\n            **kwargs,\n        )\n\n        history_messages.append(\n            {\n                \"role\": MessageRole.ASSISTANT,\n                \"content\": result,\n            }\n        )\n\n        global_context = global_context | context\n\n    elif len(self.tasks) &gt; 1:\n\n        contexts = []\n\n        for task in self.tasks:\n\n            result, context = self._submit_task(\n                task, copy.deepcopy(global_context), copy.deepcopy(chat_history), config=config, **kwargs\n            )\n\n            history_messages.append(\n                {\n                    \"role\": MessageRole.ASSISTANT,\n                    \"content\": result,\n                }\n            )\n\n            contexts.append(context)\n        global_context = global_context | self.merge_contexts(contexts)\n\n    return {\"context\": global_context, \"history_messages\": history_messages}\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_state/#dynamiq.nodes.agents.orchestrators.graph_state.GraphState.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize components of the orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>Optional[ConnectionManager]</code> <p>The connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_state.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n    \"\"\"\n    Initialize components of the orchestrator.\n\n    Args:\n        connection_manager (Optional[ConnectionManager]): The connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    super().init_components(connection_manager)\n    if self.manager and self.manager.is_postponed_component_init:\n        self.manager.init_components(connection_manager)\n\n    for task in self.tasks:\n        if task.is_postponed_component_init:\n            task.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_state/#dynamiq.nodes.agents.orchestrators.graph_state.GraphState.merge_contexts","title":"<code>merge_contexts(context_list)</code>","text":"<p>Merges contexts. Raises error when lossless merging is not possible.</p> <p>Parameters:</p> Name Type Description Default <code>context_list</code> <code>list[dict[str, Any]]</code> <p>List of contexts to merge.</p> required <p>Raises:     OrchestratorError: If multiple changes of the same context variable are detected.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_state.py</code> <pre><code>def merge_contexts(self, context_list: list[dict[str, Any]]) -&gt; dict:\n    \"\"\"\n    Merges contexts. Raises error when lossless merging is not possible.\n\n    Args:\n        context_list (list[dict[str, Any]]): List of contexts to merge.\n    Raises:\n        OrchestratorError: If multiple changes of the same context variable are detected.\n    \"\"\"\n    merged_dict = {}\n\n    for d in context_list:\n        for key, value in d.items():\n            if key in merged_dict:\n                if merged_dict[key] != value:\n                    raise OrchestratorError(f\"Error: multiple changes of context variable {key} are detected.\")\n            merged_dict[key] = value\n\n    return merged_dict\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_state/#dynamiq.nodes.agents.orchestrators.graph_state.GraphState.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_state.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    if self.manager:\n        data[\"manager\"] = self.manager.to_dict(**kwargs)\n    else:\n        data[\"manager\"] = None\n    data[\"tasks\"] = [task.to_dict(**kwargs) for task in self.tasks]\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/graph_state/#dynamiq.nodes.agents.orchestrators.graph_state.GraphState.validate_input_transformer","title":"<code>validate_input_transformer(task, input_data, **kwargs)</code>","text":"<p>Validates whether input data after transformation is a correct input for the task.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>Node</code> <p>Task that have to be executed.</p> required <code>input_data</code> <code>dict[str, Any]</code> <p>Original input to the task.</p> required Return <p>bool: Whether input data is correct.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/graph_state.py</code> <pre><code>def validate_input_transformer(self, task: Node, input_data: dict[str, Any], **kwargs) -&gt; bool:\n    \"\"\"\n    Validates whether input data after transformation is a correct input for the task.\n\n    Args:\n        task (Node): Task that have to be executed.\n        input_data (dict[str, Any]): Original input to the task.\n\n    Return:\n        bool: Whether input data is correct.\n    \"\"\"\n\n    try:\n        if task.input_transformer and (task.input_transformer.path or task.input_transformer.selector):\n            output = task.transform(input_data, task.input_transformer)\n            task.validate_input_schema(output, **kwargs)\n            return True\n        else:\n            return False\n\n    except Exception as e:\n        logger.error(f\"Error occurred while applying the InputTransformer to the {task.name} Node. {e}\")\n        return False\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/","title":"Linear","text":""},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator","title":"<code>LinearOrchestrator</code>","text":"<p>               Bases: <code>Orchestrator</code></p> <p>Manages the execution of tasks by coordinating multiple agents and leveraging LLM (Large Language Model).</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str | None</code> <p>Name of the orchestrator.</p> <code>group</code> <code>NodeGroup</code> <p>The group this node belongs to.</p> <code>manager</code> <code>LinearAgentManager</code> <p>The managing agent responsible for overseeing the orchestration process.</p> <code>agents</code> <code>list[Agent]</code> <p>List of specialized agents available for task execution.</p> <code>use_summarizer</code> <code>bool</code> <p>Indicates if a final summarizer is used.</p> <code>summarize_all_answers</code> <code>bool</code> <p>Indicates whether to summarize answers to all tasks or use only last one. Will only be applied if use_summarizer is set to True.</p> <code>max_plan_retries</code> <code>int</code> <p>Maximum number of plan generation retries.</p> <code>plan_approval</code> <code>PlanApprovalConfig</code> <p>Configuration for plan approval.</p> <code>max_user_analyze_retries</code> <code>int</code> <p>Maximum number of retries for analyzing user input.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>class LinearOrchestrator(Orchestrator):\n    \"\"\"\n    Manages the execution of tasks by coordinating multiple agents and leveraging LLM (Large Language Model).\n\n    Attributes:\n        name (str | None): Name of the orchestrator.\n        group (NodeGroup): The group this node belongs to.\n        manager (LinearAgentManager): The managing agent responsible for overseeing the orchestration process.\n        agents (list[Agent]): List of specialized agents available for task execution.\n        use_summarizer (bool): Indicates if a final summarizer is used.\n        summarize_all_answers (bool): Indicates whether to summarize answers to all tasks\n            or use only last one. Will only be applied if use_summarizer is set to True.\n        max_plan_retries (int): Maximum number of plan generation retries.\n        plan_approval (PlanApprovalConfig): Configuration for plan approval.\n        max_user_analyze_retries (int): Maximum number of retries for analyzing user input.\n    \"\"\"\n\n    name: str | None = \"LinearOrchestrator\"\n    group: NodeGroup = NodeGroup.AGENTS\n    manager: LinearAgentManager\n    agents: list[Agent] = []\n    use_summarizer: bool = True\n    summarize_all_answers: bool = False\n    max_plan_retries: int = 5\n    plan_approval: PlanApprovalConfig = Field(default_factory=PlanApprovalConfig)\n    max_user_analyze_retries: int = 3\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._results = {}\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"manager\": True, \"agents\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"manager\"] = self.manager.to_dict(**kwargs)\n        data[\"agents\"] = [agent.to_dict(**kwargs) for agent in self.agents]\n        return data\n\n    def reset_run_state(self):\n        self._results = {}\n        self._run_depends = []\n        self._chat_history = []\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize components for the manager and agents.\n\n        Args:\n            connection_manager (Optional[ConnectionManager]): The connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.manager.is_postponed_component_init:\n            self.manager.init_components(connection_manager)\n\n        for agent in self.agents:\n            if agent.is_postponed_component_init:\n                agent.init_components(connection_manager)\n\n    @cached_property\n    def agents_descriptions(self) -&gt; str:\n        \"\"\"Generate a string description of all agents.\"\"\"\n        return \"\\n\".join([f\"{i}. {_agent.name}\" for i, _agent in enumerate(self.agents)]) if self.agents else \"\"\n\n    def get_tasks(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; list[Task]:\n        \"\"\"\n        Generate tasks using the manager agent.\n\n        Args:\n            input_task (str): The input task to generate subtasks from\n            config (RunnableConfig, optional): Configuration for the runnable\n            **kwargs: Additional keyword arguments passed to the manager's run method\n\n        Returns:\n            list[Task]: List of generated tasks\n\n        Raises:\n            ValueError: If task generation fails\n            OrchestratorError: If maximum number of retries is reached\n        \"\"\"\n        manager_result_content = \"\"\n        feedback = \"\"\n\n        for _ in range(self.max_plan_retries):\n            manager_result = self.manager.run(\n                input_data={\n                    \"action\": \"plan\",\n                    \"input_task\": input_task,\n                    \"agents\": self.agents_descriptions,\n                    \"feedback\": feedback,\n                    \"previous_plan\": manager_result_content,\n                },\n                config=config,\n                run_depends=self._run_depends,\n                **kwargs,\n            )\n            self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n            if manager_result.status != RunnableStatus.SUCCESS:\n                error_message = f\"LLM '{self.manager.name}' failed: {manager_result.error.message}\"\n                raise ValueError(f\"Failed to generate tasks: {error_message}\")\n\n            manager_result_content = manager_result.output.get(\"content\").get(\"result\")\n            logger.info(\n                f\"Orchestrator {self.name} - {self.id}: Tasks generated by {self.manager.name} - {self.manager.id}:\"\n                f\"\\n{manager_result_content}\"\n            )\n            try:\n                tasks = self.parse_tasks_from_output(manager_result_content)\n                if self.manager.streaming.enabled and self.manager.streaming.mode == StreamingMode.ALL:\n                    self.manager.stream_content(\n                        content={\"tasks\": tasks},\n                        step=\"manager_planning\",\n                        source=self.manager.name,\n                        config=config,\n                        **kwargs,\n                    )\n\n            except ActionParseError as e:\n                feedback = str(e)\n                continue\n\n            if not self.plan_approval.enabled:\n                return tasks\n            else:\n                approval_result = self.send_approval_message(\n                    self.plan_approval, {\"tasks\": tasks}, config=config, **kwargs\n                )\n\n                feedback = approval_result.feedback\n                if approval_result.is_approved:\n                    return approval_result.data.get(\"tasks\")\n\n        raise OrchestratorError(\"Maximum number of loops reached for generating plan.\")\n\n    def parse_tasks_from_output(self, output: str) -&gt; list[Task]:\n        \"\"\"Parse tasks from the manager's output string.\"\"\"\n\n        output_match = re.search(r\"&lt;output&gt;(.*?)&lt;/output&gt;\", output, re.DOTALL)\n        if not output_match:\n            error_response = f\"Error parsing final answer: No &lt;output&gt; tags found in the response {output}\"\n            raise ActionParseError(f\"Error: {error_response}\")\n\n        output_content = output_match.group(1).strip()\n\n        try:\n            output_content = self._clean_output(output_content)\n        except AttributeError as e:\n            logger.warning(\n                f\"Orchestrator {self.name} - {self.id}: \"\n                f\"Failed to remove code block markers and 'json' keyword \"\n                f\"from output {output_content} due to error: {e}\"\n            )\n\n        try:\n            task_list_json = output_content.strip()\n        except AttributeError as e:\n            logger.warning(\n                f\"Orchestrator {self.name} - {self.id}: Failed to strip the output {output_content} due to error: {e}\"\n            )\n            task_list_json = output_content\n        return TypeAdapter(list[Task]).validate_json(task_list_json)\n\n    def get_dependency_outputs(self, dependencies: list[int]) -&gt; str:\n        \"\"\"Format the outputs of dependent tasks.\"\"\"\n        if not dependencies:\n            return \"\"\n\n        dependencies_formatted = \"**Here is the previously collected information:**\\n\"\n        for dep in dependencies:\n            if dep in self._results:\n                task_name = self._results[dep][\"name\"]\n                task_result = str(self._results[dep][\"result\"])\n                dependencies_formatted += f\"**Task:** {task_name}\\n**Result:** {task_result}\\n\\n\"\n\n        return dependencies_formatted.strip()\n\n    def run_tasks(self, tasks: list[Task], input_task: str, config: RunnableConfig = None, **kwargs) -&gt; None:\n        \"\"\"Execute the tasks using appropriate agents.\"\"\"\n\n        for count, task in enumerate(tasks, start=1):\n            task_per_llm = f\"**{task.description}**\\n**Required information for output**: {task.output}\"\n\n            dependency_outputs = self.get_dependency_outputs(task.dependencies)\n            if dependency_outputs:\n                task_per_llm += f\"\\n{dependency_outputs}\"\n\n            success_flag = False\n            for _ in range(self.manager.max_loops):\n                manager_result = self.manager.run(\n                    input_data={\n                        \"action\": \"assign\",\n                        \"input_task\": input_task,\n                        \"task\": task_per_llm,\n                        \"agents\": self.agents_descriptions,\n                    },\n                    config=config,\n                    run_depends=self._run_depends,\n                    **kwargs,\n                )\n                self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n                if manager_result.status == RunnableStatus.SUCCESS:\n                    assigned_agent_index = self._extract_agent_index(manager_result.output.get(\"content\", {}))\n\n                    if 0 &lt;= assigned_agent_index &lt; len(self.agents):\n                        assigned_agent = self.agents[assigned_agent_index]\n\n                        if self.manager.streaming.enabled and self.manager.streaming.mode == StreamingMode.ALL:\n                            self.manager.stream_content(\n                                content={\"agent\": assigned_agent, \"task\": task},\n                                step=\"manager_assigning\",\n                                source=self.name,\n                                config=config,\n                                **kwargs,\n                            )\n\n                        logger.info(\n                            f\"Orchestrator {self.name} - {self.id}: Loop {count} - \"\n                            f\"Assigned agent: {assigned_agent.name} - {assigned_agent.id}\"\n                        )\n                        result = assigned_agent.run(\n                            input_data={\"input\": task_per_llm},\n                            config=config,\n                            run_depends=self._run_depends,\n                            **kwargs,\n                        )\n                        self._run_depends = [NodeDependency(node=assigned_agent).to_dict(for_tracing=True)]\n                        if result.status != RunnableStatus.SUCCESS:\n                            raise ValueError(\n                                f\"Failed to execute task {task.id}.{task.name} \"\n                                f\"by agent {assigned_agent_index}.{assigned_agent.name}\"\n                                f\"due to error: {result.error.message}\"\n                            )\n\n                        self._results[task.id] = {\n                            \"name\": task.name,\n                            \"result\": result.output[\"content\"],\n                        }\n\n                        success_flag = True\n                        break\n                task_per_llm += f\"Error occurred:{manager_result.error.to_dict()}\"\n\n            if success_flag:\n                continue\n\n            else:\n                raise ValueError(\n                    f\"Orchestrator {self.name} - {self.id}: \"\n                    f\"Failed to assign task {task.id}.{task.name} \"\n                    f\"by Manager Agent due to error: \"\n                    f\"{manager_result.error.to_dict() if manager_result.error else manager_result.output}\"\n                )\n\n    def generate_final_answer(self, task: str, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"\n        Generates final answer using the manager agent logic.\n\n        Args:\n            task (str): The task to be processed.\n            config (RunnableConfig): Configuration for the runnable.\n\n        Returns:\n            str: The final answer generated after processing the task.\n        \"\"\"\n        tasks_outputs = \"\\n\\n\".join(\n            f\"**Task:** {result['name']}\\n**Result:** {result['result']}\" for result in self._results.values() if result\n        )\n\n        if self.use_summarizer:\n            if not self.summarize_all_answers:\n                final_task_id = max(self._results.keys(), default=None)\n\n                if final_task_id is not None:\n                    final_task_output = self._results[final_task_id].get(\"result\", \"\")\n                    logger.debug(f\"Orchestrator {self.name} - {self.id}: Final task output: {final_task_output}\")\n                    return final_task_output\n\n            final_result_content = self.get_final_result(\n                {\"input_task\": task, \"chat_history\": self._chat_history, \"tasks_outputs\": tasks_outputs},\n                config=config,\n                **kwargs,\n            )\n\n            try:\n                final_result = re.search(r\"&lt;final_answer&gt;(.*?)&lt;/final_answer&gt;\", final_result_content, re.DOTALL)\n                final_result_answer = final_result.group(1).strip()\n                return final_result_answer\n            except Exception as e:\n                error_response = f\"Orchestrator {self.name} - {self.id}: Error parsing final answer: {e}\"\n                logger.error(error_response)\n                if \"final_answer\" in final_result_content:\n                    logger.info(f\"Orchestrator {self.name} - {self.id}: Return raw answer\")\n                    return final_result_content\n                else:\n                    raise ActionParseError(f\"{error_response}\")\n        return tasks_outputs\n\n    def run_flow(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Process the given task using the manager agent logic.\n\n        Args:\n            input_task (str): The task to be processed.\n            config (RunnableConfig): Configuration for the runnable.\n\n        Returns:\n            dict[str, Any]: The final output generated after processing the task.\n        \"\"\"\n        analysis = self._analyze_user_input(input_task, self.agents_descriptions, config=config, **kwargs)\n        decision = analysis.decision\n        message = analysis.message\n\n        if decision == Decision.RESPOND:\n            return {\"content\": message}\n        else:\n            tasks = self.get_tasks(input_task, config=config, **kwargs)\n            self.run_tasks(tasks=tasks, input_task=input_task, config=config, **kwargs)\n            return {\"content\": self.generate_final_answer(input_task, config, **kwargs)}\n\n    def setup_streaming(self) -&gt; None:\n        \"\"\"Setups streaming for orchestrator.\"\"\"\n        self.manager.streaming = self.streaming\n        for agent in self.agents:\n            agent.streaming = self.streaming\n\n    def extract_json_from_output(self, result_text: str) -&gt; tuple[str, dict] | None:\n        \"\"\"\n        Extracts JSON data from the given text by looking for content within\n        &lt;output&gt;...&lt;/output&gt; and &lt;analysis&gt;...&lt;/analysis&gt; tags. Strips any Markdown code block fences.\n\n        Args:\n            result_text (str): The text from which to extract JSON data.\n\n        Returns:\n            dict | None: The extracted JSON dictionary if successful, otherwise None.\n        \"\"\"\n        analysis, output_content = self._extract_output_content(result_text)\n        output_content = self._clean_output(output_content)\n\n        try:\n            data = json.loads(output_content)\n            return analysis, data\n        except json.JSONDecodeError as e:\n            error_message = f\"Orchestrator {self.name} - {self.id}: JSON decoding error: {e}\"\n            logger.error(error_message)\n            return None\n\n    def _clean_output(self, text: str) -&gt; str:\n        \"\"\"Remove Markdown code fences and extra whitespace from a text.\"\"\"\n        cleaned = re.sub(r\"^```(?:json)?\\s*|```$\", \"\", text).strip()\n        return cleaned\n\n    def _extract_agent_index(self, result_content: dict[str, Any]) -&gt; int:\n        \"\"\"\n        Extracts and validates the agent index from the result content.\n\n        Args:\n            result_content (dict[str, Any]): The content containing the agent index\n\n        Returns:\n            int: The extracted agent index, or -1 if extraction fails\n        \"\"\"\n        raw = result_content.get(\"result\", -1)\n        try:\n            return int(raw)\n        except ValueError:\n            logger.warning(f\"Invalid agent index: {raw}\")\n            match = re.match(r\"^\\d+\", str(raw))\n            if match:\n                return int(match.group())\n            else:\n                logger.error(f\"Failed to extract agent index from: {raw}\")\n                return -1\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.agents_descriptions","title":"<code>agents_descriptions: str</code>  <code>cached</code> <code>property</code>","text":"<p>Generate a string description of all agents.</p>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.extract_json_from_output","title":"<code>extract_json_from_output(result_text)</code>","text":"<p>Extracts JSON data from the given text by looking for content within</p> ... <p>and ... tags. Strips any Markdown code block fences.</p> <p>Parameters:</p> Name Type Description Default <code>result_text</code> <code>str</code> <p>The text from which to extract JSON data.</p> required <p>Returns:</p> Type Description <code>tuple[str, dict] | None</code> <p>dict | None: The extracted JSON dictionary if successful, otherwise None.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def extract_json_from_output(self, result_text: str) -&gt; tuple[str, dict] | None:\n    \"\"\"\n    Extracts JSON data from the given text by looking for content within\n    &lt;output&gt;...&lt;/output&gt; and &lt;analysis&gt;...&lt;/analysis&gt; tags. Strips any Markdown code block fences.\n\n    Args:\n        result_text (str): The text from which to extract JSON data.\n\n    Returns:\n        dict | None: The extracted JSON dictionary if successful, otherwise None.\n    \"\"\"\n    analysis, output_content = self._extract_output_content(result_text)\n    output_content = self._clean_output(output_content)\n\n    try:\n        data = json.loads(output_content)\n        return analysis, data\n    except json.JSONDecodeError as e:\n        error_message = f\"Orchestrator {self.name} - {self.id}: JSON decoding error: {e}\"\n        logger.error(error_message)\n        return None\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.generate_final_answer","title":"<code>generate_final_answer(task, config, **kwargs)</code>","text":"<p>Generates final answer using the manager agent logic.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>The task to be processed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The final answer generated after processing the task.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def generate_final_answer(self, task: str, config: RunnableConfig, **kwargs) -&gt; str:\n    \"\"\"\n    Generates final answer using the manager agent logic.\n\n    Args:\n        task (str): The task to be processed.\n        config (RunnableConfig): Configuration for the runnable.\n\n    Returns:\n        str: The final answer generated after processing the task.\n    \"\"\"\n    tasks_outputs = \"\\n\\n\".join(\n        f\"**Task:** {result['name']}\\n**Result:** {result['result']}\" for result in self._results.values() if result\n    )\n\n    if self.use_summarizer:\n        if not self.summarize_all_answers:\n            final_task_id = max(self._results.keys(), default=None)\n\n            if final_task_id is not None:\n                final_task_output = self._results[final_task_id].get(\"result\", \"\")\n                logger.debug(f\"Orchestrator {self.name} - {self.id}: Final task output: {final_task_output}\")\n                return final_task_output\n\n        final_result_content = self.get_final_result(\n            {\"input_task\": task, \"chat_history\": self._chat_history, \"tasks_outputs\": tasks_outputs},\n            config=config,\n            **kwargs,\n        )\n\n        try:\n            final_result = re.search(r\"&lt;final_answer&gt;(.*?)&lt;/final_answer&gt;\", final_result_content, re.DOTALL)\n            final_result_answer = final_result.group(1).strip()\n            return final_result_answer\n        except Exception as e:\n            error_response = f\"Orchestrator {self.name} - {self.id}: Error parsing final answer: {e}\"\n            logger.error(error_response)\n            if \"final_answer\" in final_result_content:\n                logger.info(f\"Orchestrator {self.name} - {self.id}: Return raw answer\")\n                return final_result_content\n            else:\n                raise ActionParseError(f\"{error_response}\")\n    return tasks_outputs\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.get_dependency_outputs","title":"<code>get_dependency_outputs(dependencies)</code>","text":"<p>Format the outputs of dependent tasks.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def get_dependency_outputs(self, dependencies: list[int]) -&gt; str:\n    \"\"\"Format the outputs of dependent tasks.\"\"\"\n    if not dependencies:\n        return \"\"\n\n    dependencies_formatted = \"**Here is the previously collected information:**\\n\"\n    for dep in dependencies:\n        if dep in self._results:\n            task_name = self._results[dep][\"name\"]\n            task_result = str(self._results[dep][\"result\"])\n            dependencies_formatted += f\"**Task:** {task_name}\\n**Result:** {task_result}\\n\\n\"\n\n    return dependencies_formatted.strip()\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.get_tasks","title":"<code>get_tasks(input_task, config=None, **kwargs)</code>","text":"<p>Generate tasks using the manager agent.</p> <p>Parameters:</p> Name Type Description Default <code>input_task</code> <code>str</code> <p>The input task to generate subtasks from</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the manager's run method</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[Task]</code> <p>list[Task]: List of generated tasks</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If task generation fails</p> <code>OrchestratorError</code> <p>If maximum number of retries is reached</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def get_tasks(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; list[Task]:\n    \"\"\"\n    Generate tasks using the manager agent.\n\n    Args:\n        input_task (str): The input task to generate subtasks from\n        config (RunnableConfig, optional): Configuration for the runnable\n        **kwargs: Additional keyword arguments passed to the manager's run method\n\n    Returns:\n        list[Task]: List of generated tasks\n\n    Raises:\n        ValueError: If task generation fails\n        OrchestratorError: If maximum number of retries is reached\n    \"\"\"\n    manager_result_content = \"\"\n    feedback = \"\"\n\n    for _ in range(self.max_plan_retries):\n        manager_result = self.manager.run(\n            input_data={\n                \"action\": \"plan\",\n                \"input_task\": input_task,\n                \"agents\": self.agents_descriptions,\n                \"feedback\": feedback,\n                \"previous_plan\": manager_result_content,\n            },\n            config=config,\n            run_depends=self._run_depends,\n            **kwargs,\n        )\n        self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n        if manager_result.status != RunnableStatus.SUCCESS:\n            error_message = f\"LLM '{self.manager.name}' failed: {manager_result.error.message}\"\n            raise ValueError(f\"Failed to generate tasks: {error_message}\")\n\n        manager_result_content = manager_result.output.get(\"content\").get(\"result\")\n        logger.info(\n            f\"Orchestrator {self.name} - {self.id}: Tasks generated by {self.manager.name} - {self.manager.id}:\"\n            f\"\\n{manager_result_content}\"\n        )\n        try:\n            tasks = self.parse_tasks_from_output(manager_result_content)\n            if self.manager.streaming.enabled and self.manager.streaming.mode == StreamingMode.ALL:\n                self.manager.stream_content(\n                    content={\"tasks\": tasks},\n                    step=\"manager_planning\",\n                    source=self.manager.name,\n                    config=config,\n                    **kwargs,\n                )\n\n        except ActionParseError as e:\n            feedback = str(e)\n            continue\n\n        if not self.plan_approval.enabled:\n            return tasks\n        else:\n            approval_result = self.send_approval_message(\n                self.plan_approval, {\"tasks\": tasks}, config=config, **kwargs\n            )\n\n            feedback = approval_result.feedback\n            if approval_result.is_approved:\n                return approval_result.data.get(\"tasks\")\n\n    raise OrchestratorError(\"Maximum number of loops reached for generating plan.\")\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize components for the manager and agents.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>Optional[ConnectionManager]</code> <p>The connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize components for the manager and agents.\n\n    Args:\n        connection_manager (Optional[ConnectionManager]): The connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.manager.is_postponed_component_init:\n        self.manager.init_components(connection_manager)\n\n    for agent in self.agents:\n        if agent.is_postponed_component_init:\n            agent.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.parse_tasks_from_output","title":"<code>parse_tasks_from_output(output)</code>","text":"<p>Parse tasks from the manager's output string.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def parse_tasks_from_output(self, output: str) -&gt; list[Task]:\n    \"\"\"Parse tasks from the manager's output string.\"\"\"\n\n    output_match = re.search(r\"&lt;output&gt;(.*?)&lt;/output&gt;\", output, re.DOTALL)\n    if not output_match:\n        error_response = f\"Error parsing final answer: No &lt;output&gt; tags found in the response {output}\"\n        raise ActionParseError(f\"Error: {error_response}\")\n\n    output_content = output_match.group(1).strip()\n\n    try:\n        output_content = self._clean_output(output_content)\n    except AttributeError as e:\n        logger.warning(\n            f\"Orchestrator {self.name} - {self.id}: \"\n            f\"Failed to remove code block markers and 'json' keyword \"\n            f\"from output {output_content} due to error: {e}\"\n        )\n\n    try:\n        task_list_json = output_content.strip()\n    except AttributeError as e:\n        logger.warning(\n            f\"Orchestrator {self.name} - {self.id}: Failed to strip the output {output_content} due to error: {e}\"\n        )\n        task_list_json = output_content\n    return TypeAdapter(list[Task]).validate_json(task_list_json)\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.run_flow","title":"<code>run_flow(input_task, config=None, **kwargs)</code>","text":"<p>Process the given task using the manager agent logic.</p> <p>Parameters:</p> Name Type Description Default <code>input_task</code> <code>str</code> <p>The task to be processed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: The final output generated after processing the task.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def run_flow(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Process the given task using the manager agent logic.\n\n    Args:\n        input_task (str): The task to be processed.\n        config (RunnableConfig): Configuration for the runnable.\n\n    Returns:\n        dict[str, Any]: The final output generated after processing the task.\n    \"\"\"\n    analysis = self._analyze_user_input(input_task, self.agents_descriptions, config=config, **kwargs)\n    decision = analysis.decision\n    message = analysis.message\n\n    if decision == Decision.RESPOND:\n        return {\"content\": message}\n    else:\n        tasks = self.get_tasks(input_task, config=config, **kwargs)\n        self.run_tasks(tasks=tasks, input_task=input_task, config=config, **kwargs)\n        return {\"content\": self.generate_final_answer(input_task, config, **kwargs)}\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.run_tasks","title":"<code>run_tasks(tasks, input_task, config=None, **kwargs)</code>","text":"<p>Execute the tasks using appropriate agents.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def run_tasks(self, tasks: list[Task], input_task: str, config: RunnableConfig = None, **kwargs) -&gt; None:\n    \"\"\"Execute the tasks using appropriate agents.\"\"\"\n\n    for count, task in enumerate(tasks, start=1):\n        task_per_llm = f\"**{task.description}**\\n**Required information for output**: {task.output}\"\n\n        dependency_outputs = self.get_dependency_outputs(task.dependencies)\n        if dependency_outputs:\n            task_per_llm += f\"\\n{dependency_outputs}\"\n\n        success_flag = False\n        for _ in range(self.manager.max_loops):\n            manager_result = self.manager.run(\n                input_data={\n                    \"action\": \"assign\",\n                    \"input_task\": input_task,\n                    \"task\": task_per_llm,\n                    \"agents\": self.agents_descriptions,\n                },\n                config=config,\n                run_depends=self._run_depends,\n                **kwargs,\n            )\n            self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n            if manager_result.status == RunnableStatus.SUCCESS:\n                assigned_agent_index = self._extract_agent_index(manager_result.output.get(\"content\", {}))\n\n                if 0 &lt;= assigned_agent_index &lt; len(self.agents):\n                    assigned_agent = self.agents[assigned_agent_index]\n\n                    if self.manager.streaming.enabled and self.manager.streaming.mode == StreamingMode.ALL:\n                        self.manager.stream_content(\n                            content={\"agent\": assigned_agent, \"task\": task},\n                            step=\"manager_assigning\",\n                            source=self.name,\n                            config=config,\n                            **kwargs,\n                        )\n\n                    logger.info(\n                        f\"Orchestrator {self.name} - {self.id}: Loop {count} - \"\n                        f\"Assigned agent: {assigned_agent.name} - {assigned_agent.id}\"\n                    )\n                    result = assigned_agent.run(\n                        input_data={\"input\": task_per_llm},\n                        config=config,\n                        run_depends=self._run_depends,\n                        **kwargs,\n                    )\n                    self._run_depends = [NodeDependency(node=assigned_agent).to_dict(for_tracing=True)]\n                    if result.status != RunnableStatus.SUCCESS:\n                        raise ValueError(\n                            f\"Failed to execute task {task.id}.{task.name} \"\n                            f\"by agent {assigned_agent_index}.{assigned_agent.name}\"\n                            f\"due to error: {result.error.message}\"\n                        )\n\n                    self._results[task.id] = {\n                        \"name\": task.name,\n                        \"result\": result.output[\"content\"],\n                    }\n\n                    success_flag = True\n                    break\n            task_per_llm += f\"Error occurred:{manager_result.error.to_dict()}\"\n\n        if success_flag:\n            continue\n\n        else:\n            raise ValueError(\n                f\"Orchestrator {self.name} - {self.id}: \"\n                f\"Failed to assign task {task.id}.{task.name} \"\n                f\"by Manager Agent due to error: \"\n                f\"{manager_result.error.to_dict() if manager_result.error else manager_result.output}\"\n            )\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.setup_streaming","title":"<code>setup_streaming()</code>","text":"<p>Setups streaming for orchestrator.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def setup_streaming(self) -&gt; None:\n    \"\"\"Setups streaming for orchestrator.\"\"\"\n    self.manager.streaming = self.streaming\n    for agent in self.agents:\n        agent.streaming = self.streaming\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.LinearOrchestrator.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"manager\"] = self.manager.to_dict(**kwargs)\n    data[\"agents\"] = [agent.to_dict(**kwargs) for agent in self.agents]\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear/#dynamiq.nodes.agents.orchestrators.linear.Task","title":"<code>Task</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a single task in the LinearOrchestrator system.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>int</code> <p>Unique identifier for the task</p> <code>name</code> <code>str</code> <p>Name of the task</p> <code>description</code> <code>str</code> <p>Detailed description of the task</p> <code>dependencies</code> <code>list[int]</code> <p>List of task IDs that this task depends on</p> <code>output</code> <code>Union[dict[str, Any], str]</code> <p>Expected output of the task, either as a structured dictionary or string</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear.py</code> <pre><code>class Task(BaseModel):\n    \"\"\"\n    Represents a single task in the LinearOrchestrator system.\n\n    Attributes:\n        id (int): Unique identifier for the task\n        name (str): Name of the task\n        description (str): Detailed description of the task\n        dependencies (list[int]): List of task IDs that this task depends on\n        output (Union[dict[str, Any], str]): Expected output of the task,\n            either as a structured dictionary or string\n    \"\"\"\n\n    id: int\n    name: str\n    description: str\n    dependencies: list[int]\n    output: dict[str, Any] | str\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear_manager/","title":"Linear manager","text":""},{"location":"dynamiq/nodes/agents/orchestrators/linear_manager/#dynamiq.nodes.agents.orchestrators.linear_manager.LinearAgentManager","title":"<code>LinearAgentManager</code>","text":"<p>               Bases: <code>AgentManager</code></p> <p>A specialized AgentManager that manages tasks in a linear, sequential order. It uses predefined prompts to plan tasks, assign them to the appropriate agents, and compile the final result.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear_manager.py</code> <pre><code>class LinearAgentManager(AgentManager):\n    \"\"\"\n    A specialized AgentManager that manages tasks in a linear, sequential order.\n    It uses predefined prompts to plan tasks, assign them to the appropriate agents,\n    and compile the final result.\n    \"\"\"\n\n    name: str = \"Linear Manager\"\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the LinearAgentManager and sets up the prompt blocks.\n        \"\"\"\n        super().__init__(**kwargs)\n        self._init_prompt_blocks()\n\n    def _init_actions(self):\n        \"\"\"\n        Extend default actions with 'respond'.\n        \"\"\"\n        super()._init_actions()\n        self._actions[\"handle_input\"] = self._handle_input\n\n    def _init_prompt_blocks(self):\n        \"\"\"\n        Initializes the prompt blocks used in the task planning, assigning,\n        and final answer generation processes.\n        \"\"\"\n        super()._init_prompt_blocks()\n        self._prompt_blocks.update(\n            {\n                \"plan\": self._get_linear_plan_prompt(),\n                \"assign\": self._get_linear_assign_prompt(),\n                \"final\": self._get_linear_final_prompt(),\n                \"handle_input\": self._get_linear_handle_input_prompt(),\n            }\n        )\n\n    @staticmethod\n    def _get_linear_plan_prompt() -&gt; str:\n        \"\"\"\n        Returns the prompt template for planning tasks.\n        \"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_LINEAR_PLAN\n\n    @staticmethod\n    def _get_linear_assign_prompt() -&gt; str:\n        \"\"\"\n        Returns the prompt template for assigning tasks to agents.\n        \"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_LINEAR_ASSIGN\n\n    @staticmethod\n    def _get_linear_final_prompt() -&gt; str:\n        \"\"\"\n        Returns the prompt template for generating the final answer.\n        \"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_LINEAR_FINAL_ANSWER\n\n    @staticmethod\n    def _get_linear_agent_run() -&gt; str:\n        \"\"\"\n        Returns the prompt template for question answering by Linear Manager.\n        \"\"\"\n        return PROMPT_TEMPLATE_MANAGER_LINEAR_RUN\n\n    @staticmethod\n    def _get_linear_handle_input_prompt() -&gt; str:\n        \"\"\"Determines how to handle input, either by continuing the flow or providing a direct response.\"\"\"\n        return PROMPT_TEMPLATE_AGENT_MANAGER_HANDLE_INPUT\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/linear_manager/#dynamiq.nodes.agents.orchestrators.linear_manager.LinearAgentManager.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the LinearAgentManager and sets up the prompt blocks.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/linear_manager.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the LinearAgentManager and sets up the prompt blocks.\n    \"\"\"\n    super().__init__(**kwargs)\n    self._init_prompt_blocks()\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/","title":"Orchestrator","text":""},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.ActionParseError","title":"<code>ActionParseError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Exception raised when an error occurs during action parsing.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>class ActionParseError(OrchestratorError):\n    \"\"\"Exception raised when an error occurs during action parsing.\"\"\"\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Decision","title":"<code>Decision</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration for possible decisions after analyzing the user input.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>class Decision(str, Enum):\n    \"\"\"\n    Enumeration for possible decisions after analyzing the user input.\n    \"\"\"\n\n    RESPOND = \"respond\"\n    PLAN = \"plan\"\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.DecisionResult","title":"<code>DecisionResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Holds the result of analyzing the user input.</p> <p>Attributes:</p> Name Type Description <code>decision</code> <code>Decision</code> <p>The decision on how to handle the input.</p> <code>message</code> <code>str</code> <p>The message or response associated with the decision.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>class DecisionResult(BaseModel):\n    \"\"\"\n    Holds the result of analyzing the user input.\n\n    Attributes:\n        decision (Decision): The decision on how to handle the input.\n        message (str): The message or response associated with the decision.\n    \"\"\"\n\n    decision: Decision\n    message: str\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Orchestrator","title":"<code>Orchestrator</code>","text":"<p>               Bases: <code>Node</code>, <code>ABC</code></p> <p>Orchestrates the execution of complex tasks using multiple specialized agents.</p> <p>This abstract base class provides the framework for orchestrating complex tasks through multiple agents. It manages the execution flow and communication between different specialized agents.</p> <p>Attributes:</p> Name Type Description <code>manager</code> <code>ManagerAgent</code> <p>The managing agent responsible for overseeing the orchestration process.</p> <code>objective</code> <code>Optional[str]</code> <p>The main objective of the orchestration.</p> Abstract Methods <p>run_flow: Processes the given task and returns the result. setup_streaming: Configures streaming functionality for the orchestrator.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>class Orchestrator(Node, ABC):\n    \"\"\"\n    Orchestrates the execution of complex tasks using multiple specialized agents.\n\n    This abstract base class provides the framework for orchestrating complex tasks\n    through multiple agents. It manages the execution flow and communication between\n    different specialized agents.\n\n    Attributes:\n        manager (ManagerAgent): The managing agent responsible for overseeing the orchestration process.\n        objective (Optional[str]): The main objective of the orchestration.\n\n    Abstract Methods:\n        run_flow: Processes the given task and returns the result.\n        setup_streaming: Configures streaming functionality for the orchestrator.\n    \"\"\"\n\n    name: str | None = \"Orchestrator\"\n    group: NodeGroup = NodeGroup.AGENTS\n    input_schema: ClassVar[type[OrchestratorInputSchema]] = OrchestratorInputSchema\n    manager: AgentManager\n    objective: str = \"\"\n    enable_handle_input: bool = True\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the orchestrator with given parameters.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        super().__init__(**kwargs)\n        self._run_depends = []\n        self._chat_history = []\n\n    def _clean_output(self, text: str) -&gt; str:\n        \"\"\"Remove Markdown code fences and extra whitespace from a text.\"\"\"\n        cleaned = re.sub(r\"^```(?:json)?\\s*|```$\", \"\", text).strip()\n        return cleaned\n\n    def extract_json_from_output(self, result_text: str) -&gt; tuple[str, dict] | None:\n        \"\"\"\n        Extracts JSON data from the given text by looking for content within\n        &lt;output&gt;...&lt;/output&gt; and &lt;analysis&gt;...&lt;/analysis&gt; tags. Strips any Markdown code block fences.\n\n        Args:\n            result_text (str): The text from which to extract JSON data.\n\n        Returns:\n            dict | None: The extracted JSON dictionary if successful, otherwise None.\n        \"\"\"\n        analysis, output_content = self._extract_output_content(result_text)\n        output_content = self._clean_output(output_content)\n\n        try:\n            data = json.loads(output_content)\n            return analysis, data\n        except json.JSONDecodeError as e:\n            error_message = f\"Orchestrator {self.name} - {self.id}: JSON decoding error: {e}\"\n            logger.error(error_message)\n            return None\n\n    def _analyze_user_input(\n        self, input_task: str, description: str, config: RunnableConfig = None, attempt: int = 1, **kwargs\n    ) -&gt; DecisionResult:\n        \"\"\"\n        Calls the manager's 'handle_input' action to decide if we should respond\n        immediately or proceed with a plan.\n\n        Args:\n            input_task (str): The user's input or task description.\n            description (str): Description of the orchestrator capabilities.\n            config: Optional configuration object passed to the manager's run method.\n            attempt (int): The current attempt number for analyzing user input.\n            **kwargs: Additional keyword arguments passed to the manager's run method.\n\n        Returns:\n            DecisionResult: An object containing the decision (as an Enum) and a message.\n        \"\"\"\n        if not self.enable_handle_input:\n            return DecisionResult(decision=Decision.PLAN, message=\"\")\n\n        handle_result = self.manager.run(\n            input_data={\n                \"action\": \"handle_input\",\n                \"task\": input_task,\n                \"description\": description,\n            },\n            config=config,\n            run_depends=[],\n            **kwargs,\n        )\n\n        if handle_result.status != RunnableStatus.SUCCESS:\n            error = handle_result.error.to_dict()\n            error_message = f\"Orchestrator {self.name} - {self.id}: Manager failed to analyze input: {error}\"\n            logger.error(error_message)\n            return DecisionResult(decision=Decision.RESPOND, message=f\"Error analyzing request: {error}\")\n\n        content = handle_result.output.get(\"content\", {})\n        raw_text = content.get(\"result\", \"\")\n        if not raw_text:\n            error_message = f\"Orchestrator {self.name} - {self.id}: No 'result' field in manager output.\"\n            logger.error(error_message)\n            return DecisionResult(decision=Decision.RESPOND, message=\"Manager did not return any result.\")\n\n        analysis, data = self.extract_json_from_output(result_text=raw_text)\n        if self.manager.streaming.enabled and self.manager.streaming.mode == StreamingMode.ALL:\n            self.manager.stream_content(\n                content={\"analysis\": analysis, \"data\": data},\n                step=\"manager_input_handling\",\n                source=self.name,\n                config=config,\n                **kwargs,\n            )\n\n        if not data:\n            error_message = f\"Orchestrator {self.name} - {self.id}: Failed to extract JSON from manager output.\"\n            logger.error(error_message)\n            if attempt &gt;= self.max_user_analyze_retries:\n                return DecisionResult(\n                    decision=Decision.RESPOND,\n                    message=\"Unable to extract valid JSON from manager output after multiple attempts.\",\n                )\n            _json_prompt_fix = \" Please provide a valid JSON response, inside &lt;output&gt;...&lt;/output&gt; tags.\"\n            return self._analyze_user_input(input_task + _json_prompt_fix, config=config, attempt=attempt + 1, **kwargs)\n\n        decision_str = data.get(\"decision\", Decision.RESPOND.value)\n        message = data.get(\"message\", \"\")\n\n        try:\n            decision = Decision(decision_str)\n        except ValueError:\n            warning_message = (\n                f\"Orchestrator {self.name} - {self.id}: Unrecognized decision '{decision_str}', defaulting to RESPOND.\"\n            )\n            logger.warning(warning_message)\n            decision = Decision.RESPOND\n\n        return DecisionResult(decision=decision, message=message)\n\n    def get_final_result(\n        self,\n        input_data: dict[str, str],\n        config: RunnableConfig = None,\n        **kwargs,\n    ) -&gt; str:\n        \"\"\"\n        Generate a comprehensive final result based on the provided data.\n\n        Args:\n            input_data (dict[str, str]): Input data for the manager.\n            config (RunnableConfig): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            str: The final comprehensive result.\n\n        Raises:\n            OrchestratorError: If an error occurs while generating the final answer.\n        \"\"\"\n        logger.debug(f\"Orchestrator {self.name} - {self.id}: Running final summarizer\")\n        manager_result = self.manager.run(\n            input_data={\"action\": \"final\", **input_data}, config=config, run_depends=self._run_depends, **kwargs\n        )\n        self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n        if manager_result.status != RunnableStatus.SUCCESS:\n            error_message = f\"Manager '{self.manager.name}' failed: {manager_result.error.message}\"\n            logger.error(f\"Orchestrator {self.name} - {self.id}: Error generating final, due to error: {error_message}\")\n            raise OrchestratorError(\n                f\"Orchestrator {self.name} - {self.id}: Error generating final, due to error: {error_message}\"\n            )\n\n        return manager_result.output.get(\"content\").get(\"result\")\n\n    def reset_run_state(self):\n        self._run_depends = []\n        self._chat_history = []\n\n    @abstractmethod\n    def run_flow(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Process the given task.\n\n        Args:\n            input_task (str): The task to be processed.\n            config (RunnableConfig): Configuration for the runnable.\n\n        Returns:\n            dict[str, Any]: The final output generated after processing the task.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def setup_streaming(self) -&gt; None:\n        \"\"\"Setups streaming for orchestrator.\"\"\"\n        pass\n\n    def execute(self, input_data: OrchestratorInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict:\n        \"\"\"\n        Execute orchestrator flow.\n\n        Args:\n            input_data (OrchestratorInputSchema): The input data containing the objective.\n            config (Optional[RunnableConfig]): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: The result of the orchestration process.\n\n        Raises:\n            OrchestratorError: If the orchestration process fails.\n        \"\"\"\n        logger.info(f\"Orchestrator {self.name} - {self.id}: started with INPUT DATA:\\n{input_data}\")\n        self.reset_run_state()\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        input_task = input_data.input or self.objective\n\n        kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n        kwargs.pop(\"run_depends\", None)\n\n        if self.streaming.enabled:\n            self.setup_streaming()\n\n        output = self.run_flow(\n            input_task=input_task,\n            config=config,\n            **kwargs,\n        )\n\n        logger.info(f\"Orchestrator {self.name} - {self.id}: finished with RESULT:\\n{str(output)[:200]}...\")\n        return output\n\n    def parse_xml_content(self, text: str, tag: str) -&gt; str:\n        \"\"\"Extract content from XML-like tags.\"\"\"\n        match = re.search(f\"&lt;{tag}&gt;(.*?)&lt;/{tag}&gt;\", text, re.DOTALL)\n        return match.group(1).strip() if match else \"\"\n\n    def _extract_output_content(self, text: str) -&gt; tuple[str, str]:\n        \"\"\"\n        Extracts the content of the &lt;analysis&gt; and &lt;output&gt; tags. If a properly closed tag is not found,\n        fall back to extracting everything after the first occurrence of &lt;output&gt;.\n        \"\"\"\n\n        output = self.parse_xml_content(text, \"output\")\n        analysis = self.parse_xml_content(text, \"analysis\")\n\n        if output:\n            return analysis, output\n\n        start = text.find(\"&lt;output&gt;\")\n        if start != -1:\n            fallback_content = text[start + len(\"&lt;output&gt;\") :].strip()\n            if fallback_content:\n                return analysis, fallback_content\n        raise ActionParseError(\"No &lt;output&gt; tags found in the response.\")\n\n    def _clean_content(self, content: str) -&gt; LET.Element:\n        \"\"\"\n        Clean and parse XML content by removing code block markers and wrapping in a root element.\n\n        Args:\n            content (str): The input string containing XML content, possibly with code block markers.\n\n        Returns:\n            LET.Element: A parsed XML element tree with the cleaned content wrapped in a root element.\n\n        Note:\n            - Removes triple backticks (```) from the content\n            - Wraps the content in a &lt;root&gt; element for proper XML parsing\n            - Uses a lenient XML parser that attempts to recover from malformed XML\n        \"\"\"\n        cleaned_content = content.replace(\"```\", \"\").strip()\n        wrapped_content = f\"&lt;root&gt;{cleaned_content}&lt;/root&gt;\"\n        parser = LET.XMLParser(recover=True)  # nosec B320\n        return LET.fromstring(wrapped_content, parser=parser)  # nosec B320\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Orchestrator.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the orchestrator with given parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the orchestrator with given parameters.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    super().__init__(**kwargs)\n    self._run_depends = []\n    self._chat_history = []\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Orchestrator.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute orchestrator flow.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>OrchestratorInputSchema</code> <p>The input data containing the objective.</p> required <code>config</code> <code>Optional[RunnableConfig]</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dict[str, Any]: The result of the orchestration process.</p> <p>Raises:</p> Type Description <code>OrchestratorError</code> <p>If the orchestration process fails.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>def execute(self, input_data: OrchestratorInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict:\n    \"\"\"\n    Execute orchestrator flow.\n\n    Args:\n        input_data (OrchestratorInputSchema): The input data containing the objective.\n        config (Optional[RunnableConfig]): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: The result of the orchestration process.\n\n    Raises:\n        OrchestratorError: If the orchestration process fails.\n    \"\"\"\n    logger.info(f\"Orchestrator {self.name} - {self.id}: started with INPUT DATA:\\n{input_data}\")\n    self.reset_run_state()\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    input_task = input_data.input or self.objective\n\n    kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n    kwargs.pop(\"run_depends\", None)\n\n    if self.streaming.enabled:\n        self.setup_streaming()\n\n    output = self.run_flow(\n        input_task=input_task,\n        config=config,\n        **kwargs,\n    )\n\n    logger.info(f\"Orchestrator {self.name} - {self.id}: finished with RESULT:\\n{str(output)[:200]}...\")\n    return output\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Orchestrator.extract_json_from_output","title":"<code>extract_json_from_output(result_text)</code>","text":"<p>Extracts JSON data from the given text by looking for content within</p> ... <p>and ... tags. Strips any Markdown code block fences.</p> <p>Parameters:</p> Name Type Description Default <code>result_text</code> <code>str</code> <p>The text from which to extract JSON data.</p> required <p>Returns:</p> Type Description <code>tuple[str, dict] | None</code> <p>dict | None: The extracted JSON dictionary if successful, otherwise None.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>def extract_json_from_output(self, result_text: str) -&gt; tuple[str, dict] | None:\n    \"\"\"\n    Extracts JSON data from the given text by looking for content within\n    &lt;output&gt;...&lt;/output&gt; and &lt;analysis&gt;...&lt;/analysis&gt; tags. Strips any Markdown code block fences.\n\n    Args:\n        result_text (str): The text from which to extract JSON data.\n\n    Returns:\n        dict | None: The extracted JSON dictionary if successful, otherwise None.\n    \"\"\"\n    analysis, output_content = self._extract_output_content(result_text)\n    output_content = self._clean_output(output_content)\n\n    try:\n        data = json.loads(output_content)\n        return analysis, data\n    except json.JSONDecodeError as e:\n        error_message = f\"Orchestrator {self.name} - {self.id}: JSON decoding error: {e}\"\n        logger.error(error_message)\n        return None\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Orchestrator.get_final_result","title":"<code>get_final_result(input_data, config=None, **kwargs)</code>","text":"<p>Generate a comprehensive final result based on the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, str]</code> <p>Input data for the manager.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The final comprehensive result.</p> <p>Raises:</p> Type Description <code>OrchestratorError</code> <p>If an error occurs while generating the final answer.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>def get_final_result(\n    self,\n    input_data: dict[str, str],\n    config: RunnableConfig = None,\n    **kwargs,\n) -&gt; str:\n    \"\"\"\n    Generate a comprehensive final result based on the provided data.\n\n    Args:\n        input_data (dict[str, str]): Input data for the manager.\n        config (RunnableConfig): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        str: The final comprehensive result.\n\n    Raises:\n        OrchestratorError: If an error occurs while generating the final answer.\n    \"\"\"\n    logger.debug(f\"Orchestrator {self.name} - {self.id}: Running final summarizer\")\n    manager_result = self.manager.run(\n        input_data={\"action\": \"final\", **input_data}, config=config, run_depends=self._run_depends, **kwargs\n    )\n    self._run_depends = [NodeDependency(node=self.manager).to_dict(for_tracing=True)]\n\n    if manager_result.status != RunnableStatus.SUCCESS:\n        error_message = f\"Manager '{self.manager.name}' failed: {manager_result.error.message}\"\n        logger.error(f\"Orchestrator {self.name} - {self.id}: Error generating final, due to error: {error_message}\")\n        raise OrchestratorError(\n            f\"Orchestrator {self.name} - {self.id}: Error generating final, due to error: {error_message}\"\n        )\n\n    return manager_result.output.get(\"content\").get(\"result\")\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Orchestrator.parse_xml_content","title":"<code>parse_xml_content(text, tag)</code>","text":"<p>Extract content from XML-like tags.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>def parse_xml_content(self, text: str, tag: str) -&gt; str:\n    \"\"\"Extract content from XML-like tags.\"\"\"\n    match = re.search(f\"&lt;{tag}&gt;(.*?)&lt;/{tag}&gt;\", text, re.DOTALL)\n    return match.group(1).strip() if match else \"\"\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Orchestrator.run_flow","title":"<code>run_flow(input_task, config=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Process the given task.</p> <p>Parameters:</p> Name Type Description Default <code>input_task</code> <code>str</code> <p>The task to be processed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: The final output generated after processing the task.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>@abstractmethod\ndef run_flow(self, input_task: str, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Process the given task.\n\n    Args:\n        input_task (str): The task to be processed.\n        config (RunnableConfig): Configuration for the runnable.\n\n    Returns:\n        dict[str, Any]: The final output generated after processing the task.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.Orchestrator.setup_streaming","title":"<code>setup_streaming()</code>  <code>abstractmethod</code>","text":"<p>Setups streaming for orchestrator.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>@abstractmethod\ndef setup_streaming(self) -&gt; None:\n    \"\"\"Setups streaming for orchestrator.\"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/agents/orchestrators/orchestrator/#dynamiq.nodes.agents.orchestrators.orchestrator.OrchestratorError","title":"<code>OrchestratorError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for Orchestrator errors.</p> Source code in <code>dynamiq/nodes/agents/orchestrators/orchestrator.py</code> <pre><code>class OrchestratorError(Exception):\n    \"\"\"Base exception for Orchestrator errors.\"\"\"\n</code></pre>"},{"location":"dynamiq/nodes/audio/elevenlabs/","title":"Elevenlabs","text":""},{"location":"dynamiq/nodes/audio/elevenlabs/#dynamiq.nodes.audio.elevenlabs.ElevenLabsSTS","title":"<code>ElevenLabsSTS</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A component for vocalizing text using the ElevenLabs API.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[AUDIO]</code> <p>The group the node belongs to. name (str): The name of the node.</p> <code>connection</code> <code>ElevenLabs | None</code> <p>The connection to the ElevenLabs API. A new connection is created if none is provided.</p> <code>voice_id</code> <code>Voices | str | None</code> <p>The voice identifier, that should be used for vocalizing.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Error handling configuration.</p> <code>model(str)</code> <code>ErrorHandling</code> <p>The model for vocalizing, defaults to \"eleven_english_sts_v2\".</p> <code>stability(float)</code> <code>ErrorHandling</code> <p>The slider determines how stable the voice is and the randomness between each generation.</p> <code>similarity_boost(float)</code> <code>ErrorHandling</code> <p>The slider dictates how closely the AI should adhere to the original voice when attempting to replicate it.</p> <code>style(float)</code> <code>ErrorHandling</code> <p>The setting that attempts to amplify the style of the original speaker.</p> <code>use_speaker_boost(bool)</code> <code>ErrorHandling</code> <p>The setting for boosting the similarity to the original speaker</p> Source code in <code>dynamiq/nodes/audio/elevenlabs.py</code> <pre><code>class ElevenLabsSTS(ConnectionNode):\n    \"\"\"\n    A component for vocalizing text using the ElevenLabs API.\n\n    Attributes:\n        group (Literal[NodeGroup.AUDIO]): The group the node belongs to. name (str): The name of the node.\n        connection (ElevenLabsConnection | None): The connection to the ElevenLabs API. A new connection is created if\n            none is provided.\n        voice_id: The voice identifier, that should be used for vocalizing.\n        error_handling (ErrorHandling): Error handling configuration.\n        model(str): The model for vocalizing, defaults to \"eleven_english_sts_v2\".\n        stability(float): The slider determines how stable the voice is and the randomness\n            between each generation.\n        similarity_boost(float): The slider dictates how closely the AI should adhere to the original voice when\n            attempting to replicate it.\n        style(float): The setting that attempts to amplify the style of the original speaker.\n        use_speaker_boost(bool):The setting for boosting the similarity to the original speaker\n    \"\"\"\n\n    group: Literal[NodeGroup.AUDIO] = NodeGroup.AUDIO\n    name: str = \"ElevenLabsSTS\"\n    voice_id: Voices | str | None = Voices.Rachel\n    connection: ElevenLabsConnection | None = None\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=600))\n    model: str = \"eleven_english_sts_v2\"\n    stability: float = 0.5\n    similarity_boost: float = 0.5\n    style: float = 0\n    use_speaker_boost: bool = True\n    input_schema: ClassVar[type[ElevenLabsSTSInputSchema]] = ElevenLabsSTSInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the ElevenLabs audio generation.\n\n        If neither client nor connection is provided in kwargs, a new ElevenLabs connection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = ElevenLabsConnection()\n        super().__init__(**kwargs)\n\n    def execute(\n        self, input_data: ElevenLabsSTSInputSchema, config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, bytes]:\n        \"\"\"Execute the audio generation process.\n\n        This method takes input data and returns the result.\n\n        Args:\n            input_data (dict[str, Any]): The input data containing audio that should be vocalized. Audio\n                can be BytesIO or bytes format only.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n             dict: A dictionary with the following key:\n                - \"content\" (bytes): Bytes containing the audio generation result.\n        \"\"\"\n        input_dict = {\n            \"model_id\": self.model,\n            \"voice_settings\": json.dumps(\n                {\n                    \"stability\": self.stability,\n                    \"similarity_boost\": self.similarity_boost,\n                    \"style\": self.style,\n                    \"use_speaker_boost\": self.use_speaker_boost,\n                }\n            ),\n        }\n        audio = input_data.audio\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n        response = self.client.request(\n            method=self.connection.method,\n            url=format_url(\"speech-to-speech/\", self.connection.url, self.voice_id),\n            headers=self.connection.headers,\n            data=input_dict | self.connection.data,\n            files={\"audio\": audio},\n        )\n        if response.status_code != 200:\n            response.raise_for_status()\n        return {\n            \"content\": response.content,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/audio/elevenlabs/#dynamiq.nodes.audio.elevenlabs.ElevenLabsSTS.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the ElevenLabs audio generation.</p> <p>If neither client nor connection is provided in kwargs, a new ElevenLabs connection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/audio/elevenlabs.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the ElevenLabs audio generation.\n\n    If neither client nor connection is provided in kwargs, a new ElevenLabs connection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = ElevenLabsConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/audio/elevenlabs/#dynamiq.nodes.audio.elevenlabs.ElevenLabsSTS.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the audio generation process.</p> <p>This method takes input data and returns the result.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>The input data containing audio that should be vocalized. Audio can be BytesIO or bytes format only.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, bytes]</code> <p>A dictionary with the following key: - \"content\" (bytes): Bytes containing the audio generation result.</p> Source code in <code>dynamiq/nodes/audio/elevenlabs.py</code> <pre><code>def execute(\n    self, input_data: ElevenLabsSTSInputSchema, config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, bytes]:\n    \"\"\"Execute the audio generation process.\n\n    This method takes input data and returns the result.\n\n    Args:\n        input_data (dict[str, Any]): The input data containing audio that should be vocalized. Audio\n            can be BytesIO or bytes format only.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n         dict: A dictionary with the following key:\n            - \"content\" (bytes): Bytes containing the audio generation result.\n    \"\"\"\n    input_dict = {\n        \"model_id\": self.model,\n        \"voice_settings\": json.dumps(\n            {\n                \"stability\": self.stability,\n                \"similarity_boost\": self.similarity_boost,\n                \"style\": self.style,\n                \"use_speaker_boost\": self.use_speaker_boost,\n            }\n        ),\n    }\n    audio = input_data.audio\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n    response = self.client.request(\n        method=self.connection.method,\n        url=format_url(\"speech-to-speech/\", self.connection.url, self.voice_id),\n        headers=self.connection.headers,\n        data=input_dict | self.connection.data,\n        files={\"audio\": audio},\n    )\n    if response.status_code != 200:\n        response.raise_for_status()\n    return {\n        \"content\": response.content,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/audio/elevenlabs/#dynamiq.nodes.audio.elevenlabs.ElevenLabsTTS","title":"<code>ElevenLabsTTS</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A component for vocalizing text using the ElevenLabs API.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[AUDIO]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>ElevenLabs | None</code> <p>The connection to the ElevenLabs API. A new connection is created if none is provided.</p> <code>voice_id</code> <code>Voices | str | None</code> <p>The voice identifier, that should be used for vocalizing.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Error handling configuration.</p> <code>model(str)</code> <code>ErrorHandling</code> <p>The model for vocalizing, defaults to \"eleven_monolingual_v1\"</p> <code>stability(float)</code> <code>ErrorHandling</code> <p>The slider determines how stable the voice is and the randomness</p> <code>similarity_boost(float)</code> <code>ErrorHandling</code> <p>The slider dictates how closely the AI should adhere to the original voice when</p> <code>style(float)</code> <code>ErrorHandling</code> <p>The setting that attempts to amplify the style of the original speaker.</p> <code>use_speaker_boost(bool)</code> <code>ErrorHandling</code> <p>The setting for boosting the similarity to the original speaker</p> Source code in <code>dynamiq/nodes/audio/elevenlabs.py</code> <pre><code>class ElevenLabsTTS(ConnectionNode):\n    \"\"\"\n    A component for vocalizing text using the ElevenLabs API.\n\n    Attributes:\n        group (Literal[NodeGroup.AUDIO]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (ElevenLabsConnection | None): The connection to the ElevenLabs API. A new connection\n            is created if none is provided.\n        voice_id: The voice identifier, that should be used for vocalizing.\n        error_handling (ErrorHandling): Error handling configuration.\n        model(str): The model for vocalizing, defaults to \"eleven_monolingual_v1\"\n        stability(float): The slider determines how stable the voice is and the randomness\n        between each generation.\n        similarity_boost(float): The slider dictates how closely the AI should adhere to the original voice when\n        attempting to replicate it.\n        style(float): The setting that attempts to amplify the style of the original speaker.\n        use_speaker_boost(bool):The setting for boosting the similarity to the original speaker\n    \"\"\"\n\n    group: Literal[NodeGroup.AUDIO] = NodeGroup.AUDIO\n    name: str = \"ElevenLabsTTS\"\n    voice_id: Voices | str | None = Voices.Rachel\n    connection: ElevenLabsConnection | None = None\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=600))\n    model: str = \"eleven_monolingual_v1\"\n    stability: float = 0.5\n    similarity_boost: float = 0.5\n    style: float = 0\n    use_speaker_boost: bool = True\n    input_schema: ClassVar[type[ElevenLabsTTSInputSchema]] = ElevenLabsTTSInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the ElevenLabs audio generation.\n\n        If neither client nor connection is provided in kwargs, a new ElevenLabs connection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = ElevenLabsConnection()\n        super().__init__(**kwargs)\n\n    def execute(\n        self, input_data: ElevenLabsTTSInputSchema, config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, bytes]:\n        \"\"\"Execute the audio generation process.\n\n        This method takes input data and returns the result.\n\n        Args:\n            input_data (ElevenLabsTTSInputSchema): The input data containing the text.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n             dict: A dictionary with the following key:\n                - \"content\" (bytes): Bytes containing the audio generation result.\n        \"\"\"\n        input_dict = {\n            \"model_id\": self.model,\n            \"text\": input_data.text,\n            \"voice_settings\": {\n                \"stability\": self.stability,\n                \"similarity_boost\": self.similarity_boost,\n                \"style\": self.style,\n                \"use_speaker_boost\": self.use_speaker_boost,\n            },\n        }\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n        response = self.client.request(\n            method=self.connection.method,\n            url=format_url(\"text-to-speech/\", self.connection.url, self.voice_id),\n            json={**input_dict, **self.connection.data},\n            headers=self.connection.headers,\n        )\n        if response.status_code != 200:\n            response.raise_for_status()\n        return {\n            \"content\": response.content,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/audio/elevenlabs/#dynamiq.nodes.audio.elevenlabs.ElevenLabsTTS.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the ElevenLabs audio generation.</p> <p>If neither client nor connection is provided in kwargs, a new ElevenLabs connection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/audio/elevenlabs.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the ElevenLabs audio generation.\n\n    If neither client nor connection is provided in kwargs, a new ElevenLabs connection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = ElevenLabsConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/audio/elevenlabs/#dynamiq.nodes.audio.elevenlabs.ElevenLabsTTS.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the audio generation process.</p> <p>This method takes input data and returns the result.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ElevenLabsTTSInputSchema</code> <p>The input data containing the text.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, bytes]</code> <p>A dictionary with the following key: - \"content\" (bytes): Bytes containing the audio generation result.</p> Source code in <code>dynamiq/nodes/audio/elevenlabs.py</code> <pre><code>def execute(\n    self, input_data: ElevenLabsTTSInputSchema, config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, bytes]:\n    \"\"\"Execute the audio generation process.\n\n    This method takes input data and returns the result.\n\n    Args:\n        input_data (ElevenLabsTTSInputSchema): The input data containing the text.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n         dict: A dictionary with the following key:\n            - \"content\" (bytes): Bytes containing the audio generation result.\n    \"\"\"\n    input_dict = {\n        \"model_id\": self.model,\n        \"text\": input_data.text,\n        \"voice_settings\": {\n            \"stability\": self.stability,\n            \"similarity_boost\": self.similarity_boost,\n            \"style\": self.style,\n            \"use_speaker_boost\": self.use_speaker_boost,\n        },\n    }\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n    response = self.client.request(\n        method=self.connection.method,\n        url=format_url(\"text-to-speech/\", self.connection.url, self.voice_id),\n        json={**input_dict, **self.connection.data},\n        headers=self.connection.headers,\n    )\n    if response.status_code != 200:\n        response.raise_for_status()\n    return {\n        \"content\": response.content,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/audio/elevenlabs/#dynamiq.nodes.audio.elevenlabs.format_url","title":"<code>format_url(method, url, voice_id)</code>","text":"<p>Formats the given URL by including the <code>voice_id</code> if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>type of request for vocalizer</p> required <code>voice_id</code> <code>str</code> <p>voice id for vocalizer.</p> required <code>url</code> <code>str</code> <p>The URL to format.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The modified URL.</p> Source code in <code>dynamiq/nodes/audio/elevenlabs.py</code> <pre><code>def format_url(method: str, url: str, voice_id: str) -&gt; str:\n    \"\"\"Formats the given URL by including the `voice_id` if necessary.\n\n    Args:\n        method: type of request for vocalizer\n        voice_id: voice id for vocalizer.\n        url (str): The URL to format.\n\n    Returns:\n        str: The modified URL.\n    \"\"\"\n    if url.rstrip(\"/\").endswith(\"v1\"):\n        url = urljoin(url, method)\n    if \"{voice_id}\" in url:\n        url = url.format(voice_id=voice_id)\n    elif url.rstrip(\"/\").endswith(\"text-to-speech\") or url.rstrip(\"/\").endswith(\n        \"speech-to-speech\"\n    ):\n        url = urljoin(url, voice_id)\n    return url\n</code></pre>"},{"location":"dynamiq/nodes/audio/whisper/","title":"Whisper","text":""},{"location":"dynamiq/nodes/audio/whisper/#dynamiq.nodes.audio.whisper.WhisperSTT","title":"<code>WhisperSTT</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A component for transcribing audio files using the Whisper speech recognition system.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[AUDIO]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Whisper | None</code> <p>The connection to the Whisper API.A new connection is created if none is provided.</p> <code>client</code> <code>OpenAIClient | None</code> <p>The OpenAI client instance.</p> <code>model</code> <code>str</code> <p>The model name to use for transcribing.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Error handling configuration.</p> Source code in <code>dynamiq/nodes/audio/whisper.py</code> <pre><code>class WhisperSTT(ConnectionNode):\n    \"\"\"\n    A component for transcribing audio files using the Whisper speech recognition system.\n\n    Attributes:\n        group (Literal[NodeGroup.AUDIO]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (WhisperConnection | None): The connection to the Whisper API.A new connection\n            is created if none is provided.\n        client (OpenAIClient | None): The OpenAI client instance.\n        model (str): The model name to use for transcribing.\n        error_handling (ErrorHandling): Error handling configuration.\n    \"\"\"\n\n    group: Literal[NodeGroup.AUDIO] = NodeGroup.AUDIO\n    name: str = \"Whisper\"\n    model: str\n    connection: WhisperConnection | OpenAIConnection | None = None\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=600))\n    default_file_name: str = DEFAULT_FILE_NAME\n    default_content_type: str = DEFAULT_CONTENT_TYPE\n    input_schema: ClassVar[type[WhisperSTTInputSchema]] = WhisperSTTInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Whisper transcriber.\n\n        If neither client nor connection is provided in kwargs, a new Whisper connection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = WhisperConnection()\n        super().__init__(**kwargs)\n\n    def execute(self, input_data: WhisperSTTInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"Execute the audio transcribing process.\n\n        This method takes input data, modifies it(if necessary), and returns the result.\n\n        Args:\n            input_data (WhisperSTTInputSchema): The input data containing the audio.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            str: A string containing the transcribe result.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        audio = input_data.audio\n        if isinstance(audio, bytes):\n            audio = io.BytesIO(audio)\n\n        if not isinstance(audio, io.BytesIO):\n            raise ValueError(\"Audio must be a BytesIO object or bytes.\")\n\n        audio.name = getattr(audio, \"name\", self.default_file_name)\n        audio.content_type = getattr(audio, \"content_type\", self.default_content_type)\n\n        if isinstance(self.connection, WhisperConnection):\n            transcription = self.get_transcription_with_http_request(model=self.model, audio=audio)\n        elif isinstance(self.connection, OpenAIConnection):\n            transcription = self.get_transcription_with_openai_client(model=self.model, audio=audio)\n        else:\n            raise ValueError(f\"Connection type {type(self.connection)} does not fit required ones.\")\n\n        return {\"content\": transcription.get(\"text\", \"\")}\n\n    def get_transcription_with_http_request(self, model: str, audio: io.BytesIO):\n        \"\"\"Get the audio transcription by request.\n\n        This method takes whisper model and audio file, sends request with defined params, and returns the\n        transcription.\n\n        Args:\n            model(str): The model used for transcribing.\n            audio(io.BytesIO): The audio file in BytesIO that should be transcribed\n        Returns:\n            dict: transcription result.\n        \"\"\"\n        connection_url = urljoin(self.connection.url, \"audio/transcriptions\")\n        response = self.client.request(\n            method=self.connection.method,\n            url=connection_url,\n            headers=self.connection.headers,\n            params=self.connection.params,\n            data=self.connection.data | {\"model\": model},\n            files={\"file\": (audio.name, audio, audio.content_type)},\n        )\n        if response.status_code != 200:\n            response.raise_for_status()\n\n        return response.json()\n\n    def get_transcription_with_openai_client(self, model: str, audio: io.BytesIO):\n        \"\"\"Get the audio transcription by request.\n\n        This method takes whisper model and audio file, sends request with defined params, and returns the\n        transcription.\n\n        Args:\n            model(str): The model used for transcribing.\n            audio(io.BytesIO): The audio file in BytesIO that should be transcribed\n        Returns:\n            dict: transcription result.\n        \"\"\"\n        response = self.client.audio.transcriptions.create(model=model, file=audio)\n\n        return {\"text\": response.text}\n</code></pre>"},{"location":"dynamiq/nodes/audio/whisper/#dynamiq.nodes.audio.whisper.WhisperSTT.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Whisper transcriber.</p> <p>If neither client nor connection is provided in kwargs, a new Whisper connection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/audio/whisper.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Whisper transcriber.\n\n    If neither client nor connection is provided in kwargs, a new Whisper connection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = WhisperConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/audio/whisper/#dynamiq.nodes.audio.whisper.WhisperSTT.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the audio transcribing process.</p> <p>This method takes input data, modifies it(if necessary), and returns the result.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>WhisperSTTInputSchema</code> <p>The input data containing the audio.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <p>A string containing the transcribe result.</p> Source code in <code>dynamiq/nodes/audio/whisper.py</code> <pre><code>def execute(self, input_data: WhisperSTTInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"Execute the audio transcribing process.\n\n    This method takes input data, modifies it(if necessary), and returns the result.\n\n    Args:\n        input_data (WhisperSTTInputSchema): The input data containing the audio.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        str: A string containing the transcribe result.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    audio = input_data.audio\n    if isinstance(audio, bytes):\n        audio = io.BytesIO(audio)\n\n    if not isinstance(audio, io.BytesIO):\n        raise ValueError(\"Audio must be a BytesIO object or bytes.\")\n\n    audio.name = getattr(audio, \"name\", self.default_file_name)\n    audio.content_type = getattr(audio, \"content_type\", self.default_content_type)\n\n    if isinstance(self.connection, WhisperConnection):\n        transcription = self.get_transcription_with_http_request(model=self.model, audio=audio)\n    elif isinstance(self.connection, OpenAIConnection):\n        transcription = self.get_transcription_with_openai_client(model=self.model, audio=audio)\n    else:\n        raise ValueError(f\"Connection type {type(self.connection)} does not fit required ones.\")\n\n    return {\"content\": transcription.get(\"text\", \"\")}\n</code></pre>"},{"location":"dynamiq/nodes/audio/whisper/#dynamiq.nodes.audio.whisper.WhisperSTT.get_transcription_with_http_request","title":"<code>get_transcription_with_http_request(model, audio)</code>","text":"<p>Get the audio transcription by request.</p> <p>This method takes whisper model and audio file, sends request with defined params, and returns the transcription.</p> <p>Parameters:</p> Name Type Description Default <code>model(str)</code> <p>The model used for transcribing.</p> required <code>audio(io.BytesIO)</code> <p>The audio file in BytesIO that should be transcribed</p> required <p>Returns:     dict: transcription result.</p> Source code in <code>dynamiq/nodes/audio/whisper.py</code> <pre><code>def get_transcription_with_http_request(self, model: str, audio: io.BytesIO):\n    \"\"\"Get the audio transcription by request.\n\n    This method takes whisper model and audio file, sends request with defined params, and returns the\n    transcription.\n\n    Args:\n        model(str): The model used for transcribing.\n        audio(io.BytesIO): The audio file in BytesIO that should be transcribed\n    Returns:\n        dict: transcription result.\n    \"\"\"\n    connection_url = urljoin(self.connection.url, \"audio/transcriptions\")\n    response = self.client.request(\n        method=self.connection.method,\n        url=connection_url,\n        headers=self.connection.headers,\n        params=self.connection.params,\n        data=self.connection.data | {\"model\": model},\n        files={\"file\": (audio.name, audio, audio.content_type)},\n    )\n    if response.status_code != 200:\n        response.raise_for_status()\n\n    return response.json()\n</code></pre>"},{"location":"dynamiq/nodes/audio/whisper/#dynamiq.nodes.audio.whisper.WhisperSTT.get_transcription_with_openai_client","title":"<code>get_transcription_with_openai_client(model, audio)</code>","text":"<p>Get the audio transcription by request.</p> <p>This method takes whisper model and audio file, sends request with defined params, and returns the transcription.</p> <p>Parameters:</p> Name Type Description Default <code>model(str)</code> <p>The model used for transcribing.</p> required <code>audio(io.BytesIO)</code> <p>The audio file in BytesIO that should be transcribed</p> required <p>Returns:     dict: transcription result.</p> Source code in <code>dynamiq/nodes/audio/whisper.py</code> <pre><code>def get_transcription_with_openai_client(self, model: str, audio: io.BytesIO):\n    \"\"\"Get the audio transcription by request.\n\n    This method takes whisper model and audio file, sends request with defined params, and returns the\n    transcription.\n\n    Args:\n        model(str): The model used for transcribing.\n        audio(io.BytesIO): The audio file in BytesIO that should be transcribed\n    Returns:\n        dict: transcription result.\n    \"\"\"\n    response = self.client.audio.transcriptions.create(model=model, file=audio)\n\n    return {\"text\": response.text}\n</code></pre>"},{"location":"dynamiq/nodes/converters/csv/","title":"Csv","text":""},{"location":"dynamiq/nodes/converters/csv/#dynamiq.nodes.converters.csv.CSVConverter","title":"<code>CSVConverter</code>","text":"<p>               Bases: <code>Node</code></p> <p>A Node that converts CSV files into a standardized document format.</p> <p>This converter processes CSV files from either file paths or file objects, extracting specified content and metadata columns into a structured document format. Each row in the CSV becomes a document with content from the specified content column and metadata from the specified metadata columns.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Display name of the node.</p> <code>group</code> <code>CONVERTERS</code> <p>Node group classification.</p> <code>delimiter</code> <code>str | None</code> <p>Character used to separate fields in the CSV files. Defaults to comma.</p> <code>content_column</code> <code>str | None</code> <p>Name of the column to use as the main document content.</p> <code>metadata_columns</code> <code>list[str] | None</code> <p>Column names to extract as metadata for each document.</p> <code>input_schema</code> <code>type[CSVConverterInputSchema]</code> <p>Schema for validating input parameters.</p> Source code in <code>dynamiq/nodes/converters/csv.py</code> <pre><code>class CSVConverter(Node):\n    \"\"\"\n    A Node that converts CSV files into a standardized document format.\n\n    This converter processes CSV files from either file paths or file objects,\n    extracting specified content and metadata columns into a structured document format.\n    Each row in the CSV becomes a document with content from the specified content column\n    and metadata from the specified metadata columns.\n\n    Attributes:\n        name (str): Display name of the node.\n        group (NodeGroup.CONVERTERS): Node group classification.\n        delimiter (str | None): Character used to separate fields in the CSV files. Defaults to comma.\n        content_column (str | None): Name of the column to use as the main document content.\n        metadata_columns (list[str] | None): Column names to extract as metadata for each document.\n        input_schema (type[CSVConverterInputSchema]): Schema for validating input parameters.\n    \"\"\"\n\n    name: str = \"CSV File Converter\"\n    group: Literal[NodeGroup.CONVERTERS] = NodeGroup.CONVERTERS\n    delimiter: str | None = Field(default=None, description=\"Delimiter used in the CSV files.\")\n    content_column: str | None = Field(\n        ..., description=\"Name of the column that will be used as the document's main content.\"\n    )\n    metadata_columns: list[str] | None = Field(\n        default=None,\n        description=\"Optional list of column names to extract as metadata for each document. Can be None.\",\n    )\n    input_schema: ClassVar[type[CSVConverterInputSchema]] = CSVConverterInputSchema\n\n    def execute(\n        self, input_data: CSVConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, list[Any]]:\n        \"\"\"\n        Executes the CSV conversion process.\n\n        Processes one or more CSV files according to the input configuration,\n        converting each row into a document with specified content and metadata.\n        If some files fail to process but at least one succeeds, logs errors and continues.\n        If all files fail, raises the last encountered error.\n\n        Args:\n            input_data (CSVConverterInputSchema): Validated input parameters for the conversion.\n            config (RunnableConfig | None): Optional runtime configuration.\n            **kwargs: Additional keyword arguments passed to execution callbacks.\n\n        Returns:\n            dict[str, list[Any]]: Dictionary containing the list of processed documents\n                under the 'documents' key.\n\n        Raises:\n            Exception: If there are errors reading or processing the CSV files.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        all_documents = []\n        last_error = None\n        success_count = 0\n        total_files = len(input_data.file_paths or []) + len(input_data.files or [])\n        delimiter = input_data.delimiter or self.delimiter\n        content_column = input_data.content_column or self.content_column\n        metadata_columns = input_data.metadata_columns or self.metadata_columns\n        external_metadata = input_data.metadata\n\n        if input_data.file_paths:\n            for path in input_data.file_paths:\n                try:\n                    with open(path, encoding=\"utf-8\") as csv_file:\n                        reader = csv.DictReader(csv_file, delimiter=delimiter)\n                        for doc in self._process_rows_generator(\n                            reader,\n                            source=path,\n                            content_column=content_column,\n                            metadata_columns=metadata_columns,\n                            external_metadata=external_metadata,\n\n                        ):\n                            all_documents.append(doc)\n                        success_count += 1\n                except Exception as e:\n                    logger.error(f\"Error processing file {path}: {str(e)}\")\n                    last_error = e\n\n        if input_data.files:\n            for file_obj in input_data.files:\n                source_name = getattr(file_obj, \"name\", \"in-memory file\")\n                try:\n                    if isinstance(file_obj, bytes):\n                        file_obj = BytesIO(file_obj)\n\n                    file_text = TextIOWrapper(file_obj, encoding=\"utf-8\")\n                    reader = csv.DictReader(file_text, delimiter=delimiter)\n\n                    for doc in self._process_rows_generator(\n                        reader,\n                        source=source_name,\n                        content_column=content_column,\n                        metadata_columns=metadata_columns,\n                        external_metadata=external_metadata,\n\n                    ):\n                        all_documents.append(doc)\n                    success_count += 1\n                except Exception as e:\n                    logger.error(f\"Error processing file {source_name}: {str(e)}\")\n                    last_error = e\n\n        if success_count == 0 and last_error is not None:\n            raise last_error\n\n        if success_count &lt; total_files:\n            logger.warning(f\"Processed {success_count} out of {total_files} files successfully\")\n\n        return {\"documents\": all_documents}\n\n    def _process_rows_generator(\n        self,\n        reader: csv.DictReader,\n        source: str,\n        content_column: str,\n        metadata_columns: list[str] | None,\n        external_metadata: dict | list | None,\n\n    ) -&gt; Iterator[dict]:\n        \"\"\"\n        Processes CSV rows into structured document dictionaries in a streaming fashion.\n\n        This method reads CSV rows one by one from the given DictReader, extracts the\n        specified content and metadata columns, and yields each row as a dictionary\n        with 'content' and 'metadata' fields.\n\n        Args:\n            reader (csv.DictReader): The CSV DictReader from which rows are read.\n            source (str): The source identifier for the CSV data, e.g., a file path\n                or name for in-memory data.\n            content_column (str): The name of the column containing the main document content.\n            metadata_columns (list[str]|None): Column names to include as metadata in the\n                resulting document dictionary.\n            external_metadata (dict | list | None): External metadata to merge with CSV metadata.\n                If a key exists in both, the CSV metadata will override the external metadata.\n\n\n        Yields:\n            dict: A document dictionary with two keys:\n                - 'content': The content extracted from the specified `content_column`.\n                - 'metadata': A dict containing merged metadata from CSV and external sources,\n                  plus a 'source' key identifying the file or in-memory data source.\n\n        Raises:\n            KeyError: If the specified `content_column` is not present in a row of the CSV.\n        \"\"\"\n        metadata_columns = metadata_columns or []\n        for index, row in enumerate(reader):\n            if content_column not in row:\n                raise KeyError(\n                    f\"Content column '{content_column}' not found in CSV \" f\"(source: {source}) at row {index}\"\n                )\n\n            csv_metadata = {col: row[col] for col in metadata_columns if col in row}\n            csv_metadata[\"source\"] = source\n\n            if external_metadata is not None:\n                if isinstance(external_metadata, dict):\n                    merged_metadata = external_metadata.copy()  # create an independent copy\n                    merged_metadata.update(csv_metadata)  # CSV metadata takes precedence on key conflicts\n                else:\n                    # If external_metadata is not a dict (e.g. a list), store it under its own key.\n                    merged_metadata = csv_metadata.copy()\n                    merged_metadata[\"external\"] = external_metadata\n            else:\n                merged_metadata = csv_metadata\n\n            yield {\n                \"content\": row[content_column],\n                \"metadata\": merged_metadata,\n            }\n</code></pre>"},{"location":"dynamiq/nodes/converters/csv/#dynamiq.nodes.converters.csv.CSVConverter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the CSV conversion process.</p> <p>Processes one or more CSV files according to the input configuration, converting each row into a document with specified content and metadata. If some files fail to process but at least one succeeds, logs errors and continues. If all files fail, raises the last encountered error.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>CSVConverterInputSchema</code> <p>Validated input parameters for the conversion.</p> required <code>config</code> <code>RunnableConfig | None</code> <p>Optional runtime configuration.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to execution callbacks.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, list[Any]]</code> <p>dict[str, list[Any]]: Dictionary containing the list of processed documents under the 'documents' key.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there are errors reading or processing the CSV files.</p> Source code in <code>dynamiq/nodes/converters/csv.py</code> <pre><code>def execute(\n    self, input_data: CSVConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, list[Any]]:\n    \"\"\"\n    Executes the CSV conversion process.\n\n    Processes one or more CSV files according to the input configuration,\n    converting each row into a document with specified content and metadata.\n    If some files fail to process but at least one succeeds, logs errors and continues.\n    If all files fail, raises the last encountered error.\n\n    Args:\n        input_data (CSVConverterInputSchema): Validated input parameters for the conversion.\n        config (RunnableConfig | None): Optional runtime configuration.\n        **kwargs: Additional keyword arguments passed to execution callbacks.\n\n    Returns:\n        dict[str, list[Any]]: Dictionary containing the list of processed documents\n            under the 'documents' key.\n\n    Raises:\n        Exception: If there are errors reading or processing the CSV files.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    all_documents = []\n    last_error = None\n    success_count = 0\n    total_files = len(input_data.file_paths or []) + len(input_data.files or [])\n    delimiter = input_data.delimiter or self.delimiter\n    content_column = input_data.content_column or self.content_column\n    metadata_columns = input_data.metadata_columns or self.metadata_columns\n    external_metadata = input_data.metadata\n\n    if input_data.file_paths:\n        for path in input_data.file_paths:\n            try:\n                with open(path, encoding=\"utf-8\") as csv_file:\n                    reader = csv.DictReader(csv_file, delimiter=delimiter)\n                    for doc in self._process_rows_generator(\n                        reader,\n                        source=path,\n                        content_column=content_column,\n                        metadata_columns=metadata_columns,\n                        external_metadata=external_metadata,\n\n                    ):\n                        all_documents.append(doc)\n                    success_count += 1\n            except Exception as e:\n                logger.error(f\"Error processing file {path}: {str(e)}\")\n                last_error = e\n\n    if input_data.files:\n        for file_obj in input_data.files:\n            source_name = getattr(file_obj, \"name\", \"in-memory file\")\n            try:\n                if isinstance(file_obj, bytes):\n                    file_obj = BytesIO(file_obj)\n\n                file_text = TextIOWrapper(file_obj, encoding=\"utf-8\")\n                reader = csv.DictReader(file_text, delimiter=delimiter)\n\n                for doc in self._process_rows_generator(\n                    reader,\n                    source=source_name,\n                    content_column=content_column,\n                    metadata_columns=metadata_columns,\n                    external_metadata=external_metadata,\n\n                ):\n                    all_documents.append(doc)\n                success_count += 1\n            except Exception as e:\n                logger.error(f\"Error processing file {source_name}: {str(e)}\")\n                last_error = e\n\n    if success_count == 0 and last_error is not None:\n        raise last_error\n\n    if success_count &lt; total_files:\n        logger.warning(f\"Processed {success_count} out of {total_files} files successfully\")\n\n    return {\"documents\": all_documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/csv/#dynamiq.nodes.converters.csv.CSVConverterInputSchema","title":"<code>CSVConverterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema defining the input parameters for CSV file conversion.</p> <p>This model validates and structures the input configuration for converting CSV files into a standardized document format. It ensures that either file paths or file objects are provided, along with the necessary column specifications.</p> <p>Attributes:</p> Name Type Description <code>file_paths</code> <code>list[str] | None</code> <p>List of paths to CSV files on the filesystem.</p> <code>files</code> <code>list[BytesIO | bytes] | None</code> <p>List of file objects or bytes containing CSV data.</p> <code>delimiter</code> <code>str</code> <p>Character used to separate fields in the CSV files. Defaults to comma.</p> <code>content_column</code> <code>str</code> <p>Name of the column to use as the main document content.</p> <code>metadata_columns</code> <code>list[str] | None</code> <p>Column names to extract as metadata for each document.</p> Source code in <code>dynamiq/nodes/converters/csv.py</code> <pre><code>class CSVConverterInputSchema(BaseModel):\n    \"\"\"\n    Schema defining the input parameters for CSV file conversion.\n\n    This model validates and structures the input configuration for converting CSV files\n    into a standardized document format. It ensures that either file paths or file objects\n    are provided, along with the necessary column specifications.\n\n    Attributes:\n        file_paths (list[str] | None): List of paths to CSV files on the filesystem.\n        files (list[BytesIO | bytes] | None): List of file objects or bytes containing CSV data.\n        delimiter (str): Character used to separate fields in the CSV files. Defaults to comma.\n        content_column (str): Name of the column to use as the main document content.\n        metadata_columns (list[str] | None): Column names to extract as metadata for each document.\n    \"\"\"\n\n    file_paths: list[str] | None = Field(\n        default=None, description=\"List of CSV file paths. Either file_paths or files must be provided.\"\n    )\n    files: list[BytesIO | bytes] | None = Field(\n        default=None, description=\"List of file objects or bytes representing CSV files.\"\n    )\n    delimiter: str | None = Field(\n        default=None,\n        description=\"Delimiter used in the CSV files. If not provided, the Node's configured delimiter is used.\"\n    )\n    content_column: str | None = Field(\n        default=None, description=\"Name of the column that will be used as the document's main content.\"\n    )\n    metadata_columns: list[str] | None = Field(\n        default=None,\n        description=\"Optional list of column names to extract as metadata for each document. Can be None.\",\n    )\n    metadata: dict | list | None = Field(\n        default=None,\n        description=\"External metadata to be merged with metadata extracted from CSV rows.\"\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def validate_source(cls, values):\n        file_paths, files = values.file_paths, values.files\n        if not file_paths and not files:\n            raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n        return values\n</code></pre>"},{"location":"dynamiq/nodes/converters/docx/","title":"Docx","text":""},{"location":"dynamiq/nodes/converters/docx/#dynamiq.nodes.converters.docx.DOCXFileConverter","title":"<code>DOCXFileConverter</code>","text":"<p>               Bases: <code>Node</code></p> <p>A component for converting files to Documents using the docx converter.</p> Source code in <code>dynamiq/nodes/converters/docx.py</code> <pre><code>class DOCXFileConverter(Node):\n    \"\"\"\n    A component for converting files to Documents using the docx converter.\n    \"\"\"\n\n    group: Literal[NodeGroup.CONVERTERS] = NodeGroup.CONVERTERS\n    name: str = \"DOCX File Converter\"\n    document_creation_mode: DocumentCreationMode = DocumentCreationMode.ONE_DOC_PER_FILE\n    file_converter: DOCXConverterComponent | None = None\n    input_schema: ClassVar[type[DOCXFileConverterInputSchema]] = DOCXFileConverterInputSchema\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"file_converter\": True}\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the DOCXConverter.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.file_converter is None:\n            self.file_converter = DOCXConverterComponent(\n                document_creation_mode=self.document_creation_mode,\n            )\n\n    def execute(\n        self, input_data: DOCXFileConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, list[Any]]:\n        \"\"\"\n        Execute the DOCXConverter to convert files to Documents.\n\n        Args:\n            input_data (DOCXFileConverterInputSchema): An instance containing 'file_paths', 'files', and/or 'metadata'.\n            config (RunnableConfig): Optional configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Dict with 'documents' key containing a list of converted Documents.\n\n        Raises:\n            KeyError: If required keys are missing in input_data.\n\n        Example:\n            input_data = {\n                \"file_paths\": [\"/path/to/file1.docx\"],\n                \"files\": [BytesIO(b\"file content\")],\n                \"metadata\": {\"source\": \"user_upload\"}\n            }\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        file_paths = input_data.file_paths\n        files = input_data.files\n        metadata = input_data.metadata\n\n        output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n        documents = output[\"documents\"]\n\n        count_file_paths = len(file_paths) if file_paths else 0\n        count_files = len(files) if files else 0\n\n        logger.debug(\n            f\"Converted {count_file_paths} file paths and {count_files} file objects \" f\"to {len(documents)} Documents.\"\n        )\n\n        return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/docx/#dynamiq.nodes.converters.docx.DOCXFileConverter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the DOCXConverter to convert files to Documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>DOCXFileConverterInputSchema</code> <p>An instance containing 'file_paths', 'files', and/or 'metadata'.</p> required <code>config</code> <code>RunnableConfig</code> <p>Optional configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, list[Any]]</code> <p>Dict with 'documents' key containing a list of converted Documents.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If required keys are missing in input_data.</p> Example <p>input_data = {     \"file_paths\": [\"/path/to/file1.docx\"],     \"files\": [BytesIO(b\"file content\")],     \"metadata\": {\"source\": \"user_upload\"} }</p> Source code in <code>dynamiq/nodes/converters/docx.py</code> <pre><code>def execute(\n    self, input_data: DOCXFileConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, list[Any]]:\n    \"\"\"\n    Execute the DOCXConverter to convert files to Documents.\n\n    Args:\n        input_data (DOCXFileConverterInputSchema): An instance containing 'file_paths', 'files', and/or 'metadata'.\n        config (RunnableConfig): Optional configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Dict with 'documents' key containing a list of converted Documents.\n\n    Raises:\n        KeyError: If required keys are missing in input_data.\n\n    Example:\n        input_data = {\n            \"file_paths\": [\"/path/to/file1.docx\"],\n            \"files\": [BytesIO(b\"file content\")],\n            \"metadata\": {\"source\": \"user_upload\"}\n        }\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    file_paths = input_data.file_paths\n    files = input_data.files\n    metadata = input_data.metadata\n\n    output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n    documents = output[\"documents\"]\n\n    count_file_paths = len(file_paths) if file_paths else 0\n    count_files = len(files) if files else 0\n\n    logger.debug(\n        f\"Converted {count_file_paths} file paths and {count_files} file objects \" f\"to {len(documents)} Documents.\"\n    )\n\n    return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/docx/#dynamiq.nodes.converters.docx.DOCXFileConverter.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the DOCXConverter.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/converters/docx.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the DOCXConverter.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.file_converter is None:\n        self.file_converter = DOCXConverterComponent(\n            document_creation_mode=self.document_creation_mode,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/converters/docx/#dynamiq.nodes.converters.docx.DOCXFileConverterInputSchema","title":"<code>DOCXFileConverterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/converters/docx.py</code> <pre><code>class DOCXFileConverterInputSchema(BaseModel):\n    file_paths: list[str] = Field(default=None, description=\"Parameter to provide path to files.\")\n    files: list[BytesIO] = Field(default=None, description=\"Parameter to provide files.\")\n    metadata: dict | list = Field(default=None, description=\"Parameter to provide metadata.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def validate_file_source(self):\n        \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n        if not self.file_paths and not self.files:\n            raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n        return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/docx/#dynamiq.nodes.converters.docx.DOCXFileConverterInputSchema.validate_file_source","title":"<code>validate_file_source()</code>","text":"<p>Validate that either <code>file_paths</code> or <code>files</code> is specified</p> Source code in <code>dynamiq/nodes/converters/docx.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_file_source(self):\n    \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n    if not self.file_paths and not self.files:\n        raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/html/","title":"Html","text":""},{"location":"dynamiq/nodes/converters/html/#dynamiq.nodes.converters.html.HTMLConverter","title":"<code>HTMLConverter</code>","text":"<p>               Bases: <code>Node</code></p> <p>A component for converting HTML files to Documents using the HTML converter.</p> Source code in <code>dynamiq/nodes/converters/html.py</code> <pre><code>class HTMLConverter(Node):\n    \"\"\"\n    A component for converting HTML files to Documents using the HTML converter.\n    \"\"\"\n\n    group: Literal[NodeGroup.CONVERTERS] = NodeGroup.CONVERTERS\n    name: str = \"HTML File Converter\"\n    file_converter: HTMLConverterComponent | None = None\n    input_schema: ClassVar[type[HTMLConverterInputSchema]] = HTMLConverterInputSchema\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"file_converter\": True}\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the HTMLConverter.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.file_converter is None:\n            self.file_converter = HTMLConverterComponent()\n\n    def execute(\n        self, input_data: HTMLConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, list[Any]]:\n        \"\"\"\n        Execute the HTMLConverter to convert files to Documents.\n\n        Args:\n            input_data (HTMLConverterInputSchema): An instance containing 'file_paths', 'files', and/or 'metadata'.\n            config (RunnableConfig): Optional configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Dict with 'documents' key containing a list of converted Documents.\n\n        Raises:\n            KeyError: If required keys are missing in input_data.\n\n        Example:\n            input_data = {\n                \"file_paths\": [\"/path/to/file1.html\"],\n                \"files\": [BytesIO(b\"file content\")],\n                \"metadata\": {\"source\": \"user_upload\"}\n            }\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        file_paths = input_data.file_paths\n        files = input_data.files\n        metadata = input_data.metadata\n\n        output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n        documents = output[\"documents\"]\n\n        count_file_paths = len(file_paths) if file_paths else 0\n        count_files = len(files) if files else 0\n\n        logger.debug(\n            f\"Converted {count_file_paths} file paths and {count_files} file objects \" f\"to {len(documents)} Documents.\"\n        )\n\n        return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/html/#dynamiq.nodes.converters.html.HTMLConverter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the HTMLConverter to convert files to Documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>HTMLConverterInputSchema</code> <p>An instance containing 'file_paths', 'files', and/or 'metadata'.</p> required <code>config</code> <code>RunnableConfig</code> <p>Optional configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, list[Any]]</code> <p>Dict with 'documents' key containing a list of converted Documents.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If required keys are missing in input_data.</p> Example <p>input_data = {     \"file_paths\": [\"/path/to/file1.html\"],     \"files\": [BytesIO(b\"file content\")],     \"metadata\": {\"source\": \"user_upload\"} }</p> Source code in <code>dynamiq/nodes/converters/html.py</code> <pre><code>def execute(\n    self, input_data: HTMLConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, list[Any]]:\n    \"\"\"\n    Execute the HTMLConverter to convert files to Documents.\n\n    Args:\n        input_data (HTMLConverterInputSchema): An instance containing 'file_paths', 'files', and/or 'metadata'.\n        config (RunnableConfig): Optional configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Dict with 'documents' key containing a list of converted Documents.\n\n    Raises:\n        KeyError: If required keys are missing in input_data.\n\n    Example:\n        input_data = {\n            \"file_paths\": [\"/path/to/file1.html\"],\n            \"files\": [BytesIO(b\"file content\")],\n            \"metadata\": {\"source\": \"user_upload\"}\n        }\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    file_paths = input_data.file_paths\n    files = input_data.files\n    metadata = input_data.metadata\n\n    output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n    documents = output[\"documents\"]\n\n    count_file_paths = len(file_paths) if file_paths else 0\n    count_files = len(files) if files else 0\n\n    logger.debug(\n        f\"Converted {count_file_paths} file paths and {count_files} file objects \" f\"to {len(documents)} Documents.\"\n    )\n\n    return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/html/#dynamiq.nodes.converters.html.HTMLConverter.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the HTMLConverter.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/converters/html.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the HTMLConverter.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.file_converter is None:\n        self.file_converter = HTMLConverterComponent()\n</code></pre>"},{"location":"dynamiq/nodes/converters/html/#dynamiq.nodes.converters.html.HTMLConverterInputSchema","title":"<code>HTMLConverterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/converters/html.py</code> <pre><code>class HTMLConverterInputSchema(BaseModel):\n    file_paths: list[str] = Field(default=None, description=\"Parameter to provide path to files.\")\n    files: list[BytesIO] = Field(default=None, description=\"Parameter to provide files.\")\n    metadata: dict | list = Field(default=None, description=\"Parameter to provide metadata.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def validate_file_source(self):\n        \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n        if not self.file_paths and not self.files:\n            raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n        return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/html/#dynamiq.nodes.converters.html.HTMLConverterInputSchema.validate_file_source","title":"<code>validate_file_source()</code>","text":"<p>Validate that either <code>file_paths</code> or <code>files</code> is specified</p> Source code in <code>dynamiq/nodes/converters/html.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_file_source(self):\n    \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n    if not self.file_paths and not self.files:\n        raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/","title":"Llm text extractor","text":""},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter","title":"<code>LLMImageConverter</code>","text":"<p>               Bases: <code>Node</code></p> <p>A Node class for extracting text from images using a Large Language Model (LLM).</p> <p>This class extracts text from the images using an LLM and saves the text as documents with metadata.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[CONVERTERS]</code> <p>The group the node belongs to. Default is NodeGroup.CONVERTERS.</p> <code>name</code> <code>str</code> <p>The name of the node. Default is \"LLMImageConverter\".</p> <code>extraction_instruction</code> <code>str</code> <p>The instruction for text extraction. Default is DEFAULT_EXTRACTION_INSTRUCTION.</p> <code>document_creation_mode</code> <code>DocumentCreationMode</code> <p>The mode for document creation. Default is DocumentCreationMode.ONE_DOC_PER_FILE.</p> <code>llm</code> <code>BaseLLM</code> <p>The LLM instance used for text extraction. Default is None.</p> <p>Example:</p> <pre><code>from dynamiq.nodes.extractors import ImageLLMExtractor\nfrom io import BytesIO\n\n# Initialize the extractor\nextractor = ImageLLMExtractor(llm=my_llm_instance)\n\n# Example input data\ninput_data = {\n    \"file_paths\": [\"path/to/image1.jpeg\", \"path/to/image2.png\"],\n    \"files\": [BytesIO(b\"image1 content\"), BytesIO(b\"image2 content\")],\n    \"metadata\": {\"source\": \"example source\"}\n}\n\n# Execute the extractor\noutput = extractor.execute(input_data)\n\n# Output will be a dictionary with extracted documents\nprint(output)\n</code></pre> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>class LLMImageConverter(Node):\n    \"\"\"\n    A Node class for extracting text from images using a Large Language Model (LLM).\n\n    This class extracts text from the images using an LLM and saves the text as documents with metadata.\n\n    Attributes:\n        group (Literal[NodeGroup.CONVERTERS]): The group the node belongs to. Default is NodeGroup.CONVERTERS.\n        name (str): The name of the node. Default is \"LLMImageConverter\".\n        extraction_instruction (str): The instruction for text extraction.\n            Default is DEFAULT_EXTRACTION_INSTRUCTION.\n        document_creation_mode (DocumentCreationMode): The mode for document creation.\n            Default is DocumentCreationMode.ONE_DOC_PER_FILE.\n        llm (BaseLLM): The LLM instance used for text extraction. Default is None.\n\n    Example:\n\n        from dynamiq.nodes.extractors import ImageLLMExtractor\n        from io import BytesIO\n\n        # Initialize the extractor\n        extractor = ImageLLMExtractor(llm=my_llm_instance)\n\n        # Example input data\n        input_data = {\n            \"file_paths\": [\"path/to/image1.jpeg\", \"path/to/image2.png\"],\n            \"files\": [BytesIO(b\"image1 content\"), BytesIO(b\"image2 content\")],\n            \"metadata\": {\"source\": \"example source\"}\n        }\n\n        # Execute the extractor\n        output = extractor.execute(input_data)\n\n        # Output will be a dictionary with extracted documents\n        print(output)\n    \"\"\"\n\n    group: Literal[NodeGroup.CONVERTERS] = NodeGroup.CONVERTERS\n    name: str = \"LLMImageConverter\"\n    extraction_instruction: str = DEFAULT_EXTRACTION_INSTRUCTION\n    document_creation_mode: DocumentCreationMode = DocumentCreationMode.ONE_DOC_PER_FILE\n    llm: Node\n    vision_prompt: Prompt = Field(default_factory=create_vision_prompt_template)\n    input_schema: ClassVar[type[LLMImageConverterInputSchema]] = LLMImageConverterInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the LLMImageConverter with the given parameters and creates a default LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments to be passed to the parent class constructor.\n        \"\"\"\n        super().__init__(**kwargs)\n        self._run_depends = []\n\n    def reset_run_state(self):\n        \"\"\"\n        Reset the intermediate steps (run_depends) of the node.\n        \"\"\"\n        self._run_depends = []\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"\n        Property to define which parameters should be excluded when converting the class instance to a dictionary.\n\n        Returns:\n            dict: A dictionary defining the parameters to exclude.\n        \"\"\"\n        return super().to_dict_exclude_params | {\"llm\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"llm\"] = self.llm.to_dict(**kwargs)\n        return data\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the document extractor component.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.llm.is_postponed_component_init:\n            self.llm.init_components(connection_manager)\n\n    def execute(\n        self, input_data: LLMImageConverterInputSchema, config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the image text extraction process.\n\n        Args:\n            input_data (LLMImageConverterInputSchema): An instance containing the images to be processed.\n            config (RunnableConfig, optional): Configuration for the execution. Default is None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the extracted documents.\n\n        Example:\n\n            input_data = {\n                \"file_paths\": [\"path/to/image1.jpeg\", \"path/to/image2.png\"],\n                \"files\": [BytesIO(b\"image1 content\"), BytesIO(b\"image2 content\")],\n                \"metadata\": {\"source\": \"example source\"}\n            }\n\n            output = extractor.execute(input_data)\n\n            # output will be a dictionary with extracted documents\n        \"\"\"\n        config = ensure_config(config)\n        self.reset_run_state()\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = self.extract_text_from_images(\n            file_paths=input_data.file_paths,\n            files=input_data.files,\n            metadata=input_data.metadata,\n            config=config,\n            **kwargs,\n        )\n\n        return {\"documents\": documents}\n\n    def extract_text_from_images(\n        self,\n        file_paths: list[str] | None = None,\n        files: list[BytesIO] | None = None,\n        metadata: dict[str, Any] | list[dict[str, Any]] | None = None,\n        config: RunnableConfig = None,\n        **kwargs,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Extracts text from images using an LLM.\n\n        Args:\n            file_paths (list[str], optional): List of paths to image files. Default is None.\n            files (list[BytesIO], optional): List of image files as BytesIO objects. Default is None.\n            metadata (dict[str, Any] | list[dict[str, Any]], optional): Metadata for the documents. Default is None.\n            config (RunnableConfig, optional): Configuration for the execution. Default is None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            list[Document]: A list of extracted documents.\n        \"\"\"\n\n        documents = []\n\n        if file_paths is not None:\n            paths_obj = [Path(path) for path in file_paths]\n            filepaths = [path for path in paths_obj if path.is_file()]\n            filepaths_in_directories = [\n                filepath\n                for path in paths_obj\n                if path.is_dir()\n                for filepath in path.glob(\"*.*\")\n                if filepath.is_file()\n            ]\n            if filepaths_in_directories and isinstance(metadata, list):\n                raise ValueError(\n                    \"If providing directories in the `file_paths` parameter, \"\n                    \"`metadata` can only be a dictionary (metadata applied to every file), \"\n                    \"and not a list. To specify different metadata for each file, \"\n                    \"provide an explicit list of direct paths instead.\"\n                )\n\n            all_filepaths = filepaths + filepaths_in_directories\n            meta_list = self._normalize_metadata(metadata, len(all_filepaths))\n\n            for file_path, meta in zip(all_filepaths, meta_list):\n                with open(file_path, \"rb\") as upload_file:\n                    file = BytesIO(upload_file.read())\n                    file.name = upload_file.name\n\n                image = self._load_image(file)\n                meta[\"filename\"] = str(file_path)\n                documents.extend(self._process_images([image], meta, config, **kwargs))\n\n        if files is not None:\n            meta_list = self._normalize_metadata(metadata, len(files))\n\n            for file, meta in zip(files, meta_list):\n                if not isinstance(file, BytesIO):\n                    raise ValueError(\"All files must be of type BytesIO.\")\n                image = self._load_image(file)\n                meta[\"filename\"] = get_filename_for_bytesio(file)\n                documents.extend(self._process_images([image], meta, config, **kwargs))\n\n        return documents\n\n    def _load_image(self, file: BytesIO) -&gt; \"Image\":\n        \"\"\"\n        Loads an image from a BytesIO object.\n\n        Args:\n            file (BytesIO): The BytesIO object containing the image data.\n\n        Returns:\n            Image: The loaded image.\n        \"\"\"\n        from PIL import Image\n\n        return Image.open(file)\n\n    def _process_images(\n        self,\n        images: list[\"Image\"],\n        metadata: dict[str, Any],\n        config: RunnableConfig,\n        **kwargs,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Extracts text from images using a vision prompt.\n\n        Args:\n            images (list[Image]): List of images.\n            metadata (dict[str, Any]): Metadata for the documents.\n            config (RunnableConfig): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            list[Document]: A list of extracted documents.\n        \"\"\"\n        urls = self._convert_images_to_urls(images)\n\n        outputs = self.perform_llm_extraction(urls, config, **kwargs)\n\n        if self.document_creation_mode == DocumentCreationMode.ONE_DOC_PER_FILE:\n            document_content = \"\".join(output[\"content\"] for output in outputs)\n            return [Document(content=document_content, metadata=metadata)]\n        else:\n            documents = [\n                Document(content=output[\"content\"], metadata=metadata)\n                for output in outputs\n            ]\n            return documents\n\n    def perform_llm_extraction(\n        self, urls: list[str], config: RunnableConfig, **kwargs\n    ) -&gt; list[dict]:\n        \"\"\"\n        Performs the actual extraction of text from images using the LLM.\n\n        Args:\n            urls (list[str]): The list of image URLs to extract text from.\n            config (RunnableConfig): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            list[dict]: A list of extracted text results from the LLM.\n\n        Example:\n\n            urls = [\"data:image/jpeg;base64,...\", \"data:image/jpeg;base64,...\"]\n\n            extracted_texts = extractor.perform_llm_extraction(urls, config)\n\n            # extracted_texts will be a list of dictionaries with extracted text\n        \"\"\"\n        run_kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n        inputs = [\n            {\"extraction_instruction\": self.extraction_instruction, \"img_url\": url}\n            for url in urls\n        ]\n\n        prompt = self.vision_prompt\n\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            llm_results = list(\n                executor.map(\n                    lambda input_data: self.call_llm(\n                        input_data, prompt, config, **run_kwargs\n                    ),\n                    inputs,\n                )\n            )\n\n        logger.debug(\n            f\"Node {self.name} - {self.id}: LLM processed {len(llm_results)} images\"\n        )\n\n        return llm_results\n\n    def call_llm(self, input_data, prompt, config, **run_kwargs):\n        \"\"\"\n        Calls the LLM with the given input data and prompt.\n\n        Args:\n            input_data (dict): The input data for the LLM.\n            prompt (Prompt): The prompt to be used with the LLM.\n            config (RunnableConfig): Configuration for the execution.\n            **run_kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: The result from the LLM.\n        \"\"\"\n        llm_result = self.llm.run(\n            input_data=input_data,\n            prompt=prompt,\n            config=config,\n            **(run_kwargs | {\"run_depends\": self._run_depends}),\n        )\n        self._run_depends = [NodeDependency(node=self.llm).to_dict(for_tracing=True)]\n\n        if llm_result.status != RunnableStatus.SUCCESS:\n            logger.error(f\"Node {self.name} - {self.id}: LLM execution failed: {llm_result.error.to_dict()}\")\n            raise ValueError(\"ImageLLMExtractor LLM execution failed\")\n        return llm_result.output\n\n    @staticmethod\n    def _convert_image_to_url(image: \"Image\") -&gt; str:\n        \"\"\"\n        Converts a PIL Image to a base64-encoded URL.\n\n        Args:\n            image (Image): The image to convert.\n\n        Returns:\n            str: The base64-encoded URL of the image.\n        \"\"\"\n        # Ensure the image is in RGB mode (required for JPEG)\n        if image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n\n        buffered = BytesIO()\n        image.save(buffered, format=\"JPEG\")\n        buffered.seek(0)  # Ensure the buffer is at the beginning\n        decoded_image = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n        url = f\"data:image/jpeg;base64,{decoded_image}\"\n        return url\n\n    @staticmethod\n    def _convert_images_to_urls(images: list[\"Image\"]) -&gt; list[str]:\n        \"\"\"\n        Converts a list of PIL Images to a list of base64-encoded URLs.\n\n        Args:\n            images (List[Image]): The list of images to convert.\n\n        Returns:\n            List[str]: The list of base64-encoded URLs.\n        \"\"\"\n        return [LLMImageConverter._convert_image_to_url(image) for image in images]\n\n    @staticmethod\n    def _normalize_metadata(\n        metadata: dict[str, Any] | list[dict[str, Any]] | None, sources_count: int\n    ) -&gt; list[dict[str, Any]]:\n        \"\"\"Normalizes metadata input for a converter.\n\n        Given all possible values of the metadata input for a converter (None, dictionary, or list of\n        dicts), ensures to return a list of dictionaries of the correct length for the converter to use.\n\n        Args:\n            metadata: The meta input of the converter, as-is. Can be None, a dictionary, or a list of\n                dictionaries.\n            sources_count: The number of sources the converter received.\n\n        Returns:\n            A list of dictionaries of the same length as the sources list.\n\n        Raises:\n            ValueError: If metadata is not None, a dictionary, or a list of dictionaries, or if the length\n                of the metadata list doesn't match the number of sources.\n        \"\"\"\n        if metadata is None:\n            return [{} for _ in range(sources_count)]\n        if isinstance(metadata, dict):\n            return [copy.deepcopy(metadata) for _ in range(sources_count)]\n        if isinstance(metadata, list):\n            if sources_count != len(metadata):\n                raise ValueError(\n                    \"The length of the metadata list must match the number of sources.\"\n                )\n            return metadata\n        raise ValueError(\n            \"metadata must be either None, a dictionary or a list of dictionaries.\"\n        )\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Property to define which parameters should be excluded when converting the class instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary defining the parameters to exclude.</p>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the LLMImageConverter with the given parameters and creates a default LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to be passed to the parent class constructor.</p> <code>{}</code> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the LLMImageConverter with the given parameters and creates a default LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments to be passed to the parent class constructor.\n    \"\"\"\n    super().__init__(**kwargs)\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.call_llm","title":"<code>call_llm(input_data, prompt, config, **run_kwargs)</code>","text":"<p>Calls the LLM with the given input data and prompt.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict</code> <p>The input data for the LLM.</p> required <code>prompt</code> <code>Prompt</code> <p>The prompt to be used with the LLM.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> required <code>**run_kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>The result from the LLM.</p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def call_llm(self, input_data, prompt, config, **run_kwargs):\n    \"\"\"\n    Calls the LLM with the given input data and prompt.\n\n    Args:\n        input_data (dict): The input data for the LLM.\n        prompt (Prompt): The prompt to be used with the LLM.\n        config (RunnableConfig): Configuration for the execution.\n        **run_kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: The result from the LLM.\n    \"\"\"\n    llm_result = self.llm.run(\n        input_data=input_data,\n        prompt=prompt,\n        config=config,\n        **(run_kwargs | {\"run_depends\": self._run_depends}),\n    )\n    self._run_depends = [NodeDependency(node=self.llm).to_dict(for_tracing=True)]\n\n    if llm_result.status != RunnableStatus.SUCCESS:\n        logger.error(f\"Node {self.name} - {self.id}: LLM execution failed: {llm_result.error.to_dict()}\")\n        raise ValueError(\"ImageLLMExtractor LLM execution failed\")\n    return llm_result.output\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the image text extraction process.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>LLMImageConverterInputSchema</code> <p>An instance containing the images to be processed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Default is None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the extracted documents.</p> <p>Example:</p> <pre><code>input_data = {\n    \"file_paths\": [\"path/to/image1.jpeg\", \"path/to/image2.png\"],\n    \"files\": [BytesIO(b\"image1 content\"), BytesIO(b\"image2 content\")],\n    \"metadata\": {\"source\": \"example source\"}\n}\n\noutput = extractor.execute(input_data)\n\n# output will be a dictionary with extracted documents\n</code></pre> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def execute(\n    self, input_data: LLMImageConverterInputSchema, config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the image text extraction process.\n\n    Args:\n        input_data (LLMImageConverterInputSchema): An instance containing the images to be processed.\n        config (RunnableConfig, optional): Configuration for the execution. Default is None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the extracted documents.\n\n    Example:\n\n        input_data = {\n            \"file_paths\": [\"path/to/image1.jpeg\", \"path/to/image2.png\"],\n            \"files\": [BytesIO(b\"image1 content\"), BytesIO(b\"image2 content\")],\n            \"metadata\": {\"source\": \"example source\"}\n        }\n\n        output = extractor.execute(input_data)\n\n        # output will be a dictionary with extracted documents\n    \"\"\"\n    config = ensure_config(config)\n    self.reset_run_state()\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = self.extract_text_from_images(\n        file_paths=input_data.file_paths,\n        files=input_data.files,\n        metadata=input_data.metadata,\n        config=config,\n        **kwargs,\n    )\n\n    return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.extract_text_from_images","title":"<code>extract_text_from_images(file_paths=None, files=None, metadata=None, config=None, **kwargs)</code>","text":"<p>Extracts text from images using an LLM.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>list[str]</code> <p>List of paths to image files. Default is None.</p> <code>None</code> <code>files</code> <code>list[BytesIO]</code> <p>List of image files as BytesIO objects. Default is None.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | list[dict[str, Any]]</code> <p>Metadata for the documents. Default is None.</p> <code>None</code> <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Default is None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: A list of extracted documents.</p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def extract_text_from_images(\n    self,\n    file_paths: list[str] | None = None,\n    files: list[BytesIO] | None = None,\n    metadata: dict[str, Any] | list[dict[str, Any]] | None = None,\n    config: RunnableConfig = None,\n    **kwargs,\n) -&gt; list[Document]:\n    \"\"\"\n    Extracts text from images using an LLM.\n\n    Args:\n        file_paths (list[str], optional): List of paths to image files. Default is None.\n        files (list[BytesIO], optional): List of image files as BytesIO objects. Default is None.\n        metadata (dict[str, Any] | list[dict[str, Any]], optional): Metadata for the documents. Default is None.\n        config (RunnableConfig, optional): Configuration for the execution. Default is None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        list[Document]: A list of extracted documents.\n    \"\"\"\n\n    documents = []\n\n    if file_paths is not None:\n        paths_obj = [Path(path) for path in file_paths]\n        filepaths = [path for path in paths_obj if path.is_file()]\n        filepaths_in_directories = [\n            filepath\n            for path in paths_obj\n            if path.is_dir()\n            for filepath in path.glob(\"*.*\")\n            if filepath.is_file()\n        ]\n        if filepaths_in_directories and isinstance(metadata, list):\n            raise ValueError(\n                \"If providing directories in the `file_paths` parameter, \"\n                \"`metadata` can only be a dictionary (metadata applied to every file), \"\n                \"and not a list. To specify different metadata for each file, \"\n                \"provide an explicit list of direct paths instead.\"\n            )\n\n        all_filepaths = filepaths + filepaths_in_directories\n        meta_list = self._normalize_metadata(metadata, len(all_filepaths))\n\n        for file_path, meta in zip(all_filepaths, meta_list):\n            with open(file_path, \"rb\") as upload_file:\n                file = BytesIO(upload_file.read())\n                file.name = upload_file.name\n\n            image = self._load_image(file)\n            meta[\"filename\"] = str(file_path)\n            documents.extend(self._process_images([image], meta, config, **kwargs))\n\n    if files is not None:\n        meta_list = self._normalize_metadata(metadata, len(files))\n\n        for file, meta in zip(files, meta_list):\n            if not isinstance(file, BytesIO):\n                raise ValueError(\"All files must be of type BytesIO.\")\n            image = self._load_image(file)\n            meta[\"filename\"] = get_filename_for_bytesio(file)\n            documents.extend(self._process_images([image], meta, config, **kwargs))\n\n    return documents\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the document extractor component.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the document extractor component.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.llm.is_postponed_component_init:\n        self.llm.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.perform_llm_extraction","title":"<code>perform_llm_extraction(urls, config, **kwargs)</code>","text":"<p>Performs the actual extraction of text from images using the LLM.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>list[str]</code> <p>The list of image URLs to extract text from.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of extracted text results from the LLM.</p> <p>Example:</p> <pre><code>urls = [\"data:image/jpeg;base64,...\", \"data:image/jpeg;base64,...\"]\n\nextracted_texts = extractor.perform_llm_extraction(urls, config)\n\n# extracted_texts will be a list of dictionaries with extracted text\n</code></pre> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def perform_llm_extraction(\n    self, urls: list[str], config: RunnableConfig, **kwargs\n) -&gt; list[dict]:\n    \"\"\"\n    Performs the actual extraction of text from images using the LLM.\n\n    Args:\n        urls (list[str]): The list of image URLs to extract text from.\n        config (RunnableConfig): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        list[dict]: A list of extracted text results from the LLM.\n\n    Example:\n\n        urls = [\"data:image/jpeg;base64,...\", \"data:image/jpeg;base64,...\"]\n\n        extracted_texts = extractor.perform_llm_extraction(urls, config)\n\n        # extracted_texts will be a list of dictionaries with extracted text\n    \"\"\"\n    run_kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n    inputs = [\n        {\"extraction_instruction\": self.extraction_instruction, \"img_url\": url}\n        for url in urls\n    ]\n\n    prompt = self.vision_prompt\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        llm_results = list(\n            executor.map(\n                lambda input_data: self.call_llm(\n                    input_data, prompt, config, **run_kwargs\n                ),\n                inputs,\n            )\n        )\n\n    logger.debug(\n        f\"Node {self.name} - {self.id}: LLM processed {len(llm_results)} images\"\n    )\n\n    return llm_results\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Reset the intermediate steps (run_depends) of the node.</p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"\n    Reset the intermediate steps (run_depends) of the node.\n    \"\"\"\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverter.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"llm\"] = self.llm.to_dict(**kwargs)\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverterInputSchema","title":"<code>LLMImageConverterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>class LLMImageConverterInputSchema(BaseModel):\n    file_paths: list[str] = Field(default=None, description=\"Parameter to provide paths to files.\")\n    files: list[BytesIO | bytes] = Field(default=None, description=\"Parameter to provide files.\")\n    metadata: dict | list = Field(default=None, description=\"Parameter to provide metadata.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def validate_file_source(self):\n        \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n        if not self.file_paths and not self.files:\n            raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n        return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMImageConverterInputSchema.validate_file_source","title":"<code>validate_file_source()</code>","text":"<p>Validate that either <code>file_paths</code> or <code>files</code> is specified</p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_file_source(self):\n    \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n    if not self.file_paths and not self.files:\n        raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMPDFConverter","title":"<code>LLMPDFConverter</code>","text":"<p>               Bases: <code>LLMImageConverter</code></p> <p>A Node class for extracting text from PDFs using a Large Language Model (LLM).</p> <p>This class converts PDFs to images, extracts text from the images using an LLM, and saves the text as documents with metadata.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[CONVERTERS]</code> <p>The group the node belongs to. Default is NodeGroup.CONVERTERS.</p> <code>name</code> <code>str</code> <p>The name of the node. Default is \"LLMPDFConverter\".</p> <code>extraction_instruction</code> <code>str</code> <p>The instruction for text extraction. Default is DEFAULT_EXTRACTION_INSTRUCTION.</p> <code>document_creation_mode</code> <code>DocumentCreationMode</code> <p>The mode for document creation. Default is DocumentCreationMode.ONE_DOC_PER_FILE.</p> <code>llm</code> <code>BaseLLM</code> <p>The LLM instance used for text extraction. Default is None.</p> <p>Example:</p> <pre><code>from dynamiq.nodes.converters import LLMPDFConverter\nfrom io import BytesIO\n\n# Initialize the extractor\nconverter = LLMPDFConverter(llm=my_llm_instance)\n\n# Example input data\ninput_data = {\n    \"file_paths\": [\"path/to/pdf1.pdf\", \"path/to/pdf2.pdf\"],\n    \"files\": [BytesIO(b\"pdf1 content\"), BytesIO(b\"pdf2 content\")],\n    \"metadata\": {\"source\": \"example source\"}\n}\n\n# Execute the converter\noutput = converter.execute(input_data)\n\n# Output will be a dictionary with extracted documents\nprint(output)\n</code></pre> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>class LLMPDFConverter(LLMImageConverter):\n    \"\"\"\n    A Node class for extracting text from PDFs using a Large Language Model (LLM).\n\n    This class converts PDFs to images, extracts text from the images using an LLM,\n    and saves the text as documents with metadata.\n\n    Attributes:\n        group (Literal[NodeGroup.CONVERTERS]): The group the node belongs to. Default is NodeGroup.CONVERTERS.\n        name (str): The name of the node. Default is \"LLMPDFConverter\".\n        extraction_instruction (str): The instruction for text extraction.\n            Default is DEFAULT_EXTRACTION_INSTRUCTION.\n        document_creation_mode (DocumentCreationMode): The mode for document creation.\n            Default is DocumentCreationMode.ONE_DOC_PER_FILE.\n        llm (BaseLLM): The LLM instance used for text extraction. Default is None.\n\n    Example:\n\n        from dynamiq.nodes.converters import LLMPDFConverter\n        from io import BytesIO\n\n        # Initialize the extractor\n        converter = LLMPDFConverter(llm=my_llm_instance)\n\n        # Example input data\n        input_data = {\n            \"file_paths\": [\"path/to/pdf1.pdf\", \"path/to/pdf2.pdf\"],\n            \"files\": [BytesIO(b\"pdf1 content\"), BytesIO(b\"pdf2 content\")],\n            \"metadata\": {\"source\": \"example source\"}\n        }\n\n        # Execute the converter\n        output = converter.execute(input_data)\n\n        # Output will be a dictionary with extracted documents\n        print(output)\n    \"\"\"\n\n    _convert_from_bytes: Any = PrivateAttr()\n    _convert_from_path: Any = PrivateAttr()\n    input_schema: ClassVar[type[LLMPDFConverterInputSchema]] = LLMPDFConverterInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the LLMPDFConverter with the given parameters and creates a default LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments to be passed to the parent class constructor.\n        \"\"\"\n        from pdf2image import convert_from_bytes, convert_from_path\n\n        super().__init__(**kwargs)\n        self._convert_from_bytes = convert_from_bytes\n        self._convert_from_path = convert_from_path\n\n    def execute(\n        self, input_data: LLMPDFConverterInputSchema, config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the PDF text extraction process.\n\n        Args:\n            input_data (LLMPDFConverterInputSchema): An instance containing the file paths or\n              files of PDFs to be processed.\n            config (RunnableConfig, optional): Configuration for the execution. Default is None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the extracted documents.\n\n        Example:\n\n            input_data = {\n                \"file_paths\": [\"path/to/pdf1.pdf\", \"path/to/pdf2.pdf\"],\n                \"metadata\": {\"source\": \"example source\"}\n            }\n\n            output = extractor.execute(input_data)\n\n            # output will be a dictionary with extracted documents\n        \"\"\"\n        config = ensure_config(config)\n        self.reset_run_state()\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = self.extract_text_from_pdfs(\n            file_paths=input_data.file_paths,\n            files=input_data.files,\n            metadata=input_data.metadata,\n            config=config,\n            **kwargs,\n        )\n\n        return {\"documents\": documents}\n\n    def extract_text_from_pdfs(\n        self,\n        file_paths: list[str] | None = None,\n        files: list[BytesIO] | None = None,\n        metadata: dict[str, Any] | list[dict[str, Any]] | None = None,\n        config: RunnableConfig = None,\n        **kwargs,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Extracts text from PDFs by converting them to images and using an LLM.\n\n        Args:\n            file_paths (list[str], optional): List of paths to PDF files. Default is None.\n            files (list[BytesIO], optional): List of PDF files as BytesIO objects. Default is None.\n            metadata (dict[str, Any] | list[dict[str, Any]], optional): Metadata for the documents. Default is None.\n            config (RunnableConfig, optional): Configuration for the execution. Default is None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            list[Document]: A list of extracted documents.\n        \"\"\"\n        documents = []\n\n        if file_paths is not None:\n            paths_obj = [Path(path) for path in file_paths]\n            filepaths = [path for path in paths_obj if path.is_file()]\n            filepaths_in_directories = [\n                filepath\n                for path in paths_obj\n                if path.is_dir()\n                for filepath in path.glob(\"*.*\")\n                if filepath.is_file()\n            ]\n            if filepaths_in_directories and isinstance(metadata, list):\n                raise ValueError(\n                    \"If providing directories in the `file_paths` parameter, \"\n                    \"`metadata` can only be a dictionary (metadata applied to every file), \"\n                    \"and not a list. To specify different metadata for each file, \"\n                    \"provide an explicit list of direct paths instead.\"\n                )\n\n            all_filepaths = filepaths + filepaths_in_directories\n            meta_list = self._normalize_metadata(metadata, len(all_filepaths))\n\n            for file_path, meta in zip(all_filepaths, meta_list):\n                images = self._convert_from_path(file_path)\n                meta[\"filename\"] = str(file_path)\n                documents.extend(self._process_images(images, meta, config, **kwargs))\n\n        if files is not None:\n            meta_list = self._normalize_metadata(metadata, len(files))\n\n            for file, meta in zip(files, meta_list):\n                if not isinstance(file, BytesIO):\n                    raise ValueError(\"All files must be of type BytesIO.\")\n                images = self._convert_from_bytes(file.read())\n                meta[\"filename\"] = get_filename_for_bytesio(file)\n                documents.extend(self._process_images(images, meta, config, **kwargs))\n\n        return documents\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMPDFConverter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the LLMPDFConverter with the given parameters and creates a default LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to be passed to the parent class constructor.</p> <code>{}</code> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the LLMPDFConverter with the given parameters and creates a default LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments to be passed to the parent class constructor.\n    \"\"\"\n    from pdf2image import convert_from_bytes, convert_from_path\n\n    super().__init__(**kwargs)\n    self._convert_from_bytes = convert_from_bytes\n    self._convert_from_path = convert_from_path\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMPDFConverter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the PDF text extraction process.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>LLMPDFConverterInputSchema</code> <p>An instance containing the file paths or files of PDFs to be processed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Default is None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the extracted documents.</p> <p>Example:</p> <pre><code>input_data = {\n    \"file_paths\": [\"path/to/pdf1.pdf\", \"path/to/pdf2.pdf\"],\n    \"metadata\": {\"source\": \"example source\"}\n}\n\noutput = extractor.execute(input_data)\n\n# output will be a dictionary with extracted documents\n</code></pre> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def execute(\n    self, input_data: LLMPDFConverterInputSchema, config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the PDF text extraction process.\n\n    Args:\n        input_data (LLMPDFConverterInputSchema): An instance containing the file paths or\n          files of PDFs to be processed.\n        config (RunnableConfig, optional): Configuration for the execution. Default is None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the extracted documents.\n\n    Example:\n\n        input_data = {\n            \"file_paths\": [\"path/to/pdf1.pdf\", \"path/to/pdf2.pdf\"],\n            \"metadata\": {\"source\": \"example source\"}\n        }\n\n        output = extractor.execute(input_data)\n\n        # output will be a dictionary with extracted documents\n    \"\"\"\n    config = ensure_config(config)\n    self.reset_run_state()\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = self.extract_text_from_pdfs(\n        file_paths=input_data.file_paths,\n        files=input_data.files,\n        metadata=input_data.metadata,\n        config=config,\n        **kwargs,\n    )\n\n    return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMPDFConverter.extract_text_from_pdfs","title":"<code>extract_text_from_pdfs(file_paths=None, files=None, metadata=None, config=None, **kwargs)</code>","text":"<p>Extracts text from PDFs by converting them to images and using an LLM.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>list[str]</code> <p>List of paths to PDF files. Default is None.</p> <code>None</code> <code>files</code> <code>list[BytesIO]</code> <p>List of PDF files as BytesIO objects. Default is None.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | list[dict[str, Any]]</code> <p>Metadata for the documents. Default is None.</p> <code>None</code> <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Default is None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: A list of extracted documents.</p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def extract_text_from_pdfs(\n    self,\n    file_paths: list[str] | None = None,\n    files: list[BytesIO] | None = None,\n    metadata: dict[str, Any] | list[dict[str, Any]] | None = None,\n    config: RunnableConfig = None,\n    **kwargs,\n) -&gt; list[Document]:\n    \"\"\"\n    Extracts text from PDFs by converting them to images and using an LLM.\n\n    Args:\n        file_paths (list[str], optional): List of paths to PDF files. Default is None.\n        files (list[BytesIO], optional): List of PDF files as BytesIO objects. Default is None.\n        metadata (dict[str, Any] | list[dict[str, Any]], optional): Metadata for the documents. Default is None.\n        config (RunnableConfig, optional): Configuration for the execution. Default is None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        list[Document]: A list of extracted documents.\n    \"\"\"\n    documents = []\n\n    if file_paths is not None:\n        paths_obj = [Path(path) for path in file_paths]\n        filepaths = [path for path in paths_obj if path.is_file()]\n        filepaths_in_directories = [\n            filepath\n            for path in paths_obj\n            if path.is_dir()\n            for filepath in path.glob(\"*.*\")\n            if filepath.is_file()\n        ]\n        if filepaths_in_directories and isinstance(metadata, list):\n            raise ValueError(\n                \"If providing directories in the `file_paths` parameter, \"\n                \"`metadata` can only be a dictionary (metadata applied to every file), \"\n                \"and not a list. To specify different metadata for each file, \"\n                \"provide an explicit list of direct paths instead.\"\n            )\n\n        all_filepaths = filepaths + filepaths_in_directories\n        meta_list = self._normalize_metadata(metadata, len(all_filepaths))\n\n        for file_path, meta in zip(all_filepaths, meta_list):\n            images = self._convert_from_path(file_path)\n            meta[\"filename\"] = str(file_path)\n            documents.extend(self._process_images(images, meta, config, **kwargs))\n\n    if files is not None:\n        meta_list = self._normalize_metadata(metadata, len(files))\n\n        for file, meta in zip(files, meta_list):\n            if not isinstance(file, BytesIO):\n                raise ValueError(\"All files must be of type BytesIO.\")\n            images = self._convert_from_bytes(file.read())\n            meta[\"filename\"] = get_filename_for_bytesio(file)\n            documents.extend(self._process_images(images, meta, config, **kwargs))\n\n    return documents\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMPDFConverterInputSchema","title":"<code>LLMPDFConverterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>class LLMPDFConverterInputSchema(BaseModel):\n    file_paths: list[str] = Field(default=None, description=\"Parameter to provide path to files.\")\n    files: list[BytesIO | bytes] = Field(default=None, description=\"Parameter to provide files.\")\n    metadata: dict | list = Field(default=None, description=\"Parameter to provide metadata.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def validate_file_source(self):\n        \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n        if not self.file_paths and not self.files:\n            raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n        return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.LLMPDFConverterInputSchema.validate_file_source","title":"<code>validate_file_source()</code>","text":"<p>Validate that either <code>file_paths</code> or <code>files</code> is specified</p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_file_source(self):\n    \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n    if not self.file_paths and not self.files:\n        raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/llm_text_extractor/#dynamiq.nodes.converters.llm_text_extractor.create_vision_prompt_template","title":"<code>create_vision_prompt_template()</code>","text":"<p>Creates a vision prompt template.</p> <p>Returns:</p> Name Type Description <code>Prompt</code> <code>Prompt</code> <p>The vision prompt template.</p> Source code in <code>dynamiq/nodes/converters/llm_text_extractor.py</code> <pre><code>def create_vision_prompt_template() -&gt; Prompt:\n    \"\"\"\n    Creates a vision prompt template.\n\n    Returns:\n        Prompt: The vision prompt template.\n    \"\"\"\n    text_message = VisionMessageTextContent(text=\"{{extraction_instruction}}\")\n    image_message = VisionMessageImageContent(image_url=VisionMessageImageURL(url=\"{{img_url}}\"))\n    vision_message = VisionMessage(content=[text_message, image_message], role=\"user\")\n    vision_prompt = Prompt(messages=[vision_message])\n    return vision_prompt\n</code></pre>"},{"location":"dynamiq/nodes/converters/pptx/","title":"Pptx","text":""},{"location":"dynamiq/nodes/converters/pptx/#dynamiq.nodes.converters.pptx.PPTXFileConverter","title":"<code>PPTXFileConverter</code>","text":"<p>               Bases: <code>Node</code></p> <p>A component for converting files to Documents using the pptx converter.</p> Source code in <code>dynamiq/nodes/converters/pptx.py</code> <pre><code>class PPTXFileConverter(Node):\n    \"\"\"\n    A component for converting files to Documents using the pptx converter.\n\n    Args:\n        document_creation_mode (Literal[\"one-doc-per-file\", \"one-doc-per-page\", \"one-doc-per-element\"],\n            optional): Determines how to create Documents from the elements returned by PdfReader.\n            Options are:\n            - \"one-doc-per-file\": Creates one Document per file.\n                All elements are concatenated into one text field.\n            - \"one-doc-per-page\": Creates one Document per page.\n                All elements on a page are concatenated into one text field.\n            Defaults to \"one-doc-per-file\".\n    \"\"\"\n\n    group: Literal[NodeGroup.CONVERTERS] = NodeGroup.CONVERTERS\n    name: str = \"PPTX File Converter\"\n    document_creation_mode: DocumentCreationMode = DocumentCreationMode.ONE_DOC_PER_FILE\n    file_converter: PPTXConverterComponent | None = None\n    input_schema: ClassVar[type[PPTXFileConverterInputSchema]] = PPTXFileConverterInputSchema\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"file_converter\": True}\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the PPTXConverter.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.file_converter is None:\n            self.file_converter = PPTXConverterComponent(\n                document_creation_mode=self.document_creation_mode,\n            )\n\n    def execute(\n        self, input_data: PPTXFileConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, list[Any]]:\n        \"\"\"\n        Execute the PPTXConverter to convert files to Documents.\n\n        Args:\n            input_data (PPTXFileConverterInputSchema): An instance containing 'file_paths', 'files', and/or 'metadata'.\n            config (RunnableConfig): Optional configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Dict with 'documents' key containing a list of converted Documents.\n\n        Raises:\n            KeyError: If required keys are missing in input_data.\n\n        Example:\n            input_data = {\n                \"file_paths\": [\"/path/to/file1.pptx\"],\n                \"files\": [BytesIO(b\"file content\")],\n                \"metadata\": {\"source\": \"user_upload\"}\n            }\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        file_paths = input_data.file_paths\n        files = input_data.files\n        metadata = input_data.metadata\n\n        output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n        documents = output[\"documents\"]\n\n        count_file_paths = len(file_paths) if file_paths else 0\n        count_files = len(files) if files else 0\n\n        logger.debug(\n            f\"Converted {count_file_paths} file paths and {count_files} file objects \" f\"to {len(documents)} Documents.\"\n        )\n\n        return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/pptx/#dynamiq.nodes.converters.pptx.PPTXFileConverter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the PPTXConverter to convert files to Documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>PPTXFileConverterInputSchema</code> <p>An instance containing 'file_paths', 'files', and/or 'metadata'.</p> required <code>config</code> <code>RunnableConfig</code> <p>Optional configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, list[Any]]</code> <p>Dict with 'documents' key containing a list of converted Documents.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If required keys are missing in input_data.</p> Example <p>input_data = {     \"file_paths\": [\"/path/to/file1.pptx\"],     \"files\": [BytesIO(b\"file content\")],     \"metadata\": {\"source\": \"user_upload\"} }</p> Source code in <code>dynamiq/nodes/converters/pptx.py</code> <pre><code>def execute(\n    self, input_data: PPTXFileConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, list[Any]]:\n    \"\"\"\n    Execute the PPTXConverter to convert files to Documents.\n\n    Args:\n        input_data (PPTXFileConverterInputSchema): An instance containing 'file_paths', 'files', and/or 'metadata'.\n        config (RunnableConfig): Optional configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Dict with 'documents' key containing a list of converted Documents.\n\n    Raises:\n        KeyError: If required keys are missing in input_data.\n\n    Example:\n        input_data = {\n            \"file_paths\": [\"/path/to/file1.pptx\"],\n            \"files\": [BytesIO(b\"file content\")],\n            \"metadata\": {\"source\": \"user_upload\"}\n        }\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    file_paths = input_data.file_paths\n    files = input_data.files\n    metadata = input_data.metadata\n\n    output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n    documents = output[\"documents\"]\n\n    count_file_paths = len(file_paths) if file_paths else 0\n    count_files = len(files) if files else 0\n\n    logger.debug(\n        f\"Converted {count_file_paths} file paths and {count_files} file objects \" f\"to {len(documents)} Documents.\"\n    )\n\n    return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/pptx/#dynamiq.nodes.converters.pptx.PPTXFileConverter.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the PPTXConverter.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/converters/pptx.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the PPTXConverter.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.file_converter is None:\n        self.file_converter = PPTXConverterComponent(\n            document_creation_mode=self.document_creation_mode,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/converters/pptx/#dynamiq.nodes.converters.pptx.PPTXFileConverterInputSchema","title":"<code>PPTXFileConverterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/converters/pptx.py</code> <pre><code>class PPTXFileConverterInputSchema(BaseModel):\n    file_paths: list[str] = Field(default=None, description=\"Parameter to provide path to files.\")\n    files: list[BytesIO] = Field(default=None, description=\"Parameter to provide files.\")\n    metadata: dict | list = Field(default=None, description=\"Parameter to provide metadata.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def validate_file_source(self):\n        \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n        if not self.file_paths and not self.files:\n            raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n        return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/pptx/#dynamiq.nodes.converters.pptx.PPTXFileConverterInputSchema.validate_file_source","title":"<code>validate_file_source()</code>","text":"<p>Validate that either <code>file_paths</code> or <code>files</code> is specified</p> Source code in <code>dynamiq/nodes/converters/pptx.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_file_source(self):\n    \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n    if not self.file_paths and not self.files:\n        raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/pypdf/","title":"Pypdf","text":"<p>pdf</p>"},{"location":"dynamiq/nodes/converters/text/","title":"Text","text":""},{"location":"dynamiq/nodes/converters/text/#dynamiq.nodes.converters.text.TextFileConverter","title":"<code>TextFileConverter</code>","text":"<p>               Bases: <code>Node</code></p> <p>A component for converting text files to Documents using the TextFileConverter.</p> Source code in <code>dynamiq/nodes/converters/text.py</code> <pre><code>class TextFileConverter(Node):\n    \"\"\"\n    A component for converting text files to Documents using the TextFileConverter.\n    \"\"\"\n\n    group: Literal[NodeGroup.CONVERTERS] = NodeGroup.CONVERTERS\n    name: str = \"Text File Converter\"\n    file_converter: TextFileConverterComponent | None = None\n    input_schema: ClassVar[type[TextFileConverterInputSchema]] = TextFileConverterInputSchema\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"file_converter\": True}\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the TextFileConverter.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.file_converter is None:\n            self.file_converter = TextFileConverterComponent()\n\n    def execute(\n        self, input_data: TextFileConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, list[Any]]:\n        \"\"\"\n        Execute the TextFileConverter to convert files to Documents.\n\n        Args:\n            input_data (TextFileConverterInputSchema): An instance containing 'file_paths', 'files', and/or 'metadata'.\n            config (RunnableConfig): Optional configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Dict with 'documents' key containing a list of converted Documents.\n\n        Raises:\n            KeyError: If required keys are missing in input_data.\n\n        Example:\n            input_data = {\n                \"file_paths\": [\"/path/to/file1.txt\"],\n                \"files\": [BytesIO(b\"file content\")],\n                \"metadata\": {\"source\": \"user_upload\"}\n            }\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        file_paths = input_data.file_paths\n        files = input_data.files\n        metadata = input_data.metadata\n\n        output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n        documents = output[\"documents\"]\n\n        count_file_paths = len(file_paths) if file_paths else 0\n        count_files = len(files) if files else 0\n\n        logger.debug(\n            f\"Converted {count_file_paths} file paths and {count_files} file objects \" f\"to {len(documents)} Documents.\"\n        )\n\n        return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/text/#dynamiq.nodes.converters.text.TextFileConverter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the TextFileConverter to convert files to Documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>TextFileConverterInputSchema</code> <p>An instance containing 'file_paths', 'files', and/or 'metadata'.</p> required <code>config</code> <code>RunnableConfig</code> <p>Optional configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, list[Any]]</code> <p>Dict with 'documents' key containing a list of converted Documents.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If required keys are missing in input_data.</p> Example <p>input_data = {     \"file_paths\": [\"/path/to/file1.txt\"],     \"files\": [BytesIO(b\"file content\")],     \"metadata\": {\"source\": \"user_upload\"} }</p> Source code in <code>dynamiq/nodes/converters/text.py</code> <pre><code>def execute(\n    self, input_data: TextFileConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, list[Any]]:\n    \"\"\"\n    Execute the TextFileConverter to convert files to Documents.\n\n    Args:\n        input_data (TextFileConverterInputSchema): An instance containing 'file_paths', 'files', and/or 'metadata'.\n        config (RunnableConfig): Optional configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Dict with 'documents' key containing a list of converted Documents.\n\n    Raises:\n        KeyError: If required keys are missing in input_data.\n\n    Example:\n        input_data = {\n            \"file_paths\": [\"/path/to/file1.txt\"],\n            \"files\": [BytesIO(b\"file content\")],\n            \"metadata\": {\"source\": \"user_upload\"}\n        }\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    file_paths = input_data.file_paths\n    files = input_data.files\n    metadata = input_data.metadata\n\n    output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n    documents = output[\"documents\"]\n\n    count_file_paths = len(file_paths) if file_paths else 0\n    count_files = len(files) if files else 0\n\n    logger.debug(\n        f\"Converted {count_file_paths} file paths and {count_files} file objects \" f\"to {len(documents)} Documents.\"\n    )\n\n    return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/text/#dynamiq.nodes.converters.text.TextFileConverter.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the TextFileConverter.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/converters/text.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the TextFileConverter.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.file_converter is None:\n        self.file_converter = TextFileConverterComponent()\n</code></pre>"},{"location":"dynamiq/nodes/converters/text/#dynamiq.nodes.converters.text.TextFileConverterInputSchema","title":"<code>TextFileConverterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/converters/text.py</code> <pre><code>class TextFileConverterInputSchema(BaseModel):\n    file_paths: list[str] = Field(default=None, description=\"Parameter to provide path to files.\")\n    files: list[BytesIO] = Field(default=None, description=\"Parameter to provide files.\")\n    metadata: dict | list = Field(default=None, description=\"Parameter to provide metadata.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def validate_file_source(self):\n        \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n        if not self.file_paths and not self.files:\n            raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n        return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/text/#dynamiq.nodes.converters.text.TextFileConverterInputSchema.validate_file_source","title":"<code>validate_file_source()</code>","text":"<p>Validate that either <code>file_paths</code> or <code>files</code> is specified</p> Source code in <code>dynamiq/nodes/converters/text.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_file_source(self):\n    \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n    if not self.file_paths and not self.files:\n        raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/unstructured/","title":"Unstructured","text":""},{"location":"dynamiq/nodes/converters/unstructured/#dynamiq.nodes.converters.unstructured.UnstructuredFileConverter","title":"<code>UnstructuredFileConverter</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A component for converting files to Documents using the Unstructured API (hosted or running locally).</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>UnstructuredConnection</code> <p>The connection to use for the Unstructured API. Defaults to None, which will initialize a new UnstructuredConnection.</p> required <code>strategy</code> <code>Literal['auto', 'fast', 'hi_res', 'ocr_only']</code> <p>The strategy to use for document processing. Defaults to \"auto\".</p> required <code>unstructured_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Additional parameters to pass to the Unstructured API. See Unstructured API docs for available parameters. Defaults to None.</p> required Source code in <code>dynamiq/nodes/converters/unstructured.py</code> <pre><code>class UnstructuredFileConverter(ConnectionNode):\n    \"\"\"\n    A component for converting files to Documents using the Unstructured API (hosted or running locally).\n\n    Args:\n        connection (UnstructuredConnection, optional): The connection to use for the Unstructured API.\n            Defaults to None, which will initialize a new UnstructuredConnection.\n        document_creation_mode (Literal[\"one-doc-per-file\", \"one-doc-per-page\", \"one-doc-per-element\"],\n            optional): Determines how to create Documents from the elements returned by Unstructured.\n            Options are:\n            - \"one-doc-per-file\": Creates one Document per file.\n                All elements are concatenated into one text field.\n            - \"one-doc-per-page\": Creates one Document per page.\n                All elements on a page are concatenated into one text field.\n            - \"one-doc-per-element\": Creates one Document per element.\n                Each element is converted to a separate Document.\n            Defaults to \"one-doc-per-file\".\n        strategy (Literal[\"auto\", \"fast\", \"hi_res\", \"ocr_only\"], optional): The strategy to use for\n            document processing. Defaults to \"auto\".\n        unstructured_kwargs (Optional[dict[str, Any]], optional): Additional parameters to pass to the\n            Unstructured API. See Unstructured API docs for available parameters. Defaults to None.\n    \"\"\"\n\n    group: Literal[NodeGroup.CONVERTERS] = NodeGroup.CONVERTERS\n    name: str = \"Unstructured File Converter\"\n    connection: Unstructured = None\n    document_creation_mode: DocumentCreationMode = DocumentCreationMode.ONE_DOC_PER_FILE\n    strategy: ConvertStrategy = ConvertStrategy.AUTO\n    unstructured_kwargs: dict[str, Any] | None = None\n    file_converter: UnstructuredFileConverterComponent | None = None\n    input_schema: ClassVar[type[UnstructuredFileConverterInputSchema]] = UnstructuredFileConverterInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the UnstructuredFileConverter.\n\n        If no connection is provided, a new Unstructured connection will be created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the UnstructuredFileConverter.\n        \"\"\"\n        if kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Unstructured()\n        super().__init__(**kwargs)\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"file_converter\": True}\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the UnstructuredFileConverter.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.file_converter is None:\n            self.file_converter = UnstructuredFileConverterComponent(\n                connection=self.connection,\n                document_creation_mode=self.document_creation_mode,\n                strategy=self.strategy,\n                unstructured_kwargs=self.unstructured_kwargs,\n            )\n\n    def execute(\n        self, input_data: UnstructuredFileConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, list[Any]]:\n        \"\"\"\n        Execute the UnstructuredFileConverter to convert files to Documents.\n\n        Args:\n            input_data (UnstructuredFileConverterInputSchema): An instance containing 'file_paths',\n              'files', and/or 'metadata'.\n            config (RunnableConfig): Optional configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, list[Any]]: Dictionary with 'documents' key containing a list of converted Documents.\n\n        Raises:\n            KeyError: If required keys are missing in input_data.\n\n        Example:\n            input_data = {\n                \"file_paths\": [\"/path/to/file1.pdf\", \"/path/to/file2.docx\"],\n                \"files\": [BytesIO(b\"file content\")],\n                \"metadata\": {\"source\": \"user_upload\"}\n            }\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        file_paths = input_data.file_paths\n        files = input_data.files\n        metadata = input_data.metadata\n\n        output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n        documents = output[\"documents\"]\n\n        count_file_paths = len(file_paths) if file_paths else 0\n        count_files = len(files) if files else 0\n\n        logger.debug(\n            f\"Converted {count_file_paths} file paths and {count_files} file objects \"\n            f\"to {len(documents)} Documents.\"\n        )\n\n        return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/unstructured/#dynamiq.nodes.converters.unstructured.UnstructuredFileConverter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the UnstructuredFileConverter.</p> <p>If no connection is provided, a new Unstructured connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the UnstructuredFileConverter.</p> <code>{}</code> Source code in <code>dynamiq/nodes/converters/unstructured.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the UnstructuredFileConverter.\n\n    If no connection is provided, a new Unstructured connection will be created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the UnstructuredFileConverter.\n    \"\"\"\n    if kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Unstructured()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/converters/unstructured/#dynamiq.nodes.converters.unstructured.UnstructuredFileConverter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the UnstructuredFileConverter to convert files to Documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>UnstructuredFileConverterInputSchema</code> <p>An instance containing 'file_paths', 'files', and/or 'metadata'.</p> required <code>config</code> <code>RunnableConfig</code> <p>Optional configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, list[Any]]</code> <p>dict[str, list[Any]]: Dictionary with 'documents' key containing a list of converted Documents.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If required keys are missing in input_data.</p> Example <p>input_data = {     \"file_paths\": [\"/path/to/file1.pdf\", \"/path/to/file2.docx\"],     \"files\": [BytesIO(b\"file content\")],     \"metadata\": {\"source\": \"user_upload\"} }</p> Source code in <code>dynamiq/nodes/converters/unstructured.py</code> <pre><code>def execute(\n    self, input_data: UnstructuredFileConverterInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, list[Any]]:\n    \"\"\"\n    Execute the UnstructuredFileConverter to convert files to Documents.\n\n    Args:\n        input_data (UnstructuredFileConverterInputSchema): An instance containing 'file_paths',\n          'files', and/or 'metadata'.\n        config (RunnableConfig): Optional configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, list[Any]]: Dictionary with 'documents' key containing a list of converted Documents.\n\n    Raises:\n        KeyError: If required keys are missing in input_data.\n\n    Example:\n        input_data = {\n            \"file_paths\": [\"/path/to/file1.pdf\", \"/path/to/file2.docx\"],\n            \"files\": [BytesIO(b\"file content\")],\n            \"metadata\": {\"source\": \"user_upload\"}\n        }\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    file_paths = input_data.file_paths\n    files = input_data.files\n    metadata = input_data.metadata\n\n    output = self.file_converter.run(file_paths=file_paths, files=files, metadata=metadata)\n    documents = output[\"documents\"]\n\n    count_file_paths = len(file_paths) if file_paths else 0\n    count_files = len(files) if files else 0\n\n    logger.debug(\n        f\"Converted {count_file_paths} file paths and {count_files} file objects \"\n        f\"to {len(documents)} Documents.\"\n    )\n\n    return {\"documents\": documents}\n</code></pre>"},{"location":"dynamiq/nodes/converters/unstructured/#dynamiq.nodes.converters.unstructured.UnstructuredFileConverter.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the UnstructuredFileConverter.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/converters/unstructured.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the UnstructuredFileConverter.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.file_converter is None:\n        self.file_converter = UnstructuredFileConverterComponent(\n            connection=self.connection,\n            document_creation_mode=self.document_creation_mode,\n            strategy=self.strategy,\n            unstructured_kwargs=self.unstructured_kwargs,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/converters/unstructured/#dynamiq.nodes.converters.unstructured.UnstructuredFileConverterInputSchema","title":"<code>UnstructuredFileConverterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/converters/unstructured.py</code> <pre><code>class UnstructuredFileConverterInputSchema(BaseModel):\n    file_paths: list[str] = Field(default=None, description=\"Parameter to provide path to files.\")\n    files: list[BytesIO | bytes] = Field(default=None, description=\"Parameter to provide files.\")\n    metadata: dict | list = Field(default=None, description=\"Parameter to provide metadata.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def validate_file_source(self):\n        \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n        if not self.file_paths and not self.files:\n            raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n        return self\n</code></pre>"},{"location":"dynamiq/nodes/converters/unstructured/#dynamiq.nodes.converters.unstructured.UnstructuredFileConverterInputSchema.validate_file_source","title":"<code>validate_file_source()</code>","text":"<p>Validate that either <code>file_paths</code> or <code>files</code> is specified</p> Source code in <code>dynamiq/nodes/converters/unstructured.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_file_source(self):\n    \"\"\"Validate that either `file_paths` or `files` is specified\"\"\"\n    if not self.file_paths and not self.files:\n        raise ValueError(\"Either `file_paths` or `files` must be provided.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/embedders/base/","title":"Base","text":""},{"location":"dynamiq/nodes/embedders/base/#dynamiq.nodes.embedders.base.DocumentEmbedder","title":"<code>DocumentEmbedder</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> Source code in <code>dynamiq/nodes/embedders/base.py</code> <pre><code>class DocumentEmbedder(ConnectionNode):\n    group: Literal[NodeGroup.EMBEDDERS] = NodeGroup.EMBEDDERS\n    document_embedder: BaseEmbedder | None = None\n    input_schema: ClassVar[type[DocumentEmbedderInputSchema]] = DocumentEmbedderInputSchema\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"document_embedder\": True}\n\n    def execute(self, input_data: DocumentEmbedderInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Executes the document embedding process.\n\n        This method takes input documents, computes their embeddings, and returns the result.\n\n        Args:\n            input_data (DocumentEmbedderInputSchema): An instance containing the documents to embed.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            The output from the document_embedder component, typically the computed embeddings.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        output = self.document_embedder.embed_documents(input_data.documents)\n        logger.debug(f\"{self.name} executed successfully.\")\n\n        return output\n</code></pre>"},{"location":"dynamiq/nodes/embedders/base/#dynamiq.nodes.embedders.base.DocumentEmbedder.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the document embedding process.</p> <p>This method takes input documents, computes their embeddings, and returns the result.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>DocumentEmbedderInputSchema</code> <p>An instance containing the documents to embed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The output from the document_embedder component, typically the computed embeddings.</p> Source code in <code>dynamiq/nodes/embedders/base.py</code> <pre><code>def execute(self, input_data: DocumentEmbedderInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Executes the document embedding process.\n\n    This method takes input documents, computes their embeddings, and returns the result.\n\n    Args:\n        input_data (DocumentEmbedderInputSchema): An instance containing the documents to embed.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        The output from the document_embedder component, typically the computed embeddings.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    output = self.document_embedder.embed_documents(input_data.documents)\n    logger.debug(f\"{self.name} executed successfully.\")\n\n    return output\n</code></pre>"},{"location":"dynamiq/nodes/embedders/base/#dynamiq.nodes.embedders.base.TextEmbedder","title":"<code>TextEmbedder</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> Source code in <code>dynamiq/nodes/embedders/base.py</code> <pre><code>class TextEmbedder(ConnectionNode):\n    group: Literal[NodeGroup.EMBEDDERS] = NodeGroup.EMBEDDERS\n    text_embedder: BaseEmbedder | None = None\n    input_schema: ClassVar[type[TextEmbedderInputSchema]] = TextEmbedderInputSchema\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"text_embedder\": True}\n\n    def execute(self, input_data: TextEmbedderInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the text embedding process.\n\n        This method takes text input data, computes its embeddings, and returns the result.\n\n        Args:\n            input_data (TextEmbedderInputSchema): The input data containing the query to embed.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the embedding and the original query.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n        raw_output = self.text_embedder.embed_text(input_data.query)\n        logger.debug(f\"{self.name}: {raw_output['meta']}\")\n        result = TextEmbeddingOutput(\n            embedding=raw_output[\"embedding\"],\n            query=input_data.query,\n        )\n        return result\n</code></pre>"},{"location":"dynamiq/nodes/embedders/base/#dynamiq.nodes.embedders.base.TextEmbedder.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the text embedding process.</p> <p>This method takes text input data, computes its embeddings, and returns the result.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>TextEmbedderInputSchema</code> <p>The input data containing the query to embed.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the embedding and the original query.</p> Source code in <code>dynamiq/nodes/embedders/base.py</code> <pre><code>def execute(self, input_data: TextEmbedderInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the text embedding process.\n\n    This method takes text input data, computes its embeddings, and returns the result.\n\n    Args:\n        input_data (TextEmbedderInputSchema): The input data containing the query to embed.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the embedding and the original query.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n    raw_output = self.text_embedder.embed_text(input_data.query)\n    logger.debug(f\"{self.name}: {raw_output['meta']}\")\n    result = TextEmbeddingOutput(\n        embedding=raw_output[\"embedding\"],\n        query=input_data.query,\n    )\n    return result\n</code></pre>"},{"location":"dynamiq/nodes/embedders/base/#dynamiq.nodes.embedders.base.TextEmbeddingOutput","title":"<code>TextEmbeddingOutput</code>","text":"<p>               Bases: <code>dict</code></p> <p>Dict-like output for text embedders with tracing-aware to_dict().</p> Source code in <code>dynamiq/nodes/embedders/base.py</code> <pre><code>class TextEmbeddingOutput(dict):\n    \"\"\"Dict-like output for text embedders with tracing-aware to_dict().\"\"\"\n\n    query: str\n    embedding: list[float]\n\n    def to_dict(self, for_tracing: bool = False, truncate_limit: int = TRUNCATE_EMBEDDINGS_LIMIT, **kwargs) -&gt; dict:\n        data = dict(self)\n        if for_tracing and isinstance(data.get(\"embedding\"), list):\n            if len(data[\"embedding\"]) &gt; truncate_limit:\n                data[\"embedding\"] = data[\"embedding\"][:truncate_limit]\n        return data\n</code></pre>"},{"location":"dynamiq/nodes/embedders/bedrock/","title":"Bedrock","text":""},{"location":"dynamiq/nodes/embedders/bedrock/#dynamiq.nodes.embedders.bedrock.BedrockDocumentEmbedder","title":"<code>BedrockDocumentEmbedder</code>","text":"<p>               Bases: <code>DocumentEmbedder</code></p> <p>Provides functionality to compute embeddings for documents using Bedrock models.</p> <p>This class extends ConnectionNode to create embeddings for documents using Bedrock API.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>AWS | None</code> <p>The connection to the Bedrock API.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding.</p> <code>document_embedder</code> <code>BedrockDocumentEmbedderComponent</code> <p>The component for document embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[AWS]</code> <p>The connection to the Bedrock API. A new connection is created if none is provided.</p> required <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to 'amazon.titan-embed-text-v1'.</p> required Source code in <code>dynamiq/nodes/embedders/bedrock.py</code> <pre><code>class BedrockDocumentEmbedder(DocumentEmbedder):\n    \"\"\"\n    Provides functionality to compute embeddings for documents using Bedrock models.\n\n    This class extends ConnectionNode to create embeddings for documents using Bedrock API.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (BedrockConnection | None): The connection to the Bedrock API.\n        model (str): The model name to use for embedding.\n        document_embedder (BedrockDocumentEmbedderComponent): The component for document embedding.\n\n    Args:\n        connection (Optional[BedrockConnection]): The connection to the Bedrock API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to 'amazon.titan-embed-text-v1'.\n    \"\"\"\n\n    name: str = \"AmazonBedrockDocumentEmbedder\"\n    connection: BedrockConnection | None = None\n    model: str = \"amazon.titan-embed-text-v1\"\n    document_embedder: BedrockEmbedderComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the BedrockDocumentEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new BedrockConnection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = BedrockConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initializes the components of the BedrockDocumentEmbedder.\n\n        This method sets up the document_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_embedder is None:\n            self.document_embedder = BedrockEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/bedrock/#dynamiq.nodes.embedders.bedrock.BedrockDocumentEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the BedrockDocumentEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new BedrockConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/bedrock.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the BedrockDocumentEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new BedrockConnection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = BedrockConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/bedrock/#dynamiq.nodes.embedders.bedrock.BedrockDocumentEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initializes the components of the BedrockDocumentEmbedder.</p> <p>This method sets up the document_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/bedrock.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initializes the components of the BedrockDocumentEmbedder.\n\n    This method sets up the document_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_embedder is None:\n        self.document_embedder = BedrockEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/bedrock/#dynamiq.nodes.embedders.bedrock.BedrockTextEmbedder","title":"<code>BedrockTextEmbedder</code>","text":"<p>               Bases: <code>TextEmbedder</code></p> <p>A component designed to embed strings using specified Cohere models.</p> <p>This class extends ConnectionNode to provide text embedding functionality using Bedrock API.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[AWS]</code> <p>An existing connection to Bedrock API. If not provided, a new connection will be established using environment variables.</p> required <code>model</code> <code>str</code> <p>The identifier of the Bedrock model for text embeddings. Defaults to 'amazon.titan-embed-text-v1'.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>AWS | None</code> <p>The connection to Bedrock API.</p> <code>model</code> <code>str</code> <p>The Bedrock model identifier for text embeddings.</p> <code>text_embedder</code> <code>BedrockTextEmbedderComponent</code> <p>The component for text embedding.</p> Source code in <code>dynamiq/nodes/embedders/bedrock.py</code> <pre><code>class BedrockTextEmbedder(TextEmbedder):\n    \"\"\"\n    A component designed to embed strings using specified Cohere models.\n\n    This class extends ConnectionNode to provide text embedding functionality using Bedrock API.\n\n    Args:\n        connection (Optional[BedrockConnection]): An existing connection to Bedrock API. If not\n            provided, a new connection will be established using environment variables.\n        model (str): The identifier of the Bedrock model for text embeddings. Defaults to\n            'amazon.titan-embed-text-v1'.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (BedrockConnection | None): The connection to Bedrock API.\n        model (str): The Bedrock model identifier for text embeddings.\n        text_embedder (BedrockTextEmbedderComponent): The component for text embedding.\n\n    \"\"\"\n\n    name: str = \"BedrockTextEmbedder\"\n    connection: BedrockConnection | None = None\n    model: str = \"amazon.titan-embed-text-v1\"\n    text_embedder: BedrockEmbedderComponent = None\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the BedrockTextEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new BedrockConnection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = BedrockConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the BedrockTextEmbedder.\n\n        This method sets up the text_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.text_embedder is None:\n            self.text_embedder = BedrockEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/bedrock/#dynamiq.nodes.embedders.bedrock.BedrockTextEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the BedrockTextEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new BedrockConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/bedrock.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the BedrockTextEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new BedrockConnection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = BedrockConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/bedrock/#dynamiq.nodes.embedders.bedrock.BedrockTextEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the BedrockTextEmbedder.</p> <p>This method sets up the text_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/bedrock.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the BedrockTextEmbedder.\n\n    This method sets up the text_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.text_embedder is None:\n        self.text_embedder = BedrockEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/cohere/","title":"Cohere","text":""},{"location":"dynamiq/nodes/embedders/cohere/#dynamiq.nodes.embedders.cohere.CohereDocumentEmbedder","title":"<code>CohereDocumentEmbedder</code>","text":"<p>               Bases: <code>DocumentEmbedder</code></p> <p>Provides functionality to compute embeddings for documents using Cohere models.</p> <p>This class extends ConnectionNode to create embeddings for documents using Cohere API.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Cohere | None</code> <p>The connection to the Cohere API.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding.</p> <code>document_embedder</code> <code>CohereDocumentEmbedderComponent</code> <p>The component for document embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[Cohere]</code> <p>The connection to the Cohere API. A new connection is created if none is provided.</p> required <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to 'cohere/embed-english-v2.0'.</p> required Source code in <code>dynamiq/nodes/embedders/cohere.py</code> <pre><code>class CohereDocumentEmbedder(DocumentEmbedder):\n    \"\"\"\n    Provides functionality to compute embeddings for documents using Cohere models.\n\n    This class extends ConnectionNode to create embeddings for documents using Cohere API.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (CohereConnection | None): The connection to the Cohere API.\n        model (str): The model name to use for embedding.\n        document_embedder (CohereDocumentEmbedderComponent): The component for document embedding.\n\n    Args:\n        connection (Optional[CohereConnection]): The connection to the Cohere API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to 'cohere/embed-english-v2.0'.\n    \"\"\"\n\n    name: str = \"CohereDocumentEmbedder\"\n    connection: CohereConnection | None = None\n    model: str = \"cohere/embed-english-v2.0\"\n    document_embedder: CohereEmbedderComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the CohereDocumentEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new CohereConnection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = CohereConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initializes the components of the CohereDocumentEmbedder.\n\n        This method sets up the document_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_embedder is None:\n            self.document_embedder = CohereEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/cohere/#dynamiq.nodes.embedders.cohere.CohereDocumentEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the CohereDocumentEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new CohereConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/cohere.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the CohereDocumentEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new CohereConnection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = CohereConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/cohere/#dynamiq.nodes.embedders.cohere.CohereDocumentEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initializes the components of the CohereDocumentEmbedder.</p> <p>This method sets up the document_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/cohere.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initializes the components of the CohereDocumentEmbedder.\n\n    This method sets up the document_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_embedder is None:\n        self.document_embedder = CohereEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/cohere/#dynamiq.nodes.embedders.cohere.CohereTextEmbedder","title":"<code>CohereTextEmbedder</code>","text":"<p>               Bases: <code>TextEmbedder</code></p> <p>A component designed to embed strings using specified Cohere models.</p> <p>This class extends ConnectionNode to provide text embedding functionality using litellm embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[Cohere]</code> <p>An existing connection to Cohere API. If not provided, a new connection will be established using environment variables.</p> required <code>model</code> <code>str</code> <p>The identifier of the Cohere model for text embeddings. Defaults to 'cohere/embed-english-v2.0'.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Cohere | None</code> <p>The connection to Cohere API.</p> <code>model</code> <code>str</code> <p>The Cohere model identifier for text embeddings.</p> <code>text_embedder</code> <code>CohereTextEmbedderComponent</code> <p>The component for text embedding.</p> Source code in <code>dynamiq/nodes/embedders/cohere.py</code> <pre><code>class CohereTextEmbedder(TextEmbedder):\n    \"\"\"\n    A component designed to embed strings using specified Cohere models.\n\n    This class extends ConnectionNode to provide text embedding functionality using litellm embedding.\n\n    Args:\n        connection (Optional[CohereConnection]): An existing connection to Cohere API. If not\n            provided, a new connection will be established using environment variables.\n        model (str): The identifier of the Cohere model for text embeddings. Defaults to\n            'cohere/embed-english-v2.0'.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (CohereConnection | None): The connection to Cohere API.\n        model (str): The Cohere model identifier for text embeddings.\n        text_embedder (CohereTextEmbedderComponent): The component for text embedding.\n\n    \"\"\"\n\n    name: str = \"CohereTextEmbedder\"\n    connection: CohereConnection | None = None\n    model: str = \"cohere/embed-english-v2.0\"\n    text_embedder: CohereEmbedderComponent = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the CohereTextEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new CohereConnection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = CohereConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the CohereTextEmbedder.\n\n        This method sets up the text_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.text_embedder is None:\n            self.text_embedder = CohereEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/cohere/#dynamiq.nodes.embedders.cohere.CohereTextEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the CohereTextEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new CohereConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/cohere.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the CohereTextEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new CohereConnection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = CohereConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/cohere/#dynamiq.nodes.embedders.cohere.CohereTextEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the CohereTextEmbedder.</p> <p>This method sets up the text_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/cohere.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the CohereTextEmbedder.\n\n    This method sets up the text_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.text_embedder is None:\n        self.text_embedder = CohereEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/gemini/","title":"Gemini","text":""},{"location":"dynamiq/nodes/embedders/gemini/#dynamiq.nodes.embedders.gemini.GeminiDocumentEmbedder","title":"<code>GeminiDocumentEmbedder</code>","text":"<p>               Bases: <code>DocumentEmbedder</code></p> <p>Provides functionality to compute embeddings for documents using Gemini models.</p> <p>This class extends DocumentEmbedder to create embeddings for documents using Gemini API.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Gemini | None</code> <p>The connection to the Gemini API.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding.</p> <code>document_embedder</code> <code>GeminiEmbedder</code> <p>The component for document embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[Gemini]</code> <p>The connection to the Gemini API. A new connection is created if none is provided.</p> required <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to 'gemini/gemini-embedding-exp-03-07'.</p> required <code>input_type</code> <code>str</code> <p>Specifies the type of embedding task. Defaults to \"search_document\".</p> required Source code in <code>dynamiq/nodes/embedders/gemini.py</code> <pre><code>class GeminiDocumentEmbedder(DocumentEmbedder):\n    \"\"\"\n    Provides functionality to compute embeddings for documents using Gemini models.\n\n    This class extends DocumentEmbedder to create embeddings for documents using Gemini API.\n\n    Attributes:\n        name (str): The name of the node.\n        connection (GeminiConnection | None): The connection to the Gemini API.\n        model (str): The model name to use for embedding.\n        document_embedder (GeminiEmbedderComponent): The component for document embedding.\n\n    Args:\n        connection (Optional[GeminiConnection]): The connection to the Gemini API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to 'gemini/gemini-embedding-exp-03-07'.\n        input_type (str): Specifies the type of embedding task. Defaults to \"search_document\".\n    \"\"\"\n\n    name: str = \"GeminiDocumentEmbedder\"\n    connection: GeminiConnection | None = None\n    model: str = \"gemini/gemini-embedding-exp-03-07\"\n    input_type: str = \"search_document\"\n    document_embedder: GeminiEmbedderComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the GeminiDocumentEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new GeminiConnection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = GeminiConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initializes the components of the GeminiDocumentEmbedder.\n\n        This method sets up the document_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_embedder is None:\n            self.document_embedder = GeminiEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client, input_type=self.input_type\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/gemini/#dynamiq.nodes.embedders.gemini.GeminiDocumentEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the GeminiDocumentEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new GeminiConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/gemini.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the GeminiDocumentEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new GeminiConnection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = GeminiConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/gemini/#dynamiq.nodes.embedders.gemini.GeminiDocumentEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initializes the components of the GeminiDocumentEmbedder.</p> <p>This method sets up the document_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/gemini.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initializes the components of the GeminiDocumentEmbedder.\n\n    This method sets up the document_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_embedder is None:\n        self.document_embedder = GeminiEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client, input_type=self.input_type\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/gemini/#dynamiq.nodes.embedders.gemini.GeminiTextEmbedder","title":"<code>GeminiTextEmbedder</code>","text":"<p>               Bases: <code>TextEmbedder</code></p> <p>A component designed to embed strings using specified Gemini models.</p> <p>This class extends TextEmbedder to provide text embedding functionality using Gemini API.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[Gemini]</code> <p>An existing connection to Gemini API. If not provided, a new connection will be established using environment variables.</p> required <code>model</code> <code>str</code> <p>The identifier of the Gemini model for text embeddings. Defaults to 'gemini/gemini-embedding-exp-03-07'.</p> required <code>input_type</code> <code>str</code> <p>Specifies the type of embedding task. Defaults to \"search_query\".</p> required <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Gemini | None</code> <p>The connection to Gemini API.</p> <code>model</code> <code>str</code> <p>The Gemini model identifier for text embeddings.</p> <code>text_embedder</code> <code>GeminiEmbedder</code> <p>The component for text embedding.</p> Source code in <code>dynamiq/nodes/embedders/gemini.py</code> <pre><code>class GeminiTextEmbedder(TextEmbedder):\n    \"\"\"\n    A component designed to embed strings using specified Gemini models.\n\n    This class extends TextEmbedder to provide text embedding functionality using Gemini API.\n\n    Args:\n        connection (Optional[GeminiConnection]): An existing connection to Gemini API. If not\n            provided, a new connection will be established using environment variables.\n        model (str): The identifier of the Gemini model for text embeddings. Defaults to\n            'gemini/gemini-embedding-exp-03-07'.\n        input_type (str): Specifies the type of embedding task. Defaults to \"search_query\".\n\n    Attributes:\n        name (str): The name of the node.\n        connection (GeminiConnection | None): The connection to Gemini API.\n        model (str): The Gemini model identifier for text embeddings.\n        text_embedder (GeminiEmbedderComponent): The component for text embedding.\n    \"\"\"\n\n    name: str = \"GeminiTextEmbedder\"\n    connection: GeminiConnection | None = None\n    model: str = \"gemini/gemini-embedding-exp-03-07\"\n    input_type: str = \"search_query\"\n    text_embedder: GeminiEmbedderComponent = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the GeminiTextEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new GeminiConnection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = GeminiConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the GeminiTextEmbedder.\n\n        This method sets up the text_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.text_embedder is None:\n            self.text_embedder = GeminiEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client, input_type=self.input_type\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/gemini/#dynamiq.nodes.embedders.gemini.GeminiTextEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the GeminiTextEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new GeminiConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/gemini.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the GeminiTextEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new GeminiConnection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = GeminiConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/gemini/#dynamiq.nodes.embedders.gemini.GeminiTextEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the GeminiTextEmbedder.</p> <p>This method sets up the text_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/gemini.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the GeminiTextEmbedder.\n\n    This method sets up the text_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.text_embedder is None:\n        self.text_embedder = GeminiEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client, input_type=self.input_type\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/huggingface/","title":"Huggingface","text":""},{"location":"dynamiq/nodes/embedders/huggingface/#dynamiq.nodes.embedders.huggingface.HuggingFaceDocumentEmbedder","title":"<code>HuggingFaceDocumentEmbedder</code>","text":"<p>               Bases: <code>DocumentEmbedder</code></p> <p>Provides functionality to compute embeddings for documents using HuggingFace models.</p> <p>This class extends ConnectionNode to create embeddings for documents using litellm embedding.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>HuggingFace | None</code> <p>The connection to the HuggingFace API.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding.</p> <code>document_embedder</code> <code>HuggingFaceDocumentEmbedderComponent</code> <p>The component for document embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[HuggingFace]</code> <p>The connection to the HuggingFace API. A new connection is created if none is provided.</p> required <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to 'huggingface/microsoft/codebert-base'.</p> required Source code in <code>dynamiq/nodes/embedders/huggingface.py</code> <pre><code>class HuggingFaceDocumentEmbedder(DocumentEmbedder):\n    \"\"\"\n    Provides functionality to compute embeddings for documents using HuggingFace models.\n\n    This class extends ConnectionNode to create embeddings for documents using litellm embedding.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (HuggingFaceConnection | None): The connection to the HuggingFace API.\n        model (str): The model name to use for embedding.\n        document_embedder (HuggingFaceDocumentEmbedderComponent): The component for document embedding.\n\n    Args:\n        connection (Optional[HuggingFaceConnection]): The connection to the HuggingFace API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to 'huggingface/microsoft/codebert-base'.\n    \"\"\"\n    name: str = \"HuggingFaceDocumentEmbedder\"\n    connection: HuggingFaceConnection | None = None\n    model: str = \"huggingface/BAAI/bge-large-zh\"\n    document_embedder: HuggingFaceEmbedderComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the HuggingFaceDocumentEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new HuggingFaceConnection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = HuggingFaceConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initializes the components of the HuggingFaceDocumentEmbedder.\n\n        This method sets up the document_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_embedder is None:\n            self.document_embedder = HuggingFaceEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/huggingface/#dynamiq.nodes.embedders.huggingface.HuggingFaceDocumentEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the HuggingFaceDocumentEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new HuggingFaceConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/huggingface.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the HuggingFaceDocumentEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new HuggingFaceConnection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = HuggingFaceConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/huggingface/#dynamiq.nodes.embedders.huggingface.HuggingFaceDocumentEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initializes the components of the HuggingFaceDocumentEmbedder.</p> <p>This method sets up the document_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/huggingface.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initializes the components of the HuggingFaceDocumentEmbedder.\n\n    This method sets up the document_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_embedder is None:\n        self.document_embedder = HuggingFaceEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/huggingface/#dynamiq.nodes.embedders.huggingface.HuggingFaceTextEmbedder","title":"<code>HuggingFaceTextEmbedder</code>","text":"<p>               Bases: <code>TextEmbedder</code></p> <p>A component designed to embed strings using specified HuggingFace models.</p> <p>This class extends ConnectionNode to provide text embedding functionality using litellm embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[HuggingFace]</code> <p>An existing connection to HuggingFace's API. If not provided, a new connection will be established using environment variables.</p> required <code>model</code> <code>str</code> <p>The identifier of the HuggingFace model for text embeddings. Defaults to 'huggingface/microsoft/codebert-base'.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>HuggingFace | None</code> <p>The connection to HuggingFace API.</p> <code>model</code> <code>str</code> <p>The HuggingFace model identifier for text embeddings.</p> <code>text_embedder</code> <code>HuggingFaceTextEmbedderComponent</code> <p>The component for text embedding.</p> Source code in <code>dynamiq/nodes/embedders/huggingface.py</code> <pre><code>class HuggingFaceTextEmbedder(TextEmbedder):\n    \"\"\"\n    A component designed to embed strings using specified HuggingFace models.\n\n    This class extends ConnectionNode to provide text embedding functionality using litellm embedding.\n\n    Args:\n        connection (Optional[HuggingFaceConnection]): An existing connection to HuggingFace's API. If not\n            provided, a new connection will be established using environment variables.\n        model (str): The identifier of the HuggingFace model for text embeddings. Defaults to\n            'huggingface/microsoft/codebert-base'.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (HuggingFaceConnection | None): The connection to HuggingFace API.\n        model (str): The HuggingFace model identifier for text embeddings.\n        text_embedder (HuggingFaceTextEmbedderComponent): The component for text embedding.\n\n    \"\"\"\n\n    name: str = \"HuggingFaceTextEmbedder\"\n    connection: HuggingFaceConnection | None = None\n    model: str = \"huggingface/microsoft/codebert-base\"\n    text_embedder: HuggingFaceEmbedderComponent = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the HuggingFaceTextEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new HuggingFaceConnection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = HuggingFaceConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the HuggingFaceTextEmbedder.\n\n        This method sets up the text_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.text_embedder is None:\n            self.text_embedder = HuggingFaceEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/huggingface/#dynamiq.nodes.embedders.huggingface.HuggingFaceTextEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the HuggingFaceTextEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new HuggingFaceConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/huggingface.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the HuggingFaceTextEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new HuggingFaceConnection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = HuggingFaceConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/huggingface/#dynamiq.nodes.embedders.huggingface.HuggingFaceTextEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the HuggingFaceTextEmbedder.</p> <p>This method sets up the text_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/huggingface.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the HuggingFaceTextEmbedder.\n\n    This method sets up the text_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.text_embedder is None:\n        self.text_embedder = HuggingFaceEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/mistral/","title":"Mistral","text":""},{"location":"dynamiq/nodes/embedders/mistral/#dynamiq.nodes.embedders.mistral.MistralDocumentEmbedder","title":"<code>MistralDocumentEmbedder</code>","text":"<p>               Bases: <code>DocumentEmbedder</code></p> <p>Provides functionality to compute embeddings for documents using Mistral models.</p> <p>This class extends ConnectionNode to create embeddings for documents using litellm embedding.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Mistral | None</code> <p>The connection to the Mistral API.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding.</p> <code>document_embedder</code> <code>MistralDocumentEmbedderComponent</code> <p>The component for document embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[Mistral]</code> <p>The connection to the Mistral API. A new connection is created if none is provided.</p> required <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to 'mistral/mistral-embed'. only by 'text-embedding-3' and later models. Defaults to None.</p> required Source code in <code>dynamiq/nodes/embedders/mistral.py</code> <pre><code>class MistralDocumentEmbedder(DocumentEmbedder):\n    \"\"\"\n    Provides functionality to compute embeddings for documents using Mistral models.\n\n    This class extends ConnectionNode to create embeddings for documents using litellm embedding.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (MistralConnection | None): The connection to the Mistral API.\n        model (str): The model name to use for embedding.\n        document_embedder (MistralDocumentEmbedderComponent): The component for document embedding.\n\n    Args:\n        connection (Optional[MistralConnection]): The connection to the Mistral API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to 'mistral/mistral-embed'.\n            only by 'text-embedding-3' and later models. Defaults to None.\n    \"\"\"\n\n    name: str = \"MistralDocumentEmbedder\"\n    connection: MistralConnection | None = None\n    model: str = \"mistral/mistral-embed\"\n    document_embedder: MistralEmbedderComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the MistralDocumentEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new MistralConnection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = MistralConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initializes the components of the MistralDocumentEmbedder.\n\n        This method sets up the document_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_embedder is None:\n            self.document_embedder = MistralEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/mistral/#dynamiq.nodes.embedders.mistral.MistralDocumentEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the MistralDocumentEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new MistralConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/mistral.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the MistralDocumentEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new MistralConnection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = MistralConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/mistral/#dynamiq.nodes.embedders.mistral.MistralDocumentEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initializes the components of the MistralDocumentEmbedder.</p> <p>This method sets up the document_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/mistral.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initializes the components of the MistralDocumentEmbedder.\n\n    This method sets up the document_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_embedder is None:\n        self.document_embedder = MistralEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/mistral/#dynamiq.nodes.embedders.mistral.MistralTextEmbedder","title":"<code>MistralTextEmbedder</code>","text":"<p>               Bases: <code>TextEmbedder</code></p> <p>A component designed to embed strings using specified Mistral models.</p> <p>This class extends ConnectionNode to provide text embedding functionality using Mistral API.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[Mistral]</code> <p>An existing connection to Mistral API. If not provided, a new connection will be established using environment variables.</p> required <code>model</code> <code>str</code> <p>The identifier of the Mistral model for text embeddings. Defaults to 'mistral/mistral-embed'.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Mistral | None</code> <p>The connection to Mistral's API.</p> <code>model</code> <code>str</code> <p>The Mistral model identifier for text embeddings.</p> <code>text_embedder</code> <code>MistralTextEmbedderComponent</code> <p>The component for text embedding.</p> Source code in <code>dynamiq/nodes/embedders/mistral.py</code> <pre><code>class MistralTextEmbedder(TextEmbedder):\n    \"\"\"\n    A component designed to embed strings using specified Mistral models.\n\n    This class extends ConnectionNode to provide text embedding functionality using Mistral API.\n\n    Args:\n        connection (Optional[MistralConnection]): An existing connection to Mistral API. If not\n            provided, a new connection will be established using environment variables.\n        model (str): The identifier of the Mistral model for text embeddings. Defaults to\n            'mistral/mistral-embed'.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (MistralConnection | None): The connection to Mistral's API.\n        model (str): The Mistral model identifier for text embeddings.\n        text_embedder (MistralTextEmbedderComponent): The component for text embedding.\n\n    \"\"\"\n\n    name: str = \"MistralTextEmbedder\"\n    connection: MistralConnection | None = None\n    model: str = \"mistral/mistral-embed\"\n    text_embedder: MistralEmbedderComponent = None\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the MistralTextEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new MistralConnection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = MistralConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the MistralTextEmbedder.\n\n        This method sets up the text_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.text_embedder is None:\n            self.text_embedder = MistralEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/mistral/#dynamiq.nodes.embedders.mistral.MistralTextEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the MistralTextEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new MistralConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/mistral.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the MistralTextEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new MistralConnection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = MistralConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/mistral/#dynamiq.nodes.embedders.mistral.MistralTextEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the MistralTextEmbedder.</p> <p>This method sets up the text_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/mistral.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the MistralTextEmbedder.\n\n    This method sets up the text_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.text_embedder is None:\n        self.text_embedder = MistralEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/openai/","title":"Openai","text":""},{"location":"dynamiq/nodes/embedders/openai/#dynamiq.nodes.embedders.openai.OpenAIDocumentEmbedder","title":"<code>OpenAIDocumentEmbedder</code>","text":"<p>               Bases: <code>DocumentEmbedder</code></p> <p>Provides functionality to compute embeddings for documents using OpenAI's models.</p> <p>This class extends ConnectionNode to create embeddings for documents using OpenAI's API.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>OpenAI | None</code> <p>The connection to the OpenAI API.</p> <code>client</code> <code>OpenAIClient | None</code> <p>The OpenAI client instance.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding.</p> <code>dimensions</code> <code>int | None</code> <p>The number of dimensions for the output embeddings.</p> <code>document_embedder</code> <code>OpenAIDocumentEmbedderComponent</code> <p>The component for document embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[OpenAI]</code> <p>The connection to the OpenAI API. A new connection is created if none is provided.</p> required <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to 'text-embedding-3-small'.</p> required <code>dimensions</code> <code>Optional[int]</code> <p>The number of dimensions for the output embeddings. Supported only by 'text-embedding-3' and later models. Defaults to None.</p> required Source code in <code>dynamiq/nodes/embedders/openai.py</code> <pre><code>class OpenAIDocumentEmbedder(DocumentEmbedder):\n    \"\"\"\n    Provides functionality to compute embeddings for documents using OpenAI's models.\n\n    This class extends ConnectionNode to create embeddings for documents using OpenAI's API.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (OpenAIConnection | None): The connection to the OpenAI API.\n        client (OpenAIClient | None): The OpenAI client instance.\n        model (str): The model name to use for embedding.\n        dimensions (int | None): The number of dimensions for the output embeddings.\n        document_embedder (OpenAIDocumentEmbedderComponent): The component for document embedding.\n\n    Args:\n        connection (Optional[OpenAIConnection]): The connection to the OpenAI API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to 'text-embedding-3-small'.\n        dimensions (Optional[int]): The number of dimensions for the output embeddings. Supported\n            only by 'text-embedding-3' and later models. Defaults to None.\n    \"\"\"\n\n    name: str = \"OpenAIDocumentEmbedder\"\n    connection: OpenAIConnection | None = None\n    model: str = \"text-embedding-3-small\"\n    dimensions: int | None = None\n    document_embedder: OpenAIEmbedderComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the OpenAIDocumentEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new OpenAIConnection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = OpenAIConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initializes the components of the OpenAIDocumentEmbedder.\n\n        This method sets up the document_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_embedder is None:\n            self.document_embedder = OpenAIEmbedderComponent(\n                connection=self.connection,\n                model=self.model,\n                dimensions=self.dimensions,\n                client=self.client,\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/openai/#dynamiq.nodes.embedders.openai.OpenAIDocumentEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the OpenAIDocumentEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new OpenAIConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/openai.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the OpenAIDocumentEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new OpenAIConnection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = OpenAIConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/openai/#dynamiq.nodes.embedders.openai.OpenAIDocumentEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initializes the components of the OpenAIDocumentEmbedder.</p> <p>This method sets up the document_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/openai.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initializes the components of the OpenAIDocumentEmbedder.\n\n    This method sets up the document_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_embedder is None:\n        self.document_embedder = OpenAIEmbedderComponent(\n            connection=self.connection,\n            model=self.model,\n            dimensions=self.dimensions,\n            client=self.client,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/openai/#dynamiq.nodes.embedders.openai.OpenAITextEmbedder","title":"<code>OpenAITextEmbedder</code>","text":"<p>               Bases: <code>TextEmbedder</code></p> <p>A component designed to embed strings using specified OpenAI models.</p> <p>This class extends ConnectionNode to provide text embedding functionality using OpenAI's API.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[OpenAI]</code> <p>An existing connection to OpenAI's API. If not provided, a new connection will be established using environment variables.</p> required <code>model</code> <code>str</code> <p>The identifier of the OpenAI model for text embeddings. Defaults to 'text-embedding-3-small'.</p> required <code>dimensions</code> <code>Optional[int]</code> <p>Desired dimensionality of output embeddings. Defaults to None, using the model's default output dimensionality.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>OpenAI | None</code> <p>The connection to OpenAI's API.</p> <code>client</code> <code>OpenAIClient | None</code> <p>The OpenAI client instance.</p> <code>model</code> <code>str</code> <p>The OpenAI model identifier for text embeddings.</p> <code>dimensions</code> <code>int | None</code> <p>The desired dimensionality of output embeddings.</p> <code>text_embedder</code> <code>OpenAITextEmbedderComponent</code> <p>The component for text embedding.</p> Notes <p>The <code>dimensions</code> parameter is model-dependent and may not be supported by all models.</p> Source code in <code>dynamiq/nodes/embedders/openai.py</code> <pre><code>class OpenAITextEmbedder(TextEmbedder):\n    \"\"\"\n    A component designed to embed strings using specified OpenAI models.\n\n    This class extends ConnectionNode to provide text embedding functionality using OpenAI's API.\n\n    Args:\n        connection (Optional[OpenAIConnection]): An existing connection to OpenAI's API. If not\n            provided, a new connection will be established using environment variables.\n        model (str): The identifier of the OpenAI model for text embeddings. Defaults to\n            'text-embedding-3-small'.\n        dimensions (Optional[int]): Desired dimensionality of output embeddings. Defaults to None,\n            using the model's default output dimensionality.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (OpenAIConnection | None): The connection to OpenAI's API.\n        client (OpenAIClient | None): The OpenAI client instance.\n        model (str): The OpenAI model identifier for text embeddings.\n        dimensions (int | None): The desired dimensionality of output embeddings.\n        text_embedder (OpenAITextEmbedderComponent): The component for text embedding.\n\n    Notes:\n        The `dimensions` parameter is model-dependent and may not be supported by all models.\n    \"\"\"\n\n    name: str = \"OpenAITextEmbedder\"\n    connection: OpenAIConnection | None = None\n    model: str = \"text-embedding-3-small\"\n    dimensions: int | None = None\n    text_embedder: OpenAIEmbedderComponent = None\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the OpenAITextEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new OpenAIConnection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = OpenAIConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the OpenAITextEmbedder.\n\n        This method sets up the text_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.text_embedder is None:\n            self.text_embedder = OpenAIEmbedderComponent(\n                connection=self.connection,\n                model=self.model,\n                dimensions=self.dimensions,\n                client=self.client,\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/openai/#dynamiq.nodes.embedders.openai.OpenAITextEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the OpenAITextEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new OpenAIConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/openai.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the OpenAITextEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new OpenAIConnection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = OpenAIConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/openai/#dynamiq.nodes.embedders.openai.OpenAITextEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the OpenAITextEmbedder.</p> <p>This method sets up the text_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/openai.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the OpenAITextEmbedder.\n\n    This method sets up the text_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.text_embedder is None:\n        self.text_embedder = OpenAIEmbedderComponent(\n            connection=self.connection,\n            model=self.model,\n            dimensions=self.dimensions,\n            client=self.client,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/vertexai/","title":"Vertexai","text":""},{"location":"dynamiq/nodes/embedders/vertexai/#dynamiq.nodes.embedders.vertexai.VertexAIDocumentEmbedder","title":"<code>VertexAIDocumentEmbedder</code>","text":"<p>               Bases: <code>DocumentEmbedder</code></p> <p>Computes embeddings for documents using Vertex AI.</p> <p>This class extends DocumentEmbedder to generate document embeddings via the Vertex AI embedding API.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of this node.</p> <code>connection</code> <code>VertexAI</code> <p>The Vertex AI connection instance.</p> <code>model</code> <code>str</code> <p>The Vertex AI embedding model name.</p> <code>input_type</code> <code>str</code> <p>The embedding task type (defaults to \"search_document\").</p> <code>document_embedder</code> <code>VertexAIEmbedder</code> <p>The embedder component.</p> Source code in <code>dynamiq/nodes/embedders/vertexai.py</code> <pre><code>class VertexAIDocumentEmbedder(DocumentEmbedder):\n    \"\"\"\n    Computes embeddings for documents using Vertex AI.\n\n    This class extends DocumentEmbedder to generate document embeddings\n    via the Vertex AI embedding API.\n\n    Attributes:\n        name (str): The name of this node.\n        connection (VertexAIConnection): The Vertex AI connection instance.\n        model (str): The Vertex AI embedding model name.\n        input_type (str): The embedding task type (defaults to \"search_document\").\n        document_embedder (VertexAIEmbedderComponent): The embedder component.\n    \"\"\"\n\n    name: str = \"VertexAIDocumentEmbedder\"\n    connection: VertexAIConnection\n    model: str = \"vertex_ai/text-embedding-005\"\n    input_type: str = \"search_document\"\n    document_embedder: VertexAIEmbedderComponent | None = None\n\n    def __init__(\n        self,\n        *,\n        connection: VertexAIConnection | None = None,\n        model: str | None = None,\n        input_type: str | None = None,\n        **kwargs: Any\n    ):\n        \"\"\"\n        Initialize the document embedder.\n\n        Args:\n            connection: Optional existing Vertex AI connection.\n            model: Optional override for the embedding model.\n            input_type: Optional override for the embedding task type.\n            **kwargs: Additional keyword args for the base node.\n        \"\"\"\n        if connection is None:\n            connection = VertexAIConnection()\n        super().__init__(connection=connection, **kwargs)\n\n        if model:\n            self.model = model\n        if input_type:\n            self.input_type = input_type\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize or reuse the Vertex AI embedder component.\n\n        Args:\n            connection_manager: Optional connection manager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n\n        if self.document_embedder is None:\n            self.document_embedder = VertexAIEmbedderComponent(\n                connection=self.connection, model=self.model, input_type=self.input_type\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/vertexai/#dynamiq.nodes.embedders.vertexai.VertexAIDocumentEmbedder.__init__","title":"<code>__init__(*, connection=None, model=None, input_type=None, **kwargs)</code>","text":"<p>Initialize the document embedder.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>VertexAI | None</code> <p>Optional existing Vertex AI connection.</p> <code>None</code> <code>model</code> <code>str | None</code> <p>Optional override for the embedding model.</p> <code>None</code> <code>input_type</code> <code>str | None</code> <p>Optional override for the embedding task type.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword args for the base node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/vertexai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    connection: VertexAIConnection | None = None,\n    model: str | None = None,\n    input_type: str | None = None,\n    **kwargs: Any\n):\n    \"\"\"\n    Initialize the document embedder.\n\n    Args:\n        connection: Optional existing Vertex AI connection.\n        model: Optional override for the embedding model.\n        input_type: Optional override for the embedding task type.\n        **kwargs: Additional keyword args for the base node.\n    \"\"\"\n    if connection is None:\n        connection = VertexAIConnection()\n    super().__init__(connection=connection, **kwargs)\n\n    if model:\n        self.model = model\n    if input_type:\n        self.input_type = input_type\n</code></pre>"},{"location":"dynamiq/nodes/embedders/vertexai/#dynamiq.nodes.embedders.vertexai.VertexAIDocumentEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize or reuse the Vertex AI embedder component.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/vertexai.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize or reuse the Vertex AI embedder component.\n\n    Args:\n        connection_manager: Optional connection manager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n\n    if self.document_embedder is None:\n        self.document_embedder = VertexAIEmbedderComponent(\n            connection=self.connection, model=self.model, input_type=self.input_type\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/vertexai/#dynamiq.nodes.embedders.vertexai.VertexAITextEmbedder","title":"<code>VertexAITextEmbedder</code>","text":"<p>               Bases: <code>TextEmbedder</code></p> <p>Computes embeddings for text strings using Vertex AI.</p> <p>This class extends TextEmbedder to generate text embeddings via the Vertex AI embedding API.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of this node.</p> <code>connection</code> <code>VertexAI</code> <p>The Vertex AI connection instance.</p> <code>model</code> <code>str</code> <p>The Vertex AI embedding model name.</p> <code>input_type</code> <code>str</code> <p>The embedding task type (defaults to \"search_query\").</p> <code>text_embedder</code> <code>VertexAIEmbedder</code> <p>The embedder component.</p> Source code in <code>dynamiq/nodes/embedders/vertexai.py</code> <pre><code>class VertexAITextEmbedder(TextEmbedder):\n    \"\"\"\n    Computes embeddings for text strings using Vertex AI.\n\n    This class extends TextEmbedder to generate text embeddings\n    via the Vertex AI embedding API.\n\n    Attributes:\n        name (str): The name of this node.\n        connection (VertexAIConnection): The Vertex AI connection instance.\n        model (str): The Vertex AI embedding model name.\n        input_type (str): The embedding task type (defaults to \"search_query\").\n        text_embedder (VertexAIEmbedderComponent): The embedder component.\n    \"\"\"\n\n    name: str = \"VertexAITextEmbedder\"\n    connection: VertexAIConnection\n    model: str = \"vertex_ai/text-embedding-005\"\n    input_type: str = \"search_query\"\n    text_embedder: VertexAIEmbedderComponent | None = None\n\n    def __init__(\n        self,\n        *,\n        connection: VertexAIConnection | None = None,\n        model: str | None = None,\n        input_type: str | None = None,\n        **kwargs: Any\n    ):\n        \"\"\"\n        Initialize the text embedder.\n\n        Args:\n            connection: Optional existing Vertex AI connection.\n            model: Optional override for the embedding model.\n            input_type: Optional override for the embedding task type.\n            **kwargs: Additional keyword args for the base node.\n        \"\"\"\n        if connection is None:\n            connection = VertexAIConnection()\n        super().__init__(connection=connection, **kwargs)\n\n        if model:\n            self.model = model\n        if input_type:\n            self.input_type = input_type\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize or reuse the Vertex AI embedder component.\n\n        Args:\n            connection_manager: Optional connection manager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n\n        if self.text_embedder is None:\n            self.text_embedder = VertexAIEmbedderComponent(\n                connection=self.connection, model=self.model, input_type=self.input_type\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/vertexai/#dynamiq.nodes.embedders.vertexai.VertexAITextEmbedder.__init__","title":"<code>__init__(*, connection=None, model=None, input_type=None, **kwargs)</code>","text":"<p>Initialize the text embedder.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>VertexAI | None</code> <p>Optional existing Vertex AI connection.</p> <code>None</code> <code>model</code> <code>str | None</code> <p>Optional override for the embedding model.</p> <code>None</code> <code>input_type</code> <code>str | None</code> <p>Optional override for the embedding task type.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword args for the base node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/vertexai.py</code> <pre><code>def __init__(\n    self,\n    *,\n    connection: VertexAIConnection | None = None,\n    model: str | None = None,\n    input_type: str | None = None,\n    **kwargs: Any\n):\n    \"\"\"\n    Initialize the text embedder.\n\n    Args:\n        connection: Optional existing Vertex AI connection.\n        model: Optional override for the embedding model.\n        input_type: Optional override for the embedding task type.\n        **kwargs: Additional keyword args for the base node.\n    \"\"\"\n    if connection is None:\n        connection = VertexAIConnection()\n    super().__init__(connection=connection, **kwargs)\n\n    if model:\n        self.model = model\n    if input_type:\n        self.input_type = input_type\n</code></pre>"},{"location":"dynamiq/nodes/embedders/vertexai/#dynamiq.nodes.embedders.vertexai.VertexAITextEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize or reuse the Vertex AI embedder component.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/vertexai.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize or reuse the Vertex AI embedder component.\n\n    Args:\n        connection_manager: Optional connection manager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n\n    if self.text_embedder is None:\n        self.text_embedder = VertexAIEmbedderComponent(\n            connection=self.connection, model=self.model, input_type=self.input_type\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/watsonx/","title":"Watsonx","text":""},{"location":"dynamiq/nodes/embedders/watsonx/#dynamiq.nodes.embedders.watsonx.WatsonXDocumentEmbedder","title":"<code>WatsonXDocumentEmbedder</code>","text":"<p>               Bases: <code>DocumentEmbedder</code></p> <p>Provides functionality to compute embeddings for documents using WatsonX models.</p> <p>This class extends ConnectionNode to create embeddings for documents using litellm embedding.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>WatsonX | None</code> <p>The connection to the WatsonX API.</p> <code>model</code> <code>str</code> <p>The model name to use for embedding.</p> <code>document_embedder</code> <code>WatsonXDocumentEmbedderComponent</code> <p>The component for document embedding.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[WatsonX]</code> <p>The connection to the WatsonX API. A new connection is created if none is provided.</p> required <code>model</code> <code>str</code> <p>The model name to use for embedding. Defaults to 'watsonx/ibm/slate-30m-english-rtrvr'.</p> required Source code in <code>dynamiq/nodes/embedders/watsonx.py</code> <pre><code>class WatsonXDocumentEmbedder(DocumentEmbedder):\n    \"\"\"\n    Provides functionality to compute embeddings for documents using WatsonX models.\n\n    This class extends ConnectionNode to create embeddings for documents using litellm embedding.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (WatsonXConnection | None): The connection to the WatsonX API.\n        model (str): The model name to use for embedding.\n        document_embedder (WatsonXDocumentEmbedderComponent): The component for document embedding.\n\n    Args:\n        connection (Optional[WatsonXConnection]): The connection to the WatsonX API. A new connection\n            is created if none is provided.\n        model (str): The model name to use for embedding. Defaults to 'watsonx/ibm/slate-30m-english-rtrvr'.\n    \"\"\"\n\n    name: str = \"WatsonXDocumentEmbedder\"\n    connection: WatsonXConnection | None = None\n    model: str = \"watsonx/ibm/slate-30m-english-rtrvr\"\n    document_embedder: WatsonXEmbedderComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the WatsonXDocumentEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new WatsonXConnection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = WatsonXConnection()\n        super().__init__(**kwargs)\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initializes the components of the WatsonXDocumentEmbedder.\n\n        This method sets up the document_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_embedder is None:\n            self.document_embedder = WatsonXEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/watsonx/#dynamiq.nodes.embedders.watsonx.WatsonXDocumentEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the WatsonXDocumentEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new WatsonXConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/watsonx.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the WatsonXDocumentEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new WatsonXConnection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = WatsonXConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/watsonx/#dynamiq.nodes.embedders.watsonx.WatsonXDocumentEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initializes the components of the WatsonXDocumentEmbedder.</p> <p>This method sets up the document_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/watsonx.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initializes the components of the WatsonXDocumentEmbedder.\n\n    This method sets up the document_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_embedder is None:\n        self.document_embedder = WatsonXEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/watsonx/#dynamiq.nodes.embedders.watsonx.WatsonXTextEmbedder","title":"<code>WatsonXTextEmbedder</code>","text":"<p>               Bases: <code>TextEmbedder</code></p> <p>A component designed to embed strings using specified WatsonX models.</p> <p>This class extends ConnectionNode to provide text embedding functionality using WatsonX API.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[WatsonX]</code> <p>An existing connection to WatsonX API. If not provided, a new connection will be established using environment variables.</p> required <code>model</code> <code>str</code> <p>The identifier of the WatsonX model for text embeddings. Defaults to 'watsonx/ibm/slate-30m-english-rtrvr'.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[EMBEDDERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>WatsonX | None</code> <p>The connection to WatsonX's API.</p> <code>model</code> <code>str</code> <p>The WatsonX model identifier for text embeddings.</p> <code>text_embedder</code> <code>WatsonXTextEmbedderComponent</code> <p>The component for text embedding.</p> Source code in <code>dynamiq/nodes/embedders/watsonx.py</code> <pre><code>class WatsonXTextEmbedder(TextEmbedder):\n    \"\"\"\n    A component designed to embed strings using specified WatsonX models.\n\n    This class extends ConnectionNode to provide text embedding functionality using WatsonX API.\n\n    Args:\n        connection (Optional[WatsonXConnection]): An existing connection to WatsonX API. If not\n            provided, a new connection will be established using environment variables.\n        model (str): The identifier of the WatsonX model for text embeddings. Defaults to\n            'watsonx/ibm/slate-30m-english-rtrvr'.\n\n    Attributes:\n        group (Literal[NodeGroup.EMBEDDERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (WatsonXConnection | None): The connection to WatsonX's API.\n        model (str): The WatsonX model identifier for text embeddings.\n        text_embedder (WatsonXTextEmbedderComponent): The component for text embedding.\n\n    \"\"\"\n\n    name: str = \"WatsonXTextEmbedder\"\n    connection: WatsonXConnection | None = None\n    model: str = \"watsonx/ibm/slate-30m-english-rtrvr\"\n    text_embedder: WatsonXEmbedderComponent = None\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the WatsonXTextEmbedder.\n\n        If neither client nor connection is provided in kwargs, a new WatsonXConnection is created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the node.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = WatsonXConnection()\n        super().__init__(**kwargs)\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"text_embedder\": True}\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the WatsonXTextEmbedder.\n\n        This method sets up the text_embedder component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n                ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.text_embedder is None:\n            self.text_embedder = WatsonXEmbedderComponent(\n                connection=self.connection, model=self.model, client=self.client\n            )\n</code></pre>"},{"location":"dynamiq/nodes/embedders/watsonx/#dynamiq.nodes.embedders.watsonx.WatsonXTextEmbedder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the WatsonXTextEmbedder.</p> <p>If neither client nor connection is provided in kwargs, a new WatsonXConnection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/embedders/watsonx.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the WatsonXTextEmbedder.\n\n    If neither client nor connection is provided in kwargs, a new WatsonXConnection is created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the node.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = WatsonXConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/embedders/watsonx/#dynamiq.nodes.embedders.watsonx.WatsonXTextEmbedder.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the WatsonXTextEmbedder.</p> <p>This method sets up the text_embedder component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/embedders/watsonx.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the WatsonXTextEmbedder.\n\n    This method sets up the text_embedder component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Defaults to a new\n            ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.text_embedder is None:\n        self.text_embedder = WatsonXEmbedderComponent(\n            connection=self.connection, model=self.model, client=self.client\n        )\n</code></pre>"},{"location":"dynamiq/nodes/llms/ai21/","title":"Ai21","text":""},{"location":"dynamiq/nodes/llms/ai21/#dynamiq.nodes.llms.ai21.AI21","title":"<code>AI21</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>AI21 LLM node.</p> <p>This class provides an implementation for the AI21 Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>AI21</code> <p>The connection to use for the AI21 LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the AI21 model name.</p> Source code in <code>dynamiq/nodes/llms/ai21.py</code> <pre><code>class AI21(BaseLLM):\n    \"\"\"AI21 LLM node.\n\n    This class provides an implementation for the AI21 Language Model node.\n\n    Attributes:\n        connection (AI21Connection): The connection to use for the AI21 LLM.\n        MODEL_PREFIX (str): The prefix for the AI21 model name.\n    \"\"\"\n    connection: AI21Connection\n    MODEL_PREFIX = \"ai21/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the AI21 LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = AI21Connection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/ai21/#dynamiq.nodes.llms.ai21.AI21.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the AI21 LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/ai21.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the AI21 LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = AI21Connection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/anthropic/","title":"Anthropic","text":""},{"location":"dynamiq/nodes/llms/anthropic/#dynamiq.nodes.llms.anthropic.Anthropic","title":"<code>Anthropic</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Anthropic LLM node.</p> <p>This class provides an implementation for the Anthropic Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Anthropic | None</code> <p>The connection to use for the Anthropic LLM.</p> Source code in <code>dynamiq/nodes/llms/anthropic.py</code> <pre><code>class Anthropic(BaseLLM):\n    \"\"\"Anthropic LLM node.\n\n    This class provides an implementation for the Anthropic Language Model node.\n\n    Attributes:\n        connection (AnthropicConnection | None): The connection to use for the Anthropic LLM.\n    \"\"\"\n    connection: AnthropicConnection | None = None\n    MODEL_PREFIX = \"anthropic/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Anthropic LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = AnthropicConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/anthropic/#dynamiq.nodes.llms.anthropic.Anthropic.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Anthropic LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/anthropic.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Anthropic LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = AnthropicConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/anyscale/","title":"Anyscale","text":""},{"location":"dynamiq/nodes/llms/anyscale/#dynamiq.nodes.llms.anyscale.Anyscale","title":"<code>Anyscale</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Anyscale LLM node.</p> <p>This class provides an implementation for the Anyscale Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Anyscale | None</code> <p>The connection to use for the Anyscale LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Anyscale model name.</p> Source code in <code>dynamiq/nodes/llms/anyscale.py</code> <pre><code>class Anyscale(BaseLLM):\n    \"\"\"Anyscale LLM node.\n\n    This class provides an implementation for the Anyscale Language Model node.\n\n    Attributes:\n        connection (AnyscaleConnection | None): The connection to use for the Anyscale LLM.\n        MODEL_PREFIX (str): The prefix for the Anyscale model name.\n    \"\"\"\n    connection: AnyscaleConnection | None = None\n    MODEL_PREFIX = \"anyscale/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Anyscale LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = AnyscaleConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/anyscale/#dynamiq.nodes.llms.anyscale.Anyscale.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Anyscale LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/anyscale.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Anyscale LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = AnyscaleConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/azureai/","title":"Azureai","text":""},{"location":"dynamiq/nodes/llms/azureai/#dynamiq.nodes.llms.azureai.AzureAI","title":"<code>AzureAI</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>AzureAI LLM node.</p> <p>This class provides an implementation for the AzureAI Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>AzureAI | None</code> <p>The connection to use for the AzureAI LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the AzureAI model name.</p> Source code in <code>dynamiq/nodes/llms/azureai.py</code> <pre><code>class AzureAI(BaseLLM):\n    \"\"\"AzureAI LLM node.\n\n    This class provides an implementation for the AzureAI Language Model node.\n\n    Attributes:\n        connection (AzureAIConnection | None): The connection to use for the AzureAI LLM.\n        MODEL_PREFIX (str): The prefix for the AzureAI model name.\n    \"\"\"\n    connection: AzureAIConnection | None = None\n    MODEL_PREFIX = \"azure/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the AzureAI LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = AzureAIConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/azureai/#dynamiq.nodes.llms.azureai.AzureAI.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the AzureAI LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/azureai.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the AzureAI LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = AzureAIConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/","title":"Base","text":""},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM","title":"<code>BaseLLM</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>Base class for all LLM nodes.</p> <p>Attributes:</p> Name Type Description <code>MODEL_PREFIX</code> <code>ClassVar[str | None]</code> <p>Optional model prefix.</p> <code>name</code> <code>str | None</code> <p>Name of the LLM node. Defaults to \"LLM\".</p> <code>model</code> <code>str</code> <p>Model to use for the LLM.</p> <code>prompt</code> <code>Prompt | None</code> <p>Prompt to use for the LLM.</p> <code>connection</code> <code>BaseConnection</code> <p>Connection to use for the LLM.</p> <code>group</code> <code>Literal[LLMS]</code> <p>Group for the node. Defaults to NodeGroup.LLMS.</p> <code>temperature</code> <code>float | None</code> <p>Temperature for the LLM.</p> <code>max_tokens</code> <code>int | None</code> <p>Maximum number of tokens for the LLM.</p> <code>stop</code> <code>list[str]</code> <p>List of tokens to stop at for the LLM.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Error handling config. Defaults to ErrorHandling(timeout_seconds=600).</p> <code>top_p</code> <code>float | None</code> <p>Value to consider tokens with top_p probability.</p> <code>seed</code> <code>int | None</code> <p>Seed for generating the same result for repeated requests.</p> <code>presence_penalty</code> <code>float | None</code> <p>Penalize new tokens based on their existence in the text.</p> <code>frequency_penalty</code> <code>float | None</code> <p>Penalize new tokens based on their frequency in the text.</p> <code>tool_choice</code> <code>str | None</code> <p>Value to control which function is called by the model.</p> <code>thinking_enabled</code> <code>bool</code> <p>Enables advanced reasoning if set to True.</p> <code>budget_tokens</code> <code>int</code> <p>Maximum number of tokens allocated for thinking.</p> <code>response_format</code> <code>dict[str, Any]</code> <p>JSON schema that specifies the structure of the llm's output</p> <code>tools</code> <code>list[Tool]</code> <p>List of tools that llm can call.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>class BaseLLM(ConnectionNode):\n    \"\"\"Base class for all LLM nodes.\n\n    Attributes:\n        MODEL_PREFIX (ClassVar[str | None]): Optional model prefix.\n        name (str | None): Name of the LLM node. Defaults to \"LLM\".\n        model (str): Model to use for the LLM.\n        prompt (Prompt | None): Prompt to use for the LLM.\n        connection (BaseConnection): Connection to use for the LLM.\n        group (Literal[NodeGroup.LLMS]): Group for the node. Defaults to NodeGroup.LLMS.\n        temperature (float | None): Temperature for the LLM.\n        max_tokens (int | None): Maximum number of tokens for the LLM.\n        stop (list[str]): List of tokens to stop at for the LLM.\n        error_handling (ErrorHandling): Error handling config. Defaults to ErrorHandling(timeout_seconds=600).\n        top_p (float | None): Value to consider tokens with top_p probability.\n        seed (int | None): Seed for generating the same result for repeated requests.\n        presence_penalty (float | None): Penalize new tokens based on their existence in the text.\n        frequency_penalty (float | None): Penalize new tokens based on their frequency in the text.\n        tool_choice (str | None): Value to control which function is called by the model.\n        thinking_enabled (bool): Enables advanced reasoning if set to True.\n        budget_tokens (int): Maximum number of tokens allocated for thinking.\n        response_format (dict[str, Any]): JSON schema that specifies the structure of the llm's output\n        tools list[Tool]: List of tools that llm can call.\n    \"\"\"\n    MODEL_PREFIX: ClassVar[str | None] = None\n    name: str | None = \"LLM\"\n    model: str\n    prompt: Prompt | None = None\n    connection: BaseConnection\n    group: Literal[NodeGroup.LLMS] = NodeGroup.LLMS\n    temperature: float | None = None\n    max_tokens: int | None = None\n    stop: list[str] | None = None\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=600))\n    top_p: float | None = None\n    seed: int | None = None\n    presence_penalty: float | None = None\n    frequency_penalty: float | None = None\n    tool_choice: str | None = None\n    thinking_enabled: bool | None = None\n    budget_tokens: int = 1024\n    response_format: dict[str, Any] | None = None\n    tools: list[Tool | dict] | None = None\n    input_schema: ClassVar[type[BaseLLMInputSchema]] = BaseLLMInputSchema\n    inference_mode: InferenceMode = Field(\n        default=InferenceMode.DEFAULT,\n        deprecated=\"Please use `tools` and `response_format` parameters \"\n        \"for selecting between function calling and structured output.\",\n    )\n    schema_: dict[str, Any] | type[BaseModel] | None = Field(\n        None,\n        description=\"Schema for structured output or function calling.\",\n        alias=\"schema\",\n        deprecated=\"Please use `tools` and `response_format` parameters \"\n        \"for function calling and structured output respectively.\",\n    )\n    model_config = ConfigDict(extra=\"allow\", arbitrary_types_allowed=True)\n\n    _completion: Callable = PrivateAttr()\n    _stream_chunk_builder: Callable = PrivateAttr()\n    _json_schema_fields: ClassVar[list[str]] = [\"model\", \"temperature\", \"max_tokens\", \"prompt\"]\n\n    @classmethod\n    def _generate_json_schema(cls, models: list[str], **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Generates full json schema of BaseLLM Node.\n\n        This schema is designed for compatibility with the WorkflowYamlParser,\n        containing enough partial information to instantiate an BaseLLM.\n        Parameters name to be included in the schema are either defined in the _json_schema_fields class variable or\n        passed via the fields parameter.\n\n        It generates a schema using provided models.\n\n        Args:\n            models (list[str]): List of available models.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: Generated json schema.\n        \"\"\"\n        schema = super()._generate_json_schema(**kwargs)\n        schema[\"properties\"][\"model\"][\"enum\"] = models\n        return schema\n\n    @field_validator(\"model\")\n    @classmethod\n    def set_model(cls, value: str | None) -&gt; str:\n        \"\"\"Set the model with the appropriate prefix.\n\n        Args:\n            value (str | None): The model value.\n\n        Returns:\n            str: The model value with the prefix.\n        \"\"\"\n        if cls.MODEL_PREFIX is not None and not value.startswith(cls.MODEL_PREFIX):\n            value = f\"{cls.MODEL_PREFIX}{value}\"\n        return value\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the BaseLLM instance.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        super().__init__(**kwargs)\n\n        # Save a bit of loading time as litellm is slow\n        from litellm import completion, stream_chunk_builder\n\n        # Avoid the same imports multiple times and for future usage in execute\n        self._completion = completion\n        self._stream_chunk_builder = stream_chunk_builder\n\n    def get_context_for_input_schema(self) -&gt; dict:\n        \"\"\"Provides context for input schema that is required for proper validation.\"\"\"\n        return {\"instance_prompt\": self.prompt}\n\n    def get_token_limit(self) -&gt; int:\n        \"\"\"Returns token limits of a llm.\n\n        Returns:\n            int: Number of tokens.\n        \"\"\"\n        return get_max_tokens(self.model)\n\n    @property\n    def is_vision_supported(self) -&gt; bool:\n        \"\"\"Check if the LLM supports vision/image processing.\"\"\"\n        return supports_vision(self.model)\n\n    @property\n    def is_pdf_input_supported(self) -&gt; bool:\n        \"\"\"Check if the LLM supports PDF input.\"\"\"\n        return supports_pdf_input(self.model)\n\n    def get_messages(\n        self,\n        prompt,\n        input_data,\n    ) -&gt; list[dict]:\n        \"\"\"\n        Format and filter message parameters based on provider requirements.\n        Override this in provider-specific subclasses.\n        \"\"\"\n        messages = prompt.format_messages(**dict(input_data))\n        return messages\n\n    @classmethod\n    def get_usage_data(\n        cls,\n        model: str,\n        completion: \"ModelResponse\",\n    ) -&gt; BaseLLMUsageData:\n        \"\"\"Get usage data for the LLM.\n\n        This method generates usage data for the LLM based on the provided messages.\n\n        Args:\n            model (str): The model to use for generating the usage data.\n            completion (ModelResponse): The completion response from the LLM.\n\n        Returns:\n            BaseLLMUsageData: A model containing the usage data for the LLM.\n        \"\"\"\n        from litellm import cost_per_token\n\n        usage = completion.model_extra[\"usage\"]\n        prompt_tokens = usage.prompt_tokens\n        completion_tokens = usage.completion_tokens\n        total_tokens = usage.total_tokens\n\n        try:\n            prompt_tokens_cost_usd, completion_tokens_cost_usd = cost_per_token(\n                model=model, prompt_tokens=prompt_tokens, completion_tokens=completion_tokens\n            )\n            total_tokens_cost_usd = prompt_tokens_cost_usd + completion_tokens_cost_usd\n        except Exception:\n            prompt_tokens_cost_usd, completion_tokens_cost_usd, total_tokens_cost_usd = None, None, None\n\n        return BaseLLMUsageData(\n            prompt_tokens=prompt_tokens,\n            prompt_tokens_cost_usd=prompt_tokens_cost_usd,\n            completion_tokens=completion_tokens,\n            completion_tokens_cost_usd=completion_tokens_cost_usd,\n            total_tokens=total_tokens,\n            total_tokens_cost_usd=total_tokens_cost_usd,\n        )\n\n    def _handle_completion_response(\n        self,\n        response: Union[\"ModelResponse\", \"CustomStreamWrapper\"],\n        config: RunnableConfig = None,\n        **kwargs,\n    ) -&gt; dict:\n        \"\"\"Handle completion response.\n\n        Args:\n            response (ModelResponse | CustomStreamWrapper): The response from the LLM.\n            config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the generated content and tool calls if present.\n        \"\"\"\n        content = response.choices[0].message.content\n        result = {\"content\": content}\n        if tool_calls := response.choices[0].message.tool_calls:\n            tool_calls_parsed = {}\n            for tc in tool_calls:\n                call = tc.model_dump()\n                call[\"function\"][\"arguments\"] = json.loads(call[\"function\"][\"arguments\"])\n                tool_calls_parsed[call[\"function\"][\"name\"]] = call\n            result[\"tool_calls\"] = tool_calls_parsed\n\n        usage_data = self.get_usage_data(model=self.model, completion=response).model_dump()\n        self.run_on_node_execute_run(callbacks=config.callbacks, usage_data=usage_data, **kwargs)\n\n        return result\n\n    def _handle_streaming_completion_response(\n        self,\n        response: Union[\"ModelResponse\", \"CustomStreamWrapper\"],\n        messages: list[dict],\n        config: RunnableConfig = None,\n        **kwargs,\n    ):\n        \"\"\"Handle streaming completion response.\n\n        Args:\n            response (ModelResponse | CustomStreamWrapper): The response from the LLM.\n            messages (list[dict]): The messages used for the LLM.\n            config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the generated content and tool calls.\n        \"\"\"\n        chunks = []\n        for chunk in response:\n            chunks.append(chunk)\n\n            self.run_on_node_execute_stream(\n                config.callbacks,\n                chunk.model_dump(),\n                **kwargs,\n            )\n\n        full_response = self._stream_chunk_builder(chunks=chunks, messages=messages)\n        return self._handle_completion_response(response=full_response, config=config, **kwargs)\n\n    def _get_response_format_and_tools(\n        self,\n        prompt: Prompt | None = None,\n        tools: list[Tool | dict] | None = None,\n        response_format: dict[str, Any] | None = None,\n    ) -&gt; tuple[dict[str, Any] | None, dict[str, Any] | None]:\n        \"\"\"Get response format and tools\n        Args:\n            input_data (BaseLLMInputSchema): The input data for the LLM.\n            prompt (Prompt | None): The prompt to use.\n            tools (list[Tool] | None): The tools to use.\n            response_format (dict[str, Any] | None): The response format to use.\n        Returns:\n            tuple[dict[str, Any] | None, dict[str, Any] | None]: Response format and tools.\n        Raises:\n            ValueError: If schema is None when using STRUCTURED_OUTPUT or FUNCTION_CALLING modes.\n        \"\"\"\n        response_format = response_format or self.response_format or prompt.response_format\n        tools = tools or self.tools or prompt.tools\n\n        # Suppress DeprecationWarning if deprecated parameters are not set\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n            use_inference_mode = (not response_format or not tools) and self.inference_mode != InferenceMode.DEFAULT\n\n        if use_inference_mode:\n            schema = self.schema_\n            match self.inference_mode:\n                case InferenceMode.STRUCTURED_OUTPUT:\n                    if schema is None:\n                        raise ValueError(\"Schema must be provided when using STRUCTURED_OUTPUT inference mode\")\n                    response_format = response_format or schema\n                case InferenceMode.FUNCTION_CALLING:\n                    if schema is None:\n                        raise ValueError(\"Schema must be provided when using FUNCTION_CALLING inference mode\")\n                    tools = tools or schema\n\n        if tools:\n            tools = [tool.model_dump() if isinstance(tool, Tool) else tool for tool in tools]\n\n        return response_format, tools\n\n    def update_completion_params(self, params: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"\n        Updates or modifies the parameters for the completion method.\n\n        This method can be overridden by subclasses to customize the parameters\n        passed to the completion method. By default, it enables usage information\n        in streaming mode if streaming is enabled and include_usage is set.\n        Args:\n            params (dict[str, Any]): The parameters to be updated.\n\n        Returns:\n            dict[str, Any]: The updated parameters.\n        \"\"\"\n        if self.streaming and self.streaming.enabled and self.streaming.include_usage and params.get(\"stream\", False):\n            params.setdefault(\"stream_options\", {})\n            params[\"stream_options\"][\"include_usage\"] = True\n        return params\n\n    def execute(\n        self,\n        input_data: BaseLLMInputSchema,\n        config: RunnableConfig = None,\n        prompt: Prompt | None = None,\n        tools: list[Tool | dict] | None = None,\n        response_format: dict[str, Any] | None = None,\n        **kwargs,\n    ):\n        \"\"\"Execute the LLM node.\n\n        This method processes the input data, formats the prompt, and generates a response using\n        the configured LLM.\n\n        Args:\n            input_data (BaseLLMInputSchema): The input data for the LLM.\n            config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n            prompt (Prompt, optional): The prompt to use for this execution. Defaults to None.\n            tools (list[Tool|dict]): List of tools that llm can call.\n            response_format (dict[str, Any]): JSON schema that specifies the structure of the llm's output\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the generated content and tool calls.\n        \"\"\"\n        config = ensure_config(config)\n        prompt = prompt or self.prompt or Prompt(messages=[], tools=None, response_format=None)\n        messages = self.get_messages(prompt, input_data)\n        self.run_on_node_execute_run(callbacks=config.callbacks, prompt_messages=messages, **kwargs)\n\n        extra = copy.deepcopy(self.__pydantic_extra__)\n        params = self.connection.conn_params.copy()\n        if self.client and not isinstance(self.connection, HttpApiKey):\n            params.update({\"client\": self.client})\n        if self.thinking_enabled:\n            params.update({\"thinking\": {\"type\": \"enabled\", \"budget_tokens\": self.budget_tokens}})\n        if extra:\n            params.update(extra)\n\n        response_format, tools = self._get_response_format_and_tools(\n            prompt=prompt,\n            tools=tools,\n            response_format=response_format,\n        )\n        # Check if a streaming callback is available in the config and enable streaming only if it is\n        # This is to avoid unnecessary streaming to reduce CPU usage\n        is_streaming_callback_available = any(\n            isinstance(callback, BaseStreamingCallbackHandler) for callback in config.callbacks\n        )\n        common_params: dict[str, Any] = {\n            \"model\": self.model,\n            \"messages\": messages,\n            \"stream\": self.streaming.enabled and is_streaming_callback_available,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens,\n            \"tools\": tools,\n            \"tool_choice\": self.tool_choice,\n            \"stop\": self.stop if self.stop else None,\n            \"top_p\": self.top_p,\n            \"seed\": self.seed,\n            \"presence_penalty\": self.presence_penalty,\n            \"frequency_penalty\": self.frequency_penalty,\n            \"response_format\": response_format,\n            \"drop_params\": True,\n            **params,\n        }\n\n        common_params = self.update_completion_params(common_params)\n\n        response = self._completion(**common_params)\n        handle_completion = (\n            self._handle_streaming_completion_response\n            if self.streaming.enabled and is_streaming_callback_available\n            else self._handle_completion_response\n        )\n\n        return handle_completion(\n            response=response, messages=messages, config=config, input_data=dict(input_data), **kwargs\n        )\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.is_pdf_input_supported","title":"<code>is_pdf_input_supported: bool</code>  <code>property</code>","text":"<p>Check if the LLM supports PDF input.</p>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.is_vision_supported","title":"<code>is_vision_supported: bool</code>  <code>property</code>","text":"<p>Check if the LLM supports vision/image processing.</p>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the BaseLLM instance.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the BaseLLM instance.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    super().__init__(**kwargs)\n\n    # Save a bit of loading time as litellm is slow\n    from litellm import completion, stream_chunk_builder\n\n    # Avoid the same imports multiple times and for future usage in execute\n    self._completion = completion\n    self._stream_chunk_builder = stream_chunk_builder\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.execute","title":"<code>execute(input_data, config=None, prompt=None, tools=None, response_format=None, **kwargs)</code>","text":"<p>Execute the LLM node.</p> <p>This method processes the input data, formats the prompt, and generates a response using the configured LLM.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>BaseLLMInputSchema</code> <p>The input data for the LLM.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the execution. Defaults to None.</p> <code>None</code> <code>prompt</code> <code>Prompt</code> <p>The prompt to use for this execution. Defaults to None.</p> <code>None</code> <code>tools</code> <code>list[Tool | dict]</code> <p>List of tools that llm can call.</p> <code>None</code> <code>response_format</code> <code>dict[str, Any]</code> <p>JSON schema that specifies the structure of the llm's output</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the generated content and tool calls.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>def execute(\n    self,\n    input_data: BaseLLMInputSchema,\n    config: RunnableConfig = None,\n    prompt: Prompt | None = None,\n    tools: list[Tool | dict] | None = None,\n    response_format: dict[str, Any] | None = None,\n    **kwargs,\n):\n    \"\"\"Execute the LLM node.\n\n    This method processes the input data, formats the prompt, and generates a response using\n    the configured LLM.\n\n    Args:\n        input_data (BaseLLMInputSchema): The input data for the LLM.\n        config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n        prompt (Prompt, optional): The prompt to use for this execution. Defaults to None.\n        tools (list[Tool|dict]): List of tools that llm can call.\n        response_format (dict[str, Any]): JSON schema that specifies the structure of the llm's output\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the generated content and tool calls.\n    \"\"\"\n    config = ensure_config(config)\n    prompt = prompt or self.prompt or Prompt(messages=[], tools=None, response_format=None)\n    messages = self.get_messages(prompt, input_data)\n    self.run_on_node_execute_run(callbacks=config.callbacks, prompt_messages=messages, **kwargs)\n\n    extra = copy.deepcopy(self.__pydantic_extra__)\n    params = self.connection.conn_params.copy()\n    if self.client and not isinstance(self.connection, HttpApiKey):\n        params.update({\"client\": self.client})\n    if self.thinking_enabled:\n        params.update({\"thinking\": {\"type\": \"enabled\", \"budget_tokens\": self.budget_tokens}})\n    if extra:\n        params.update(extra)\n\n    response_format, tools = self._get_response_format_and_tools(\n        prompt=prompt,\n        tools=tools,\n        response_format=response_format,\n    )\n    # Check if a streaming callback is available in the config and enable streaming only if it is\n    # This is to avoid unnecessary streaming to reduce CPU usage\n    is_streaming_callback_available = any(\n        isinstance(callback, BaseStreamingCallbackHandler) for callback in config.callbacks\n    )\n    common_params: dict[str, Any] = {\n        \"model\": self.model,\n        \"messages\": messages,\n        \"stream\": self.streaming.enabled and is_streaming_callback_available,\n        \"temperature\": self.temperature,\n        \"max_tokens\": self.max_tokens,\n        \"tools\": tools,\n        \"tool_choice\": self.tool_choice,\n        \"stop\": self.stop if self.stop else None,\n        \"top_p\": self.top_p,\n        \"seed\": self.seed,\n        \"presence_penalty\": self.presence_penalty,\n        \"frequency_penalty\": self.frequency_penalty,\n        \"response_format\": response_format,\n        \"drop_params\": True,\n        **params,\n    }\n\n    common_params = self.update_completion_params(common_params)\n\n    response = self._completion(**common_params)\n    handle_completion = (\n        self._handle_streaming_completion_response\n        if self.streaming.enabled and is_streaming_callback_available\n        else self._handle_completion_response\n    )\n\n    return handle_completion(\n        response=response, messages=messages, config=config, input_data=dict(input_data), **kwargs\n    )\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.get_context_for_input_schema","title":"<code>get_context_for_input_schema()</code>","text":"<p>Provides context for input schema that is required for proper validation.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>def get_context_for_input_schema(self) -&gt; dict:\n    \"\"\"Provides context for input schema that is required for proper validation.\"\"\"\n    return {\"instance_prompt\": self.prompt}\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.get_messages","title":"<code>get_messages(prompt, input_data)</code>","text":"<p>Format and filter message parameters based on provider requirements. Override this in provider-specific subclasses.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>def get_messages(\n    self,\n    prompt,\n    input_data,\n) -&gt; list[dict]:\n    \"\"\"\n    Format and filter message parameters based on provider requirements.\n    Override this in provider-specific subclasses.\n    \"\"\"\n    messages = prompt.format_messages(**dict(input_data))\n    return messages\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.get_token_limit","title":"<code>get_token_limit()</code>","text":"<p>Returns token limits of a llm.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of tokens.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>def get_token_limit(self) -&gt; int:\n    \"\"\"Returns token limits of a llm.\n\n    Returns:\n        int: Number of tokens.\n    \"\"\"\n    return get_max_tokens(self.model)\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.get_usage_data","title":"<code>get_usage_data(model, completion)</code>  <code>classmethod</code>","text":"<p>Get usage data for the LLM.</p> <p>This method generates usage data for the LLM based on the provided messages.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to use for generating the usage data.</p> required <code>completion</code> <code>ModelResponse</code> <p>The completion response from the LLM.</p> required <p>Returns:</p> Name Type Description <code>BaseLLMUsageData</code> <code>BaseLLMUsageData</code> <p>A model containing the usage data for the LLM.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>@classmethod\ndef get_usage_data(\n    cls,\n    model: str,\n    completion: \"ModelResponse\",\n) -&gt; BaseLLMUsageData:\n    \"\"\"Get usage data for the LLM.\n\n    This method generates usage data for the LLM based on the provided messages.\n\n    Args:\n        model (str): The model to use for generating the usage data.\n        completion (ModelResponse): The completion response from the LLM.\n\n    Returns:\n        BaseLLMUsageData: A model containing the usage data for the LLM.\n    \"\"\"\n    from litellm import cost_per_token\n\n    usage = completion.model_extra[\"usage\"]\n    prompt_tokens = usage.prompt_tokens\n    completion_tokens = usage.completion_tokens\n    total_tokens = usage.total_tokens\n\n    try:\n        prompt_tokens_cost_usd, completion_tokens_cost_usd = cost_per_token(\n            model=model, prompt_tokens=prompt_tokens, completion_tokens=completion_tokens\n        )\n        total_tokens_cost_usd = prompt_tokens_cost_usd + completion_tokens_cost_usd\n    except Exception:\n        prompt_tokens_cost_usd, completion_tokens_cost_usd, total_tokens_cost_usd = None, None, None\n\n    return BaseLLMUsageData(\n        prompt_tokens=prompt_tokens,\n        prompt_tokens_cost_usd=prompt_tokens_cost_usd,\n        completion_tokens=completion_tokens,\n        completion_tokens_cost_usd=completion_tokens_cost_usd,\n        total_tokens=total_tokens,\n        total_tokens_cost_usd=total_tokens_cost_usd,\n    )\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.set_model","title":"<code>set_model(value)</code>  <code>classmethod</code>","text":"<p>Set the model with the appropriate prefix.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str | None</code> <p>The model value.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The model value with the prefix.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>@field_validator(\"model\")\n@classmethod\ndef set_model(cls, value: str | None) -&gt; str:\n    \"\"\"Set the model with the appropriate prefix.\n\n    Args:\n        value (str | None): The model value.\n\n    Returns:\n        str: The model value with the prefix.\n    \"\"\"\n    if cls.MODEL_PREFIX is not None and not value.startswith(cls.MODEL_PREFIX):\n        value = f\"{cls.MODEL_PREFIX}{value}\"\n    return value\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLM.update_completion_params","title":"<code>update_completion_params(params)</code>","text":"<p>Updates or modifies the parameters for the completion method.</p> <p>This method can be overridden by subclasses to customize the parameters passed to the completion method. By default, it enables usage information in streaming mode if streaming is enabled and include_usage is set. Args:     params (dict[str, Any]): The parameters to be updated.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: The updated parameters.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>def update_completion_params(self, params: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"\n    Updates or modifies the parameters for the completion method.\n\n    This method can be overridden by subclasses to customize the parameters\n    passed to the completion method. By default, it enables usage information\n    in streaming mode if streaming is enabled and include_usage is set.\n    Args:\n        params (dict[str, Any]): The parameters to be updated.\n\n    Returns:\n        dict[str, Any]: The updated parameters.\n    \"\"\"\n    if self.streaming and self.streaming.enabled and self.streaming.include_usage and params.get(\"stream\", False):\n        params.setdefault(\"stream_options\", {})\n        params[\"stream_options\"][\"include_usage\"] = True\n    return params\n</code></pre>"},{"location":"dynamiq/nodes/llms/base/#dynamiq.nodes.llms.base.BaseLLMUsageData","title":"<code>BaseLLMUsageData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model for LLM usage data.</p> <p>Attributes:</p> Name Type Description <code>prompt_tokens</code> <code>int</code> <p>Number of prompt tokens.</p> <code>prompt_tokens_cost_usd</code> <code>float | None</code> <p>Cost of prompt tokens in USD.</p> <code>completion_tokens</code> <code>int</code> <p>Number of completion tokens.</p> <code>completion_tokens_cost_usd</code> <code>float | None</code> <p>Cost of completion tokens in USD.</p> <code>total_tokens</code> <code>int</code> <p>Total number of tokens.</p> <code>total_tokens_cost_usd</code> <code>float | None</code> <p>Total cost of tokens in USD.</p> Source code in <code>dynamiq/nodes/llms/base.py</code> <pre><code>class BaseLLMUsageData(BaseModel):\n    \"\"\"Model for LLM usage data.\n\n    Attributes:\n        prompt_tokens (int): Number of prompt tokens.\n        prompt_tokens_cost_usd (float | None): Cost of prompt tokens in USD.\n        completion_tokens (int): Number of completion tokens.\n        completion_tokens_cost_usd (float | None): Cost of completion tokens in USD.\n        total_tokens (int): Total number of tokens.\n        total_tokens_cost_usd (float | None): Total cost of tokens in USD.\n    \"\"\"\n    prompt_tokens: int\n    prompt_tokens_cost_usd: float | None\n    completion_tokens: int\n    completion_tokens_cost_usd: float | None\n    total_tokens: int\n    total_tokens_cost_usd: float | None\n</code></pre>"},{"location":"dynamiq/nodes/llms/bedrock/","title":"Bedrock","text":""},{"location":"dynamiq/nodes/llms/bedrock/#dynamiq.nodes.llms.bedrock.Bedrock","title":"<code>Bedrock</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Bedrock LLM node.</p> <p>This class provides an implementation for the Bedrock Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>AWS | None</code> <p>The connection to use for the Bedrock LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Bedrock model name.</p> Source code in <code>dynamiq/nodes/llms/bedrock.py</code> <pre><code>class Bedrock(BaseLLM):\n    \"\"\"Bedrock LLM node.\n\n    This class provides an implementation for the Bedrock Language Model node.\n\n    Attributes:\n        connection (AWSConnection | None): The connection to use for the Bedrock LLM.\n        MODEL_PREFIX (str): The prefix for the Bedrock model name.\n    \"\"\"\n    connection: AWSConnection | None = None\n    MODEL_PREFIX = \"bedrock/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Bedrock LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = AWSConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/bedrock/#dynamiq.nodes.llms.bedrock.Bedrock.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Bedrock LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/bedrock.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Bedrock LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = AWSConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/cerebras/","title":"Cerebras","text":""},{"location":"dynamiq/nodes/llms/cerebras/#dynamiq.nodes.llms.cerebras.Cerebras","title":"<code>Cerebras</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Cerebras LLM node.</p> <p>This class provides an implementation for the Cerebras Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Cerebras</code> <p>The connection to use for the Cerebras LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Cerebras model name.</p> Source code in <code>dynamiq/nodes/llms/cerebras.py</code> <pre><code>class Cerebras(BaseLLM):\n    \"\"\"Cerebras LLM node.\n\n    This class provides an implementation for the Cerebras Language Model node.\n\n    Attributes:\n        connection (CerebrasConnection): The connection to use for the Cerebras LLM.\n        MODEL_PREFIX (str): The prefix for the Cerebras model name.\n    \"\"\"\n    connection: CerebrasConnection\n    MODEL_PREFIX = \"cerebras/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Cerebras LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = CerebrasConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/cerebras/#dynamiq.nodes.llms.cerebras.Cerebras.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Cerebras LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/cerebras.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Cerebras LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = CerebrasConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/cohere/","title":"Cohere","text":""},{"location":"dynamiq/nodes/llms/cohere/#dynamiq.nodes.llms.cohere.Cohere","title":"<code>Cohere</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Cohere LLM node.</p> <p>This class provides an implementation for the Cohere Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Cohere</code> <p>The connection to use for the Cohere LLM.</p> Source code in <code>dynamiq/nodes/llms/cohere.py</code> <pre><code>class Cohere(BaseLLM):\n    \"\"\"Cohere LLM node.\n\n    This class provides an implementation for the Cohere Language Model node.\n\n    Attributes:\n        connection (CohereConnection): The connection to use for the Cohere LLM.\n    \"\"\"\n    connection: CohereConnection\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Cohere LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = CohereConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/cohere/#dynamiq.nodes.llms.cohere.Cohere.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Cohere LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/cohere.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Cohere LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = CohereConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/custom_llm/","title":"Custom llm","text":""},{"location":"dynamiq/nodes/llms/custom_llm/#dynamiq.nodes.llms.custom_llm.CustomLLM","title":"<code>CustomLLM</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Custom LLM implementation for third-party providers requiring specific formatting.</p> <p>This class extends BaseLLM to support providers like OpenRouter, Anthropic, or custom endpoints that need special request formatting. It allows adding provider prefixes to model names.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str | None</code> <p>Name of the LLM node. Defaults to \"CustomLLM\".</p> <code>connection</code> <code>HttpApiKey</code> <p>Connection to use for the LLM API.</p> <code>provider_prefix</code> <code>str | None</code> <p>Provider prefix to add to model names (e.g., \"openrouter\").                          When specified, this will automatically prepend                          \"{provider_prefix}/\" to the model name when sending requests.</p> Source code in <code>dynamiq/nodes/llms/custom_llm.py</code> <pre><code>class CustomLLM(BaseLLM):\n    \"\"\"\n    Custom LLM implementation for third-party providers requiring specific formatting.\n\n    This class extends BaseLLM to support providers like OpenRouter, Anthropic, or custom\n    endpoints that need special request formatting. It allows adding provider prefixes to\n    model names.\n\n    Attributes:\n        name (str | None): Name of the LLM node. Defaults to \"CustomLLM\".\n        connection (HttpApiKey): Connection to use for the LLM API.\n        provider_prefix (str | None): Provider prefix to add to model names (e.g., \"openrouter\").\n                                     When specified, this will automatically prepend\n                                     \"{provider_prefix}/\" to the model name when sending requests.\n\n    \"\"\"\n\n    name: str | None = \"CustomLLM\"\n    connection: HttpApiKey\n    provider_prefix: str | None = None\n\n    def update_completion_params(self, params: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"\n        Customizes LLM request parameters for third-party providers.\n\n        This method adds the provider prefix to model name if specified\n        (e.g., \"openrouter/anthropic/claude-2\").\n\n        Args:\n            params (dict[str, Any]): The original parameters to be sent to the LLM provider.\n                                    This includes model, messages, temperature, etc.\n\n        Returns:\n            dict[str, Any]: The modified parameters with proper model name formatting.\n        \"\"\"\n        params = super().update_completion_params(params)\n\n        if self.provider_prefix and not params[\"model\"].startswith(self.provider_prefix + \"/\"):\n            params[\"model\"] = f\"{self.provider_prefix}/{params['model']}\"\n\n        return params\n</code></pre>"},{"location":"dynamiq/nodes/llms/custom_llm/#dynamiq.nodes.llms.custom_llm.CustomLLM.update_completion_params","title":"<code>update_completion_params(params)</code>","text":"<p>Customizes LLM request parameters for third-party providers.</p> <p>This method adds the provider prefix to model name if specified (e.g., \"openrouter/anthropic/claude-2\").</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict[str, Any]</code> <p>The original parameters to be sent to the LLM provider.                     This includes model, messages, temperature, etc.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: The modified parameters with proper model name formatting.</p> Source code in <code>dynamiq/nodes/llms/custom_llm.py</code> <pre><code>def update_completion_params(self, params: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"\n    Customizes LLM request parameters for third-party providers.\n\n    This method adds the provider prefix to model name if specified\n    (e.g., \"openrouter/anthropic/claude-2\").\n\n    Args:\n        params (dict[str, Any]): The original parameters to be sent to the LLM provider.\n                                This includes model, messages, temperature, etc.\n\n    Returns:\n        dict[str, Any]: The modified parameters with proper model name formatting.\n    \"\"\"\n    params = super().update_completion_params(params)\n\n    if self.provider_prefix and not params[\"model\"].startswith(self.provider_prefix + \"/\"):\n        params[\"model\"] = f\"{self.provider_prefix}/{params['model']}\"\n\n    return params\n</code></pre>"},{"location":"dynamiq/nodes/llms/databricks/","title":"Databricks","text":""},{"location":"dynamiq/nodes/llms/databricks/#dynamiq.nodes.llms.databricks.Databricks","title":"<code>Databricks</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Databricks LLM node.</p> <p>This class provides an implementation for the Databricks Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Databricks</code> <p>The connection to use for the Databricks LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Databricks model name.</p> <code>reasoning_effort</code> <code>ReasoningEffort | None</code> <p>Controls the depth and complexity of reasoning</p> Source code in <code>dynamiq/nodes/llms/databricks.py</code> <pre><code>class Databricks(BaseLLM):\n    \"\"\"Databricks LLM node.\n\n    This class provides an implementation for the Databricks Language Model node.\n\n    Attributes:\n        connection (DatabricksConnection): The connection to use for the Databricks LLM.\n        MODEL_PREFIX (str): The prefix for the Databricks model name.\n        reasoning_effort (ReasoningEffort | None): Controls the depth and complexity of reasoning\n        performed by the model.\n    \"\"\"\n\n    connection: DatabricksConnection\n    MODEL_PREFIX = \"databricks/\"\n    reasoning_effort: ReasoningEffort | None = ReasoningEffort.MEDIUM\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Databricks LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = DatabricksConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/databricks/#dynamiq.nodes.llms.databricks.Databricks.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Databricks LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/databricks.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Databricks LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = DatabricksConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/deepinfra/","title":"Deepinfra","text":""},{"location":"dynamiq/nodes/llms/deepinfra/#dynamiq.nodes.llms.deepinfra.DeepInfra","title":"<code>DeepInfra</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>DeepInfra LLM node.</p> <p>This class provides an implementation for the DeepInfra Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>DeepInfra</code> <p>The connection to use for the DeepInfra LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the DeepInfra model name.</p> Source code in <code>dynamiq/nodes/llms/deepinfra.py</code> <pre><code>class DeepInfra(BaseLLM):\n    \"\"\"DeepInfra LLM node.\n\n    This class provides an implementation for the DeepInfra Language Model node.\n\n    Attributes:\n        connection (DeepInfraConnection): The connection to use for the DeepInfra LLM.\n        MODEL_PREFIX (str): The prefix for the DeepInfra model name.\n    \"\"\"\n    connection: DeepInfraConnection\n    MODEL_PREFIX = \"deepinfra/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the DeepInfra LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = DeepInfraConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/deepinfra/#dynamiq.nodes.llms.deepinfra.DeepInfra.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the DeepInfra LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/deepinfra.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the DeepInfra LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = DeepInfraConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/deepseek/","title":"Deepseek","text":""},{"location":"dynamiq/nodes/llms/deepseek/#dynamiq.nodes.llms.deepseek.DeepSeek","title":"<code>DeepSeek</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>DeepSeek LLM node.</p> <p>This class provides an implementation for the DeepSeek Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>DeepSeek</code> <p>The connection to use for the DeepSeek LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the DeepSeek model name.</p> Source code in <code>dynamiq/nodes/llms/deepseek.py</code> <pre><code>class DeepSeek(BaseLLM):\n    \"\"\"DeepSeek LLM node.\n\n    This class provides an implementation for the DeepSeek Language Model node.\n\n    Attributes:\n        connection (DeepSeekConnection): The connection to use for the DeepSeek LLM.\n        MODEL_PREFIX (str): The prefix for the DeepSeek model name.\n    \"\"\"\n\n    connection: DeepSeekConnection\n    MODEL_PREFIX = \"deepseek/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Replicate LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = DeepSeekConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/deepseek/#dynamiq.nodes.llms.deepseek.DeepSeek.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Replicate LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/deepseek.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Replicate LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = DeepSeekConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/fireworksai/","title":"Fireworksai","text":""},{"location":"dynamiq/nodes/llms/fireworksai/#dynamiq.nodes.llms.fireworksai.FireworksAI","title":"<code>FireworksAI</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>FireworksAI LLM node.</p> <p>This class provides an implementation for the Fireworks AI Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>FireworksAI | None</code> <p>The connection to use for the Fireworks AI LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Fireworks AI model name.</p> Source code in <code>dynamiq/nodes/llms/fireworksai.py</code> <pre><code>class FireworksAI(BaseLLM):\n    \"\"\"FireworksAI LLM node.\n\n    This class provides an implementation for the Fireworks AI Language Model node.\n\n    Attributes:\n        connection (FireworksAIConnection | None): The connection to use for the Fireworks AI LLM.\n        MODEL_PREFIX (str): The prefix for the Fireworks AI model name.\n    \"\"\"\n\n    connection: FireworksAIConnection | None = None\n    MODEL_PREFIX = \"fireworks_ai/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the FireworksAI LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = FireworksAIConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/fireworksai/#dynamiq.nodes.llms.fireworksai.FireworksAI.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the FireworksAI LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/fireworksai.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the FireworksAI LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = FireworksAIConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/gemini/","title":"Gemini","text":""},{"location":"dynamiq/nodes/llms/gemini/#dynamiq.nodes.llms.gemini.Gemini","title":"<code>Gemini</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Gemini LLM node.</p> <p>This class provides an implementation for the Gemini Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Gemini</code> <p>The connection to use for the Gemini LLM.</p> Source code in <code>dynamiq/nodes/llms/gemini.py</code> <pre><code>class Gemini(BaseLLM):\n    \"\"\"Gemini LLM node.\n\n    This class provides an implementation for the Gemini Language Model node.\n\n    Attributes:\n        connection (GeminiConnection): The connection to use for the Gemini LLM.\n    \"\"\"\n\n    connection: GeminiConnection\n    MODEL_PREFIX = \"gemini/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Gemini LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = GeminiConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/gemini/#dynamiq.nodes.llms.gemini.Gemini.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Gemini LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/gemini.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Gemini LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = GeminiConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/groq/","title":"Groq","text":""},{"location":"dynamiq/nodes/llms/groq/#dynamiq.nodes.llms.groq.Groq","title":"<code>Groq</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Groq LLM node.</p> <p>This class provides an implementation for the Groq Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Groq | None</code> <p>The connection to use for the Groq LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Groq model name.</p> Source code in <code>dynamiq/nodes/llms/groq.py</code> <pre><code>class Groq(BaseLLM):\n    \"\"\"Groq LLM node.\n\n    This class provides an implementation for the Groq Language Model node.\n\n    Attributes:\n        connection (GroqConnection | None): The connection to use for the Groq LLM.\n        MODEL_PREFIX (str): The prefix for the Groq model name.\n    \"\"\"\n    connection: GroqConnection | None = None\n    MODEL_PREFIX = \"groq/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Groq LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = GroqConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/groq/#dynamiq.nodes.llms.groq.Groq.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Groq LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/groq.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Groq LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = GroqConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/huggingface/","title":"Huggingface","text":""},{"location":"dynamiq/nodes/llms/huggingface/#dynamiq.nodes.llms.huggingface.HuggingFace","title":"<code>HuggingFace</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>HuggingFace LLM node.</p> <p>This class provides an implementation for the HuggingFace Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>HuggingFace | None</code> <p>The connection to use for the HuggingFace LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the HuggingFace model name.</p> Source code in <code>dynamiq/nodes/llms/huggingface.py</code> <pre><code>class HuggingFace(BaseLLM):\n    \"\"\"HuggingFace LLM node.\n\n    This class provides an implementation for the HuggingFace Language Model node.\n\n    Attributes:\n        connection (HuggingFaceConnection | None): The connection to use for the HuggingFace LLM.\n        MODEL_PREFIX (str): The prefix for the HuggingFace model name.\n    \"\"\"\n    connection: HuggingFaceConnection | None = None\n    MODEL_PREFIX = \"huggingface/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the HuggingFace LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = HuggingFaceConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/huggingface/#dynamiq.nodes.llms.huggingface.HuggingFace.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the HuggingFace LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/huggingface.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the HuggingFace LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = HuggingFaceConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/mistral/","title":"Mistral","text":""},{"location":"dynamiq/nodes/llms/mistral/#dynamiq.nodes.llms.mistral.Mistral","title":"<code>Mistral</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Mistral LLM node.</p> <p>This class provides an implementation for the Mistral Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Mistral | None</code> <p>The connection to use for the Mistral LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Mistral model name.</p> Source code in <code>dynamiq/nodes/llms/mistral.py</code> <pre><code>class Mistral(BaseLLM):\n    \"\"\"Mistral LLM node.\n\n    This class provides an implementation for the Mistral Language Model node.\n\n    Attributes:\n        connection (MistralConnection | None): The connection to use for the Mistral LLM.\n        MODEL_PREFIX (str): The prefix for the Mistral model name.\n    \"\"\"\n    connection: MistralConnection | None = None\n    MODEL_PREFIX = \"mistral/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Mistral LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = MistralConnection()\n        super().__init__(**kwargs)\n\n    def get_messages(\n        self,\n        prompt,\n        input_data,\n    ) -&gt; list[dict]:\n        \"\"\"\n        Format and filter message parameters based on provider requirements.\n        Override this in provider-specific subclasses.\n        \"\"\"\n        messages = prompt.format_messages(**dict(input_data))\n        formatted_messages = []\n        for i, msg in enumerate(messages):\n            msg_copy = msg.copy()\n\n            is_last_message = i == len(messages) - 1\n            if is_last_message and msg_copy[\"role\"] == MessageRole.ASSISTANT.value:\n                msg_copy[\"prefix\"] = True\n\n            formatted_messages.append(msg_copy)\n\n        return formatted_messages\n</code></pre>"},{"location":"dynamiq/nodes/llms/mistral/#dynamiq.nodes.llms.mistral.Mistral.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Mistral LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/mistral.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Mistral LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = MistralConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/mistral/#dynamiq.nodes.llms.mistral.Mistral.get_messages","title":"<code>get_messages(prompt, input_data)</code>","text":"<p>Format and filter message parameters based on provider requirements. Override this in provider-specific subclasses.</p> Source code in <code>dynamiq/nodes/llms/mistral.py</code> <pre><code>def get_messages(\n    self,\n    prompt,\n    input_data,\n) -&gt; list[dict]:\n    \"\"\"\n    Format and filter message parameters based on provider requirements.\n    Override this in provider-specific subclasses.\n    \"\"\"\n    messages = prompt.format_messages(**dict(input_data))\n    formatted_messages = []\n    for i, msg in enumerate(messages):\n        msg_copy = msg.copy()\n\n        is_last_message = i == len(messages) - 1\n        if is_last_message and msg_copy[\"role\"] == MessageRole.ASSISTANT.value:\n            msg_copy[\"prefix\"] = True\n\n        formatted_messages.append(msg_copy)\n\n    return formatted_messages\n</code></pre>"},{"location":"dynamiq/nodes/llms/nvidia_nim/","title":"Nvidia nim","text":""},{"location":"dynamiq/nodes/llms/nvidia_nim/#dynamiq.nodes.llms.nvidia_nim.NvidiaNIM","title":"<code>NvidiaNIM</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Nvidia NIM LLM node.</p> <p>This class provides an implementation for the Nvidia NIM Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Nvidia_NIM_Connection | None</code> <p>The connection to use for the Nvidia NIM LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Nvidia NIM model name.</p> Source code in <code>dynamiq/nodes/llms/nvidia_nim.py</code> <pre><code>class NvidiaNIM(BaseLLM):\n    \"\"\"Nvidia NIM LLM node.\n\n    This class provides an implementation for the Nvidia NIM Language Model node.\n\n    Attributes:\n        connection (Nvidia_NIM_Connection | None): The connection to use for the Nvidia NIM LLM.\n        MODEL_PREFIX (str): The prefix for the Nvidia NIM model name.\n    \"\"\"\n\n    connection: NvidiaNIMConnection | None = None\n    MODEL_PREFIX = \"nvidia_nim/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Nvidia NIM LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = NvidiaNIMConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/nvidia_nim/#dynamiq.nodes.llms.nvidia_nim.NvidiaNIM.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Nvidia NIM LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/nvidia_nim.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Nvidia NIM LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = NvidiaNIMConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/ollama/","title":"Ollama","text":""},{"location":"dynamiq/nodes/llms/ollama/#dynamiq.nodes.llms.ollama.Ollama","title":"<code>Ollama</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Ollama LLM node.</p> <p>This class provides an implementation for the Ollama Language Model node. It supports both chat and completion endpoints through model prefixes.</p> <p>Attributes:</p> Name Type Description <code>MODEL_PREFIX</code> <code>ClassVar[str | None]</code> <p>Optional model prefix, None to allow both ollama/ and ollama_chat/.</p> <code>connection</code> <code>Ollama | None</code> <p>The connection to use for the Ollama LLM.</p> Source code in <code>dynamiq/nodes/llms/ollama.py</code> <pre><code>class Ollama(BaseLLM):\n    \"\"\"Ollama LLM node.\n\n    This class provides an implementation for the Ollama Language Model node.\n    It supports both chat and completion endpoints through model prefixes.\n\n    Attributes:\n        MODEL_PREFIX (ClassVar[str | None]): Optional model prefix, None to allow both ollama/ and ollama_chat/.\n        connection (OllamaConnection | None): The connection to use for the Ollama LLM.\n    \"\"\"\n\n    MODEL_PREFIX: ClassVar[str | None] = \"ollama/\"\n    connection: OllamaConnection | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Ollama LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = OllamaConnection()\n\n        super().__init__(**kwargs)\n\n    @classmethod\n    def get_usage_data(cls, model: str, completion: \"ModelResponse\") -&gt; \"BaseLLMUsageData\":\n        \"\"\"Get usage data for the Ollama LLM.\n\n        Args:\n            model (str): The model used for generation.\n            completion (ModelResponse): The completion response from the LLM.\n\n        Returns:\n            BaseLLMUsageData: A model containing the usage data for the LLM.\n        \"\"\"\n        usage = completion.model_extra.get(\"usage\", {})\n        prompt_tokens = usage.get(\"prompt_eval_count\", 0)\n        completion_tokens = usage.get(\"eval_count\", 0)\n        total_tokens = prompt_tokens + completion_tokens\n\n        return BaseLLMUsageData(\n            prompt_tokens=prompt_tokens,\n            prompt_tokens_cost_usd=None,\n            completion_tokens=completion_tokens,\n            completion_tokens_cost_usd=None,\n            total_tokens=total_tokens,\n            total_tokens_cost_usd=None,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/llms/ollama/#dynamiq.nodes.llms.ollama.Ollama.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Ollama LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/ollama.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Ollama LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = OllamaConnection()\n\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/ollama/#dynamiq.nodes.llms.ollama.Ollama.get_usage_data","title":"<code>get_usage_data(model, completion)</code>  <code>classmethod</code>","text":"<p>Get usage data for the Ollama LLM.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model used for generation.</p> required <code>completion</code> <code>ModelResponse</code> <p>The completion response from the LLM.</p> required <p>Returns:</p> Name Type Description <code>BaseLLMUsageData</code> <code>BaseLLMUsageData</code> <p>A model containing the usage data for the LLM.</p> Source code in <code>dynamiq/nodes/llms/ollama.py</code> <pre><code>@classmethod\ndef get_usage_data(cls, model: str, completion: \"ModelResponse\") -&gt; \"BaseLLMUsageData\":\n    \"\"\"Get usage data for the Ollama LLM.\n\n    Args:\n        model (str): The model used for generation.\n        completion (ModelResponse): The completion response from the LLM.\n\n    Returns:\n        BaseLLMUsageData: A model containing the usage data for the LLM.\n    \"\"\"\n    usage = completion.model_extra.get(\"usage\", {})\n    prompt_tokens = usage.get(\"prompt_eval_count\", 0)\n    completion_tokens = usage.get(\"eval_count\", 0)\n    total_tokens = prompt_tokens + completion_tokens\n\n    return BaseLLMUsageData(\n        prompt_tokens=prompt_tokens,\n        prompt_tokens_cost_usd=None,\n        completion_tokens=completion_tokens,\n        completion_tokens_cost_usd=None,\n        total_tokens=total_tokens,\n        total_tokens_cost_usd=None,\n    )\n</code></pre>"},{"location":"dynamiq/nodes/llms/openai/","title":"Openai","text":""},{"location":"dynamiq/nodes/llms/openai/#dynamiq.nodes.llms.openai.OpenAI","title":"<code>OpenAI</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>OpenAI LLM node.</p> <p>This class provides an implementation for the OpenAI Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>OpenAI | None</code> <p>The connection to use for the OpenAI LLM.</p> Source code in <code>dynamiq/nodes/llms/openai.py</code> <pre><code>class OpenAI(BaseLLM):\n    \"\"\"OpenAI LLM node.\n\n    This class provides an implementation for the OpenAI Language Model node.\n\n    Attributes:\n        connection (OpenAIConnection | None): The connection to use for the OpenAI LLM.\n    \"\"\"\n    connection: OpenAIConnection | None = None\n    reasoning_effort: ReasoningEffort | None = ReasoningEffort.MEDIUM\n    verbosity: Verbosity | None = Verbosity.MEDIUM\n    O_SERIES_MODEL_PREFIXES: ClassVar[tuple[str, ...]] = (\"o1\", \"o3\", \"o4\")\n    MODEL_PREFIX = \"openai/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the OpenAI LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = OpenAIConnection()\n        super().__init__(**kwargs)\n\n    @cached_property\n    def is_o_series_model(self) -&gt; bool:\n        \"\"\"\n        Determine if the model belongs to the O-series (e.g. o1 or o3, o4)\n        by checking if the model starts with any of the O-series prefixes.\n        \"\"\"\n        model_lower = self.model.lower().removeprefix(self.MODEL_PREFIX)\n        return any(model_lower.startswith(prefix) for prefix in self.O_SERIES_MODEL_PREFIXES)\n\n    def update_completion_params(self, params: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"\n        Override the base method to update the completion parameters for OpenAI.\n        For new series models, use \"max_completion_tokens\" instead of \"max_tokens\".\n        \"\"\"\n        params = super().update_completion_params(params)\n\n        new_params = params.copy()\n        model_lower = self.model.lower().removeprefix(self.MODEL_PREFIX)\n        if self.is_o_series_model:\n            new_params[\"max_completion_tokens\"] = self.max_tokens\n            if model_lower.startswith(\"o3\") or model_lower.startswith(\"o4\"):\n                new_params[\"reasoning_effort\"] = self.reasoning_effort\n            if model_lower not in [\"o3-mini\"]:\n                new_params.pop(\"stop\", None)\n            new_params.pop(\"max_tokens\", None)\n            new_params.pop(\"temperature\", None)\n        elif model_lower.startswith(\"gpt-5\"):\n            if \"chat\" not in model_lower:\n                new_params[\"verbosity\"] = self.verbosity\n                if \"pro\" in model_lower:\n                    new_params[\"reasoning_effort\"] = ReasoningEffort.HIGH\n                else:\n                    new_params[\"reasoning_effort\"] = self.reasoning_effort\n            new_params[\"max_completion_tokens\"] = self.max_tokens\n            new_params.pop(\"stop\", None)\n            new_params.pop(\"max_tokens\", None)\n\n        return new_params\n</code></pre>"},{"location":"dynamiq/nodes/llms/openai/#dynamiq.nodes.llms.openai.OpenAI.is_o_series_model","title":"<code>is_o_series_model: bool</code>  <code>cached</code> <code>property</code>","text":"<p>Determine if the model belongs to the O-series (e.g. o1 or o3, o4) by checking if the model starts with any of the O-series prefixes.</p>"},{"location":"dynamiq/nodes/llms/openai/#dynamiq.nodes.llms.openai.OpenAI.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the OpenAI LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/openai.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the OpenAI LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = OpenAIConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/openai/#dynamiq.nodes.llms.openai.OpenAI.update_completion_params","title":"<code>update_completion_params(params)</code>","text":"<p>Override the base method to update the completion parameters for OpenAI. For new series models, use \"max_completion_tokens\" instead of \"max_tokens\".</p> Source code in <code>dynamiq/nodes/llms/openai.py</code> <pre><code>def update_completion_params(self, params: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"\n    Override the base method to update the completion parameters for OpenAI.\n    For new series models, use \"max_completion_tokens\" instead of \"max_tokens\".\n    \"\"\"\n    params = super().update_completion_params(params)\n\n    new_params = params.copy()\n    model_lower = self.model.lower().removeprefix(self.MODEL_PREFIX)\n    if self.is_o_series_model:\n        new_params[\"max_completion_tokens\"] = self.max_tokens\n        if model_lower.startswith(\"o3\") or model_lower.startswith(\"o4\"):\n            new_params[\"reasoning_effort\"] = self.reasoning_effort\n        if model_lower not in [\"o3-mini\"]:\n            new_params.pop(\"stop\", None)\n        new_params.pop(\"max_tokens\", None)\n        new_params.pop(\"temperature\", None)\n    elif model_lower.startswith(\"gpt-5\"):\n        if \"chat\" not in model_lower:\n            new_params[\"verbosity\"] = self.verbosity\n            if \"pro\" in model_lower:\n                new_params[\"reasoning_effort\"] = ReasoningEffort.HIGH\n            else:\n                new_params[\"reasoning_effort\"] = self.reasoning_effort\n        new_params[\"max_completion_tokens\"] = self.max_tokens\n        new_params.pop(\"stop\", None)\n        new_params.pop(\"max_tokens\", None)\n\n    return new_params\n</code></pre>"},{"location":"dynamiq/nodes/llms/openai/#dynamiq.nodes.llms.openai.ReasoningEffort","title":"<code>ReasoningEffort</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>The reasoning effort to use for the OpenAI LLM.</p> Source code in <code>dynamiq/nodes/llms/openai.py</code> <pre><code>class ReasoningEffort(str, enum.Enum):\n    \"\"\"\n    The reasoning effort to use for the OpenAI LLM.\n    \"\"\"\n\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    MINIMAL = \"minimal\"\n</code></pre>"},{"location":"dynamiq/nodes/llms/openai/#dynamiq.nodes.llms.openai.Verbosity","title":"<code>Verbosity</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>The verbosity level for the OpenAI LLM.</p> Source code in <code>dynamiq/nodes/llms/openai.py</code> <pre><code>class Verbosity(str, enum.Enum):\n    \"\"\"\n    The verbosity level for the OpenAI LLM.\n    \"\"\"\n\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n</code></pre>"},{"location":"dynamiq/nodes/llms/perplexity/","title":"Perplexity","text":""},{"location":"dynamiq/nodes/llms/perplexity/#dynamiq.nodes.llms.perplexity.Perplexity","title":"<code>Perplexity</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Perplexity LLM node.</p> <p>This class provides an implementation for the Perplexity Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Perplexity</code> <p>The connection to use for the Perplexity LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Perplexity model name.</p> <code>return_citations</code> <code>bool</code> <p>Whether to return citations in the response.</p> Source code in <code>dynamiq/nodes/llms/perplexity.py</code> <pre><code>class Perplexity(BaseLLM):\n    \"\"\"Perplexity LLM node.\n\n    This class provides an implementation for the Perplexity Language Model node.\n\n    Attributes:\n        connection (PerplexityConnection): The connection to use for the Perplexity LLM.\n        MODEL_PREFIX (str): The prefix for the Perplexity model name.\n        return_citations (bool): Whether to return citations in the response.\n    \"\"\"\n\n    connection: PerplexityConnection\n    return_citations: bool = Field(default=False, description=\"Whether to return citations in the response\")\n\n    MODEL_PREFIX = \"perplexity/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Perplexity LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = PerplexityConnection()\n\n        if \"connection\" in kwargs:\n            kwargs[\"connection\"].conn_params[\"return_citations\"] = kwargs.get(\"return_citations\", False)\n\n        super().__init__(**kwargs)\n\n    def _handle_completion_response(\n        self,\n        response: Union[\"ModelResponse\", \"CustomStreamWrapper\"],\n        config: RunnableConfig = None,\n        **kwargs,\n    ) -&gt; dict:\n        \"\"\"Handle completion response with citations.\n\n        Args:\n            response (ModelResponse | CustomStreamWrapper): The response from the LLM.\n            config (RunnableConfig, optional): The configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the generated content, tool calls, and citations.\n        \"\"\"\n        result = super()._handle_completion_response(response, config, **kwargs)\n\n        if hasattr(response, \"citations\"):\n            result[\"citations\"] = response.citations\n\n        return result\n</code></pre>"},{"location":"dynamiq/nodes/llms/perplexity/#dynamiq.nodes.llms.perplexity.Perplexity.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Perplexity LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/perplexity.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Perplexity LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = PerplexityConnection()\n\n    if \"connection\" in kwargs:\n        kwargs[\"connection\"].conn_params[\"return_citations\"] = kwargs.get(\"return_citations\", False)\n\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/replicate/","title":"Replicate","text":""},{"location":"dynamiq/nodes/llms/replicate/#dynamiq.nodes.llms.replicate.Replicate","title":"<code>Replicate</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>Replicate LLM node.</p> <p>This class provides an implementation for the Replicate Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>Replicate</code> <p>The connection to use for the Replicate LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the Replicate model name.</p> Source code in <code>dynamiq/nodes/llms/replicate.py</code> <pre><code>class Replicate(BaseLLM):\n    \"\"\"Replicate LLM node.\n\n    This class provides an implementation for the Replicate Language Model node.\n\n    Attributes:\n        connection (ReplicateConnection): The connection to use for the Replicate LLM.\n        MODEL_PREFIX (str): The prefix for the Replicate model name.\n    \"\"\"\n    connection: ReplicateConnection\n    MODEL_PREFIX = \"replicate/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the Replicate LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = ReplicateConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/replicate/#dynamiq.nodes.llms.replicate.Replicate.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the Replicate LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/replicate.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the Replicate LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = ReplicateConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/sambanova/","title":"Sambanova","text":""},{"location":"dynamiq/nodes/llms/sambanova/#dynamiq.nodes.llms.sambanova.SambaNova","title":"<code>SambaNova</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>SambaNova LLM node.</p> <p>This class provides an implementation for the SambaNova Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>SambaNova</code> <p>The connection to use for the SambaNova LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the SambaNova model name.</p> Source code in <code>dynamiq/nodes/llms/sambanova.py</code> <pre><code>class SambaNova(BaseLLM):\n    \"\"\"SambaNova LLM node.\n\n    This class provides an implementation for the SambaNova Language Model node.\n\n    Attributes:\n        connection (SambaNovaConnection): The connection to use for the SambaNova LLM.\n        MODEL_PREFIX (str): The prefix for the SambaNova model name.\n    \"\"\"\n    connection: SambaNovaConnection\n    MODEL_PREFIX = \"sambanova/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the SambaNova LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = SambaNovaConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/sambanova/#dynamiq.nodes.llms.sambanova.SambaNova.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the SambaNova LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/sambanova.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the SambaNova LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = SambaNovaConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/togetherai/","title":"Togetherai","text":""},{"location":"dynamiq/nodes/llms/togetherai/#dynamiq.nodes.llms.togetherai.TogetherAI","title":"<code>TogetherAI</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>TogetherAI LLM node.</p> <p>This class provides an implementation for the TogetherAI Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>TogetherAI | None</code> <p>The connection to use for the TogetherAI LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the TogetherAI model name.</p> Source code in <code>dynamiq/nodes/llms/togetherai.py</code> <pre><code>class TogetherAI(BaseLLM):\n    \"\"\"TogetherAI LLM node.\n\n    This class provides an implementation for the TogetherAI Language Model node.\n\n    Attributes:\n        connection (TogetherAIConnection | None): The connection to use for the TogetherAI LLM.\n        MODEL_PREFIX (str): The prefix for the TogetherAI model name.\n    \"\"\"\n    connection: TogetherAIConnection | None = None\n    MODEL_PREFIX = \"together_ai/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the TogetherAI LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = TogetherAIConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/togetherai/#dynamiq.nodes.llms.togetherai.TogetherAI.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the TogetherAI LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/togetherai.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the TogetherAI LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = TogetherAIConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/vertexai/","title":"Vertexai","text":""},{"location":"dynamiq/nodes/llms/vertexai/#dynamiq.nodes.llms.vertexai.VertexAI","title":"<code>VertexAI</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>VertexAI LLM node.</p> <p>This class provides an implementation for the VertexAI Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>VertexAI | None</code> <p>The connection to use for the VertexAI LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the VertexAI model name.</p> Source code in <code>dynamiq/nodes/llms/vertexai.py</code> <pre><code>class VertexAI(BaseLLM):\n    \"\"\"VertexAI LLM node.\n\n    This class provides an implementation for the VertexAI Language Model node.\n\n    Attributes:\n        connection (VertexAIConnection | None): The connection to use for the VertexAI LLM.\n        MODEL_PREFIX (str): The prefix for the VertexAI model name.\n    \"\"\"\n\n    connection: VertexAIConnection | None = None\n    MODEL_PREFIX = \"vertex_ai/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the VertexAI LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = VertexAIConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/vertexai/#dynamiq.nodes.llms.vertexai.VertexAI.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the VertexAI LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/vertexai.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the VertexAI LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = VertexAIConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/watsonx/","title":"Watsonx","text":""},{"location":"dynamiq/nodes/llms/watsonx/#dynamiq.nodes.llms.watsonx.WatsonX","title":"<code>WatsonX</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>WatsonX LLM node.</p> <p>This class provides an implementation for the WatsonX Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>WatsonX | None</code> <p>The connection to use for the WatsonX LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the WatsonX model name.</p> Source code in <code>dynamiq/nodes/llms/watsonx.py</code> <pre><code>class WatsonX(BaseLLM):\n    \"\"\"WatsonX LLM node.\n\n    This class provides an implementation for the WatsonX Language Model node.\n\n    Attributes:\n        connection (WatsonXConnection | None): The connection to use for the WatsonX LLM.\n        MODEL_PREFIX (str): The prefix for the WatsonX model name.\n    \"\"\"\n    connection: WatsonXConnection | None = None\n    MODEL_PREFIX = \"watsonx_text/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the WatsonX LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = WatsonXConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/watsonx/#dynamiq.nodes.llms.watsonx.WatsonX.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the WatsonX LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/watsonx.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the WatsonX LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = WatsonXConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/xai/","title":"Xai","text":""},{"location":"dynamiq/nodes/llms/xai/#dynamiq.nodes.llms.xai.xAI","title":"<code>xAI</code>","text":"<p>               Bases: <code>BaseLLM</code></p> <p>xAI LLM node.</p> <p>This class provides an implementation for the xAI Language Model node.</p> <p>Attributes:</p> Name Type Description <code>connection</code> <code>xAI | None</code> <p>The connection to use for the xAI LLM.</p> <code>MODEL_PREFIX</code> <code>str</code> <p>The prefix for the xAI model name.</p> Source code in <code>dynamiq/nodes/llms/xai.py</code> <pre><code>class xAI(BaseLLM):\n    \"\"\"xAI LLM node.\n\n    This class provides an implementation for the xAI Language Model node.\n\n    Attributes:\n        connection (xAIConnection | None): The connection to use for the xAI LLM.\n        MODEL_PREFIX (str): The prefix for the xAI model name.\n    \"\"\"\n\n    connection: xAIConnection | None = None\n    MODEL_PREFIX = \"xai/\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the xAI LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = xAIConnection()\n        super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/llms/xai/#dynamiq.nodes.llms.xai.xAI.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the xAI LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/llms/xai.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the xAI LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if kwargs.get(\"client\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = xAIConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/","title":"Operators","text":""},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Choice","title":"<code>Choice</code>","text":"<p>               Bases: <code>Node</code></p> <p>Represents a choice node in a flow.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>class Choice(Node):\n    \"\"\"Represents a choice node in a flow.\"\"\"\n\n    name: str | None = \"Choice\"\n    group: Literal[NodeGroup.OPERATORS] = NodeGroup.OPERATORS\n    options: list[ChoiceOption] = []\n    input_schema: ClassVar[type[ChoiceInputSchema]] = ChoiceInputSchema\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"options\": True}\n\n    def to_dict(self, include_secure_params: bool = True, for_tracing=False, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs)\n        data[\"options\"] = [option.model_dump(**kwargs) for option in self.options]\n        return data\n\n    def execute(\n        self, input_data: ChoiceInputSchema, config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, RunnableResult]:\n        \"\"\"\n        Executes the choice node.\n\n        Args:\n            input_data: The input data for the node.\n            config: The runnable configuration.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A dictionary of RunnableResults for each option.\n        \"\"\"\n        results = {}\n        if self.options:\n            run_id = kwargs.get(\"run_id\", uuid4())\n            config = ensure_config(config)\n            merged_kwargs = {**kwargs, \"parent_run_id\": run_id}\n\n            self.run_on_node_execute_run(config.callbacks, **merged_kwargs)\n\n            is_success_evaluation = False\n            for option in self.options:\n                if is_success_evaluation:\n                    results[option.id] = RunnableResult(\n                        status=RunnableStatus.SKIP, input=input_data.model_dump(), output=None\n                    )\n                elif option.condition and self.evaluate(option.condition, input_data.model_dump()):\n                    results[option.id] = RunnableResult(\n                        status=RunnableStatus.SUCCESS, input=input_data.model_dump(), output=True\n                    )\n                    is_success_evaluation = True\n                elif not option.condition:\n                    results[option.id] = RunnableResult(\n                        status=RunnableStatus.SUCCESS, input=input_data.model_dump(), output=True\n                    )\n                    is_success_evaluation = True\n                else:\n                    results[option.id] = RunnableResult(\n                        status=RunnableStatus.FAILURE, input=input_data.model_dump(), output=False\n                    )\n\n        return results\n\n    @staticmethod\n    def evaluate(cond: ChoiceCondition, input_data: Any) -&gt; bool:\n        \"\"\"\n        Evaluates a choice condition.\n\n        Args:\n            cond: The condition to evaluate.\n            input_data: The input data to evaluate against.\n\n        Returns:\n            A boolean indicating whether the condition is met.\n\n        Raises:\n            ValueError: If the operator is not supported.\n        \"\"\"\n        value = jsonpath.filter(input_data, cond.variable)\n\n        if cond.operator == ConditionOperator.OR:\n            return (\n                any(Choice.evaluate(cond, value) for cond in cond.operands)\n                and not cond.is_not\n            )\n        elif cond.operator == ConditionOperator.AND:\n            return (\n                all(Choice.evaluate(cond, value) for cond in cond.operands)\n                and not cond.is_not\n            )\n        # boolean\n        elif cond.operator == ConditionOperator.BOOLEAN_EQUALS:\n            return (value == cond.value) == (not cond.is_not)\n        # numeric\n        if cond.operator == ConditionOperator.NUMERIC_EQUALS:\n            return (value == cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.NUMERIC_GREATER_THAN:\n            return (value &gt; cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.NUMERIC_GREATER_THAN_OR_EQUALS:\n            return (value &gt;= cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.NUMERIC_LESS_THAN:\n            return (value &lt; cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.NUMERIC_LESS_THAN_OR_EQUALS:\n            return (value &lt;= cond.value) == (not cond.is_not)\n        # string\n        elif cond.operator == ConditionOperator.STRING_EQUALS:\n            return (value == cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.STRING_GREATER_THAN:\n            return (value &gt; cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.STRING_GREATER_THAN_OR_EQUALS:\n            return (value &gt;= cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.STRING_LESS_THAN:\n            return (value &lt; cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.STRING_LESS_THAN_OR_EQUALS:\n            return (value &lt;= cond.value) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.STRING_STARTS_WITH:\n            return (str(value).startswith(str(cond.value))) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.STRING_CONTAINS:\n            return (str(cond.value) in str(value)) == (not cond.is_not)\n        elif cond.operator == ConditionOperator.STRING_REGEXP:\n            try:\n                return bool(re.search(str(cond.value), str(value))) == (not cond.is_not)\n            except re.error as e:\n                raise ValueError(f\"Invalid regular expression '{cond.value}': {e}\")\n        elif cond.operator == ConditionOperator.STRING_ENDS_WITH:\n            return (str(value).endswith(str(cond.value))) == (not cond.is_not)\n        else:\n            raise ValueError(f\"Operator {cond.operator} not supported.\")\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Choice.evaluate","title":"<code>evaluate(cond, input_data)</code>  <code>staticmethod</code>","text":"<p>Evaluates a choice condition.</p> <p>Parameters:</p> Name Type Description Default <code>cond</code> <code>ChoiceCondition</code> <p>The condition to evaluate.</p> required <code>input_data</code> <code>Any</code> <p>The input data to evaluate against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>A boolean indicating whether the condition is met.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the operator is not supported.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>@staticmethod\ndef evaluate(cond: ChoiceCondition, input_data: Any) -&gt; bool:\n    \"\"\"\n    Evaluates a choice condition.\n\n    Args:\n        cond: The condition to evaluate.\n        input_data: The input data to evaluate against.\n\n    Returns:\n        A boolean indicating whether the condition is met.\n\n    Raises:\n        ValueError: If the operator is not supported.\n    \"\"\"\n    value = jsonpath.filter(input_data, cond.variable)\n\n    if cond.operator == ConditionOperator.OR:\n        return (\n            any(Choice.evaluate(cond, value) for cond in cond.operands)\n            and not cond.is_not\n        )\n    elif cond.operator == ConditionOperator.AND:\n        return (\n            all(Choice.evaluate(cond, value) for cond in cond.operands)\n            and not cond.is_not\n        )\n    # boolean\n    elif cond.operator == ConditionOperator.BOOLEAN_EQUALS:\n        return (value == cond.value) == (not cond.is_not)\n    # numeric\n    if cond.operator == ConditionOperator.NUMERIC_EQUALS:\n        return (value == cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.NUMERIC_GREATER_THAN:\n        return (value &gt; cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.NUMERIC_GREATER_THAN_OR_EQUALS:\n        return (value &gt;= cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.NUMERIC_LESS_THAN:\n        return (value &lt; cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.NUMERIC_LESS_THAN_OR_EQUALS:\n        return (value &lt;= cond.value) == (not cond.is_not)\n    # string\n    elif cond.operator == ConditionOperator.STRING_EQUALS:\n        return (value == cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.STRING_GREATER_THAN:\n        return (value &gt; cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.STRING_GREATER_THAN_OR_EQUALS:\n        return (value &gt;= cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.STRING_LESS_THAN:\n        return (value &lt; cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.STRING_LESS_THAN_OR_EQUALS:\n        return (value &lt;= cond.value) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.STRING_STARTS_WITH:\n        return (str(value).startswith(str(cond.value))) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.STRING_CONTAINS:\n        return (str(cond.value) in str(value)) == (not cond.is_not)\n    elif cond.operator == ConditionOperator.STRING_REGEXP:\n        try:\n            return bool(re.search(str(cond.value), str(value))) == (not cond.is_not)\n        except re.error as e:\n            raise ValueError(f\"Invalid regular expression '{cond.value}': {e}\")\n    elif cond.operator == ConditionOperator.STRING_ENDS_WITH:\n        return (str(value).endswith(str(cond.value))) == (not cond.is_not)\n    else:\n        raise ValueError(f\"Operator {cond.operator} not supported.\")\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Choice.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the choice node.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ChoiceInputSchema</code> <p>The input data for the node.</p> required <code>config</code> <code>RunnableConfig</code> <p>The runnable configuration.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, RunnableResult]</code> <p>A dictionary of RunnableResults for each option.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>def execute(\n    self, input_data: ChoiceInputSchema, config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, RunnableResult]:\n    \"\"\"\n    Executes the choice node.\n\n    Args:\n        input_data: The input data for the node.\n        config: The runnable configuration.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A dictionary of RunnableResults for each option.\n    \"\"\"\n    results = {}\n    if self.options:\n        run_id = kwargs.get(\"run_id\", uuid4())\n        config = ensure_config(config)\n        merged_kwargs = {**kwargs, \"parent_run_id\": run_id}\n\n        self.run_on_node_execute_run(config.callbacks, **merged_kwargs)\n\n        is_success_evaluation = False\n        for option in self.options:\n            if is_success_evaluation:\n                results[option.id] = RunnableResult(\n                    status=RunnableStatus.SKIP, input=input_data.model_dump(), output=None\n                )\n            elif option.condition and self.evaluate(option.condition, input_data.model_dump()):\n                results[option.id] = RunnableResult(\n                    status=RunnableStatus.SUCCESS, input=input_data.model_dump(), output=True\n                )\n                is_success_evaluation = True\n            elif not option.condition:\n                results[option.id] = RunnableResult(\n                    status=RunnableStatus.SUCCESS, input=input_data.model_dump(), output=True\n                )\n                is_success_evaluation = True\n            else:\n                results[option.id] = RunnableResult(\n                    status=RunnableStatus.FAILURE, input=input_data.model_dump(), output=False\n                )\n\n    return results\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Choice.to_dict","title":"<code>to_dict(include_secure_params=True, for_tracing=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>def to_dict(self, include_secure_params: bool = True, for_tracing=False, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs)\n    data[\"options\"] = [option.model_dump(**kwargs) for option in self.options]\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.ChoiceOption","title":"<code>ChoiceOption</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an option for a choice node.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>class ChoiceOption(BaseModel):\n    \"\"\"Represents an option for a choice node.\"\"\"\n\n    id: str = Field(default_factory=generate_uuid)\n    name: str | None = None\n    condition: ChoiceCondition | None = None\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Map","title":"<code>Map</code>","text":"<p>               Bases: <code>Node</code></p> <p>Represents a map node in a flow.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>class Map(Node):\n    \"\"\"Represents a map node in a flow.\"\"\"\n\n    name: str | None = \"Map\"\n    group: Literal[NodeGroup.OPERATORS] = NodeGroup.OPERATORS\n    node: Node\n    behavior: Behavior | None = Behavior.RETURN\n    input_schema: ClassVar[type[MapInputSchema]] = MapInputSchema\n    max_workers: int = 1\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"\n        Property to define which parameters should be excluded when converting the class instance to a dictionary.\n\n        Returns:\n            dict: A dictionary defining the parameters to exclude.\n        \"\"\"\n        return super().to_dict_exclude_params | {\"node\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"node\"] = self.node.to_dict(**kwargs)\n        return data\n\n    def regenerate_ids(self, obj):\n        if isinstance(obj, BaseModel):\n            if hasattr(obj, \"id\"):\n                setattr(obj, \"id\", str(uuid.uuid4()))\n\n            for field_name in obj.model_fields:\n                value = getattr(obj, field_name)\n                if isinstance(value, list):\n                    new_list = [self.regenerate_ids(item) for item in value]\n                    setattr(obj, field_name, new_list)\n                elif isinstance(value, dict):\n                    new_dict = {k: self.regenerate_ids(v) for k, v in value.items()}\n                    setattr(obj, field_name, new_dict)\n                else:\n                    setattr(obj, field_name, self.regenerate_ids(value))\n            return obj\n        elif isinstance(obj, list):\n            return [self.regenerate_ids(item) for item in obj]\n        elif isinstance(obj, dict):\n            return {k: self.regenerate_ids(v) for k, v in obj.items()}\n        else:\n            return obj\n\n    def dry_run_cleanup(self, dry_run_config: DryRunConfig | None = None) -&gt; None:\n        \"\"\"Clean up resources created during dry run.\"\"\"\n        self.node.dry_run_cleanup(dry_run_config)\n\n    def execute_workflow(self, index, data, config, merged_kwargs):\n        \"\"\"Execute a single workflow and handle errors.\"\"\"\n        node_copy = self.node.clone()\n        node_copy = self.regenerate_ids(node_copy)\n\n        # Create an isolated config per iteration with unique streaming override for the cloned node\n        local_config = config\n        try:\n            local_config = config.model_copy(deep=False) if config is not None else RunnableConfig()\n            if node_config := local_config.nodes_override.get(self.node.id):\n                local_config.nodes_override[node_copy.id] = node_config\n        except Exception as e:\n            logger.warning(f\"Map: failed to prepare isolated streaming config for iteration {index}: {e}\")\n\n        result = node_copy.run(data, local_config, **merged_kwargs)\n        if result.status != RunnableStatus.SUCCESS:\n            if self.behavior == Behavior.RAISE:\n                raise ValueError(f\"Node under iteration index {index + 1} has failed.\")\n        return result.output\n\n    def execute(self, input_data: MapInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Executes the map node.\n\n        Args:\n            input_data: The input data for the node.\n            config: The runnable configuration.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            A list of outputs from executing the flow on each input item.\n\n        Raises:\n            Exception: If the input is not a list or if any flow execution fails.\n        \"\"\"\n        input_data = input_data.input\n\n        run_id = kwargs.get(\"run_id\", uuid4())\n        config = ensure_config(config)\n        merged_kwargs = {**kwargs, \"parent_run_id\": run_id}\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        try:\n            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n                results = executor.map(\n                    lambda args: self.execute_workflow(args[0], args[1], config, merged_kwargs),\n                    enumerate(input_data),\n                )\n        except Exception as e:\n            logger.error(str(e))\n            raise ValueError(f\"Map node failed to execute:{str(e)}\")\n\n        return {\"output\": list(results)}\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Map.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Property to define which parameters should be excluded when converting the class instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary defining the parameters to exclude.</p>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Map.dry_run_cleanup","title":"<code>dry_run_cleanup(dry_run_config=None)</code>","text":"<p>Clean up resources created during dry run.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>def dry_run_cleanup(self, dry_run_config: DryRunConfig | None = None) -&gt; None:\n    \"\"\"Clean up resources created during dry run.\"\"\"\n    self.node.dry_run_cleanup(dry_run_config)\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Map.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the map node.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>MapInputSchema</code> <p>The input data for the node.</p> required <code>config</code> <code>RunnableConfig</code> <p>The runnable configuration.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <p>A list of outputs from executing the flow on each input item.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the input is not a list or if any flow execution fails.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>def execute(self, input_data: MapInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Executes the map node.\n\n    Args:\n        input_data: The input data for the node.\n        config: The runnable configuration.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        A list of outputs from executing the flow on each input item.\n\n    Raises:\n        Exception: If the input is not a list or if any flow execution fails.\n    \"\"\"\n    input_data = input_data.input\n\n    run_id = kwargs.get(\"run_id\", uuid4())\n    config = ensure_config(config)\n    merged_kwargs = {**kwargs, \"parent_run_id\": run_id}\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    try:\n        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            results = executor.map(\n                lambda args: self.execute_workflow(args[0], args[1], config, merged_kwargs),\n                enumerate(input_data),\n            )\n    except Exception as e:\n        logger.error(str(e))\n        raise ValueError(f\"Map node failed to execute:{str(e)}\")\n\n    return {\"output\": list(results)}\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Map.execute_workflow","title":"<code>execute_workflow(index, data, config, merged_kwargs)</code>","text":"<p>Execute a single workflow and handle errors.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>def execute_workflow(self, index, data, config, merged_kwargs):\n    \"\"\"Execute a single workflow and handle errors.\"\"\"\n    node_copy = self.node.clone()\n    node_copy = self.regenerate_ids(node_copy)\n\n    # Create an isolated config per iteration with unique streaming override for the cloned node\n    local_config = config\n    try:\n        local_config = config.model_copy(deep=False) if config is not None else RunnableConfig()\n        if node_config := local_config.nodes_override.get(self.node.id):\n            local_config.nodes_override[node_copy.id] = node_config\n    except Exception as e:\n        logger.warning(f\"Map: failed to prepare isolated streaming config for iteration {index}: {e}\")\n\n    result = node_copy.run(data, local_config, **merged_kwargs)\n    if result.status != RunnableStatus.SUCCESS:\n        if self.behavior == Behavior.RAISE:\n            raise ValueError(f\"Node under iteration index {index + 1} has failed.\")\n    return result.output\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Map.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"node\"] = self.node.to_dict(**kwargs)\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Pass","title":"<code>Pass</code>","text":"<p>               Bases: <code>Node</code></p> <p>Represents a pass node in a flow.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>class Pass(Node):\n    \"\"\"Represents a pass node in a flow.\"\"\"\n\n    group: Literal[NodeGroup.OPERATORS] = NodeGroup.OPERATORS\n    transformers: list[Transformer] = []\n\n    def execute(self, input_data: dict[str, Any], config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Executes the pass node.\n\n        Args:\n            input_data: The input data for the node.\n            config: The runnable configuration.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            The input data if no transformers are present, otherwise the transformed data.\n        \"\"\"\n        config = ensure_config(config)\n        merged_kwargs = {**kwargs, \"parent_run_id\": kwargs.get(\"run_id\", uuid4())}\n        self.run_on_node_execute_run(config.callbacks, **merged_kwargs)\n\n        output = input_data\n        for transformer in self.transformers:\n            output = self.transform(output, transformer)\n\n        return output\n</code></pre>"},{"location":"dynamiq/nodes/operators/operators/#dynamiq.nodes.operators.operators.Pass.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the pass node.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>The input data for the node.</p> required <code>config</code> <code>RunnableConfig</code> <p>The runnable configuration.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The input data if no transformers are present, otherwise the transformed data.</p> Source code in <code>dynamiq/nodes/operators/operators.py</code> <pre><code>def execute(self, input_data: dict[str, Any], config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Executes the pass node.\n\n    Args:\n        input_data: The input data for the node.\n        config: The runnable configuration.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        The input data if no transformers are present, otherwise the transformed data.\n    \"\"\"\n    config = ensure_config(config)\n    merged_kwargs = {**kwargs, \"parent_run_id\": kwargs.get(\"run_id\", uuid4())}\n    self.run_on_node_execute_run(config.callbacks, **merged_kwargs)\n\n    output = input_data\n    for transformer in self.transformers:\n        output = self.transform(output, transformer)\n\n    return output\n</code></pre>"},{"location":"dynamiq/nodes/rankers/cohere/","title":"Cohere","text":""},{"location":"dynamiq/nodes/rankers/cohere/#dynamiq.nodes.rankers.cohere.CohereReranker","title":"<code>CohereReranker</code>","text":"<p>               Bases: <code>Node</code></p> <p>A Node class for reranking documents using Cohere's reranking model.</p> <p>This ranker uses Cohere's API to rerank documents based on their relevance to a query.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RANKERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>top_k</code> <code>int</code> <p>The number of top documents to return.</p> <code>model</code> <code>str</code> <p>The Cohere model to use for reranking.</p> <code>threshold</code> <code>float</code> <p>The threshold for relevance score. Default is 0.</p> <code>connection</code> <code>Cohere</code> <p>The Cohere connection instance.</p> Source code in <code>dynamiq/nodes/rankers/cohere.py</code> <pre><code>class CohereReranker(Node):\n    \"\"\"\n    A Node class for reranking documents using Cohere's reranking model.\n\n    This ranker uses Cohere's API to rerank documents based on their relevance to a query.\n\n    Attributes:\n        group (Literal[NodeGroup.RANKERS]): The group the node belongs to.\n        name (str): The name of the node.\n        top_k (int): The number of top documents to return.\n        model (str): The Cohere model to use for reranking.\n        threshold (float): The threshold for relevance score. Default is 0.\n        connection (Cohere): The Cohere connection instance.\n    \"\"\"\n\n    group: Literal[NodeGroup.RANKERS] = NodeGroup.RANKERS\n    name: str = \"CohereReranker\"\n    top_k: int = 5\n    model: str = \"cohere/rerank-v3.5\"\n    threshold: float = 0\n    connection: Cohere\n    input_schema: ClassVar[type[CohereRerankerInputSchema]] = CohereRerankerInputSchema\n    _rerank: Callable = PrivateAttr()\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the CohereReranker instance.\"\"\"\n        super().__init__(**kwargs)\n\n        from litellm import rerank\n\n        self._rerank = rerank\n\n    def execute(self, input_data: CohereRerankerInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the document reranking process.\n\n        Args:\n            input_data (CohereRerankerInputSchema): The input data containing documents and query.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the reranked documents.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query = input_data.query\n        documents = input_data.documents\n\n        if not documents:\n            logger.warning(f\"Node {self.name} - {self.id}: No documents provided for reranking\")\n            return {\"documents\": []}\n\n        document_texts = [doc.content for doc in documents]\n\n        logger.debug(f\"Node {self.name} - {self.id}: Reranking {len(documents)} documents\")\n\n        response = self._rerank(\n            model=self.model, query=query, documents=document_texts, top_n=self.top_k, **self.connection.conn_params\n        )\n\n        reranked_documents = []\n        for result in response.results:\n            doc = documents[result.get(\"index\")]\n            doc.score = result.get(\"relevance_score\")\n            if doc.score &gt; self.threshold:\n                reranked_documents.append(doc)\n\n        logger.debug(f\"Node {self.name} - {self.id}: Successfully reranked {len(reranked_documents)} documents\")\n\n        return {\"documents\": reranked_documents[: self.top_k]}\n</code></pre>"},{"location":"dynamiq/nodes/rankers/cohere/#dynamiq.nodes.rankers.cohere.CohereReranker.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the CohereReranker instance.</p> Source code in <code>dynamiq/nodes/rankers/cohere.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the CohereReranker instance.\"\"\"\n    super().__init__(**kwargs)\n\n    from litellm import rerank\n\n    self._rerank = rerank\n</code></pre>"},{"location":"dynamiq/nodes/rankers/cohere/#dynamiq.nodes.rankers.cohere.CohereReranker.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document reranking process.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>CohereRerankerInputSchema</code> <p>The input data containing documents and query.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the reranked documents.</p> Source code in <code>dynamiq/nodes/rankers/cohere.py</code> <pre><code>def execute(self, input_data: CohereRerankerInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the document reranking process.\n\n    Args:\n        input_data (CohereRerankerInputSchema): The input data containing documents and query.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the reranked documents.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    query = input_data.query\n    documents = input_data.documents\n\n    if not documents:\n        logger.warning(f\"Node {self.name} - {self.id}: No documents provided for reranking\")\n        return {\"documents\": []}\n\n    document_texts = [doc.content for doc in documents]\n\n    logger.debug(f\"Node {self.name} - {self.id}: Reranking {len(documents)} documents\")\n\n    response = self._rerank(\n        model=self.model, query=query, documents=document_texts, top_n=self.top_k, **self.connection.conn_params\n    )\n\n    reranked_documents = []\n    for result in response.results:\n        doc = documents[result.get(\"index\")]\n        doc.score = result.get(\"relevance_score\")\n        if doc.score &gt; self.threshold:\n            reranked_documents.append(doc)\n\n    logger.debug(f\"Node {self.name} - {self.id}: Successfully reranked {len(reranked_documents)} documents\")\n\n    return {\"documents\": reranked_documents[: self.top_k]}\n</code></pre>"},{"location":"dynamiq/nodes/rankers/llm/","title":"Llm","text":""},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker","title":"<code>LLMDocumentRanker</code>","text":"<p>               Bases: <code>Node</code></p> <p>A Node class for ranking documents using a Large Language Model (LLM).</p> <p>This class can use any LLM to rank and select relevant documents based on a query. By default, it utilizes an OpenAI language model.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RANKERS]</code> <p>The group the node belongs to. Default is NodeGroup.RANKERS.</p> <code>name</code> <code>str</code> <p>The name of the node. Default is \"LLMDocumentRanker\".</p> <code>prompt_template</code> <code>str</code> <p>The template for the prompt to be used with the LLM. Default is DEFAULT_PROMPT.</p> <code>top_k</code> <code>int</code> <p>The number of top documents to return. Default is 5.</p> <code>llm</code> <code>BaseLLM</code> <p>The LLM instance used for ranking. Default is None.</p> <p>Example:</p> <pre><code>from dynamiq.nodes.rankers import LLMDocumentRanker\nfrom dynamiq.types import Document\n\n# Initialize the ranker\nranker = LLMDocumentRanker()\n\n# Example input data\ninput_data = {\n    \"query\": \"example query\",\n    \"documents\": [\n        Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n        Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n    ]\n}\n\n# Execute the ranker\noutput = ranker.execute(input_data)\n\n# Output will be a dictionary with ranked documents\nprint(output)\n</code></pre> Source code in <code>dynamiq/nodes/rankers/llm.py</code> <pre><code>class LLMDocumentRanker(Node):\n    \"\"\"\n    A Node class for ranking documents using a Large Language Model (LLM).\n\n    This class can use any LLM to rank and select relevant documents based on a query. By default, it utilizes an OpenAI\n    language model.\n\n    Attributes:\n        group (Literal[NodeGroup.RANKERS]): The group the node belongs to. Default is NodeGroup.RANKERS.\n        name (str): The name of the node. Default is \"LLMDocumentRanker\".\n        prompt_template (str): The template for the prompt to be used with the LLM. Default is DEFAULT_PROMPT.\n        top_k (int): The number of top documents to return. Default is 5.\n        llm (BaseLLM): The LLM instance used for ranking. Default is None.\n\n    Example:\n\n        from dynamiq.nodes.rankers import LLMDocumentRanker\n        from dynamiq.types import Document\n\n        # Initialize the ranker\n        ranker = LLMDocumentRanker()\n\n        # Example input data\n        input_data = {\n            \"query\": \"example query\",\n            \"documents\": [\n                Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n                Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n            ]\n        }\n\n        # Execute the ranker\n        output = ranker.execute(input_data)\n\n        # Output will be a dictionary with ranked documents\n        print(output)\n    \"\"\"\n\n    group: Literal[NodeGroup.RANKERS] = NodeGroup.RANKERS\n    name: str = \"LLMDocumentRanker\"\n    prompt_template: str = DEFAULT_PROMPT\n    top_k: int = 5\n    llm: Node\n    input_schema: ClassVar[type[LLMDocumentRankerInputSchema]] = LLMDocumentRankerInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the LLMDocumentRanker with the given parameters and creates a default LLM node.\n\n        Args:\n            **kwargs: Additional keyword arguments to be passed to the parent class constructor.\n        \"\"\"\n        super().__init__(**kwargs)\n        self._run_depends = []\n\n    def reset_run_state(self):\n        \"\"\"\n        Reset the intermediate steps (run_depends) of the node.\n        \"\"\"\n        self._run_depends = []\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"\n        Property to define which parameters should be excluded when converting the class instance to a dictionary.\n\n        Returns:\n            dict: A dictionary defining the parameters to exclude.\n        \"\"\"\n        return super().to_dict_exclude_params | {\"llm\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"llm\"] = self.llm.to_dict(**kwargs)\n        return data\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the document ranker component.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use. Default is a new instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.llm.is_postponed_component_init:\n            self.llm.init_components(connection_manager)\n\n    def execute(\n        self, input_data: LLMDocumentRankerInputSchema, config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the document ranking process.\n\n        Args:\n            input_data (LLMDocumentRankerInputSchema): A dictionary containing the query and documents to be ranked.\n            config (RunnableConfig, optional): Configuration for the execution. Default is None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the original query and the ranked documents.\n\n        Example:\n\n            input_data = {\n                \"query\": \"example query\",\n                \"documents\": [\n                    Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n                    Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n                ]\n            }\n\n            output = ranker.execute(input_data)\n\n            # output will be a dictionary with ranked documents\n        \"\"\"\n        config = ensure_config(config)\n        self.reset_run_state()\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        ranked_documents = self.perform_llm_ranking(\n            query=input_data.query,\n            documents=input_data.documents,\n            config=config,\n            **kwargs,\n        )\n\n        return {\n            \"documents\": ranked_documents,\n        }\n\n    def perform_llm_ranking(\n        self, query: str, documents: list[Document], config: RunnableConfig, **kwargs\n    ) -&gt; list[Document]:\n        \"\"\"\n        Performs the actual ranking of documents using the LLM.\n\n        Args:\n            query (str): The query to rank documents against.\n            documents (list[Document]): The list of documents to be ranked.\n            config (RunnableConfig): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            list[Document]: A list of selected documents deemed relevant by the LLM.\n\n        Example:\n\n            query = \"example query\"\n            documents = [\n                Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n                Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n            ]\n\n            ranked_documents = ranker.perform_llm_ranking(query, documents, config)\n\n            # ranked_documents will be a list of documents deemed relevant by the LLM\n        \"\"\"\n        run_kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n        inputs = [\n            {\"query\": query, \"passage\": document.content} for document in documents\n        ]\n\n        prompt = prompts.Prompt(\n            messages=[prompts.Message(role=\"user\", content=self.prompt_template)]\n        )\n\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            llm_results = list(\n                executor.map(\n                    lambda input_data: self.call_llm(\n                        input_data, prompt, config, **run_kwargs\n                    ),\n                    inputs,\n                )\n            )\n\n        logger.debug(\n            f\"Node {self.name} - {self.id}: LLM processed {len(llm_results)} documents\"\n        )\n\n        selected_documents = []\n\n        for result, document in zip(llm_results, documents):\n            if result == \"Yes\":\n                selected_documents.append(document)\n\n        logger.debug(\n            f\"Node {self.name} - {self.id}: LLM selected {len(selected_documents)} documents for context\"\n        )\n        return selected_documents\n\n    def call_llm(self, input_data, prompt, config, **run_kwargs):\n        \"\"\"\n        Calls the LLM with the given input data and prompt.\n\n        Args:\n            input_data (dict): The input data for the LLM.\n            prompt (prompts.Prompt): The prompt to be used with the LLM.\n            config (RunnableConfig): Configuration for the execution.\n            **run_kwargs: Additional keyword arguments.\n\n        Returns:\n            str: The result from the LLM.\n\n        Example:\n\n            input_data = {\"query\": \"example query\", \"passage\": \"Document content\"}\n            prompt = prompts.Prompt(\n                messages=[prompts.Message(role=\"user\", content=DEFAULT_PROMPT)]\n            )\n            config = RunnableConfig()\n\n            result = ranker.call_llm(input_data, prompt, config)\n\n            # result will be the LLM's response, either 'Yes' or 'No'\n        \"\"\"\n        llm_result = self.llm.run(\n            input_data=input_data,\n            prompt=prompt,\n            config=config,\n            run_depends=self._run_depends,\n            **run_kwargs,\n        )\n        self._run_depends = [NodeDependency(node=self.llm).to_dict(for_tracing=True)]\n        if llm_result.status != RunnableStatus.SUCCESS:\n            logger.error(f\"Node {self.name} - {self.id}: LLM execution failed: {llm_result.error.to_dict()}\")\n            raise ValueError(\"LLMDocumentRanker LLM execution failed\")\n        return llm_result.output[\"content\"]\n</code></pre>"},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Property to define which parameters should be excluded when converting the class instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary defining the parameters to exclude.</p>"},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the LLMDocumentRanker with the given parameters and creates a default LLM node.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to be passed to the parent class constructor.</p> <code>{}</code> Source code in <code>dynamiq/nodes/rankers/llm.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the LLMDocumentRanker with the given parameters and creates a default LLM node.\n\n    Args:\n        **kwargs: Additional keyword arguments to be passed to the parent class constructor.\n    \"\"\"\n    super().__init__(**kwargs)\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker.call_llm","title":"<code>call_llm(input_data, prompt, config, **run_kwargs)</code>","text":"<p>Calls the LLM with the given input data and prompt.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict</code> <p>The input data for the LLM.</p> required <code>prompt</code> <code>Prompt</code> <p>The prompt to be used with the LLM.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> required <code>**run_kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The result from the LLM.</p> <p>Example:</p> <pre><code>input_data = {\"query\": \"example query\", \"passage\": \"Document content\"}\nprompt = prompts.Prompt(\n    messages=[prompts.Message(role=\"user\", content=DEFAULT_PROMPT)]\n)\nconfig = RunnableConfig()\n\nresult = ranker.call_llm(input_data, prompt, config)\n\n# result will be the LLM's response, either 'Yes' or 'No'\n</code></pre> Source code in <code>dynamiq/nodes/rankers/llm.py</code> <pre><code>def call_llm(self, input_data, prompt, config, **run_kwargs):\n    \"\"\"\n    Calls the LLM with the given input data and prompt.\n\n    Args:\n        input_data (dict): The input data for the LLM.\n        prompt (prompts.Prompt): The prompt to be used with the LLM.\n        config (RunnableConfig): Configuration for the execution.\n        **run_kwargs: Additional keyword arguments.\n\n    Returns:\n        str: The result from the LLM.\n\n    Example:\n\n        input_data = {\"query\": \"example query\", \"passage\": \"Document content\"}\n        prompt = prompts.Prompt(\n            messages=[prompts.Message(role=\"user\", content=DEFAULT_PROMPT)]\n        )\n        config = RunnableConfig()\n\n        result = ranker.call_llm(input_data, prompt, config)\n\n        # result will be the LLM's response, either 'Yes' or 'No'\n    \"\"\"\n    llm_result = self.llm.run(\n        input_data=input_data,\n        prompt=prompt,\n        config=config,\n        run_depends=self._run_depends,\n        **run_kwargs,\n    )\n    self._run_depends = [NodeDependency(node=self.llm).to_dict(for_tracing=True)]\n    if llm_result.status != RunnableStatus.SUCCESS:\n        logger.error(f\"Node {self.name} - {self.id}: LLM execution failed: {llm_result.error.to_dict()}\")\n        raise ValueError(\"LLMDocumentRanker LLM execution failed\")\n    return llm_result.output[\"content\"]\n</code></pre>"},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the document ranking process.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>LLMDocumentRankerInputSchema</code> <p>A dictionary containing the query and documents to be ranked.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Default is None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the original query and the ranked documents.</p> <p>Example:</p> <pre><code>input_data = {\n    \"query\": \"example query\",\n    \"documents\": [\n        Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n        Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n    ]\n}\n\noutput = ranker.execute(input_data)\n\n# output will be a dictionary with ranked documents\n</code></pre> Source code in <code>dynamiq/nodes/rankers/llm.py</code> <pre><code>def execute(\n    self, input_data: LLMDocumentRankerInputSchema, config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the document ranking process.\n\n    Args:\n        input_data (LLMDocumentRankerInputSchema): A dictionary containing the query and documents to be ranked.\n        config (RunnableConfig, optional): Configuration for the execution. Default is None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the original query and the ranked documents.\n\n    Example:\n\n        input_data = {\n            \"query\": \"example query\",\n            \"documents\": [\n                Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n                Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n            ]\n        }\n\n        output = ranker.execute(input_data)\n\n        # output will be a dictionary with ranked documents\n    \"\"\"\n    config = ensure_config(config)\n    self.reset_run_state()\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    ranked_documents = self.perform_llm_ranking(\n        query=input_data.query,\n        documents=input_data.documents,\n        config=config,\n        **kwargs,\n    )\n\n    return {\n        \"documents\": ranked_documents,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the document ranker component.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Default is a new instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/rankers/llm.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the document ranker component.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use. Default is a new instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.llm.is_postponed_component_init:\n        self.llm.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker.perform_llm_ranking","title":"<code>perform_llm_ranking(query, documents, config, **kwargs)</code>","text":"<p>Performs the actual ranking of documents using the LLM.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The query to rank documents against.</p> required <code>documents</code> <code>list[Document]</code> <p>The list of documents to be ranked.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: A list of selected documents deemed relevant by the LLM.</p> <p>Example:</p> <pre><code>query = \"example query\"\ndocuments = [\n    Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n    Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n]\n\nranked_documents = ranker.perform_llm_ranking(query, documents, config)\n\n# ranked_documents will be a list of documents deemed relevant by the LLM\n</code></pre> Source code in <code>dynamiq/nodes/rankers/llm.py</code> <pre><code>def perform_llm_ranking(\n    self, query: str, documents: list[Document], config: RunnableConfig, **kwargs\n) -&gt; list[Document]:\n    \"\"\"\n    Performs the actual ranking of documents using the LLM.\n\n    Args:\n        query (str): The query to rank documents against.\n        documents (list[Document]): The list of documents to be ranked.\n        config (RunnableConfig): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        list[Document]: A list of selected documents deemed relevant by the LLM.\n\n    Example:\n\n        query = \"example query\"\n        documents = [\n            Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n            Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n        ]\n\n        ranked_documents = ranker.perform_llm_ranking(query, documents, config)\n\n        # ranked_documents will be a list of documents deemed relevant by the LLM\n    \"\"\"\n    run_kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n    inputs = [\n        {\"query\": query, \"passage\": document.content} for document in documents\n    ]\n\n    prompt = prompts.Prompt(\n        messages=[prompts.Message(role=\"user\", content=self.prompt_template)]\n    )\n\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        llm_results = list(\n            executor.map(\n                lambda input_data: self.call_llm(\n                    input_data, prompt, config, **run_kwargs\n                ),\n                inputs,\n            )\n        )\n\n    logger.debug(\n        f\"Node {self.name} - {self.id}: LLM processed {len(llm_results)} documents\"\n    )\n\n    selected_documents = []\n\n    for result, document in zip(llm_results, documents):\n        if result == \"Yes\":\n            selected_documents.append(document)\n\n    logger.debug(\n        f\"Node {self.name} - {self.id}: LLM selected {len(selected_documents)} documents for context\"\n    )\n    return selected_documents\n</code></pre>"},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Reset the intermediate steps (run_depends) of the node.</p> Source code in <code>dynamiq/nodes/rankers/llm.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"\n    Reset the intermediate steps (run_depends) of the node.\n    \"\"\"\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/rankers/llm/#dynamiq.nodes.rankers.llm.LLMDocumentRanker.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/rankers/llm.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"llm\"] = self.llm.to_dict(**kwargs)\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/rankers/recency/","title":"Recency","text":""},{"location":"dynamiq/nodes/rankers/recency/#dynamiq.nodes.rankers.recency.TimeWeightedDocumentRanker","title":"<code>TimeWeightedDocumentRanker</code>","text":"<p>               Bases: <code>Node</code></p> <p>A document ranker node boosting the recent content more.</p> <p>This ranker adjusts the initial scores of documents based on their recency. The recency coefficient depends on the number of days from today. The initial score is multiplied by the recency coefficient, and the documents are re-ranked based on the adjusted score.</p> The formula for the adjustment is <p>adjusted_score = score * recency_coefficient</p> The recency coefficient is calculated as follows <p>min_coefficient &lt;= coefficient &lt;= 1 (if the same date)</p> <p>The coefficient is determined based on the number of days since the content was created.</p> <p>An exponential decay formula is used to ensure that the coefficient decreases as the number of days increases, but never goes below the specified minimum coefficient.</p> The formula used is <p>coefficient = min_coefficient + (1 - min_coefficient) * exp(-3 * days / max_days)</p> This ensures that <ul> <li>If days &lt;= 0, the coefficient is 1.0 (no decay).</li> <li>If days &gt;= max_days, the coefficient is min_coefficient (maximum decay).</li> <li>For days in between, the coefficient smoothly transitions from 1.0 to min_coefficient.</li> </ul> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RANKERS]</code> <p>The group this node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>top_k</code> <code>int</code> <p>The number of top documents to return. Default is 5.</p> <code>max_days</code> <code>int</code> <p>The maximum number of days to consider for adjustment. Default is 3600.</p> <code>min_coefficient</code> <code>float</code> <p>The minimum coefficient for score adjustment. Default is 0.9.</p> <code>date_field</code> <code>str</code> <p>The field name in the metadata containing the date. Default is \"date\".</p> <code>date_format</code> <code>str</code> <p>The format of the date string. Default is \"%d %B, %Y\".</p> <p>Example:</p> <pre><code>from dynamiq.nodes.rankers import TimeWeightedDocumentRanker\nfrom dynamiq.types import Document\n\n# Initialize the ranker\nranker = TimeWeightedDocumentRanker()\n\n# Example input data\ninput_data = {\n    \"query\": \"example query\",\n    \"documents\": [\n        Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n        Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n    ]\n}\n\n# Execute the ranker\noutput = ranker.execute(input_data)\n\n# Output will be a dictionary with ranked documents\nprint(output)\n</code></pre> Source code in <code>dynamiq/nodes/rankers/recency.py</code> <pre><code>class TimeWeightedDocumentRanker(Node):\n    \"\"\"\n    A document ranker node boosting the recent content more.\n\n    This ranker adjusts the initial scores of documents based on their recency. The recency coefficient\n    depends on the number of days from today. The initial score is multiplied by the recency coefficient,\n    and the documents are re-ranked based on the adjusted score.\n\n    The formula for the adjustment is:\n        adjusted_score = score * recency_coefficient\n\n    The recency coefficient is calculated as follows:\n        min_coefficient &lt;= coefficient &lt;= 1 (if the same date)\n\n    The coefficient is determined based on the number of days since the content was created.\n\n    An exponential decay formula is used to ensure that the coefficient decreases as the number of days\n    increases, but never goes below the specified minimum coefficient.\n\n    The formula used is:\n        coefficient = min_coefficient + (1 - min_coefficient) * exp(-3 * days / max_days)\n\n    This ensures that:\n        - If days &lt;= 0, the coefficient is 1.0 (no decay).\n        - If days &gt;= max_days, the coefficient is min_coefficient (maximum decay).\n        - For days in between, the coefficient smoothly transitions from 1.0 to min_coefficient.\n\n    Attributes:\n        group (Literal[NodeGroup.RANKERS]): The group this node belongs to.\n        name (str): The name of the node.\n        top_k (int): The number of top documents to return. Default is 5.\n        max_days (int): The maximum number of days to consider for adjustment. Default is 3600.\n        min_coefficient (float): The minimum coefficient for score adjustment. Default is 0.9.\n        date_field (str): The field name in the metadata containing the date. Default is \"date\".\n        date_format (str): The format of the date string. Default is \"%d %B, %Y\".\n\n    Example:\n\n        from dynamiq.nodes.rankers import TimeWeightedDocumentRanker\n        from dynamiq.types import Document\n\n        # Initialize the ranker\n        ranker = TimeWeightedDocumentRanker()\n\n        # Example input data\n        input_data = {\n            \"query\": \"example query\",\n            \"documents\": [\n                Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n                Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n            ]\n        }\n\n        # Execute the ranker\n        output = ranker.execute(input_data)\n\n        # Output will be a dictionary with ranked documents\n        print(output)\n    \"\"\"\n\n    group: Literal[NodeGroup.RANKERS] = NodeGroup.RANKERS\n    name: str = \"Time Weighted Document Ranker\"\n    top_k: int = 5\n    max_days: int = 3600\n    min_coefficient: float = 0.9\n    date_field: str = \"date\"\n    date_format: str = \"%d %B, %Y\"\n    input_schema: ClassVar[type[TimeWeightedDocumentRankerInputSchema]] = TimeWeightedDocumentRankerInputSchema\n\n    def execute(\n        self, input_data: TimeWeightedDocumentRankerInputSchema, config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the document ranking process.\n\n        Args:\n            input_data (TimeWeightedDocumentRankerInputSchema): The input data containing documents and query.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the original query and the ranked documents.\n\n        Example:\n\n            input_data = {\n                \"documents\": [\n                    Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n                    Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n                ]\n            }\n\n            output = ranker.execute(input_data)\n\n            # output will be a dictionary with ranked documents\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = input_data.documents\n\n        ranked_documents = self.adjust_similarity_scores(\n            documents,\n            date_field=self.date_field,\n            max_days=self.max_days,\n            min_coefficient=self.min_coefficient,\n            date_format=self.date_format,\n        )\n\n        return {\n            \"documents\": ranked_documents,\n        }\n\n    @staticmethod\n    def date_to_days(date_string: str, date_format: str = \"%d %B, %Y\") -&gt; int:\n        \"\"\"\n        Convert a date string to the number of days since that date.\n\n        Args:\n            date_string (str): Date in the format \"dd Month, YYYY\"\n            date_format (str): The format of the date string (default: \"%d %B, %Y\").\n\n        Returns:\n            int: Number of days since the given date.\n\n        Example:\n\n            days = TimeWeightedDocumentRanker.date_to_days(\"01 January, 2022\")\n\n            # days will be the number of days since 01 January, 2022\n        \"\"\"\n        date_object = datetime.strptime(date_string, date_format)\n        current_date = datetime.now()\n        return (current_date - date_object).days\n\n    @staticmethod\n    def days_to_coefficient(\n        days: int, max_days: int = 3600, min_coefficient: float = 0.1\n    ) -&gt; float:\n        \"\"\"\n        Transform number of days into a coefficient for score adjustment.\n\n        The coefficient is calculated based on the number of days since the content was created.\n\n        The function uses an exponential decay formula to ensure that the coefficient decreases\n        as the number of days increases, but never goes below the specified minimum coefficient.\n\n        The formula used is:\n            coefficient = min_coefficient + (1 - min_coefficient) * exp(-3 * days / max_days)\n\n        This ensures that:\n            - If days &lt;= 0, the coefficient is 1.0 (no decay).\n            - If days &gt;= max_days, the coefficient is min_coefficient (maximum decay).\n            - For days in between, the coefficient smoothly transitions from 1.0 to min_coefficient.\n\n        Args:\n            days (int): Number of days since the content was created.\n            max_days (int): Maximum number of days to consider (default: 3600, about 12 years).\n            min_coefficient (float): Minimum coefficient value (default: 0.1).\n\n        Returns:\n            float: Coefficient between min_coefficient and 1.\n\n        Example:\n\n            coefficient = TimeWeightedDocumentRanker.days_to_coefficient(365)\n\n            # coefficient will be a value between 0.1 and 1 based on the number of days\n        \"\"\"\n        if days &lt;= 0:\n            return 1.0\n        elif days &gt;= max_days:\n            return min_coefficient\n        else:\n            return min_coefficient + (1 - min_coefficient) * math.exp(\n                -3 * days / max_days\n            )\n\n    @staticmethod\n    def adjust_similarity_scores(\n        candidates: list[Document],\n        date_field: str = \"date\",\n        max_days: int = 3600,\n        min_coefficient: float = 0.9,\n        date_format: str = \"%d %B, %Y\",\n    ) -&gt; list[Document]:\n        \"\"\"\n        Adjust cosine similarity scores based on content recency.\n\n        Args:\n            candidates (list[Document]): List of Document objects containing candidates with 'score' and date fields.\n            date_field (str): Name of the field containing the date string (default: 'date').\n            max_days (int): Maximum number of days to consider for adjustment.\n            min_coefficient (float): Minimum coefficient for score adjustment.\n            date_format (str): The format of the date string (default: \"%d %B, %Y\").\n\n        Returns:\n            list[Document]: List of candidates with adjusted scores, sorted by the new scores.\n\n        Example:\n\n            candidates = [\n                Document(content=\"Document content\", score=0.5, metadata={\"date\": \"01 January, 2022\"}),\n                Document(content=\"Document content\", score=0.5, metadata={\"date\": \"01 January, 2021\"})\n            ]\n\n            adjusted_candidates = TimeWeightedDocumentRanker.adjust_similarity_scores(candidates)\n\n            # adjusted_candidates will be sorted by adjusted scores\n        \"\"\"\n        for candidate in candidates:\n            if date := candidate.metadata.get(date_field):\n                days = TimeWeightedDocumentRanker.date_to_days(\n                    date,\n                    date_format=date_format,\n                )\n                coefficient = TimeWeightedDocumentRanker.days_to_coefficient(\n                    days, max_days=max_days, min_coefficient=min_coefficient\n                )\n                candidate.score = candidate.score * coefficient\n\n        documents = [\n            {\"score\": candidate.score, \"document\": candidate}\n            for candidate in candidates\n        ]\n\n        sorted_documents = sorted(documents, key=lambda x: x[\"score\"], reverse=True)\n\n        return [document[\"document\"] for document in sorted_documents]\n</code></pre>"},{"location":"dynamiq/nodes/rankers/recency/#dynamiq.nodes.rankers.recency.TimeWeightedDocumentRanker.adjust_similarity_scores","title":"<code>adjust_similarity_scores(candidates, date_field='date', max_days=3600, min_coefficient=0.9, date_format='%d %B, %Y')</code>  <code>staticmethod</code>","text":"<p>Adjust cosine similarity scores based on content recency.</p> <p>Parameters:</p> Name Type Description Default <code>candidates</code> <code>list[Document]</code> <p>List of Document objects containing candidates with 'score' and date fields.</p> required <code>date_field</code> <code>str</code> <p>Name of the field containing the date string (default: 'date').</p> <code>'date'</code> <code>max_days</code> <code>int</code> <p>Maximum number of days to consider for adjustment.</p> <code>3600</code> <code>min_coefficient</code> <code>float</code> <p>Minimum coefficient for score adjustment.</p> <code>0.9</code> <code>date_format</code> <code>str</code> <p>The format of the date string (default: \"%d %B, %Y\").</p> <code>'%d %B, %Y'</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: List of candidates with adjusted scores, sorted by the new scores.</p> <p>Example:</p> <pre><code>candidates = [\n    Document(content=\"Document content\", score=0.5, metadata={\"date\": \"01 January, 2022\"}),\n    Document(content=\"Document content\", score=0.5, metadata={\"date\": \"01 January, 2021\"})\n]\n\nadjusted_candidates = TimeWeightedDocumentRanker.adjust_similarity_scores(candidates)\n\n# adjusted_candidates will be sorted by adjusted scores\n</code></pre> Source code in <code>dynamiq/nodes/rankers/recency.py</code> <pre><code>@staticmethod\ndef adjust_similarity_scores(\n    candidates: list[Document],\n    date_field: str = \"date\",\n    max_days: int = 3600,\n    min_coefficient: float = 0.9,\n    date_format: str = \"%d %B, %Y\",\n) -&gt; list[Document]:\n    \"\"\"\n    Adjust cosine similarity scores based on content recency.\n\n    Args:\n        candidates (list[Document]): List of Document objects containing candidates with 'score' and date fields.\n        date_field (str): Name of the field containing the date string (default: 'date').\n        max_days (int): Maximum number of days to consider for adjustment.\n        min_coefficient (float): Minimum coefficient for score adjustment.\n        date_format (str): The format of the date string (default: \"%d %B, %Y\").\n\n    Returns:\n        list[Document]: List of candidates with adjusted scores, sorted by the new scores.\n\n    Example:\n\n        candidates = [\n            Document(content=\"Document content\", score=0.5, metadata={\"date\": \"01 January, 2022\"}),\n            Document(content=\"Document content\", score=0.5, metadata={\"date\": \"01 January, 2021\"})\n        ]\n\n        adjusted_candidates = TimeWeightedDocumentRanker.adjust_similarity_scores(candidates)\n\n        # adjusted_candidates will be sorted by adjusted scores\n    \"\"\"\n    for candidate in candidates:\n        if date := candidate.metadata.get(date_field):\n            days = TimeWeightedDocumentRanker.date_to_days(\n                date,\n                date_format=date_format,\n            )\n            coefficient = TimeWeightedDocumentRanker.days_to_coefficient(\n                days, max_days=max_days, min_coefficient=min_coefficient\n            )\n            candidate.score = candidate.score * coefficient\n\n    documents = [\n        {\"score\": candidate.score, \"document\": candidate}\n        for candidate in candidates\n    ]\n\n    sorted_documents = sorted(documents, key=lambda x: x[\"score\"], reverse=True)\n\n    return [document[\"document\"] for document in sorted_documents]\n</code></pre>"},{"location":"dynamiq/nodes/rankers/recency/#dynamiq.nodes.rankers.recency.TimeWeightedDocumentRanker.date_to_days","title":"<code>date_to_days(date_string, date_format='%d %B, %Y')</code>  <code>staticmethod</code>","text":"<p>Convert a date string to the number of days since that date.</p> <p>Parameters:</p> Name Type Description Default <code>date_string</code> <code>str</code> <p>Date in the format \"dd Month, YYYY\"</p> required <code>date_format</code> <code>str</code> <p>The format of the date string (default: \"%d %B, %Y\").</p> <code>'%d %B, %Y'</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of days since the given date.</p> <p>Example:</p> <pre><code>days = TimeWeightedDocumentRanker.date_to_days(\"01 January, 2022\")\n\n# days will be the number of days since 01 January, 2022\n</code></pre> Source code in <code>dynamiq/nodes/rankers/recency.py</code> <pre><code>@staticmethod\ndef date_to_days(date_string: str, date_format: str = \"%d %B, %Y\") -&gt; int:\n    \"\"\"\n    Convert a date string to the number of days since that date.\n\n    Args:\n        date_string (str): Date in the format \"dd Month, YYYY\"\n        date_format (str): The format of the date string (default: \"%d %B, %Y\").\n\n    Returns:\n        int: Number of days since the given date.\n\n    Example:\n\n        days = TimeWeightedDocumentRanker.date_to_days(\"01 January, 2022\")\n\n        # days will be the number of days since 01 January, 2022\n    \"\"\"\n    date_object = datetime.strptime(date_string, date_format)\n    current_date = datetime.now()\n    return (current_date - date_object).days\n</code></pre>"},{"location":"dynamiq/nodes/rankers/recency/#dynamiq.nodes.rankers.recency.TimeWeightedDocumentRanker.days_to_coefficient","title":"<code>days_to_coefficient(days, max_days=3600, min_coefficient=0.1)</code>  <code>staticmethod</code>","text":"<p>Transform number of days into a coefficient for score adjustment.</p> <p>The coefficient is calculated based on the number of days since the content was created.</p> <p>The function uses an exponential decay formula to ensure that the coefficient decreases as the number of days increases, but never goes below the specified minimum coefficient.</p> The formula used is <p>coefficient = min_coefficient + (1 - min_coefficient) * exp(-3 * days / max_days)</p> This ensures that <ul> <li>If days &lt;= 0, the coefficient is 1.0 (no decay).</li> <li>If days &gt;= max_days, the coefficient is min_coefficient (maximum decay).</li> <li>For days in between, the coefficient smoothly transitions from 1.0 to min_coefficient.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>days</code> <code>int</code> <p>Number of days since the content was created.</p> required <code>max_days</code> <code>int</code> <p>Maximum number of days to consider (default: 3600, about 12 years).</p> <code>3600</code> <code>min_coefficient</code> <code>float</code> <p>Minimum coefficient value (default: 0.1).</p> <code>0.1</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Coefficient between min_coefficient and 1.</p> <p>Example:</p> <pre><code>coefficient = TimeWeightedDocumentRanker.days_to_coefficient(365)\n\n# coefficient will be a value between 0.1 and 1 based on the number of days\n</code></pre> Source code in <code>dynamiq/nodes/rankers/recency.py</code> <pre><code>@staticmethod\ndef days_to_coefficient(\n    days: int, max_days: int = 3600, min_coefficient: float = 0.1\n) -&gt; float:\n    \"\"\"\n    Transform number of days into a coefficient for score adjustment.\n\n    The coefficient is calculated based on the number of days since the content was created.\n\n    The function uses an exponential decay formula to ensure that the coefficient decreases\n    as the number of days increases, but never goes below the specified minimum coefficient.\n\n    The formula used is:\n        coefficient = min_coefficient + (1 - min_coefficient) * exp(-3 * days / max_days)\n\n    This ensures that:\n        - If days &lt;= 0, the coefficient is 1.0 (no decay).\n        - If days &gt;= max_days, the coefficient is min_coefficient (maximum decay).\n        - For days in between, the coefficient smoothly transitions from 1.0 to min_coefficient.\n\n    Args:\n        days (int): Number of days since the content was created.\n        max_days (int): Maximum number of days to consider (default: 3600, about 12 years).\n        min_coefficient (float): Minimum coefficient value (default: 0.1).\n\n    Returns:\n        float: Coefficient between min_coefficient and 1.\n\n    Example:\n\n        coefficient = TimeWeightedDocumentRanker.days_to_coefficient(365)\n\n        # coefficient will be a value between 0.1 and 1 based on the number of days\n    \"\"\"\n    if days &lt;= 0:\n        return 1.0\n    elif days &gt;= max_days:\n        return min_coefficient\n    else:\n        return min_coefficient + (1 - min_coefficient) * math.exp(\n            -3 * days / max_days\n        )\n</code></pre>"},{"location":"dynamiq/nodes/rankers/recency/#dynamiq.nodes.rankers.recency.TimeWeightedDocumentRanker.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document ranking process.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>TimeWeightedDocumentRankerInputSchema</code> <p>The input data containing documents and query.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the original query and the ranked documents.</p> <p>Example:</p> <pre><code>input_data = {\n    \"documents\": [\n        Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n        Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n    ]\n}\n\noutput = ranker.execute(input_data)\n\n# output will be a dictionary with ranked documents\n</code></pre> Source code in <code>dynamiq/nodes/rankers/recency.py</code> <pre><code>def execute(\n    self, input_data: TimeWeightedDocumentRankerInputSchema, config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the document ranking process.\n\n    Args:\n        input_data (TimeWeightedDocumentRankerInputSchema): The input data containing documents and query.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the original query and the ranked documents.\n\n    Example:\n\n        input_data = {\n            \"documents\": [\n                Document(content=\"Document content\", score=0.8, metadata={\"date\": \"01 January, 2022\"}),\n                Document(content=\"Document content\", score=0.9, metadata={\"date\": \"01 January, 2021\"})\n            ]\n        }\n\n        output = ranker.execute(input_data)\n\n        # output will be a dictionary with ranked documents\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = input_data.documents\n\n    ranked_documents = self.adjust_similarity_scores(\n        documents,\n        date_field=self.date_field,\n        max_days=self.max_days,\n        min_coefficient=self.min_coefficient,\n        date_format=self.date_format,\n    )\n\n    return {\n        \"documents\": ranked_documents,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/base/","title":"Base","text":""},{"location":"dynamiq/nodes/retrievers/chroma/","title":"Chroma","text":""},{"location":"dynamiq/nodes/retrievers/chroma/#dynamiq.nodes.retrievers.chroma.ChromaDocumentRetriever","title":"<code>ChromaDocumentRetriever</code>","text":"<p>               Bases: <code>Retriever</code></p> <p>Document Retriever using Chroma.</p> <p>This class implements a document retriever that uses Chroma as the underlying vector store. It extends the VectorStoreNode class and provides functionality to retrieve documents based on vector similarity.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RETRIEVERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>vector_store</code> <code>ChromaVectorStore | None</code> <p>The ChromaVectorStore instance.</p> <code>filters</code> <code>dict[str, Any] | None</code> <p>Filters to apply when retrieving documents.</p> <code>top_k</code> <code>int</code> <p>The maximum number of documents to retrieve.</p> <code>document_retriever</code> <code>ChromaDocumentRetriever</code> <p>The document retriever component.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for initializing the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/chroma.py</code> <pre><code>class ChromaDocumentRetriever(Retriever):\n    \"\"\"\n    Document Retriever using Chroma.\n\n    This class implements a document retriever that uses Chroma as the underlying vector store.\n    It extends the VectorStoreNode class and provides functionality to retrieve documents\n    based on vector similarity.\n\n    Attributes:\n        group (Literal[NodeGroup.RETRIEVERS]): The group the node belongs to.\n        name (str): The name of the node.\n        vector_store (ChromaVectorStore | None): The ChromaVectorStore instance.\n        filters (dict[str, Any] | None): Filters to apply when retrieving documents.\n        top_k (int): The maximum number of documents to retrieve.\n        document_retriever (ChromaDocumentRetrieverComponent): The document retriever component.\n\n    Args:\n        **kwargs: Keyword arguments for initializing the node.\n    \"\"\"\n\n    name: str = \"ChromaDocumentRetriever\"\n    connection: Chroma | None = None\n    vector_store: ChromaVectorStore | None = None\n    document_retriever: ChromaDocumentRetrieverComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the ChromaDocumentRetriever.\n\n        If neither vector_store nor connection is provided in kwargs, a default Chroma connection will be created.\n\n        Args:\n            **kwargs: Keyword arguments for initializing the node.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Chroma()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return ChromaVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include={\"index_name\"}) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the ChromaDocumentRetriever.\n\n        This method sets up the document retriever component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_retriever is None:\n            self.document_retriever = ChromaDocumentRetrieverComponent(\n                vector_store=self.vector_store,\n                filters=self.filters,\n                top_k=self.top_k,\n                similarity_threshold=self.similarity_threshold,\n            )\n\n    def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the document retrieval process.\n\n        This method takes an input embedding, retrieves similar documents using the\n        document retriever component, and returns the retrieved documents.\n\n        Args:\n            input_data (RetrieverInputSchema): The input data containing the query embedding.\n            config (RunnableConfig, optional): The configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the retrieved documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query_embedding = input_data.embedding\n        filters = input_data.filters or self.filters\n        top_k = input_data.top_k or self.top_k\n        similarity_threshold = (\n            input_data.similarity_threshold\n            if input_data.similarity_threshold is not None\n            else self.similarity_threshold\n        )\n\n        output = self.document_retriever.run(\n            query_embedding,\n            filters=filters,\n            top_k=top_k,\n            similarity_threshold=similarity_threshold,\n        )\n\n        return {\n            \"documents\": output[\"documents\"],\n        }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/chroma/#dynamiq.nodes.retrievers.chroma.ChromaDocumentRetriever.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the ChromaDocumentRetriever.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Chroma connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for initializing the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/chroma.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the ChromaDocumentRetriever.\n\n    If neither vector_store nor connection is provided in kwargs, a default Chroma connection will be created.\n\n    Args:\n        **kwargs: Keyword arguments for initializing the node.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Chroma()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/chroma/#dynamiq.nodes.retrievers.chroma.ChromaDocumentRetriever.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document retrieval process.</p> <p>This method takes an input embedding, retrieves similar documents using the document retriever component, and returns the retrieved documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>RetrieverInputSchema</code> <p>The input data containing the query embedding.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the retrieved documents.</p> Source code in <code>dynamiq/nodes/retrievers/chroma.py</code> <pre><code>def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the document retrieval process.\n\n    This method takes an input embedding, retrieves similar documents using the\n    document retriever component, and returns the retrieved documents.\n\n    Args:\n        input_data (RetrieverInputSchema): The input data containing the query embedding.\n        config (RunnableConfig, optional): The configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the retrieved documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    query_embedding = input_data.embedding\n    filters = input_data.filters or self.filters\n    top_k = input_data.top_k or self.top_k\n    similarity_threshold = (\n        input_data.similarity_threshold\n        if input_data.similarity_threshold is not None\n        else self.similarity_threshold\n    )\n\n    output = self.document_retriever.run(\n        query_embedding,\n        filters=filters,\n        top_k=top_k,\n        similarity_threshold=similarity_threshold,\n    )\n\n    return {\n        \"documents\": output[\"documents\"],\n    }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/chroma/#dynamiq.nodes.retrievers.chroma.ChromaDocumentRetriever.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the ChromaDocumentRetriever.</p> <p>This method sets up the document retriever component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/retrievers/chroma.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the ChromaDocumentRetriever.\n\n    This method sets up the document retriever component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_retriever is None:\n        self.document_retriever = ChromaDocumentRetrieverComponent(\n            vector_store=self.vector_store,\n            filters=self.filters,\n            top_k=self.top_k,\n            similarity_threshold=self.similarity_threshold,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/elasticsearch/","title":"Elasticsearch","text":""},{"location":"dynamiq/nodes/retrievers/elasticsearch/#dynamiq.nodes.retrievers.elasticsearch.ElasticsearchDocumentRetriever","title":"<code>ElasticsearchDocumentRetriever</code>","text":"<p>               Bases: <code>Retriever</code>, <code>ElasticsearchVectorStoreParams</code></p> <p>Document Retriever using Elasticsearch for vector similarity search.</p> <p>This class implements a document retriever that uses Elasticsearch as the underlying store for vector similarity search with optional metadata filtering.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RETRIEVERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>vector_store</code> <code>Optional[ElasticsearchVectorStore]</code> <p>The ElasticsearchVectorStore instance.</p> <code>filters</code> <code>Optional[dict[str, Any]]</code> <p>Filters to apply when retrieving documents.</p> <code>top_k</code> <code>int</code> <p>The maximum number of documents to retrieve.</p> <code>document_retriever</code> <code>ElasticsearchDocumentRetriever</code> <p>The document retriever component.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for initializing the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/elasticsearch.py</code> <pre><code>class ElasticsearchDocumentRetriever(Retriever, ElasticsearchVectorStoreParams):\n    \"\"\"\n    Document Retriever using Elasticsearch for vector similarity search.\n\n    This class implements a document retriever that uses Elasticsearch as the underlying store\n    for vector similarity search with optional metadata filtering.\n\n    Attributes:\n        group (Literal[NodeGroup.RETRIEVERS]): The group the node belongs to.\n        name (str): The name of the node.\n        vector_store (Optional[ElasticsearchVectorStore]): The ElasticsearchVectorStore instance.\n        filters (Optional[dict[str, Any]]): Filters to apply when retrieving documents.\n        top_k (int): The maximum number of documents to retrieve.\n        document_retriever (ElasticsearchDocumentRetrieverComponent): The document retriever component.\n\n    Args:\n        **kwargs: Keyword arguments for initializing the node.\n    \"\"\"\n\n    name: str = \"ElasticsearchDocumentRetriever\"\n    connection: Elasticsearch | None = None\n    vector_store: ElasticsearchVectorStore | None = None\n    document_retriever: ElasticsearchDocumentRetrieverComponent | None = None\n    input_schema = ElasticsearchRetrieverInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the ElasticsearchDocumentRetriever.\n\n        If neither vector_store nor connection is provided in kwargs,\n        a default Elasticsearch connection will be created.\n\n        Args:\n            **kwargs: Keyword arguments for initializing the node.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Elasticsearch()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return ElasticsearchVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(ElasticsearchVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"Initialize the components of the ElasticsearchDocumentRetriever.\n\n        This method sets up the document retriever component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_retriever is None:\n            self.document_retriever = ElasticsearchDocumentRetrieverComponent(\n                vector_store=self.vector_store,\n                filters=self.filters,\n                top_k=self.top_k,\n                similarity_threshold=self.similarity_threshold,\n            )\n\n    def execute(\n        self, input_data: ElasticsearchRetrieverInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"Execute the document retrieval process.\n\n        This method takes input data containing the vector query and search parameters,\n        retrieves relevant documents using vector similarity search,\n        and returns the retrieved documents.\n\n        Args:\n            input_data (ElasticsearchRetrieverInputSchema): The input data containing:\n            config (Optional[RunnableConfig]): The configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the retrieved documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        output = self.document_retriever.run(\n            query_embedding=input_data.query_embedding,\n            filters=input_data.filters or self.filters,\n            top_k=input_data.top_k or self.top_k,\n            exclude_document_embeddings=input_data.exclude_document_embeddings,\n            scale_scores=input_data.scale_scores,\n            content_key=input_data.content_key,\n            embedding_key=input_data.embedding_key,\n            similarity_threshold=(\n                input_data.similarity_threshold\n                if input_data.similarity_threshold is not None\n                else self.similarity_threshold\n            ),\n        )\n\n        return {\n            \"documents\": output[\"documents\"],\n        }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/elasticsearch/#dynamiq.nodes.retrievers.elasticsearch.ElasticsearchDocumentRetriever.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the ElasticsearchDocumentRetriever.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Elasticsearch connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for initializing the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/elasticsearch.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the ElasticsearchDocumentRetriever.\n\n    If neither vector_store nor connection is provided in kwargs,\n    a default Elasticsearch connection will be created.\n\n    Args:\n        **kwargs: Keyword arguments for initializing the node.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Elasticsearch()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/elasticsearch/#dynamiq.nodes.retrievers.elasticsearch.ElasticsearchDocumentRetriever.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document retrieval process.</p> <p>This method takes input data containing the vector query and search parameters, retrieves relevant documents using vector similarity search, and returns the retrieved documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ElasticsearchRetrieverInputSchema</code> <p>The input data containing:</p> required <code>config</code> <code>Optional[RunnableConfig]</code> <p>The configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the retrieved documents.</p> Source code in <code>dynamiq/nodes/retrievers/elasticsearch.py</code> <pre><code>def execute(\n    self, input_data: ElasticsearchRetrieverInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"Execute the document retrieval process.\n\n    This method takes input data containing the vector query and search parameters,\n    retrieves relevant documents using vector similarity search,\n    and returns the retrieved documents.\n\n    Args:\n        input_data (ElasticsearchRetrieverInputSchema): The input data containing:\n        config (Optional[RunnableConfig]): The configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the retrieved documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    output = self.document_retriever.run(\n        query_embedding=input_data.query_embedding,\n        filters=input_data.filters or self.filters,\n        top_k=input_data.top_k or self.top_k,\n        exclude_document_embeddings=input_data.exclude_document_embeddings,\n        scale_scores=input_data.scale_scores,\n        content_key=input_data.content_key,\n        embedding_key=input_data.embedding_key,\n        similarity_threshold=(\n            input_data.similarity_threshold\n            if input_data.similarity_threshold is not None\n            else self.similarity_threshold\n        ),\n    )\n\n    return {\n        \"documents\": output[\"documents\"],\n    }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/elasticsearch/#dynamiq.nodes.retrievers.elasticsearch.ElasticsearchDocumentRetriever.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the ElasticsearchDocumentRetriever.</p> <p>This method sets up the document retriever component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/retrievers/elasticsearch.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"Initialize the components of the ElasticsearchDocumentRetriever.\n\n    This method sets up the document retriever component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_retriever is None:\n        self.document_retriever = ElasticsearchDocumentRetrieverComponent(\n            vector_store=self.vector_store,\n            filters=self.filters,\n            top_k=self.top_k,\n            similarity_threshold=self.similarity_threshold,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/elasticsearch/#dynamiq.nodes.retrievers.elasticsearch.ElasticsearchRetrieverInputSchema","title":"<code>ElasticsearchRetrieverInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input schema for Elasticsearch retriever.</p> <p>Attributes:</p> Name Type Description <code>query_embedding</code> <code>list[float]</code> <p>Vector query for similarity search.</p> <code>filters</code> <code>dict[str, Any]</code> <p>Filters to apply for retrieving specific documents. Defaults to an empty dictionary.</p> <code>top_k</code> <code>int</code> <p>Number of documents to retrieve. Defaults to 0.</p> <code>exclude_document_embeddings</code> <code>bool</code> <p>Whether to exclude embeddings in the response. Defaults to True.</p> <code>scale_scores</code> <code>bool</code> <p>Whether to scale scores to the 0-1 range. Defaults to False.</p> <code>content_key</code> <code>str</code> <p>Key to use for content in the response. Defaults to \"content\".</p> <code>embedding_key</code> <code>str</code> <p>Key to use for embedding in the response. Defaults to \"embedding\".</p> Source code in <code>dynamiq/nodes/retrievers/elasticsearch.py</code> <pre><code>class ElasticsearchRetrieverInputSchema(BaseModel):\n    \"\"\"\n    Input schema for Elasticsearch retriever.\n\n    Attributes:\n        query_embedding (list[float]): Vector query for similarity search.\n        filters (dict[str, Any]): Filters to apply for retrieving specific documents. Defaults to an empty dictionary.\n        top_k (int): Number of documents to retrieve. Defaults to 0.\n        exclude_document_embeddings (bool): Whether to exclude embeddings in the response. Defaults to True.\n        scale_scores (bool): Whether to scale scores to the 0-1 range. Defaults to False.\n        content_key (str): Key to use for content in the response. Defaults to \"content\".\n        embedding_key (str): Key to use for embedding in the response. Defaults to \"embedding\".\n    \"\"\"\n\n    query_embedding: list[float] = Field(..., description=\"Vector query for similarity search\")\n    filters: dict[str, Any] = Field(default={}, description=\"Filters to apply for retrieving specific documents\")\n    top_k: int = Field(default=0, description=\"Number of documents to retrieve\")\n    exclude_document_embeddings: bool = Field(default=True, description=\"Whether to exclude embeddings in response\")\n    scale_scores: bool = Field(default=False, description=\"Whether to scale scores to 0-1 range\")\n    content_key: str = Field(default=\"content\", description=\"Key to use for content in response\")\n    embedding_key: str = Field(default=\"embedding\", description=\"Key to use for embedding in response\")\n    similarity_threshold: float | None = Field(\n        default=None,\n        description=\"Minimal similarity or maximal distance score accepted for retrieved documents.\",\n    )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/milvus/","title":"Milvus","text":""},{"location":"dynamiq/nodes/retrievers/milvus/#dynamiq.nodes.retrievers.milvus.MilvusDocumentRetriever","title":"<code>MilvusDocumentRetriever</code>","text":"<p>               Bases: <code>Retriever</code>, <code>MilvusVectorStoreParams</code></p> <p>Document Retriever using Milvus.</p> <p>This class implements a document retriever that uses Milvus as the underlying vector store. It extends the VectorStoreNode class and provides functionality to retrieve documents based on vector similarity.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RETRIEVERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>vector_store</code> <code>MilvusVectorStore | None</code> <p>The MilvusVectorStore instance.</p> <code>filters</code> <code>dict[str, Any] | None</code> <p>Filters to apply when retrieving documents.</p> <code>top_k</code> <code>int</code> <p>The maximum number of documents to retrieve.</p> <code>document_retriever</code> <code>MilvusDocumentRetriever</code> <p>The document retriever component.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for initializing the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/milvus.py</code> <pre><code>class MilvusDocumentRetriever(Retriever, MilvusVectorStoreParams):\n    \"\"\"\n    Document Retriever using Milvus.\n\n    This class implements a document retriever that uses Milvus as the underlying vector store.\n    It extends the VectorStoreNode class and provides functionality to retrieve documents\n    based on vector similarity.\n\n    Attributes:\n        group (Literal[NodeGroup.RETRIEVERS]): The group the node belongs to.\n        name (str): The name of the node.\n        vector_store (MilvusVectorStore | None): The MilvusVectorStore instance.\n        filters (dict[str, Any] | None): Filters to apply when retrieving documents.\n        top_k (int): The maximum number of documents to retrieve.\n        document_retriever (MilvusDocumentRetrieverComponent): The document retriever component.\n\n    Args:\n        **kwargs: Keyword arguments for initializing the node.\n    \"\"\"\n\n    name: str = \"MilvusDocumentRetriever\"\n    connection: Milvus | None = None\n    vector_store: MilvusVectorStore | None = None\n    document_retriever: MilvusDocumentRetrieverComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the MilvusDocumentRetriever.\n\n        If neither vector_store nor connection is provided in kwargs, a default Milvus connection will be created.\n\n        Args:\n            **kwargs: Keyword arguments for initializing the node.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Milvus()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return MilvusVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(MilvusVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the MilvusDocumentRetriever.\n\n        This method sets up the document retriever component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_retriever is None:\n            self.document_retriever = MilvusDocumentRetrieverComponent(\n                vector_store=self.vector_store,\n                filters=self.filters,\n                top_k=self.top_k,\n                similarity_threshold=self.similarity_threshold,\n            )\n\n    def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the document retrieval process.\n\n        This method takes an input embedding, retrieves similar documents using the\n        document retriever component, and returns the retrieved documents.\n\n        Args:\n            input_data (RetrieverInputSchema): The input data containing the query embedding.\n            config (RunnableConfig, optional): The configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the retrieved documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query_embedding = input_data.embedding\n        query = input_data.query\n        content_key = input_data.content_key\n        embedding_key = input_data.embedding_key\n        filters = input_data.filters or self.filters\n        top_k = input_data.top_k or self.top_k\n        similarity_threshold = (\n            input_data.similarity_threshold\n            if input_data.similarity_threshold is not None\n            else self.similarity_threshold\n        )\n\n        output = self.document_retriever.run(\n            query_embedding,\n            query=query,\n            filters=filters,\n            top_k=top_k,\n            content_key=content_key,\n            embedding_key=embedding_key,\n            similarity_threshold=similarity_threshold,\n        )\n\n        return {\n            \"documents\": output[\"documents\"],\n        }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/milvus/#dynamiq.nodes.retrievers.milvus.MilvusDocumentRetriever.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the MilvusDocumentRetriever.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Milvus connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for initializing the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/milvus.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the MilvusDocumentRetriever.\n\n    If neither vector_store nor connection is provided in kwargs, a default Milvus connection will be created.\n\n    Args:\n        **kwargs: Keyword arguments for initializing the node.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Milvus()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/milvus/#dynamiq.nodes.retrievers.milvus.MilvusDocumentRetriever.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document retrieval process.</p> <p>This method takes an input embedding, retrieves similar documents using the document retriever component, and returns the retrieved documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>RetrieverInputSchema</code> <p>The input data containing the query embedding.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the retrieved documents.</p> Source code in <code>dynamiq/nodes/retrievers/milvus.py</code> <pre><code>def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the document retrieval process.\n\n    This method takes an input embedding, retrieves similar documents using the\n    document retriever component, and returns the retrieved documents.\n\n    Args:\n        input_data (RetrieverInputSchema): The input data containing the query embedding.\n        config (RunnableConfig, optional): The configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the retrieved documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    query_embedding = input_data.embedding\n    query = input_data.query\n    content_key = input_data.content_key\n    embedding_key = input_data.embedding_key\n    filters = input_data.filters or self.filters\n    top_k = input_data.top_k or self.top_k\n    similarity_threshold = (\n        input_data.similarity_threshold\n        if input_data.similarity_threshold is not None\n        else self.similarity_threshold\n    )\n\n    output = self.document_retriever.run(\n        query_embedding,\n        query=query,\n        filters=filters,\n        top_k=top_k,\n        content_key=content_key,\n        embedding_key=embedding_key,\n        similarity_threshold=similarity_threshold,\n    )\n\n    return {\n        \"documents\": output[\"documents\"],\n    }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/milvus/#dynamiq.nodes.retrievers.milvus.MilvusDocumentRetriever.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the MilvusDocumentRetriever.</p> <p>This method sets up the document retriever component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/retrievers/milvus.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the MilvusDocumentRetriever.\n\n    This method sets up the document retriever component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_retriever is None:\n        self.document_retriever = MilvusDocumentRetrieverComponent(\n            vector_store=self.vector_store,\n            filters=self.filters,\n            top_k=self.top_k,\n            similarity_threshold=self.similarity_threshold,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/pgvector/","title":"Pgvector","text":""},{"location":"dynamiq/nodes/retrievers/pgvector/#dynamiq.nodes.retrievers.pgvector.PGVectorDocumentRetriever","title":"<code>PGVectorDocumentRetriever</code>","text":"<p>               Bases: <code>Retriever</code>, <code>PGVectorStoreRetrieverParams</code></p> <p>Document Retriever using PGVector.</p> <p>This class implements a document retriever that uses PGVector as the underlying vector store. It extends the VectorStoreNode class and provides functionality to retrieve documents based on vector similarity.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RETRIEVERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>vector_store</code> <code>PGVectorStore | None</code> <p>The PGVectorStore instance.</p> <code>filters</code> <code>dict[str, Any] | None</code> <p>Filters to apply when retrieving documents.</p> <code>top_k</code> <code>int</code> <p>The maximum number of documents to retrieve.</p> <code>document_retriever</code> <code>PGVectorDocumentRetriever</code> <p>The document retriever component.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for initializing the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/pgvector.py</code> <pre><code>class PGVectorDocumentRetriever(Retriever, PGVectorStoreRetrieverParams):\n    \"\"\"\n    Document Retriever using PGVector.\n\n    This class implements a document retriever that uses PGVector as the underlying vector store.\n    It extends the VectorStoreNode class and provides functionality to retrieve documents\n    based on vector similarity.\n\n    Attributes:\n        group (Literal[NodeGroup.RETRIEVERS]): The group the node belongs to.\n        name (str): The name of the node.\n        vector_store (PGVectorStore | None): The PGVectorStore instance.\n        filters (dict[str, Any] | None): Filters to apply when retrieving documents.\n        top_k (int): The maximum number of documents to retrieve.\n        document_retriever (PGVectorDocumentRetrieverComponent): The document retriever component.\n\n    Args:\n        **kwargs: Keyword arguments for initializing the node.\n    \"\"\"\n\n    name: str = \"PGVectorDocumentRetriever\"\n    connection: PostgreSQL | None = None\n    vector_store: PGVectorStore | None = None\n    document_retriever: PGVectorDocumentRetrieverComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the PGVectorDocumentRetriever.\n\n        If neither vector_store nor connection is provided in kwargs, a default PostgreSQL connection will be created.\n\n        Args:\n            **kwargs: Keyword arguments for initializing the node.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = PostgreSQL()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return PGVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(PGVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"document_retriever\": True}\n\n    def init_components(self, connection_manager: ConnectionManager = ConnectionManager()):\n        \"\"\"\n        Initialize the components of the PGVectorDocumentRetriever.\n\n        This method sets up the document retriever component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        super().init_components(connection_manager)\n        if self.document_retriever is None:\n            self.document_retriever = PGVectorDocumentRetrieverComponent(\n                vector_store=self.vector_store,\n                filters=self.filters,\n                top_k=self.top_k,\n                similarity_threshold=self.similarity_threshold,\n            )\n\n    def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the document retrieval process.\n\n        This method takes an input embedding, retrieves similar documents using the\n        document retriever component, and returns the retrieved documents.\n\n        Args:\n            input_data (RetrieverInputSchema): The input data containing the query embedding.\n            config (RunnableConfig, optional): The configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the retrieved documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query_embedding = input_data.embedding\n        content_key = input_data.content_key\n        embedding_key = input_data.embedding_key\n        filters = input_data.filters or self.filters\n        top_k = input_data.top_k or self.top_k\n        similarity_threshold = (\n            input_data.similarity_threshold\n            if input_data.similarity_threshold is not None\n            else self.similarity_threshold\n        )\n\n        alpha = input_data.alpha or self.alpha\n        query = input_data.query\n\n        output = self.document_retriever.run(\n            query_embedding,\n            filters=filters,\n            top_k=top_k,\n            content_key=content_key,\n            embedding_key=embedding_key,\n            query=query,\n            alpha=alpha,\n            similarity_threshold=similarity_threshold,\n        )\n\n        return {\n            \"documents\": output[\"documents\"],\n        }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/pgvector/#dynamiq.nodes.retrievers.pgvector.PGVectorDocumentRetriever.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the PGVectorDocumentRetriever.</p> <p>If neither vector_store nor connection is provided in kwargs, a default PostgreSQL connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for initializing the node.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/pgvector.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the PGVectorDocumentRetriever.\n\n    If neither vector_store nor connection is provided in kwargs, a default PostgreSQL connection will be created.\n\n    Args:\n        **kwargs: Keyword arguments for initializing the node.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = PostgreSQL()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/pgvector/#dynamiq.nodes.retrievers.pgvector.PGVectorDocumentRetriever.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document retrieval process.</p> <p>This method takes an input embedding, retrieves similar documents using the document retriever component, and returns the retrieved documents.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>RetrieverInputSchema</code> <p>The input data containing the query embedding.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the retrieved documents.</p> Source code in <code>dynamiq/nodes/retrievers/pgvector.py</code> <pre><code>def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the document retrieval process.\n\n    This method takes an input embedding, retrieves similar documents using the\n    document retriever component, and returns the retrieved documents.\n\n    Args:\n        input_data (RetrieverInputSchema): The input data containing the query embedding.\n        config (RunnableConfig, optional): The configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the retrieved documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    query_embedding = input_data.embedding\n    content_key = input_data.content_key\n    embedding_key = input_data.embedding_key\n    filters = input_data.filters or self.filters\n    top_k = input_data.top_k or self.top_k\n    similarity_threshold = (\n        input_data.similarity_threshold\n        if input_data.similarity_threshold is not None\n        else self.similarity_threshold\n    )\n\n    alpha = input_data.alpha or self.alpha\n    query = input_data.query\n\n    output = self.document_retriever.run(\n        query_embedding,\n        filters=filters,\n        top_k=top_k,\n        content_key=content_key,\n        embedding_key=embedding_key,\n        query=query,\n        alpha=alpha,\n        similarity_threshold=similarity_threshold,\n    )\n\n    return {\n        \"documents\": output[\"documents\"],\n    }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/pgvector/#dynamiq.nodes.retrievers.pgvector.PGVectorDocumentRetriever.init_components","title":"<code>init_components(connection_manager=ConnectionManager())</code>","text":"<p>Initialize the components of the PGVectorDocumentRetriever.</p> <p>This method sets up the document retriever component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>ConnectionManager()</code> Source code in <code>dynamiq/nodes/retrievers/pgvector.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager = ConnectionManager()):\n    \"\"\"\n    Initialize the components of the PGVectorDocumentRetriever.\n\n    This method sets up the document retriever component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    super().init_components(connection_manager)\n    if self.document_retriever is None:\n        self.document_retriever = PGVectorDocumentRetrieverComponent(\n            vector_store=self.vector_store,\n            filters=self.filters,\n            top_k=self.top_k,\n            similarity_threshold=self.similarity_threshold,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/pinecone/","title":"Pinecone","text":""},{"location":"dynamiq/nodes/retrievers/pinecone/#dynamiq.nodes.retrievers.pinecone.PineconeDocumentRetriever","title":"<code>PineconeDocumentRetriever</code>","text":"<p>               Bases: <code>Retriever</code>, <code>PineconeVectorStoreParams</code></p> <p>Document Retriever using Pinecone.</p> <p>This class implements a document retriever that uses Pinecone as the vector store backend.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RETRIEVERS]</code> <p>The group of the node.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>vector_store</code> <code>PineconeVectorStore | None</code> <p>The Pinecone vector store.</p> <code>filters</code> <code>dict[str, Any] | None</code> <p>Filters to apply for retrieving specific documents.</p> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return.</p> <code>document_retriever</code> <code>PineconeDocumentRetriever</code> <p>The document retriever component.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/pinecone.py</code> <pre><code>class PineconeDocumentRetriever(Retriever, PineconeVectorStoreParams):\n    \"\"\"Document Retriever using Pinecone.\n\n    This class implements a document retriever that uses Pinecone as the vector store backend.\n\n    Attributes:\n        group (Literal[NodeGroup.RETRIEVERS]): The group of the node.\n        name (str): The name of the node.\n        vector_store (PineconeVectorStore | None): The Pinecone vector store.\n        filters (dict[str, Any] | None): Filters to apply for retrieving specific documents.\n        top_k (int): The maximum number of documents to return.\n        document_retriever (PineconeDocumentRetrieverComponent): The document retriever component.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n\n    name: str = \"PineconeDocumentRetriever\"\n    connection: Pinecone | None = None\n    vector_store: PineconeVectorStore | None = None\n    document_retriever: PineconeDocumentRetrieverComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the PineconeDocumentRetriever.\n\n        If neither vector_store nor connection is provided in kwargs, a default Pinecone connection will be created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Pinecone()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return PineconeVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(PineconeVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the PineconeDocumentRetriever.\n\n        This method sets up the document retriever component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_retriever is None:\n            self.document_retriever = PineconeDocumentRetrieverComponent(\n                vector_store=self.vector_store,\n                filters=self.filters,\n                top_k=self.top_k,\n                similarity_threshold=self.similarity_threshold,\n            )\n\n    def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the document retrieval process.\n\n        This method retrieves documents based on the input embedding.\n\n        Args:\n            input_data (RetrieverInputSchema): The input data containing the query embedding.\n            config (RunnableConfig, optional): The configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the retrieved documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query_embedding = input_data.embedding\n        content_key = input_data.content_key\n        filters = input_data.filters or self.filters\n        top_k = input_data.top_k or self.top_k\n        similarity_threshold = (\n            input_data.similarity_threshold\n            if input_data.similarity_threshold is not None\n            else self.similarity_threshold\n        )\n\n        output = self.document_retriever.run(\n            query_embedding,\n            filters=filters,\n            top_k=top_k,\n            content_key=content_key,\n            similarity_threshold=similarity_threshold,\n        )\n\n        return {\n            \"documents\": output[\"documents\"],\n        }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/pinecone/#dynamiq.nodes.retrievers.pinecone.PineconeDocumentRetriever.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the PineconeDocumentRetriever.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Pinecone connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/pinecone.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the PineconeDocumentRetriever.\n\n    If neither vector_store nor connection is provided in kwargs, a default Pinecone connection will be created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Pinecone()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/pinecone/#dynamiq.nodes.retrievers.pinecone.PineconeDocumentRetriever.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document retrieval process.</p> <p>This method retrieves documents based on the input embedding.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>RetrieverInputSchema</code> <p>The input data containing the query embedding.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the retrieved documents.</p> Source code in <code>dynamiq/nodes/retrievers/pinecone.py</code> <pre><code>def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the document retrieval process.\n\n    This method retrieves documents based on the input embedding.\n\n    Args:\n        input_data (RetrieverInputSchema): The input data containing the query embedding.\n        config (RunnableConfig, optional): The configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the retrieved documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    query_embedding = input_data.embedding\n    content_key = input_data.content_key\n    filters = input_data.filters or self.filters\n    top_k = input_data.top_k or self.top_k\n    similarity_threshold = (\n        input_data.similarity_threshold\n        if input_data.similarity_threshold is not None\n        else self.similarity_threshold\n    )\n\n    output = self.document_retriever.run(\n        query_embedding,\n        filters=filters,\n        top_k=top_k,\n        content_key=content_key,\n        similarity_threshold=similarity_threshold,\n    )\n\n    return {\n        \"documents\": output[\"documents\"],\n    }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/pinecone/#dynamiq.nodes.retrievers.pinecone.PineconeDocumentRetriever.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the PineconeDocumentRetriever.</p> <p>This method sets up the document retriever component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/retrievers/pinecone.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the PineconeDocumentRetriever.\n\n    This method sets up the document retriever component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_retriever is None:\n        self.document_retriever = PineconeDocumentRetrieverComponent(\n            vector_store=self.vector_store,\n            filters=self.filters,\n            top_k=self.top_k,\n            similarity_threshold=self.similarity_threshold,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/qdrant/","title":"Qdrant","text":""},{"location":"dynamiq/nodes/retrievers/qdrant/#dynamiq.nodes.retrievers.qdrant.QdrantDocumentRetriever","title":"<code>QdrantDocumentRetriever</code>","text":"<p>               Bases: <code>Retriever</code></p> <p>Document Retriever using Qdrant.</p> <p>This class implements a document retriever that uses Qdrant as the vector store backend.</p> <p>Parameters:</p> Name Type Description Default <code>vector_store</code> <code>QdrantVectorStore</code> <p>An instance of QdrantVectorStore to interface with Qdrant vectors.</p> required <code>filters</code> <code>dict[str, Any]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> required <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to 10.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RETRIEVERS]</code> <p>The group of the node.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>vector_store</code> <code>QdrantVectorStore | None</code> <p>The QdrantVectorStore instance.</p> <code>filters</code> <code>dict[str, Any] | None</code> <p>Filters for document retrieval.</p> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return.</p> <code>document_retriever</code> <code>QdrantDocumentRetriever</code> <p>The document retriever component.</p> Source code in <code>dynamiq/nodes/retrievers/qdrant.py</code> <pre><code>class QdrantDocumentRetriever(Retriever):\n    \"\"\"Document Retriever using Qdrant.\n\n    This class implements a document retriever that uses Qdrant as the vector store backend.\n\n    Args:\n        vector_store (QdrantVectorStore, optional): An instance of QdrantVectorStore to interface\n            with Qdrant vectors.\n        filters (dict[str, Any], optional): Filters to apply for retrieving specific documents.\n            Defaults to None.\n        top_k (int, optional): The maximum number of documents to return. Defaults to 10.\n\n    Attributes:\n        group (Literal[NodeGroup.RETRIEVERS]): The group of the node.\n        name (str): The name of the node.\n        vector_store (QdrantVectorStore | None): The QdrantVectorStore instance.\n        filters (dict[str, Any] | None): Filters for document retrieval.\n        top_k (int): The maximum number of documents to return.\n        document_retriever (QdrantDocumentRetrieverComponent): The document retriever component.\n    \"\"\"\n\n    name: str = \"QdrantDocumentRetriever\"\n    connection: Qdrant | None = None\n    vector_store: QdrantVectorStore | None = None\n    document_retriever: QdrantDocumentRetrieverComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the QdrantDocumentRetriever.\n\n        If neither vector_store nor connection is provided in kwargs, a default Qdrant connection will be created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the retriever.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Qdrant()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return QdrantVectorStore\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the retriever.\n\n        This method sets up the document retriever component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_retriever is None:\n            self.document_retriever = QdrantDocumentRetrieverComponent(\n                vector_store=self.vector_store,\n                filters=self.filters,\n                top_k=self.top_k,\n                similarity_threshold=self.similarity_threshold,\n            )\n\n    def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the document retrieval process.\n\n        This method retrieves documents based on the input embedding.\n\n        Args:\n            input_data (RetrieverInputSchema): The input data containing the query embedding.\n            config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the retrieved documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query_embedding = input_data.embedding\n        content_key = input_data.content_key\n        filters = input_data.filters or self.filters\n        top_k = input_data.top_k or self.top_k\n        similarity_threshold = (\n            input_data.similarity_threshold\n            if input_data.similarity_threshold is not None\n            else self.similarity_threshold\n        )\n\n        output = self.document_retriever.run(\n            query_embedding,\n            filters=filters,\n            top_k=top_k,\n            content_key=content_key,\n            similarity_threshold=similarity_threshold,\n        )\n\n        return {\n            \"documents\": output[\"documents\"],\n        }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/qdrant/#dynamiq.nodes.retrievers.qdrant.QdrantDocumentRetriever.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the QdrantDocumentRetriever.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Qdrant connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the retriever.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/qdrant.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the QdrantDocumentRetriever.\n\n    If neither vector_store nor connection is provided in kwargs, a default Qdrant connection will be created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the retriever.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Qdrant()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/qdrant/#dynamiq.nodes.retrievers.qdrant.QdrantDocumentRetriever.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document retrieval process.</p> <p>This method retrieves documents based on the input embedding.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>RetrieverInputSchema</code> <p>The input data containing the query embedding.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the retrieved documents.</p> Source code in <code>dynamiq/nodes/retrievers/qdrant.py</code> <pre><code>def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the document retrieval process.\n\n    This method retrieves documents based on the input embedding.\n\n    Args:\n        input_data (RetrieverInputSchema): The input data containing the query embedding.\n        config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the retrieved documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    query_embedding = input_data.embedding\n    content_key = input_data.content_key\n    filters = input_data.filters or self.filters\n    top_k = input_data.top_k or self.top_k\n    similarity_threshold = (\n        input_data.similarity_threshold\n        if input_data.similarity_threshold is not None\n        else self.similarity_threshold\n    )\n\n    output = self.document_retriever.run(\n        query_embedding,\n        filters=filters,\n        top_k=top_k,\n        content_key=content_key,\n        similarity_threshold=similarity_threshold,\n    )\n\n    return {\n        \"documents\": output[\"documents\"],\n    }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/qdrant/#dynamiq.nodes.retrievers.qdrant.QdrantDocumentRetriever.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the retriever.</p> <p>This method sets up the document retriever component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/retrievers/qdrant.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the retriever.\n\n    This method sets up the document retriever component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_retriever is None:\n        self.document_retriever = QdrantDocumentRetrieverComponent(\n            vector_store=self.vector_store,\n            filters=self.filters,\n            top_k=self.top_k,\n            similarity_threshold=self.similarity_threshold,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/retriever/","title":"Retriever","text":""},{"location":"dynamiq/nodes/retrievers/retriever/#dynamiq.nodes.retrievers.retriever.VectorStoreRetriever","title":"<code>VectorStoreRetriever</code>","text":"<p>               Bases: <code>Node</code></p> <p>Node for retrieving relevant documents based on a query.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>Group for the node. Defaults to NodeGroup.TOOLS.</p> <code>name</code> <code>str</code> <p>Name of the tool. Defaults to \"Retrieval Tool\".</p> <code>description</code> <code>str</code> <p>Description of the tool.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Error handling configuration.</p> <code>text_embedder</code> <code>TextEmbedder</code> <p>Text embedder node.</p> <code>document_retriever</code> <code>Retriever</code> <p>Document retriever node.</p> <code>filters</code> <code>dict[str, Any] | None</code> <p>Filters for document retrieval.</p> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return.</p> <code>alpha</code> <code>float</code> <p>The alpha parameter for hybrid retrieval.</p> Source code in <code>dynamiq/nodes/retrievers/retriever.py</code> <pre><code>class VectorStoreRetriever(Node):\n    \"\"\"Node for retrieving relevant documents based on a query.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): Group for the node. Defaults to NodeGroup.TOOLS.\n        name (str): Name of the tool. Defaults to \"Retrieval Tool\".\n        description (str): Description of the tool.\n        error_handling (ErrorHandling): Error handling configuration.\n        text_embedder (TextEmbedder): Text embedder node.\n        document_retriever (Retriever): Document retriever node.\n        filters (dict[str, Any] | None): Filters for document retrieval.\n        top_k (int): The maximum number of documents to return.\n        alpha (float): The alpha parameter for hybrid retrieval.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"VectorStore Retriever\"\n    description: str = \"A node for retrieving relevant documents based on a query.\"\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=600))\n    text_embedder: TextEmbedder\n    document_retriever: Retriever\n    filters: dict[str, Any] = {}\n    top_k: int | None = None\n    alpha: float = 0.0\n    similarity_threshold: float | None = None\n\n    input_schema: ClassVar[type[VectorStoreRetrieverInputSchema]] = VectorStoreRetrieverInputSchema\n    _EXCLUDED_METADATA_FIELDS: ClassVar[tuple[str, ...]] = (\n        \"embedding\",\n        \"embeddings\",\n        \"vector\",\n        \"vectors\",\n    )\n    _EXCLUDED_METADATA_TOKENS: ClassVar[tuple[str, ...]] = (\"id\", \"hash\")\n    _EXPECTED_METADATA_KEYWORDS: ClassVar[tuple[str, ...]] = (\"url\", \"link\", \"source\", \"file\", \"title\")\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initializes the VectorStoreRetriever with the given parameters.\n\n        Args:\n            **kwargs: Additional keyword arguments to be passed to the parent class constructor.\n        \"\"\"\n        super().__init__(**kwargs)\n        self._run_depends = []\n\n    def reset_run_state(self):\n        \"\"\"\n        Reset the intermediate steps (run_depends) of the node.\n        \"\"\"\n        self._run_depends = []\n\n    def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n        \"\"\"\n        Initialize the components of the tool.\n\n        Args:\n            connection_manager (ConnectionManager, optional): connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.text_embedder.is_postponed_component_init:\n            self.text_embedder.init_components(connection_manager)\n        if self.document_retriever.is_postponed_component_init:\n            self.document_retriever.init_components(connection_manager)\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"\n        Property to define which parameters should be excluded when converting the class instance to a dictionary.\n\n        Returns:\n            dict: A dictionary defining the parameters to exclude.\n        \"\"\"\n        return super().to_dict_exclude_params | {\"text_embedder\": True, \"document_retriever\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"text_embedder\"] = self.text_embedder.to_dict(**kwargs)\n        data[\"document_retriever\"] = self.document_retriever.to_dict(**kwargs)\n        return data\n\n    def format_content(self, documents: list[Document], metadata_fields: list[str] | None = None) -&gt; str:\n        \"\"\"Format the retrieved documents' metadata and content.\n\n        Args:\n            documents (list[Document]): List of retrieved documents.\n            metadata_fields (list[str]): Metadata fields to include. If None, uses all metadata except embeddings.\n\n        Returns:\n            str: Formatted content of the documents.\n        \"\"\"\n        formatted_docs: list[str] = []\n\n        normalized_metadata_fields: list[str] | None = None\n        include_score = False\n        if metadata_fields is not None:\n            seen_fields: set[str] = set()\n            cleaned_fields: list[str] = []\n            for field in metadata_fields:\n                stripped = field.strip() if field else \"\"\n                if not stripped:\n                    continue\n                lowered = stripped.lower()\n                if lowered in seen_fields:\n                    continue\n                if lowered == \"score\":\n                    include_score = True\n                    seen_fields.add(lowered)\n                    continue\n                seen_fields.add(lowered)\n                cleaned_fields.append(stripped)\n\n            if cleaned_fields:\n                normalized_metadata_fields = cleaned_fields\n            elif include_score:\n                normalized_metadata_fields = []\n\n        for index, doc in enumerate(documents):\n            metadata = doc.metadata or {}\n            metadata_lines: list[str] = []\n\n            if normalized_metadata_fields is not None:\n                if include_score and doc.score is not None:\n                    metadata_lines.append(self._format_metadata_line(\"Score\", doc.score))\n            else:\n                if doc.score is not None:\n                    metadata_lines.append(self._format_metadata_line(\"Score\", doc.score))\n\n            metadata_lines.extend(self._generate_metadata_lines(metadata, normalized_metadata_fields))\n\n            metadata_block = \"\\n\\n\".join(metadata_lines) if metadata_lines else \"No metadata available.\"\n            content_block = doc.content or \"\"\n\n            formatted_doc = (\n                f\"\\n\\n== Source {index + 1} ==\\n\\n\"\n                f\"\\n\\n== Metadata ==\\n{metadata_block}\\n\\n\"\n                f\"\\n\\n== Content (Source {index + 1}) ==\\n\\n{content_block}\"\n            ).rstrip()\n            formatted_docs.append(formatted_doc)\n\n        return \"\\n\\n\".join(formatted_docs)\n\n    @staticmethod\n    def _prettify_field_name(field_name: str) -&gt; str:\n        if not field_name:\n            return field_name\n\n        cleaned = field_name.replace(\"_\", \" \").strip()\n        lowered = cleaned.lower()\n        if lowered.startswith(\"dynamiq\"):\n            cleaned = cleaned[len(\"dynamiq\") :].lstrip(\" -_/\")\n\n        prettified = cleaned.strip().title()\n        return prettified or field_name\n\n    @classmethod\n    def _format_metadata_line(cls, field: str, value: Any) -&gt; str:\n        formatted_value = cls._stringify_metadata_value(value)\n        return f\"{field}: {formatted_value}\"\n\n    @classmethod\n    def _stringify_metadata_value(cls, value: Any) -&gt; str:\n        if isinstance(value, (dict, list)):\n            try:\n                serialized = json.dumps(value, indent=2, sort_keys=True)\n                return cls._postprocess_metadata_string(serialized)\n            except (TypeError, ValueError):\n                return cls._postprocess_metadata_string(str(value))\n        return cls._postprocess_metadata_string(str(value))\n\n    @staticmethod\n    def _postprocess_metadata_string(value: str) -&gt; str:\n        if not value:\n            return value\n\n        if value.lower().startswith(\"dynamiq\"):\n            trimmed = value[7:]\n            return trimmed.lstrip(\"/\\\\ \")\n        return value\n\n    def _resolve_metadata_path(\n        self,\n        metadata: dict[str, Any],\n        field: str,\n    ) -&gt; tuple[Any | None, list[str]]:\n        if not metadata:\n            return None, []\n\n        parts = field.split(\".\")\n        current: Any = metadata\n        actual_path: list[str] = []\n\n        for part in parts:\n            if not isinstance(current, dict):\n                return None, []\n\n            matching_key = next((key for key in current.keys() if key.lower() == part.lower()), None)\n            if matching_key is None:\n                return None, []\n\n            actual_path.append(matching_key)\n            current = current[matching_key]\n\n        return current, actual_path\n\n    def _iter_metadata_entries(\n        self,\n        metadata: dict[str, Any],\n        requested_fields: list[str] | None,\n    ) -&gt; Iterator[tuple[list[str], list[str], Any]]:\n        if not metadata:\n            return\n\n        if requested_fields is None:\n            for key, value in metadata.items():\n                if self._should_exclude_metadata_key(key):\n                    continue\n                yield from self._flatten_metadata(value, [self._prettify_field_name(key)], [key])\n            return\n\n        for field in requested_fields:\n            value, path = self._resolve_metadata_path(metadata, field)\n            if not path:\n                continue\n\n            if any(self._should_exclude_metadata_key(part) for part in path):\n                continue\n\n            label_parts = [self._prettify_field_name(part) for part in path]\n            yield from self._flatten_metadata(value, label_parts, path)\n\n    def _flatten_metadata(\n        self,\n        value: Any,\n        label_parts: list[str],\n        raw_parts: list[str],\n    ) -&gt; Iterator[tuple[list[str], list[str], Any]]:\n        if isinstance(value, dict):\n            for key, nested_value in value.items():\n                if self._should_exclude_metadata_key(key):\n                    continue\n                yield from self._flatten_metadata(\n                    nested_value,\n                    label_parts + [self._prettify_field_name(key)],\n                    raw_parts + [key],\n                )\n            return\n\n        yield (label_parts or [\"Metadata\"]), raw_parts, value\n\n    def _generate_metadata_lines(\n        self,\n        metadata: dict[str, Any],\n        requested_fields: list[str] | None,\n    ) -&gt; list[str]:\n        if not metadata:\n            return []\n\n        base_entries = list(self._iter_metadata_entries(metadata, requested_fields))\n\n        expected_source_entries = (\n            base_entries if requested_fields is None else list(self._iter_metadata_entries(metadata, None))\n        )\n\n        expected_entries: list[tuple[list[str], list[str], Any]] = []\n        expected_paths: set[tuple[str, ...]] = set()\n        for display_parts, raw_parts, value in expected_source_entries:\n            if not self._contains_expected_keyword(raw_parts):\n                continue\n            path_key = self._normalize_raw_path(raw_parts)\n            if path_key in expected_paths:\n                continue\n            expected_entries.append((display_parts, raw_parts, value))\n            expected_paths.add(path_key)\n\n        seen_paths: set[tuple[str, ...]] = set()\n        lines_by_path: dict[tuple[str, ...], str] = {}\n        general_lines: list[str] = []\n\n        for display_parts, raw_parts, value in base_entries:\n            path_key = self._normalize_raw_path(raw_parts)\n            if path_key in seen_paths:\n                continue\n            seen_paths.add(path_key)\n            line = self._format_metadata_line(\" - \".join(display_parts), value)\n            lines_by_path[path_key] = line\n            if path_key not in expected_paths:\n                general_lines.append(line)\n\n        expected_lines: list[str] = []\n        for display_parts, raw_parts, value in expected_entries:\n            path_key = self._normalize_raw_path(raw_parts)\n            if path_key not in seen_paths:\n                line = self._format_metadata_line(\" - \".join(display_parts), value)\n                lines_by_path[path_key] = line\n                seen_paths.add(path_key)\n            expected_lines.append(lines_by_path[path_key])\n\n        return general_lines + expected_lines\n\n    @staticmethod\n    def _normalize_raw_path(raw_parts: list[str]) -&gt; tuple[str, ...]:\n        return tuple(part.lower() for part in raw_parts)\n\n    @classmethod\n    def _should_exclude_metadata_key(cls, key: str) -&gt; bool:\n        if not key:\n            return False\n\n        lowered_key = key.lower()\n        if lowered_key in cls._EXCLUDED_METADATA_FIELDS:\n            return True\n\n        tokens = cls._tokenize_metadata_key(key)\n        return any(token in cls._EXCLUDED_METADATA_TOKENS for token in tokens)\n\n    @classmethod\n    def _contains_expected_keyword(cls, raw_parts: list[str]) -&gt; bool:\n        for part in raw_parts:\n            tokens = cls._tokenize_metadata_key(part)\n            if any(token in cls._EXPECTED_METADATA_KEYWORDS for token in tokens):\n                return True\n        return False\n\n    @staticmethod\n    def _tokenize_metadata_key(key: str) -&gt; list[str]:\n        if not key:\n            return []\n\n        normalized = re.sub(r\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", key)\n        normalized = re.sub(r\"[^0-9a-zA-Z]+\", \"_\", normalized)\n        return [token for token in normalized.lower().split(\"_\") if token]\n\n    def execute(\n        self, input_data: VectorStoreRetrieverInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"Execute the retrieval tool.\n\n        Args:\n            input_data (dict[str, Any]): Input data for the tool.\n            config (RunnableConfig, optional): Configuration for the runnable, including callbacks.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: Result of the retrieval.\n        \"\"\"\n\n        logger.info(f\"Tool {self.name} - {self.id}: started with INPUT DATA:\\n{input_data.model_dump()}\")\n        config = ensure_config(config)\n        self.reset_run_state()\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        filters = input_data.filters or self.filters\n        top_k = input_data.top_k or self.top_k\n        similarity_threshold = (\n            input_data.similarity_threshold\n            if input_data.similarity_threshold is not None\n            else self.similarity_threshold\n        )\n\n        alpha = input_data.alpha or self.alpha\n        query = input_data.query\n        try:\n            kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n            kwargs.pop(\"run_depends\", None)\n            text_embedder_output = self.text_embedder.run(\n                input_data={\"query\": query}, run_depends=self._run_depends, config=config, **kwargs\n            )\n            self._run_depends = [NodeDependency(node=self.text_embedder).to_dict(for_tracing=True)]\n            embedding = text_embedder_output.output.get(\"embedding\")\n\n            document_retriever_output = self.document_retriever.run(\n                input_data={\n                    \"embedding\": embedding,\n                    **({\"top_k\": top_k} if top_k else {}),\n                    \"filters\": filters,\n                    \"alpha\": alpha,\n                    **({\"query\": query} if alpha else {}),\n                    **({\"similarity_threshold\": similarity_threshold} if similarity_threshold is not None else {}),\n                },\n                run_depends=self._run_depends,\n                config=config,\n                **kwargs,\n            )\n            self._run_depends = [NodeDependency(node=self.document_retriever).to_dict(for_tracing=True)]\n            retrieved_documents = document_retriever_output.output.get(\"documents\", [])\n            logger.debug(f\"Tool {self.name} - {self.id}: retrieved {len(retrieved_documents)} documents\")\n\n            result = self.format_content(retrieved_documents)\n            logger.info(f\"Tool {self.name} - {self.id}: finished with RESULT:\\n{str(result)[:200]}...\")\n\n            return {\"content\": result, \"documents\": retrieved_documents}\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: execution error: {str(e)}\", exc_info=True)\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to retrieve data using the specified action. \"\n                f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/retriever/#dynamiq.nodes.retrievers.retriever.VectorStoreRetriever.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Property to define which parameters should be excluded when converting the class instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary defining the parameters to exclude.</p>"},{"location":"dynamiq/nodes/retrievers/retriever/#dynamiq.nodes.retrievers.retriever.VectorStoreRetriever.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes the VectorStoreRetriever with the given parameters.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to be passed to the parent class constructor.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/retriever.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initializes the VectorStoreRetriever with the given parameters.\n\n    Args:\n        **kwargs: Additional keyword arguments to be passed to the parent class constructor.\n    \"\"\"\n    super().__init__(**kwargs)\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/retriever/#dynamiq.nodes.retrievers.retriever.VectorStoreRetriever.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the retrieval tool.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>Input data for the tool.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable, including callbacks.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Result of the retrieval.</p> Source code in <code>dynamiq/nodes/retrievers/retriever.py</code> <pre><code>def execute(\n    self, input_data: VectorStoreRetrieverInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"Execute the retrieval tool.\n\n    Args:\n        input_data (dict[str, Any]): Input data for the tool.\n        config (RunnableConfig, optional): Configuration for the runnable, including callbacks.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: Result of the retrieval.\n    \"\"\"\n\n    logger.info(f\"Tool {self.name} - {self.id}: started with INPUT DATA:\\n{input_data.model_dump()}\")\n    config = ensure_config(config)\n    self.reset_run_state()\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    filters = input_data.filters or self.filters\n    top_k = input_data.top_k or self.top_k\n    similarity_threshold = (\n        input_data.similarity_threshold\n        if input_data.similarity_threshold is not None\n        else self.similarity_threshold\n    )\n\n    alpha = input_data.alpha or self.alpha\n    query = input_data.query\n    try:\n        kwargs = kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}\n        kwargs.pop(\"run_depends\", None)\n        text_embedder_output = self.text_embedder.run(\n            input_data={\"query\": query}, run_depends=self._run_depends, config=config, **kwargs\n        )\n        self._run_depends = [NodeDependency(node=self.text_embedder).to_dict(for_tracing=True)]\n        embedding = text_embedder_output.output.get(\"embedding\")\n\n        document_retriever_output = self.document_retriever.run(\n            input_data={\n                \"embedding\": embedding,\n                **({\"top_k\": top_k} if top_k else {}),\n                \"filters\": filters,\n                \"alpha\": alpha,\n                **({\"query\": query} if alpha else {}),\n                **({\"similarity_threshold\": similarity_threshold} if similarity_threshold is not None else {}),\n            },\n            run_depends=self._run_depends,\n            config=config,\n            **kwargs,\n        )\n        self._run_depends = [NodeDependency(node=self.document_retriever).to_dict(for_tracing=True)]\n        retrieved_documents = document_retriever_output.output.get(\"documents\", [])\n        logger.debug(f\"Tool {self.name} - {self.id}: retrieved {len(retrieved_documents)} documents\")\n\n        result = self.format_content(retrieved_documents)\n        logger.info(f\"Tool {self.name} - {self.id}: finished with RESULT:\\n{str(result)[:200]}...\")\n\n        return {\"content\": result, \"documents\": retrieved_documents}\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: execution error: {str(e)}\", exc_info=True)\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to retrieve data using the specified action. \"\n            f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/retriever/#dynamiq.nodes.retrievers.retriever.VectorStoreRetriever.format_content","title":"<code>format_content(documents, metadata_fields=None)</code>","text":"<p>Format the retrieved documents' metadata and content.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>List of retrieved documents.</p> required <code>metadata_fields</code> <code>list[str]</code> <p>Metadata fields to include. If None, uses all metadata except embeddings.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted content of the documents.</p> Source code in <code>dynamiq/nodes/retrievers/retriever.py</code> <pre><code>def format_content(self, documents: list[Document], metadata_fields: list[str] | None = None) -&gt; str:\n    \"\"\"Format the retrieved documents' metadata and content.\n\n    Args:\n        documents (list[Document]): List of retrieved documents.\n        metadata_fields (list[str]): Metadata fields to include. If None, uses all metadata except embeddings.\n\n    Returns:\n        str: Formatted content of the documents.\n    \"\"\"\n    formatted_docs: list[str] = []\n\n    normalized_metadata_fields: list[str] | None = None\n    include_score = False\n    if metadata_fields is not None:\n        seen_fields: set[str] = set()\n        cleaned_fields: list[str] = []\n        for field in metadata_fields:\n            stripped = field.strip() if field else \"\"\n            if not stripped:\n                continue\n            lowered = stripped.lower()\n            if lowered in seen_fields:\n                continue\n            if lowered == \"score\":\n                include_score = True\n                seen_fields.add(lowered)\n                continue\n            seen_fields.add(lowered)\n            cleaned_fields.append(stripped)\n\n        if cleaned_fields:\n            normalized_metadata_fields = cleaned_fields\n        elif include_score:\n            normalized_metadata_fields = []\n\n    for index, doc in enumerate(documents):\n        metadata = doc.metadata or {}\n        metadata_lines: list[str] = []\n\n        if normalized_metadata_fields is not None:\n            if include_score and doc.score is not None:\n                metadata_lines.append(self._format_metadata_line(\"Score\", doc.score))\n        else:\n            if doc.score is not None:\n                metadata_lines.append(self._format_metadata_line(\"Score\", doc.score))\n\n        metadata_lines.extend(self._generate_metadata_lines(metadata, normalized_metadata_fields))\n\n        metadata_block = \"\\n\\n\".join(metadata_lines) if metadata_lines else \"No metadata available.\"\n        content_block = doc.content or \"\"\n\n        formatted_doc = (\n            f\"\\n\\n== Source {index + 1} ==\\n\\n\"\n            f\"\\n\\n== Metadata ==\\n{metadata_block}\\n\\n\"\n            f\"\\n\\n== Content (Source {index + 1}) ==\\n\\n{content_block}\"\n        ).rstrip()\n        formatted_docs.append(formatted_doc)\n\n    return \"\\n\\n\".join(formatted_docs)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/retriever/#dynamiq.nodes.retrievers.retriever.VectorStoreRetriever.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the tool.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/retrievers/retriever.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n    \"\"\"\n    Initialize the components of the tool.\n\n    Args:\n        connection_manager (ConnectionManager, optional): connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.text_embedder.is_postponed_component_init:\n        self.text_embedder.init_components(connection_manager)\n    if self.document_retriever.is_postponed_component_init:\n        self.document_retriever.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/retriever/#dynamiq.nodes.retrievers.retriever.VectorStoreRetriever.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Reset the intermediate steps (run_depends) of the node.</p> Source code in <code>dynamiq/nodes/retrievers/retriever.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"\n    Reset the intermediate steps (run_depends) of the node.\n    \"\"\"\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/retriever/#dynamiq.nodes.retrievers.retriever.VectorStoreRetriever.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/retrievers/retriever.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"text_embedder\"] = self.text_embedder.to_dict(**kwargs)\n    data[\"document_retriever\"] = self.document_retriever.to_dict(**kwargs)\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/weaviate/","title":"Weaviate","text":""},{"location":"dynamiq/nodes/retrievers/weaviate/#dynamiq.nodes.retrievers.weaviate.WeaviateDocumentRetriever","title":"<code>WeaviateDocumentRetriever</code>","text":"<p>               Bases: <code>Retriever</code>, <code>WeaviateRetrieverVectorStoreParams</code></p> <p>Document Retriever using Weaviate.</p> <p>This class implements a document retriever that uses Weaviate as the vector store backend.</p> <p>Parameters:</p> Name Type Description Default <code>vector_store</code> <code>WeaviateVectorStore</code> <p>An instance of WeaviateVectorStore to interface with Weaviate vectors.</p> required <code>filters</code> <code>dict[str, Any]</code> <p>Filters to apply for retrieving specific documents. Defaults to None.</p> required <code>top_k</code> <code>int</code> <p>The maximum number of documents to return. Defaults to 10.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[RETRIEVERS]</code> <p>The group of the node.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>vector_store</code> <code>WeaviateVectorStore | None</code> <p>The WeaviateVectorStore instance.</p> <code>filters</code> <code>dict[str, Any] | None</code> <p>Filters for document retrieval.</p> <code>top_k</code> <code>int</code> <p>The maximum number of documents to return.</p> <code>document_retriever</code> <code>WeaviateDocumentRetriever</code> <p>The document retriever component.</p> Source code in <code>dynamiq/nodes/retrievers/weaviate.py</code> <pre><code>class WeaviateDocumentRetriever(Retriever, WeaviateRetrieverVectorStoreParams):\n    \"\"\"Document Retriever using Weaviate.\n\n    This class implements a document retriever that uses Weaviate as the vector store backend.\n\n    Args:\n        vector_store (WeaviateVectorStore, optional): An instance of WeaviateVectorStore to interface\n            with Weaviate vectors.\n        filters (dict[str, Any], optional): Filters to apply for retrieving specific documents.\n            Defaults to None.\n        top_k (int, optional): The maximum number of documents to return. Defaults to 10.\n\n    Attributes:\n        group (Literal[NodeGroup.RETRIEVERS]): The group of the node.\n        name (str): The name of the node.\n        vector_store (WeaviateVectorStore | None): The WeaviateVectorStore instance.\n        filters (dict[str, Any] | None): Filters for document retrieval.\n        top_k (int): The maximum number of documents to return.\n        document_retriever (WeaviateDocumentRetrieverComponent): The document retriever component.\n    \"\"\"\n\n    name: str = \"WeaviateDocumentRetriever\"\n    connection: Weaviate | None = None\n    vector_store: WeaviateVectorStore | None = None\n    document_retriever: WeaviateDocumentRetrieverComponent | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the WeaviateDocumentRetriever.\n\n        If neither vector_store nor connection is provided in kwargs, a default Weaviate connection will be created.\n\n        Args:\n            **kwargs: Keyword arguments to initialize the retriever.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Weaviate()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return WeaviateVectorStore\n\n    @property\n    def vector_store_params(self):\n        params = self.model_dump(include=set(WeaviateRetrieverVectorStoreParams.model_fields))\n        params.update(\n            {\n                \"connection\": self.connection,\n                \"client\": self.client,\n            }\n        )\n        return params\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the retriever.\n\n        This method sets up the document retriever component if it hasn't been initialized yet.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_retriever is None:\n            self.document_retriever = WeaviateDocumentRetrieverComponent(\n                vector_store=self.vector_store,\n                filters=self.filters,\n                top_k=self.top_k,\n                similarity_threshold=self.similarity_threshold,\n            )\n\n    def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the document retrieval process.\n\n        This method retrieves documents based on the input embedding.\n\n        Args:\n            input_data (RetrieverInputSchema): The input data containing the query embedding.\n            config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the retrieved documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query_embedding = input_data.embedding\n        content_key = input_data.content_key\n        filters = input_data.filters or self.filters\n        top_k = input_data.top_k or self.top_k\n        similarity_threshold = (\n            input_data.similarity_threshold\n            if input_data.similarity_threshold is not None\n            else self.similarity_threshold\n        )\n\n        alpha = input_data.alpha or self.alpha\n        query = input_data.query\n\n        output = self.document_retriever.run(\n            query_embedding,\n            filters=filters,\n            top_k=top_k,\n            content_key=content_key,\n            query=query,\n            alpha=alpha,\n            similarity_threshold=similarity_threshold,\n        )\n\n        return {\n            \"documents\": output[\"documents\"],\n        }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/weaviate/#dynamiq.nodes.retrievers.weaviate.WeaviateDocumentRetriever.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the WeaviateDocumentRetriever.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Weaviate connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments to initialize the retriever.</p> <code>{}</code> Source code in <code>dynamiq/nodes/retrievers/weaviate.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the WeaviateDocumentRetriever.\n\n    If neither vector_store nor connection is provided in kwargs, a default Weaviate connection will be created.\n\n    Args:\n        **kwargs: Keyword arguments to initialize the retriever.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Weaviate()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/weaviate/#dynamiq.nodes.retrievers.weaviate.WeaviateDocumentRetriever.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document retrieval process.</p> <p>This method retrieves documents based on the input embedding.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>RetrieverInputSchema</code> <p>The input data containing the query embedding.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the retrieved documents.</p> Source code in <code>dynamiq/nodes/retrievers/weaviate.py</code> <pre><code>def execute(self, input_data: RetrieverInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the document retrieval process.\n\n    This method retrieves documents based on the input embedding.\n\n    Args:\n        input_data (RetrieverInputSchema): The input data containing the query embedding.\n        config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the retrieved documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    query_embedding = input_data.embedding\n    content_key = input_data.content_key\n    filters = input_data.filters or self.filters\n    top_k = input_data.top_k or self.top_k\n    similarity_threshold = (\n        input_data.similarity_threshold\n        if input_data.similarity_threshold is not None\n        else self.similarity_threshold\n    )\n\n    alpha = input_data.alpha or self.alpha\n    query = input_data.query\n\n    output = self.document_retriever.run(\n        query_embedding,\n        filters=filters,\n        top_k=top_k,\n        content_key=content_key,\n        query=query,\n        alpha=alpha,\n        similarity_threshold=similarity_threshold,\n    )\n\n    return {\n        \"documents\": output[\"documents\"],\n    }\n</code></pre>"},{"location":"dynamiq/nodes/retrievers/weaviate/#dynamiq.nodes.retrievers.weaviate.WeaviateDocumentRetriever.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the retriever.</p> <p>This method sets up the document retriever component if it hasn't been initialized yet.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/retrievers/weaviate.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the retriever.\n\n    This method sets up the document retriever component if it hasn't been initialized yet.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_retriever is None:\n        self.document_retriever = WeaviateDocumentRetrieverComponent(\n            vector_store=self.vector_store,\n            filters=self.filters,\n            top_k=self.top_k,\n            similarity_threshold=self.similarity_threshold,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/splitters/document/","title":"Document","text":""},{"location":"dynamiq/nodes/splitters/document/#dynamiq.nodes.splitters.document.DocumentSplitter","title":"<code>DocumentSplitter</code>","text":"<p>               Bases: <code>Node</code></p> <p>Splits a list of text documents into a list of text documents with shorter texts.</p> <p>Splitting documents with long texts is a common preprocessing step during indexing. This allows Embedders to create significant semantic representations and avoids exceeding the maximum context length of language models.</p> <p>Parameters:</p> Name Type Description Default <code>split_by</code> <code>Literal['word', 'sentence', 'page', 'passage']</code> <p>Determines the unit by which the document should be split. Defaults to \"word\".</p> required <code>split_length</code> <code>int</code> <p>Maximum number of units (as defined by <code>split_by</code>) to include in each split. Defaults to 200.</p> required <code>split_overlap</code> <code>int</code> <p>Number of units that should overlap between consecutive splits. Defaults to 0.</p> required <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[SPLITTERS]</code> <p>The group of the node.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>split_by</code> <code>DocumentSplitBy</code> <p>The unit by which the document should be split.</p> <code>split_length</code> <code>int</code> <p>The maximum number of units to include in each split.</p> <code>split_overlap</code> <code>int</code> <p>The number of units that should overlap between consecutive splits.</p> <code>document_splitter</code> <code>DocumentSplitter</code> <p>The component used for document splitting.</p> Source code in <code>dynamiq/nodes/splitters/document.py</code> <pre><code>class DocumentSplitter(Node):\n    \"\"\"Splits a list of text documents into a list of text documents with shorter texts.\n\n    Splitting documents with long texts is a common preprocessing step during indexing.\n    This allows Embedders to create significant semantic representations\n    and avoids exceeding the maximum context length of language models.\n\n    Args:\n        split_by (Literal[\"word\", \"sentence\", \"page\", \"passage\"], optional): Determines the unit by\n            which the document should be split. Defaults to \"word\".\n        split_length (int, optional): Maximum number of units (as defined by `split_by`) to include\n            in each split. Defaults to 200.\n        split_overlap (int, optional): Number of units that should overlap between consecutive\n            splits. Defaults to 0.\n\n    Attributes:\n        group (Literal[NodeGroup.SPLITTERS]): The group of the node.\n        name (str): The name of the node.\n        split_by (DocumentSplitBy): The unit by which the document should be split.\n        split_length (int): The maximum number of units to include in each split.\n        split_overlap (int): The number of units that should overlap between consecutive splits.\n        document_splitter (DocumentSplitterComponent): The component used for document splitting.\n    \"\"\"\n\n    group: Literal[NodeGroup.SPLITTERS] = NodeGroup.SPLITTERS\n    name: str = \"DocumentSplitter\"\n    split_by: DocumentSplitBy = DocumentSplitBy.PASSAGE\n    split_length: int = 10\n    split_overlap: int = 0\n    document_splitter: DocumentSplitterComponent = None\n    input_schema: ClassVar[type[DocumentSplitterInputSchema]] = DocumentSplitterInputSchema\n\n    @property\n    def to_dict_exclude_params(self):\n        return super().to_dict_exclude_params | {\"document_splitter\": True}\n\n    def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n        \"\"\"Initializes the components of the DocumentSplitter.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to ConnectionManager().\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.document_splitter is None:\n            self.document_splitter = DocumentSplitterComponent(\n                split_by=self.split_by,\n                split_length=self.split_length,\n                split_overlap=self.split_overlap,\n            )\n\n    def execute(\n        self, input_data: DocumentSplitterInputSchema, config: RunnableConfig = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"Executes the document splitting process.\n\n        Args:\n            input_data (DocumentSplitterInputSchema): The input data containing the documents to split.\n            config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the split documents under the key \"documents\".\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = input_data.documents\n        logger.debug(f\"Splitting {len(documents)} documents\")\n        output = self.document_splitter.run(documents=documents)\n\n        split_documents = output[\"documents\"]\n        logger.debug(\n            f\"Split {len(documents)} documents into {len(split_documents)} parts\"\n        )\n\n        return {\n            \"documents\": split_documents,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/splitters/document/#dynamiq.nodes.splitters.document.DocumentSplitter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the document splitting process.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>DocumentSplitterInputSchema</code> <p>The input data containing the documents to split.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the split documents under the key \"documents\".</p> Source code in <code>dynamiq/nodes/splitters/document.py</code> <pre><code>def execute(\n    self, input_data: DocumentSplitterInputSchema, config: RunnableConfig = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"Executes the document splitting process.\n\n    Args:\n        input_data (DocumentSplitterInputSchema): The input data containing the documents to split.\n        config (RunnableConfig, optional): The configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the split documents under the key \"documents\".\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = input_data.documents\n    logger.debug(f\"Splitting {len(documents)} documents\")\n    output = self.document_splitter.run(documents=documents)\n\n    split_documents = output[\"documents\"]\n    logger.debug(\n        f\"Split {len(documents)} documents into {len(split_documents)} parts\"\n    )\n\n    return {\n        \"documents\": split_documents,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/splitters/document/#dynamiq.nodes.splitters.document.DocumentSplitter.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initializes the components of the DocumentSplitter.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to ConnectionManager().</p> <code>None</code> Source code in <code>dynamiq/nodes/splitters/document.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n    \"\"\"Initializes the components of the DocumentSplitter.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to ConnectionManager().\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.document_splitter is None:\n        self.document_splitter = DocumentSplitterComponent(\n            split_by=self.split_by,\n            split_length=self.split_length,\n            split_overlap=self.split_overlap,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/tools/context_manager/","title":"Context manager","text":""},{"location":"dynamiq/nodes/tools/context_manager/#dynamiq.nodes.tools.context_manager.ContextManagerInputSchema","title":"<code>ContextManagerInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input for ContextManagerTool.</p> <ul> <li>history: The recent conversation/messages to compress. Can be a single string or list of strings.</li> <li>is_history_preserved: Preserve the history with summarization. If False, the history will not be preserved,  only notes will.</li> <li>notes: Verbatim content that must be preserved as-is (not processed by LLM) and prepended to the result.</li> </ul> Source code in <code>dynamiq/nodes/tools/context_manager.py</code> <pre><code>class ContextManagerInputSchema(BaseModel):\n    \"\"\"Input for ContextManagerTool.\n\n    - history: The recent conversation/messages to compress. Can be a single string or list of strings.\n    - is_history_preserved: Preserve the history with summarization. If False, the history will not be preserved,\n     only notes will.\n    - notes: Verbatim content that must be preserved as-is (not processed by LLM) and prepended to the result.\n    \"\"\"\n\n    history: list[Message] | None = Field(\n        ..., description=\"Conversation history to be summarized and used to replace prior messages\"\n    )\n\n    is_history_preserved: bool = Field(\n        default=True,\n        description=\"Preserve the history with summarization. If False, the history will not be preserved,\"\n        \" only notes will.\",\n    )\n\n    notes: str | None = Field(\n        default=None,\n        description=(\n            \"Verbatim content to preserve as-is (e.g., IDs, filenames, critical details). \"\n            \"This will be prepended unchanged to the output and NOT sent to the LLM.\"\n        ),\n    )\n</code></pre>"},{"location":"dynamiq/nodes/tools/context_manager/#dynamiq.nodes.tools.context_manager.ContextManagerTool","title":"<code>ContextManagerTool</code>","text":"<p>               Bases: <code>Node</code></p> <p>A tool to prune previous message history and replace it with a concise summary.</p> <p>IMPORTANT: Before calling this tool, ensure any necessary details are explicitly saved (e.g., files, pinned notes, or artifacts). This tool is intended to remove previous messages and keep only a structured summary to tighten context and focus on the active subtask.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group this node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>Tool description with usage warning.</p> <code>llm</code> <code>BaseLLM</code> <p>The LLM used to produce the compressed summary.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Configuration for error handling.</p> <code>prompt_template</code> <code>str</code> <p>Prompt template guiding the summarization.</p> Source code in <code>dynamiq/nodes/tools/context_manager.py</code> <pre><code>class ContextManagerTool(Node):\n    \"\"\"\n    A tool to prune previous message history and replace it with a concise summary.\n\n    IMPORTANT: Before calling this tool, ensure any necessary details are explicitly saved\n    (e.g., files, pinned notes, or artifacts). This tool is intended to remove previous messages\n    and keep only a structured summary to tighten context and focus on the active subtask.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group this node belongs to.\n        name (str): The name of the tool.\n        description (str): Tool description with usage warning.\n        llm (BaseLLM): The LLM used to produce the compressed summary.\n        error_handling (ErrorHandling): Configuration for error handling.\n        prompt_template (str): Prompt template guiding the summarization.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Context Manager Tool\"\n    description: str = (\n        \"Cleans prior message history and replaces it with a concise, self-contained summary.\\n\\n\"\n        \"WARNING: Before calling this tool, the agent must save any necessary information (f.e in FileStore),\\n\"\n        \"because previous messages will be removed and replaced by the summary. \"\n        \"You can also provide notes to the tool to preserve important information without being processed by the LLM. \"\n        \"Make sure to provide all necessary information for the agent to stay on track and\"\n        \" not lose any important details. \"\n        \"You can also disable history preservation, only notes will be preserved. \"\n        \"Disable history when you don't care about the history and only want to preserve notes.\"\n    )\n\n    llm: BaseLLM = Field(..., description=\"LLM used to produce the compressed context summary\")\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=600))\n    prompt_template: str = Field(\n        default=CONTEXT_MANAGER_PROMPT_TEMPLATE, description=\"Prompt template for context compression\"\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[ContextManagerInputSchema]] = ContextManagerInputSchema\n\n    def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n        \"\"\"Initialize components for the tool.\"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.llm.is_postponed_component_init:\n            self.llm.init_components(connection_manager)\n\n    def reset_run_state(self):\n        \"\"\"Reset the intermediate steps (run_depends) of the node.\"\"\"\n        self._run_depends = []\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict:\n        \"\"\"Exclude LLM object during serialization.\"\"\"\n        return super().to_dict_exclude_params | {\"llm\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        data = super().to_dict(**kwargs)\n        data[\"llm\"] = self.llm.to_dict(**kwargs)\n        return data\n\n    def _build_prompt(self, history: list[Message]) -&gt; str:\n        formatted_history = \"\\n\\n---\\n\\n\".join([f\"{m.role}: {str(m.content)}\" for m in history])\n        return self.prompt_template.format(history=formatted_history)\n\n    def _summarize_history(self, history: list[Message], config: RunnableConfig, **kwargs) -&gt; str:\n        prompt_content = self._build_prompt(history)\n\n        result = self.llm.run(\n            input_data={},\n            prompt=Prompt(messages=[Message(role=\"user\", content=prompt_content, static=True)]),\n            config=config,\n            **(kwargs | {\"parent_run_id\": kwargs.get(\"run_id\"), \"run_depends\": []}),\n        )\n\n        self._run_depends = [NodeDependency(node=self.llm).to_dict(for_tracing=True)]\n\n        if result.status != RunnableStatus.SUCCESS:\n            raise ValueError(\"LLM execution failed during context compression\")\n\n        return result.output.get(\"content\", \"\").strip()\n\n    def execute(\n        self, input_data: ContextManagerInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Summarize the provided history and emit an instruction to replace prior messages with the summary.\n\n        Returns:\n            dict[str, Any]:\n                - content: human-readable status message\n                - summary: the compressed summary text\n                - keep_last_n: advisory hint for UI/agent to keep last N messages\n                - replacement_message: suggested system message to insert as new context root\n                - instructions_for_agent: explicit instructions for applying the change\n        \"\"\"\n        config = ensure_config(config)\n        self.reset_run_state()\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        summary = \"\"\n\n        if input_data.is_history_preserved:\n            summary = self._summarize_history(input_data.history, config, **kwargs)\n            summary = f\"\\nContext compressed; Summary:\\n {summary}\"\n\n        if input_data.notes:\n            summary = f\"Notes: {input_data.notes}\\n\\n{summary}\"\n\n        logger.debug(f\"Tool {self.name} - {self.id}: context compression completed, summary length: {len(summary)}\")\n\n        return {\"content\": summary}\n</code></pre>"},{"location":"dynamiq/nodes/tools/context_manager/#dynamiq.nodes.tools.context_manager.ContextManagerTool.to_dict_exclude_params","title":"<code>to_dict_exclude_params: dict</code>  <code>property</code>","text":"<p>Exclude LLM object during serialization.</p>"},{"location":"dynamiq/nodes/tools/context_manager/#dynamiq.nodes.tools.context_manager.ContextManagerTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Summarize the provided history and emit an instruction to replace prior messages with the summary.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: - content: human-readable status message - summary: the compressed summary text - keep_last_n: advisory hint for UI/agent to keep last N messages - replacement_message: suggested system message to insert as new context root - instructions_for_agent: explicit instructions for applying the change</p> Source code in <code>dynamiq/nodes/tools/context_manager.py</code> <pre><code>def execute(\n    self, input_data: ContextManagerInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Summarize the provided history and emit an instruction to replace prior messages with the summary.\n\n    Returns:\n        dict[str, Any]:\n            - content: human-readable status message\n            - summary: the compressed summary text\n            - keep_last_n: advisory hint for UI/agent to keep last N messages\n            - replacement_message: suggested system message to insert as new context root\n            - instructions_for_agent: explicit instructions for applying the change\n    \"\"\"\n    config = ensure_config(config)\n    self.reset_run_state()\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    summary = \"\"\n\n    if input_data.is_history_preserved:\n        summary = self._summarize_history(input_data.history, config, **kwargs)\n        summary = f\"\\nContext compressed; Summary:\\n {summary}\"\n\n    if input_data.notes:\n        summary = f\"Notes: {input_data.notes}\\n\\n{summary}\"\n\n    logger.debug(f\"Tool {self.name} - {self.id}: context compression completed, summary length: {len(summary)}\")\n\n    return {\"content\": summary}\n</code></pre>"},{"location":"dynamiq/nodes/tools/context_manager/#dynamiq.nodes.tools.context_manager.ContextManagerTool.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize components for the tool.</p> Source code in <code>dynamiq/nodes/tools/context_manager.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n    \"\"\"Initialize components for the tool.\"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.llm.is_postponed_component_init:\n        self.llm.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/tools/context_manager/#dynamiq.nodes.tools.context_manager.ContextManagerTool.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Reset the intermediate steps (run_depends) of the node.</p> Source code in <code>dynamiq/nodes/tools/context_manager.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"Reset the intermediate steps (run_depends) of the node.\"\"\"\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/","title":"E2b sandbox","text":""},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterInputSchema","title":"<code>E2BInterpreterInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Input schema for E2B interpreter tool.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>class E2BInterpreterInputSchema(BaseModel):\n    \"\"\"Input schema for E2B interpreter tool.\"\"\"\n\n    model_config = ConfigDict(extra=\"allow\", arbitrary_types_allowed=True)\n\n    packages: str = Field(default=\"\", description=\"Comma-separated pip packages to install.\")\n    shell_command: str = Field(default=\"\", description=\"Shell command to execute.\")\n    python: str = Field(default=\"\", description=\"Python code to execute.\")\n    download_files: list[str] = Field(default_factory=list, description=\"Exact file paths to fetch as base64.\")\n    files: list[io.BytesIO] | None = Field(\n        default=None,\n        description=\"Files to upload to the sandbox.\",\n        json_schema_extra={\"is_accessible_to_agent\": False, \"map_from_storage\": True},\n    )\n    params: dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Arbitrary variables to inject as Python globals before executing 'python'.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n    env: dict[str, str] = Field(\n        default_factory=dict,\n        description=\"Environment variables for shell commands.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n    cwd: str = Field(default=\"/home/user/output\", description=\"Working directory for shell commands.\")\n    timeout: int | None = Field(default=None, description=\"Override sandbox timeout for this execution (seconds)\")\n\n    @model_validator(mode=\"after\")\n    def validate_execution_commands(self):\n        \"\"\"Validate that either shell command, python code, or download files is specified.\"\"\"\n        if not self.shell_command and not self.python and not self.download_files:\n            raise ValueError(\"shell_command, python code, or download_files has to be specified.\")\n        return self\n\n    @field_validator(\"files\", mode=\"before\")\n    @classmethod\n    def files_validator(cls, files: list[bytes | io.BytesIO | FileInfo], **kwargs):\n        \"\"\"Validate and process files.\"\"\"\n        if files in (None, [], ()):\n            return None\n\n        return handle_file_upload(files)\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterInputSchema.files_validator","title":"<code>files_validator(files, **kwargs)</code>  <code>classmethod</code>","text":"<p>Validate and process files.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>@field_validator(\"files\", mode=\"before\")\n@classmethod\ndef files_validator(cls, files: list[bytes | io.BytesIO | FileInfo], **kwargs):\n    \"\"\"Validate and process files.\"\"\"\n    if files in (None, [], ()):\n        return None\n\n    return handle_file_upload(files)\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterInputSchema.validate_execution_commands","title":"<code>validate_execution_commands()</code>","text":"<p>Validate that either shell command, python code, or download files is specified.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_execution_commands(self):\n    \"\"\"Validate that either shell command, python code, or download files is specified.\"\"\"\n    if not self.shell_command and not self.python and not self.download_files:\n        raise ValueError(\"shell_command, python code, or download_files has to be specified.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterTool","title":"<code>E2BInterpreterTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool for executing code and managing files in an E2B sandbox environment.</p> <p>This tool provides a secure execution environment for running Python code, shell commands, and managing file operations.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The node group identifier.</p> <code>name</code> <code>str</code> <p>The unique name of the tool.</p> <code>description</code> <code>str</code> <p>Detailed usage instructions and capabilities.</p> <code>connection</code> <code>E2B</code> <p>Configuration for E2B connection.</p> <code>installed_packages</code> <code>list</code> <p>Pre-installed packages in the sandbox.</p> <code>files</code> <code>list[BytesIO] | None</code> <p>Files to be uploaded.</p> <code>persistent_sandbox</code> <code>bool</code> <p>Whether to maintain sandbox between executions.</p> <code>is_files_allowed</code> <code>bool</code> <p>Whether file uploads are permitted.</p> <code>_sandbox</code> <code>Sandbox | None</code> <p>Internal sandbox instance for persistent mode.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>class E2BInterpreterTool(ConnectionNode):\n    \"\"\"\n    A tool for executing code and managing files in an E2B sandbox environment.\n\n    This tool provides a secure execution environment for running Python code,\n    shell commands, and managing file operations.\n\n    Attributes:\n        group: The node group identifier.\n        name: The unique name of the tool.\n        description: Detailed usage instructions and capabilities.\n        connection: Configuration for E2B connection.\n        installed_packages: Pre-installed packages in the sandbox.\n        files: Files to be uploaded.\n        persistent_sandbox: Whether to maintain sandbox between executions.\n        is_files_allowed: Whether file uploads are permitted.\n        _sandbox: Internal sandbox instance for persistent mode.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"E2b Code Interpreter Tool\"\n    description: str = DESCRIPTION_E2B\n    connection: E2BConnection\n    installed_packages: list = []\n    files: list[io.BytesIO] | None = None\n    persistent_sandbox: bool = True\n    timeout: int = Field(default=600, description=\"Sandbox timeout in seconds (default: 600 seconds)\")\n    is_files_allowed: bool = True\n    creation_error_handling: SandboxCreationErrorHandling = Field(default_factory=SandboxCreationErrorHandling)\n\n    _sandbox: Sandbox | None = None\n\n    input_schema: ClassVar[type[E2BInterpreterInputSchema]] = E2BInterpreterInputSchema\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the E2B interpreter tool.\"\"\"\n        super().__init__(**kwargs)\n        if self.persistent_sandbox and self.connection.api_key:\n            self._initialize_persistent_sandbox()\n        else:\n            logger.debug(f\"Tool {self.name} - {self.id}: Will initialize sandbox on each execute\")\n\n    @property\n    def to_dict_exclude_params(self) -&gt; set:\n        \"\"\"\n        Get parameters to exclude from dictionary representation.\n\n        Returns:\n            set: Set of parameters to exclude.\n        \"\"\"\n        return super().to_dict_exclude_params | {\"files\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Convert instance to dictionary format.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: Dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        if self.files:\n            data[\"files\"] = [{\"name\": getattr(f, \"name\", f\"file_{i}\")} for i, f in enumerate(self.files)]\n        return data\n\n    def _initialize_persistent_sandbox(self):\n        \"\"\"Initialize the persistent sandbox, install packages, and upload initial files.\"\"\"\n        logger.debug(f\"Tool {self.name} - {self.id}: \" f\"Initializing Persistent Sandbox with timeout {self.timeout}s\")\n        self._sandbox = self._create_sandbox_with_retry()\n        self._install_default_packages(self._sandbox)\n        if self.files:\n            self._upload_files(files=self.files, sandbox=self._sandbox)\n\n    def _install_default_packages(self, sandbox: Sandbox) -&gt; None:\n        \"\"\"Install the default packages in the specified sandbox.\"\"\"\n        if self.installed_packages:\n            for package in self.installed_packages:\n                self._install_packages(sandbox, package)\n\n    def _install_packages(self, sandbox: Sandbox, packages: str) -&gt; None:\n        \"\"\"\n        Install the specified packages in the given sandbox.\n\n        Args:\n            sandbox: The sandbox instance to install packages in.\n            packages: Comma-separated string of package names.\n\n        Raises:\n            ToolExecutionException: If package installation fails.\n        \"\"\"\n        if packages:\n            logger.debug(f\"Tool {self.name} - {self.id}: Installing packages: {packages}\")\n            try:\n                process = sandbox.commands.run(f\"pip install -qq {' '.join(packages.split(','))}\")\n            except Exception as e:\n                raise ToolExecutionException(f\"Error during package installation: {e}\", recoverable=True)\n\n            if process.exit_code != 0:\n                raise ToolExecutionException(f\"Error during package installation: {process.stderr}\", recoverable=True)\n\n    def _upload_files(self, files: list[io.BytesIO], sandbox: Sandbox) -&gt; str:\n        \"\"\"\n        Upload multiple files to the sandbox and return details for each file.\n\n        Args:\n            files: List of file data objects to upload.\n            sandbox: The sandbox instance to upload files to.\n\n        Returns:\n            str: Details of uploaded files.\n        \"\"\"\n        upload_details = []\n        for file in files:\n            uploaded_path = self._upload_file(file, sandbox)\n            file_name = getattr(file, \"name\", \"unknown_file\")\n            upload_details.append(\n                {\n                    \"original_name\": file_name,\n                    \"description\": getattr(file, \"description\", \"\"),\n                    \"uploaded_path\": uploaded_path,\n                }\n            )\n        self._update_description_with_files(upload_details)\n        return \"\\n\".join([f\"{file['original_name']} -&gt; {file['uploaded_path']}\" for file in upload_details])\n\n    def _upload_file(self, file: io.BytesIO, sandbox: Sandbox | None = None) -&gt; str:\n        \"\"\"\n        Upload a single file to the specified sandbox and return the uploaded path.\n\n        Args:\n            file: The file data to upload.\n            sandbox: The sandbox instance to upload to.\n\n        Returns:\n            str: The path where the file was uploaded.\n\n        Raises:\n            ValueError: If sandbox instance is not provided.\n        \"\"\"\n        if not sandbox:\n            raise ValueError(\"Sandbox instance is required for file upload.\")\n\n        file_name = getattr(file, \"name\", \"unknown_file\")\n\n        if \"/\" in file_name:\n            dir_path = \"/\".join(file_name.split(\"/\")[:-1])\n            sandbox.commands.run(f\"mkdir -p /home/user/input/{shlex.quote(dir_path)}\")\n\n        # Reset file position to beginning\n        file.seek(0)\n\n        # Upload to /home/user/input directory\n        target_path = (\n            f\"/home/user/input/{file_name}\" if not file_name.startswith(\"/\") else f\"/home/user/input{file_name}\"\n        )\n        uploaded_info = sandbox.files.write(target_path, file)\n        logger.debug(f\"Tool {self.name} - {self.id}: Uploaded file info: {uploaded_info}\")\n\n        return uploaded_info.path\n\n    def _update_description_with_files(self, upload_details: list[dict]) -&gt; None:\n        \"\"\"\n        Update the tool description with detailed information about the uploaded files.\n\n        Args:\n            upload_details: List of dictionaries containing file upload details.\n        \"\"\"\n        if upload_details:\n            self.description = self.description.strip().replace(\"&lt;/tool_description&gt;\", \"\")\n            self.description += \"\\n\\n**Uploaded Files Details:**\"\n            for file_info in upload_details:\n                self.description += (\n                    f\"\\n- **Original File Name**: {file_info['original_name']}\\n\"\n                    f\"  **Description**: {file_info['description']}\\n\"\n                    f\"  **Uploaded Path**: {file_info['uploaded_path']}\\n\"\n                )\n            self.description += \"\\n&lt;/tool_description&gt;\"\n\n    def _execute_python_code(self, code: str, sandbox: Sandbox | None = None, params: dict = None) -&gt; str:\n        \"\"\"\n        Execute Python code in the specified sandbox with persistent session state.\n\n        Args:\n            code: The Python code to execute.\n            sandbox: The sandbox instance to execute code in.\n            params: Variables to inject into the execution environment.\n\n        Returns:\n            str: The output from code execution.\n\n        Raises:\n            ValueError: If sandbox instance is not provided.\n            ToolExecutionException: If code execution fails.\n        \"\"\"\n        if not sandbox:\n            raise ValueError(\"Sandbox instance is required for code execution.\")\n\n        if params:\n            vars_code = \"\\n# Tool params variables injected by framework\\n\"\n            for key, value in params.items():\n                if isinstance(value, str):\n                    vars_code += f\"{key} = {repr(value)}\\n\"\n                elif isinstance(value, (int, float, bool)) or value is None:\n                    vars_code += f\"{key} = {value}\\n\"\n                elif isinstance(value, (list, dict)):\n                    vars_code += f\"{key} = {repr(value)}\\n\"\n                else:\n                    vars_code += f\"{key} = {repr(str(value))}\\n\"\n\n            code = vars_code + \"\\n\" + code\n\n        try:\n            logger.info(f\"Executing Python code: {code}\")\n            execution = sandbox.run_code(code)\n            output_parts = []\n\n            if execution.text:\n                output_parts.append(execution.text)\n\n            if execution.error:\n                if \"NameError\" in str(execution.error) and self.persistent_sandbox:\n                    logger.debug(\n                        f\"Tool {self.name}: Recoverable NameError in persistent session: \" f\"{execution.error}\"\n                    )\n                raise ToolExecutionException(f\"Error during Python code execution: {execution.error}\", recoverable=True)\n\n            if hasattr(execution, \"logs\") and execution.logs:\n                if hasattr(execution.logs, \"stdout\") and execution.logs.stdout:\n                    for log in execution.logs.stdout:\n                        output_parts.append(log)\n                if hasattr(execution.logs, \"stderr\") and execution.logs.stderr:\n                    for log in execution.logs.stderr:\n                        output_parts.append(f\"[stderr] {log}\")\n\n            return \"\\n\".join(output_parts) if output_parts else \"\"\n\n        except Exception as e:\n            raise ToolExecutionException(f\"Error during Python code execution: {e}\", recoverable=True)\n\n    def _execute_shell_command(\n        self, command: str, sandbox: Sandbox | None = None, env: dict | None = None, cwd: str | None = None\n    ) -&gt; str:\n        \"\"\"\n        Execute a shell command in the specified sandbox.\n\n        Args:\n            command: The shell command to execute.\n            sandbox: The sandbox instance to execute command in.\n            env: Environment variables for the command.\n            cwd: Working directory for the command.\n\n        Returns:\n            str: The output from command execution.\n\n        Raises:\n            ValueError: If sandbox instance is not provided.\n            ToolExecutionException: If command execution fails.\n        \"\"\"\n        if not sandbox:\n            raise ValueError(\"Sandbox instance is required for command execution.\")\n\n        try:\n            process = sandbox.commands.run(command, background=True, envs=env or {}, cwd=cwd or \"/home/user\")\n        except Exception as e:\n            raise ToolExecutionException(f\"Error during shell command execution: {e}\", recoverable=True)\n\n        output = process.wait()\n        if output.exit_code != 0:\n            raise ToolExecutionException(f\"Error during shell command execution: {output.stderr}\", recoverable=True)\n        return output.stdout\n\n    def _download_files(self, file_paths: list[str], sandbox: Sandbox | None = None) -&gt; dict[str, str]:\n        \"\"\"\n        Download files from sandbox and return them with proper MIME types and data URIs.\n\n        Args:\n            file_paths: List of file paths to download.\n            sandbox: The sandbox instance to download from.\n\n        Returns:\n            dict[str, str]: Dictionary mapping file paths to base64 or data URI content.\n\n        Raises:\n            ValueError: If sandbox instance is not provided.\n        \"\"\"\n        if not sandbox:\n            raise ValueError(\"Sandbox instance is required for file download.\")\n\n        downloaded_files = {}\n        for file_path in file_paths:\n            try:\n\n                file_bytes = sandbox.files.read(file_path, \"bytes\")\n\n                base64_content = base64.b64encode(file_bytes).decode(\"utf-8\")\n\n                downloaded_files[file_path] = base64_content\n\n            except Exception as e:\n                logger.warning(f\"Tool {self.name} - {self.id}: Failed to download {file_path}: {e}\")\n                downloaded_files[file_path] = f\"Error: {str(e)}\"\n\n        return downloaded_files\n\n    def _is_simple_structure(self, obj: Any, max_depth: int = 3) -&gt; bool:\n        \"\"\"\n        Check if object contains only simple, serializable types.\n\n        Args:\n            obj: The object to check.\n            max_depth: Maximum depth to check for nested structures.\n\n        Returns:\n            bool: True if object contains only simple types.\n        \"\"\"\n        if max_depth &lt;= 0:\n            return False\n        if isinstance(obj, (str, int, float, bool, type(None))):\n            return True\n        elif isinstance(obj, list):\n            return all(self._is_simple_structure(item, max_depth - 1) for item in obj[:10])  # Limit list size\n        elif isinstance(obj, dict):\n            return all(\n                isinstance(k, str) and self._is_simple_structure(v, max_depth - 1)\n                for k, v in list(obj.items())[:10]  # Limit dict size\n            )\n        else:\n            return False\n\n    def _collect_output_files(self, sandbox: Sandbox, base_dir: str = \"\") -&gt; dict[str, str]:\n        \"\"\"\n        Collect common output files from /home/user/output directory.\n\n        Args:\n            sandbox: The sandbox instance to collect files from.\n            base_dir: Base directory to search for files.\n\n        Returns:\n            dict[str, str]: Dictionary mapping file paths to base64 or data URI content.\n        \"\"\"\n        try:\n            collected_files = {}\n\n            search_dirs = [\"/home/user/output\"]\n\n            for search_dir in search_dirs:\n                check_cmd = f\"test -d {shlex.quote(search_dir)} &amp;&amp; echo exists\"\n                check_res = sandbox.commands.run(check_cmd)\n                if hasattr(check_res, \"wait\"):\n                    check_out = check_res.wait()\n                else:\n                    check_out = check_res\n\n                if check_out.exit_code != 0 or \"exists\" not in check_out.stdout:\n                    continue\n\n                max_depth = \"3\"  # Allow deeper search in /home/user/output directory\n                cmd = (\n                    f\"cd {shlex.quote(search_dir)} &amp;&amp; find . -maxdepth {max_depth} \"\n                    f\"-type f -printf '%P\\\\n' 2&gt;/dev/null | head -20\"\n                )\n                res = sandbox.commands.run(cmd)\n\n                if hasattr(res, \"wait\"):\n                    out = res.wait()\n                else:\n                    out = res\n\n                if out.exit_code != 0 or not out.stdout.strip():\n                    continue\n\n                file_paths = [f for f in out.stdout.splitlines() if f.strip()]\n                if file_paths:\n                    abs_paths = [str(PurePosixPath(search_dir) / p) for p in file_paths]\n                    files = self._download_files(abs_paths, sandbox=sandbox)\n                    collected_files.update(files)\n\n            return collected_files\n\n        except Exception as e:\n            logger.warning(f\"Failed to collect output files: {e}\")\n            return {}\n\n    def execute(\n        self, input_data: E2BInterpreterInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the requested action based on the input data.\n\n        Args:\n            input_data: The input schema containing execution parameters.\n            config: Optional runnable configuration.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: Dictionary containing execution results.\n\n        Raises:\n            ToolExecutionException: If execution fails or invalid input provided.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n\" f\"{str(input_data.model_dump())[:300]}\")\n        config = ensure_config(config)\n\n        if self.persistent_sandbox and self._sandbox:\n            sandbox = self._sandbox\n        else:\n            sandbox = self._create_sandbox_with_retry()\n            self._install_default_packages(sandbox)\n            if self.files:\n                self._upload_files(files=self.files, sandbox=sandbox)\n\n        tool_data = {\n            \"tool_session_id\": sandbox.sandbox_id,\n            \"tool_session_host\": sandbox.get_host(port=sandbox.envd_port),\n        }\n        self.run_on_node_execute_run(\n            config.callbacks,\n            tool_data=tool_data,\n            **kwargs,\n        )\n\n        if sandbox and self.is_files_allowed:\n            try:\n                sandbox.commands.run(\"mkdir -p /home/user/input /home/user/output\")\n                logger.debug(\"Created /home/user/input and /home/user/output directories\")\n            except Exception as e:\n                logger.warning(f\"Failed to create directories: {e}\")\n\n        if input_data.timeout and sandbox:\n            try:\n                sandbox.set_timeout(input_data.timeout)\n                logger.debug(f\"Set per-call timeout to {input_data.timeout}s\")\n            except Exception as e:\n                logger.warning(f\"Failed to set per-call timeout: {e}\")\n\n        try:\n            content = {}\n\n            if files := input_data.files:\n                content[\"files_uploaded\"] = self._upload_files(files=files, sandbox=sandbox)\n\n            if packages := input_data.packages:\n                self._install_packages(sandbox=sandbox, packages=packages)\n                content[\"packages_installation\"] = f\"Installed packages: {input_data.packages}\"\n\n            if shell_command := input_data.shell_command:\n                content[\"shell_command_execution\"] = self._execute_shell_command(\n                    shell_command, sandbox=sandbox, env=input_data.env, cwd=input_data.cwd\n                )\n\n            if python := input_data.python:\n                content[\"code_execution\"] = self._execute_python_code(python, sandbox=sandbox, params=input_data.params)\n\n            if download_files := input_data.download_files:\n                downloaded_files = self._download_files(download_files, sandbox=sandbox)\n                content.setdefault(\"files\", {}).update(downloaded_files)\n\n            if shell_command or python:\n                collected_files = self._collect_output_files(sandbox)\n                if collected_files:\n                    content.setdefault(\"files\", {}).update(collected_files)\n\n            if not (packages or files or shell_command or python or download_files):\n                raise ToolExecutionException(\n                    \"Error: Invalid input data. Please provide packages, files, shell_command, \"\n                    \"python code, or download_files.\",\n                    recoverable=True,\n                )\n\n            if python and not content.get(\"code_execution\") and not content.get(\"files\"):\n                raise ToolExecutionException(\n                    \"Error: No output from Python execution. \"\n                    \"Please use 'print()' to display the result of your Python code.\",\n                    recoverable=True,\n                )\n\n        finally:\n            if not self.persistent_sandbox:\n                logger.debug(f\"Tool {self.name} - {self.id}: Closing Sandbox\")\n                sandbox.kill()\n\n        if self.is_optimized_for_agents:\n            result_text = \"\"\n\n            if code_execution := content.get(\"code_execution\"):\n                result_text += \"## Output\\n\\n\" + code_execution + \"\\n\\n\"\n\n            if shell_command_execution := content.get(\"shell_command_execution\"):\n                result_text += \"## Shell Output\\n\\n\" + shell_command_execution + \"\\n\\n\"\n\n            all_files = content.get(\"files\", {})\n\n            uploaded_files = set()\n            if files_uploaded := content.get(\"files_uploaded\"):\n                for line in files_uploaded.split(\"\\n\"):\n                    if \" -&gt; \" in line:\n                        uploaded_path = line.split(\" -&gt; \")[1].strip()\n                        uploaded_files.add(uploaded_path)\n\n            new_files = {k: v for k, v in all_files.items() if k not in uploaded_files}\n\n            # Convert files to BytesIO objects for proper storage handling\n            files_bytesio = []\n            if new_files:\n                result_text += \"## Generated Files (ready for download)\\n\\n\"\n                for file_path, file_content in new_files.items():\n                    if file_content.startswith(\"Error:\"):\n                        result_text += f\"- {file_path}: {file_content}\\n\"\n                    else:\n                        try:\n                            # Decode content to bytes\n                            if file_content.startswith(\"data:\"):\n                                # Handle data URI format\n                                mime_part = file_content.split(\";\")[0].replace(\"data:\", \"\")\n                                base64_part = file_content.split(\",\", 1)[1]\n                                content_bytes = base64.b64decode(base64_part)\n                                content_type = mime_part\n                            else:\n                                # Handle plain base64 content\n                                content_bytes = base64.b64decode(file_content)\n                                content_type = detect_mime_type(content_bytes, file_path)\n\n                            file_name = file_path.split(\"/\")[-1]\n                            file_size = len(content_bytes)\n                            result_text += f\"- **{file_name}** ({file_size:,} bytes, {content_type})\\n\"\n\n                            # Create BytesIO object with metadata\n                            file_bytesio = io.BytesIO(content_bytes)\n                            file_bytesio.name = file_name\n                            file_bytesio.description = f\"Generated file from E2B sandbox: {file_path}\"\n                            file_bytesio.content_type = content_type\n\n                            # Ensure the BytesIO object is positioned at the beginning for reading\n                            file_bytesio.seek(0)\n\n                            files_bytesio.append(file_bytesio)\n\n                        except (base64.binascii.Error, ValueError, Exception) as e:\n                            error_msg = f\"Failed to decode file {file_path}: {str(e)}\"\n                            result_text += f\"- {file_path}: {error_msg}\\n\"\n                            logger.warning(f\"Tool {self.name} - {self.id}: {error_msg}\")\n\n                result_text += \"\\n\"\n\n            if packages_installation := content.get(\"packages_installation\"):\n                packages = packages_installation.replace(\"Installed packages: \", \"\")\n                if packages:\n                    result_text += f\"*Packages installed: {packages}*\\n\\n\"\n\n            if files_uploaded := content.get(\"files_uploaded\"):\n                files_list = []\n                for line in files_uploaded.split(\"\\n\"):\n                    if \" -&gt; \" in line:\n                        file_name = line.split(\" -&gt; \")[0].strip()\n                        files_list.append(file_name)\n                if files_list:\n                    result_text += f\"*Files uploaded: {', '.join(files_list)}*\\n\"\n                    result_text += \"Note: Uploaded files are available under /home/user/input. \"\n            logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n\" f\"{str(result_text)[:200]}...\")\n\n            return {\"content\": result_text, \"files\": files_bytesio}\n\n        return {\"content\": content}\n\n    def _create_sandbox_with_retry(self) -&gt; Sandbox:\n        \"\"\"Create E2B Sandbox with tenacity retry on 429 responses.\n\n        Uses exponential backoff strategy for rate limit errors with configuration\n        from the node's error_handling settings.\n        \"\"\"\n\n        @retry(\n            retry=retry_if_exception_type(E2BRateLimitException),\n            stop=stop_after_attempt(self.creation_error_handling.max_retries),\n            wait=wait_exponential_jitter(\n                initial=self.creation_error_handling.initial_wait_seconds,\n                max=self.creation_error_handling.max_wait_seconds,\n                exp_base=self.creation_error_handling.exponential_base,\n                jitter=self.creation_error_handling.jitter,\n            ),\n            reraise=True,\n        )\n        def create_sandbox() -&gt; Sandbox:\n            try:\n                sandbox = Sandbox(api_key=self.connection.api_key, timeout=self.timeout)\n                logger.debug(f\"Tool {self.name} - {self.id}: Successfully created sandbox\")\n                return sandbox\n            except E2BRateLimitException:\n                logger.warning(\n                    f\"Tool {self.name} - {self.id}: Sandbox creation rate-limited. \"\n                    f\"Retrying with exponential backoff.\"\n                )\n                raise\n            except Exception:\n                raise\n\n        return create_sandbox()\n\n    def set_timeout(self, timeout: int) -&gt; None:\n        \"\"\"\n        Update the timeout for the sandbox during runtime.\n\n        Args:\n            timeout: New timeout value in seconds.\n        \"\"\"\n        self.timeout = timeout\n        if self._sandbox and self.persistent_sandbox:\n            try:\n                self._sandbox.set_timeout(timeout)\n                logger.debug(f\"Tool {self.name} - {self.id}: Updated sandbox timeout to {timeout}s\")\n            except Exception as e:\n                logger.warning(f\"Tool {self.name} - {self.id}: Failed to update sandbox timeout: {e}\")\n\n    def close(self) -&gt; None:\n        \"\"\"Close the persistent sandbox if it exists.\"\"\"\n        if self._sandbox and self.persistent_sandbox:\n            logger.debug(f\"Tool {self.name} - {self.id}: Closing Sandbox\")\n            self._sandbox.kill()\n            self._sandbox = None\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterTool.to_dict_exclude_params","title":"<code>to_dict_exclude_params: set</code>  <code>property</code>","text":"<p>Get parameters to exclude from dictionary representation.</p> <p>Returns:</p> Name Type Description <code>set</code> <code>set</code> <p>Set of parameters to exclude.</p>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterTool.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the E2B interpreter tool.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the E2B interpreter tool.\"\"\"\n    super().__init__(**kwargs)\n    if self.persistent_sandbox and self.connection.api_key:\n        self._initialize_persistent_sandbox()\n    else:\n        logger.debug(f\"Tool {self.name} - {self.id}: Will initialize sandbox on each execute\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterTool.close","title":"<code>close()</code>","text":"<p>Close the persistent sandbox if it exists.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the persistent sandbox if it exists.\"\"\"\n    if self._sandbox and self.persistent_sandbox:\n        logger.debug(f\"Tool {self.name} - {self.id}: Closing Sandbox\")\n        self._sandbox.kill()\n        self._sandbox = None\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the requested action based on the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>E2BInterpreterInputSchema</code> <p>The input schema containing execution parameters.</p> required <code>config</code> <code>RunnableConfig | None</code> <p>Optional runnable configuration.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing execution results.</p> <p>Raises:</p> Type Description <code>ToolExecutionException</code> <p>If execution fails or invalid input provided.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def execute(\n    self, input_data: E2BInterpreterInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the requested action based on the input data.\n\n    Args:\n        input_data: The input schema containing execution parameters.\n        config: Optional runnable configuration.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: Dictionary containing execution results.\n\n    Raises:\n        ToolExecutionException: If execution fails or invalid input provided.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n\" f\"{str(input_data.model_dump())[:300]}\")\n    config = ensure_config(config)\n\n    if self.persistent_sandbox and self._sandbox:\n        sandbox = self._sandbox\n    else:\n        sandbox = self._create_sandbox_with_retry()\n        self._install_default_packages(sandbox)\n        if self.files:\n            self._upload_files(files=self.files, sandbox=sandbox)\n\n    tool_data = {\n        \"tool_session_id\": sandbox.sandbox_id,\n        \"tool_session_host\": sandbox.get_host(port=sandbox.envd_port),\n    }\n    self.run_on_node_execute_run(\n        config.callbacks,\n        tool_data=tool_data,\n        **kwargs,\n    )\n\n    if sandbox and self.is_files_allowed:\n        try:\n            sandbox.commands.run(\"mkdir -p /home/user/input /home/user/output\")\n            logger.debug(\"Created /home/user/input and /home/user/output directories\")\n        except Exception as e:\n            logger.warning(f\"Failed to create directories: {e}\")\n\n    if input_data.timeout and sandbox:\n        try:\n            sandbox.set_timeout(input_data.timeout)\n            logger.debug(f\"Set per-call timeout to {input_data.timeout}s\")\n        except Exception as e:\n            logger.warning(f\"Failed to set per-call timeout: {e}\")\n\n    try:\n        content = {}\n\n        if files := input_data.files:\n            content[\"files_uploaded\"] = self._upload_files(files=files, sandbox=sandbox)\n\n        if packages := input_data.packages:\n            self._install_packages(sandbox=sandbox, packages=packages)\n            content[\"packages_installation\"] = f\"Installed packages: {input_data.packages}\"\n\n        if shell_command := input_data.shell_command:\n            content[\"shell_command_execution\"] = self._execute_shell_command(\n                shell_command, sandbox=sandbox, env=input_data.env, cwd=input_data.cwd\n            )\n\n        if python := input_data.python:\n            content[\"code_execution\"] = self._execute_python_code(python, sandbox=sandbox, params=input_data.params)\n\n        if download_files := input_data.download_files:\n            downloaded_files = self._download_files(download_files, sandbox=sandbox)\n            content.setdefault(\"files\", {}).update(downloaded_files)\n\n        if shell_command or python:\n            collected_files = self._collect_output_files(sandbox)\n            if collected_files:\n                content.setdefault(\"files\", {}).update(collected_files)\n\n        if not (packages or files or shell_command or python or download_files):\n            raise ToolExecutionException(\n                \"Error: Invalid input data. Please provide packages, files, shell_command, \"\n                \"python code, or download_files.\",\n                recoverable=True,\n            )\n\n        if python and not content.get(\"code_execution\") and not content.get(\"files\"):\n            raise ToolExecutionException(\n                \"Error: No output from Python execution. \"\n                \"Please use 'print()' to display the result of your Python code.\",\n                recoverable=True,\n            )\n\n    finally:\n        if not self.persistent_sandbox:\n            logger.debug(f\"Tool {self.name} - {self.id}: Closing Sandbox\")\n            sandbox.kill()\n\n    if self.is_optimized_for_agents:\n        result_text = \"\"\n\n        if code_execution := content.get(\"code_execution\"):\n            result_text += \"## Output\\n\\n\" + code_execution + \"\\n\\n\"\n\n        if shell_command_execution := content.get(\"shell_command_execution\"):\n            result_text += \"## Shell Output\\n\\n\" + shell_command_execution + \"\\n\\n\"\n\n        all_files = content.get(\"files\", {})\n\n        uploaded_files = set()\n        if files_uploaded := content.get(\"files_uploaded\"):\n            for line in files_uploaded.split(\"\\n\"):\n                if \" -&gt; \" in line:\n                    uploaded_path = line.split(\" -&gt; \")[1].strip()\n                    uploaded_files.add(uploaded_path)\n\n        new_files = {k: v for k, v in all_files.items() if k not in uploaded_files}\n\n        # Convert files to BytesIO objects for proper storage handling\n        files_bytesio = []\n        if new_files:\n            result_text += \"## Generated Files (ready for download)\\n\\n\"\n            for file_path, file_content in new_files.items():\n                if file_content.startswith(\"Error:\"):\n                    result_text += f\"- {file_path}: {file_content}\\n\"\n                else:\n                    try:\n                        # Decode content to bytes\n                        if file_content.startswith(\"data:\"):\n                            # Handle data URI format\n                            mime_part = file_content.split(\";\")[0].replace(\"data:\", \"\")\n                            base64_part = file_content.split(\",\", 1)[1]\n                            content_bytes = base64.b64decode(base64_part)\n                            content_type = mime_part\n                        else:\n                            # Handle plain base64 content\n                            content_bytes = base64.b64decode(file_content)\n                            content_type = detect_mime_type(content_bytes, file_path)\n\n                        file_name = file_path.split(\"/\")[-1]\n                        file_size = len(content_bytes)\n                        result_text += f\"- **{file_name}** ({file_size:,} bytes, {content_type})\\n\"\n\n                        # Create BytesIO object with metadata\n                        file_bytesio = io.BytesIO(content_bytes)\n                        file_bytesio.name = file_name\n                        file_bytesio.description = f\"Generated file from E2B sandbox: {file_path}\"\n                        file_bytesio.content_type = content_type\n\n                        # Ensure the BytesIO object is positioned at the beginning for reading\n                        file_bytesio.seek(0)\n\n                        files_bytesio.append(file_bytesio)\n\n                    except (base64.binascii.Error, ValueError, Exception) as e:\n                        error_msg = f\"Failed to decode file {file_path}: {str(e)}\"\n                        result_text += f\"- {file_path}: {error_msg}\\n\"\n                        logger.warning(f\"Tool {self.name} - {self.id}: {error_msg}\")\n\n            result_text += \"\\n\"\n\n        if packages_installation := content.get(\"packages_installation\"):\n            packages = packages_installation.replace(\"Installed packages: \", \"\")\n            if packages:\n                result_text += f\"*Packages installed: {packages}*\\n\\n\"\n\n        if files_uploaded := content.get(\"files_uploaded\"):\n            files_list = []\n            for line in files_uploaded.split(\"\\n\"):\n                if \" -&gt; \" in line:\n                    file_name = line.split(\" -&gt; \")[0].strip()\n                    files_list.append(file_name)\n            if files_list:\n                result_text += f\"*Files uploaded: {', '.join(files_list)}*\\n\"\n                result_text += \"Note: Uploaded files are available under /home/user/input. \"\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n\" f\"{str(result_text)[:200]}...\")\n\n        return {\"content\": result_text, \"files\": files_bytesio}\n\n    return {\"content\": content}\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterTool.set_timeout","title":"<code>set_timeout(timeout)</code>","text":"<p>Update the timeout for the sandbox during runtime.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>int</code> <p>New timeout value in seconds.</p> required Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def set_timeout(self, timeout: int) -&gt; None:\n    \"\"\"\n    Update the timeout for the sandbox during runtime.\n\n    Args:\n        timeout: New timeout value in seconds.\n    \"\"\"\n    self.timeout = timeout\n    if self._sandbox and self.persistent_sandbox:\n        try:\n            self._sandbox.set_timeout(timeout)\n            logger.debug(f\"Tool {self.name} - {self.id}: Updated sandbox timeout to {timeout}s\")\n        except Exception as e:\n            logger.warning(f\"Tool {self.name} - {self.id}: Failed to update sandbox timeout: {e}\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.E2BInterpreterTool.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Convert instance to dictionary format.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Convert instance to dictionary format.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: Dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    if self.files:\n        data[\"files\"] = [{\"name\": getattr(f, \"name\", f\"file_{i}\")} for i, f in enumerate(self.files)]\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.detect_mime_type","title":"<code>detect_mime_type(file_content, file_path)</code>","text":"<p>Detect MIME type using magic numbers and file extension.</p> <p>Parameters:</p> Name Type Description Default <code>file_content</code> <code>bytes</code> <p>The raw file content as bytes</p> required <code>file_path</code> <code>str</code> <p>The file path to extract extension from</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The detected MIME type</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def detect_mime_type(file_content: bytes, file_path: str) -&gt; str:\n    \"\"\"\n    Detect MIME type using magic numbers and file extension.\n\n    Args:\n        file_content: The raw file content as bytes\n        file_path: The file path to extract extension from\n\n    Returns:\n        str: The detected MIME type\n    \"\"\"\n    magic_signatures = {\n        # Images\n        b\"\\x89PNG\\r\\n\\x1a\\n\": \"image/png\",\n        b\"\\xff\\xd8\\xff\": \"image/jpeg\",\n        b\"GIF87a\": \"image/gif\",\n        b\"GIF89a\": \"image/gif\",\n        b\"RIFF\": \"image/webp\",\n        b\"BM\": \"image/bmp\",\n        b\"\\x00\\x00\\x01\\x00\": \"image/x-icon\",\n        # Documents\n        b\"%PDF\": \"application/pdf\",\n        b\"PK\\x03\\x04\": \"application/zip\",\n        b\"\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\": \"application/vnd.ms-office\",\n        # Text/Data\n        b\"{\\n\": \"application/json\",\n        b'{\"': \"application/json\",\n        b\"[\\n\": \"application/json\",\n        b\"[{\": \"application/json\",\n    }\n\n    for signature, mime_type in magic_signatures.items():\n        if file_content.startswith(signature):\n            if signature == b\"RIFF\" and len(file_content) &gt; 12:\n                if file_content[8:12] == b\"WEBP\":\n                    return \"image/webp\"\n                else:\n                    continue\n            return mime_type\n\n    extension = file_path.lower().split(\".\")[-1] if \".\" in file_path else \"\"\n\n    extension_map = {\n        \"png\": \"image/png\",\n        \"jpg\": \"image/jpeg\",\n        \"jpeg\": \"image/jpeg\",\n        \"gif\": \"image/gif\",\n        \"webp\": \"image/webp\",\n        \"bmp\": \"image/bmp\",\n        \"ico\": \"image/x-icon\",\n        \"svg\": \"image/svg+xml\",\n        \"pdf\": \"application/pdf\",\n        \"xlsx\": \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n        \"xls\": \"application/vnd.ms-excel\",\n        \"docx\": \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\n        \"doc\": \"application/msword\",\n        \"pptx\": \"application/vnd.openxmlformats-officedocument.presentationml.presentation\",\n        \"ppt\": \"application/vnd.ms-powerpoint\",\n        \"txt\": \"text/plain\",\n        \"csv\": \"text/csv\",\n        \"json\": \"application/json\",\n        \"xml\": \"application/xml\",\n        \"html\": \"text/html\",\n        \"htm\": \"text/html\",\n        \"css\": \"text/css\",\n        \"js\": \"application/javascript\",\n        \"md\": \"text/markdown\",\n        \"zip\": \"application/zip\",\n        \"tar\": \"application/x-tar\",\n        \"gz\": \"application/gzip\",\n        \"rar\": \"application/vnd.rar\",\n    }\n\n    return extension_map.get(extension, \"application/octet-stream\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.generate_fallback_filename","title":"<code>generate_fallback_filename(file)</code>","text":"<p>Generate a unique fallback filename for uploaded files.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>bytes | BytesIO</code> <p>File content as bytes or BytesIO object.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A unique filename based on the object's id.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def generate_fallback_filename(file: bytes | io.BytesIO) -&gt; str:\n    \"\"\"\n    Generate a unique fallback filename for uploaded files.\n\n    Args:\n        file: File content as bytes or BytesIO object.\n\n    Returns:\n        str: A unique filename based on the object's id.\n    \"\"\"\n    return f\"uploaded_file_{id(file)}.bin\"\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.generate_file_description","title":"<code>generate_file_description(file, length=20)</code>","text":"<p>Generate a description for a file based on its content.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>bytes | BytesIO</code> <p>File content as bytes or BytesIO object.</p> required <code>length</code> <code>int</code> <p>Maximum number of bytes to include in the description.</p> <code>20</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A description of the file's content or existing description.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def generate_file_description(file: bytes | io.BytesIO, length: int = 20) -&gt; str:\n    \"\"\"\n    Generate a description for a file based on its content.\n\n    Args:\n        file: File content as bytes or BytesIO object.\n        length: Maximum number of bytes to include in the description.\n\n    Returns:\n        str: A description of the file's content or existing description.\n    \"\"\"\n    if description := getattr(file, \"description\", None):\n        return description\n\n    file_content = file.getbuffer()[:length] if isinstance(file, io.BytesIO) else file[:length]\n    return f\"File starting with: {file_content.hex()}\"\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.handle_file_upload","title":"<code>handle_file_upload(files)</code>","text":"<p>Handles file uploading and converts all inputs to BytesIO objects.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[bytes | BytesIO | FileInfo]</code> <p>List of file objects to upload.</p> required <p>Returns:</p> Type Description <code>list[BytesIO]</code> <p>list[io.BytesIO]: List of BytesIO objects with file data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If invalid file data type is provided.</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def handle_file_upload(files: list[bytes | io.BytesIO | FileInfo]) -&gt; list[io.BytesIO]:\n    \"\"\"\n    Handles file uploading and converts all inputs to BytesIO objects.\n\n    Args:\n        files: List of file objects to upload.\n\n    Returns:\n        list[io.BytesIO]: List of BytesIO objects with file data.\n\n    Raises:\n        ValueError: If invalid file data type is provided.\n    \"\"\"\n    files_data = []\n    for file in files:\n        if isinstance(file, io.BytesIO):\n            files_data.append(file)\n        elif isinstance(file, bytes):\n            file_name = getattr(file, \"name\", generate_fallback_filename(file))\n            bytes_io = io.BytesIO(file)\n            bytes_io.name = file_name\n            files_data.append(bytes_io)\n        elif isinstance(file, FileInfo):\n            bytes_io = io.BytesIO(file.content)\n            bytes_io.name = file.name\n            files_data.append(bytes_io)\n        else:\n            raise ValueError(f\"Error: Invalid file data type: {type(file)}. \" f\"Expected bytes or BytesIO or FileInfo.\")\n\n    return files_data\n</code></pre>"},{"location":"dynamiq/nodes/tools/e2b_sandbox/#dynamiq.nodes.tools.e2b_sandbox.should_use_data_uri","title":"<code>should_use_data_uri(mime_type)</code>","text":"<p>Determine if a file should be returned as a data URI.</p> <p>Parameters:</p> Name Type Description Default <code>mime_type</code> <code>str</code> <p>The MIME type of the file</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if should use data URI format</p> Source code in <code>dynamiq/nodes/tools/e2b_sandbox.py</code> <pre><code>def should_use_data_uri(mime_type: str) -&gt; bool:\n    \"\"\"\n    Determine if a file should be returned as a data URI.\n\n    Args:\n        mime_type: The MIME type of the file\n\n    Returns:\n        bool: True if should use data URI format\n    \"\"\"\n    # Use data URIs for images and other web-renderable content\n    data_uri_types = [\n        \"image/\",\n        \"text/html\",\n        \"text/css\",\n        \"application/javascript\",\n        \"image/svg+xml\",\n    ]\n\n    return any(mime_type.startswith(prefix) for prefix in data_uri_types)\n</code></pre>"},{"location":"dynamiq/nodes/tools/exa_search/","title":"Exa search","text":""},{"location":"dynamiq/nodes/tools/exa_search/#dynamiq.nodes.tools.exa_search.ExaInputSchema","title":"<code>ExaInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema for Exa search input parameters.</p> Source code in <code>dynamiq/nodes/tools/exa_search.py</code> <pre><code>class ExaInputSchema(BaseModel):\n    \"\"\"Schema for Exa search input parameters.\"\"\"\n\n    query: str = Field(description=\"The search query string.\")\n    include_full_content: bool | None = Field(\n        default=None,\n        description=\"If true, retrieve full content, highlights, and summaries for search results.\",\n        json_schema_extra={\"is_accessible_to_agent\": True},\n    )\n    use_autoprompt: bool | None = Field(\n        default=None,\n        description=\"If true, query will be converted to a Exa query.\"\n        \"Enabled by default for auto search, optional for neural search, and not available for keyword search.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n    query_type: QueryType | None = Field(\n        default=None,\n        description=\"Type of query to be used. Options are 'keyword', 'neural', or 'auto'.\"\n        \"Neural uses an embeddings-based model, keyword is google-like SERP. \"\n        \"Default is auto, which automatically decides between keyword and neural.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n    category: CategoryType | None = Field(\n        default=None,\n        description=\"A data category to focus on.\"\n        \"Options are company, research paper, news, pdf,\"\n        \" github, tweet, personal site, linkedin profile, financial report.\",\n        json_schema_extra={\"is_accessible_to_agent\": True},\n    )\n    limit: int | None = Field(\n        default=None,\n        ge=1,\n        le=100,\n        description=\"Number of search results to return.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n    include_domains: list[str] | None = Field(\n        default=None,\n        description=\"List of domains to include in the search.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n    exclude_domains: list[str] | None = Field(\n        default=None,\n        description=\"List of domains to exclude from the search.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n    include_text: list[str] | None = Field(\n        default=None,\n        description=\"Strings that must be present in webpage text.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n    exclude_text: list[str] | None = Field(\n        default=None,\n        description=\"Strings that must not be present in webpage text.\",\n        json_schema_extra={\"is_accessible_to_agent\": False},\n    )\n</code></pre>"},{"location":"dynamiq/nodes/tools/exa_search/#dynamiq.nodes.tools.exa_search.ExaTool","title":"<code>ExaTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool for performing web searches using the Exa AI API.</p> <p>This tool accepts various search parameters and returns relevant search results with options for filtering by date, domain, and content.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group to which this tool belongs.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A brief description of the tool.</p> <code>connection</code> <code>Exa</code> <p>The connection instance for the Exa API.</p> <code>include_full_content</code> <code>bool</code> <p>If true, retrieve full content, highlights, and summaries.</p> <code>use_autoprompt</code> <code>bool</code> <p>If true, query will be converted to a Exa query.</p> <code>query_type</code> <code>QueryType</code> <p>Type of query to be used.</p> <code>category</code> <code>CategoryType</code> <p>A data category to focus on.</p> <code>limit</code> <code>int</code> <p>Number of search results to return.</p> <code>include_domains</code> <code>list[str]</code> <p>List of domains to include.</p> <code>exclude_domains</code> <code>list[str]</code> <p>List of domains to exclude.</p> <code>include_text</code> <code>list[str]</code> <p>Strings that must be present.</p> <code>exclude_text</code> <code>list[str]</code> <p>Strings that must not be present.</p> Source code in <code>dynamiq/nodes/tools/exa_search.py</code> <pre><code>class ExaTool(ConnectionNode):\n    \"\"\"\n    A tool for performing web searches using the Exa AI API.\n\n    This tool accepts various search parameters and returns relevant search results\n    with options for filtering by date, domain, and content.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group to which this tool belongs.\n        name (str): The name of the tool.\n        description (str): A brief description of the tool.\n        connection (Exa): The connection instance for the Exa API.\n        include_full_content (bool): If true, retrieve full content, highlights, and summaries.\n        use_autoprompt (bool): If true, query will be converted to a Exa query.\n        query_type (QueryType): Type of query to be used.\n        category (CategoryType): A data category to focus on.\n        limit (int): Number of search results to return.\n        include_domains (list[str], optional): List of domains to include.\n        exclude_domains (list[str], optional): List of domains to exclude.\n        include_text (list[str], optional): Strings that must be present.\n        exclude_text (list[str], optional): Strings that must not be present.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Exa Search Tool\"\n    description: str = DESCRIPTION_EXA\n    connection: Exa\n\n    include_full_content: bool = Field(\n        default=False, description=\"If true, retrieve full content, highlights, and summaries for search results.\"\n    )\n    use_autoprompt: bool = Field(default=False, description=\"If true, query will be converted to a Exa query.\")\n    query_type: QueryType = Field(default=QueryType.auto, description=\"Type of query to be used.\")\n    category: CategoryType | None = Field(default=None, description=\"A data category to focus on.\")\n    limit: int = Field(default=10, ge=1, le=100, description=\"Number of search results to return.\")\n    include_domains: list[str] | None = Field(default=None, description=\"List of domains to include in the search.\")\n    exclude_domains: list[str] | None = Field(default=None, description=\"List of domains to exclude from the search.\")\n    include_text: list[str] | None = Field(default=None, description=\"Strings that must be present in webpage text.\")\n    exclude_text: list[str] | None = Field(\n        default=None, description=\"Strings that must not be present in webpage text.\"\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[ExaInputSchema]] = ExaInputSchema\n\n    @staticmethod\n    def to_camel_case(snake_str: str) -&gt; str:\n        \"\"\"Convert snake_case to camelCase.\"\"\"\n        components = snake_str.split(\"_\")\n        return components[0] + \"\".join(x.title() for x in components[1:])\n\n    def _format_search_results(self, results: list[dict[str, Any]]) -&gt; str:\n        \"\"\"\n        Formats the search results into a human-readable string.\n\n        Args:\n            results (list[dict[str, Any]]): The raw search results.\n\n        Returns:\n            str: A formatted string containing the search results.\n        \"\"\"\n        formatted_results = []\n        for result in results:\n            formatted_results.extend(\n                [\n                    f\"Title: {result.get('title', 'N/A')}\",\n                    f\"URL: {result.get('url', 'N/A')}\",\n                    f\"Published Date: {result.get('publishedDate', 'N/A')}\",\n                    f\"Author: {result.get('author', 'N/A')}\",\n                    f\"Score: {result.get('score', 'N/A')}\",\n                ]\n            )\n\n            if \"highlights\" in result and result[\"highlights\"]:\n                formatted_results.extend(\n                    [\n                        \"Highlights:\",\n                        *[f\"  \u2022 {highlight}\" for highlight in result[\"highlights\"]],\n                    ]\n                )\n\n            if \"summary\" in result and result[\"summary\"]:\n                formatted_results.extend([\"Summary:\", f\"  {result['summary']}\"])\n\n            formatted_results.append(\"\")\n\n        return \"\\n\".join(formatted_results).strip()\n\n    def execute(self, input_data: ExaInputSchema, config: RunnableConfig | None = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the search using the Exa API and returns the formatted results.\n\n        Input parameters override node parameters when provided.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        payload = {\n            \"query\": input_data.query,\n            \"useAutoprompt\": (\n                input_data.use_autoprompt if input_data.use_autoprompt is not None else self.use_autoprompt\n            ),\n            \"type\": input_data.query_type if input_data.query_type is not None else self.query_type,\n            \"numResults\": input_data.limit if input_data.limit is not None else self.limit,\n            \"includeDomains\": (\n                input_data.include_domains if input_data.include_domains is not None else self.include_domains\n            ),\n            \"excludeDomains\": (\n                input_data.exclude_domains if input_data.exclude_domains is not None else self.exclude_domains\n            ),\n            \"includeText\": input_data.include_text if input_data.include_text is not None else self.include_text,\n            \"excludeText\": input_data.exclude_text if input_data.exclude_text is not None else self.exclude_text,\n            \"category\": input_data.category if input_data.category is not None else self.category,\n        }\n\n        if isinstance(payload[\"type\"], QueryType):\n            payload[\"type\"] = payload[\"type\"].value\n\n        payload = {k: v for k, v in payload.items() if v is not None}\n\n        include_full_content = (\n            input_data.include_full_content\n            if input_data.include_full_content is not None\n            else self.include_full_content\n        )\n\n        if include_full_content:\n            payload[\"contents\"] = {\n                \"text\": {\"maxCharacters\": 1000, \"includeHtmlTags\": False},\n                \"highlights\": {\"numSentences\": 3, \"highlightsPerUrl\": 2, \"query\": payload[\"query\"]},\n                \"summary\": {\"query\": f\"Summarize the main points about {payload['query']}\"},\n            }\n\n        connection_url = urljoin(self.connection.url, \"search\")\n\n        try:\n            response = self.client.request(\n                method=self.connection.method,\n                url=connection_url,\n                json=payload,\n                headers=self.connection.headers,\n            )\n            response.raise_for_status()\n            search_result = response.json()\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to retrieve search results. Error: {str(e)}. \"\n                f\"Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        results = search_result.get(\"results\", [])\n        formatted_results = self._format_search_results(results)\n\n        sources_with_url = [f\"{result.get('title')}: ({result.get('url')})\" for result in results]\n\n        if self.is_optimized_for_agents:\n            result_parts = [\"## Sources with URLs\", \"\\n\".join(sources_with_url)]\n            result_parts.extend([\"## Search Results\", formatted_results])\n            result = \"\\n\\n\".join(result_parts)\n        else:\n            urls = [result.get(\"url\") for result in results]\n            result = {\n                \"result\": formatted_results,\n                \"sources_with_url\": sources_with_url,\n                \"urls\": urls,\n                \"raw_response\": search_result,\n            }\n\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n\n        return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/exa_search/#dynamiq.nodes.tools.exa_search.ExaTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the search using the Exa API and returns the formatted results.</p> <p>Input parameters override node parameters when provided.</p> Source code in <code>dynamiq/nodes/tools/exa_search.py</code> <pre><code>def execute(self, input_data: ExaInputSchema, config: RunnableConfig | None = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the search using the Exa API and returns the formatted results.\n\n    Input parameters override node parameters when provided.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    payload = {\n        \"query\": input_data.query,\n        \"useAutoprompt\": (\n            input_data.use_autoprompt if input_data.use_autoprompt is not None else self.use_autoprompt\n        ),\n        \"type\": input_data.query_type if input_data.query_type is not None else self.query_type,\n        \"numResults\": input_data.limit if input_data.limit is not None else self.limit,\n        \"includeDomains\": (\n            input_data.include_domains if input_data.include_domains is not None else self.include_domains\n        ),\n        \"excludeDomains\": (\n            input_data.exclude_domains if input_data.exclude_domains is not None else self.exclude_domains\n        ),\n        \"includeText\": input_data.include_text if input_data.include_text is not None else self.include_text,\n        \"excludeText\": input_data.exclude_text if input_data.exclude_text is not None else self.exclude_text,\n        \"category\": input_data.category if input_data.category is not None else self.category,\n    }\n\n    if isinstance(payload[\"type\"], QueryType):\n        payload[\"type\"] = payload[\"type\"].value\n\n    payload = {k: v for k, v in payload.items() if v is not None}\n\n    include_full_content = (\n        input_data.include_full_content\n        if input_data.include_full_content is not None\n        else self.include_full_content\n    )\n\n    if include_full_content:\n        payload[\"contents\"] = {\n            \"text\": {\"maxCharacters\": 1000, \"includeHtmlTags\": False},\n            \"highlights\": {\"numSentences\": 3, \"highlightsPerUrl\": 2, \"query\": payload[\"query\"]},\n            \"summary\": {\"query\": f\"Summarize the main points about {payload['query']}\"},\n        }\n\n    connection_url = urljoin(self.connection.url, \"search\")\n\n    try:\n        response = self.client.request(\n            method=self.connection.method,\n            url=connection_url,\n            json=payload,\n            headers=self.connection.headers,\n        )\n        response.raise_for_status()\n        search_result = response.json()\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to retrieve search results. Error: {str(e)}. \"\n            f\"Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    results = search_result.get(\"results\", [])\n    formatted_results = self._format_search_results(results)\n\n    sources_with_url = [f\"{result.get('title')}: ({result.get('url')})\" for result in results]\n\n    if self.is_optimized_for_agents:\n        result_parts = [\"## Sources with URLs\", \"\\n\".join(sources_with_url)]\n        result_parts.extend([\"## Search Results\", formatted_results])\n        result = \"\\n\\n\".join(result_parts)\n    else:\n        urls = [result.get(\"url\") for result in results]\n        result = {\n            \"result\": formatted_results,\n            \"sources_with_url\": sources_with_url,\n            \"urls\": urls,\n            \"raw_response\": search_result,\n        }\n\n    logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/exa_search/#dynamiq.nodes.tools.exa_search.ExaTool.to_camel_case","title":"<code>to_camel_case(snake_str)</code>  <code>staticmethod</code>","text":"<p>Convert snake_case to camelCase.</p> Source code in <code>dynamiq/nodes/tools/exa_search.py</code> <pre><code>@staticmethod\ndef to_camel_case(snake_str: str) -&gt; str:\n    \"\"\"Convert snake_case to camelCase.\"\"\"\n    components = snake_str.split(\"_\")\n    return components[0] + \"\".join(x.title() for x in components[1:])\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/","title":"File tools","text":""},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileListInputSchema","title":"<code>FileListInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema for file list input parameters.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>class FileListInputSchema(BaseModel):\n    \"\"\"Schema for file list input parameters.\"\"\"\n\n    file_path: str = Field(\n        default=\"\", description=\"Path of the file to list. Default is the root path. Keep empty to list all files.\"\n    )\n    recursive: bool = Field(default=True, description=\"Whether to list files recursively. Default is True.\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileListTool","title":"<code>FileListTool</code>","text":"<p>               Bases: <code>Node</code></p> <p>A tool for listing files in storage.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>class FileListTool(Node):\n    \"\"\"\n    A tool for listing files in storage.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"FileListTool\"\n    description: str = \"\"\"Lists files in storage based on the provided file path.\"\"\"\n\n    file_store: FileStore = Field(..., description=\"File storage to list from.\")\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[FileListInputSchema]] = FileListInputSchema\n\n    def execute(\n        self,\n        input_data: FileListInputSchema,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; dict[str, Any]:\n\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        try:\n            files_list = self.file_store.list_files(directory=input_data.file_path, recursive=input_data.recursive)\n            files_string = \"Files currently available in the filesystem storage:\\n\"\n            for file in files_list:\n                files_string += f\"File: {file.name} | Path: {file.path} | Size: {file.size} bytes\\n\"\n\n            logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{files_string}\")\n            return {\"content\": files_string}\n\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to list files. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to list files. Error: {str(e)}. \"\n                f\"Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileReadInputSchema","title":"<code>FileReadInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema for file read input parameters.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>class FileReadInputSchema(BaseModel):\n    \"\"\"Schema for file read input parameters.\"\"\"\n\n    file_path: str = Field(default=\"\", description=\"Path of the file to read\")\n    instructions: str | None = Field(\n        default=None,\n        description=\"Instructions for the file read. If not provided, the file will be read in its entirety.\",\n    )\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileReadTool","title":"<code>FileReadTool</code>","text":"<p>               Bases: <code>Node</code></p> <p>A tool for reading files from storage with intelligent file processing.</p> <p>This tool can be passed to Agents to read files from the configured storage backend. It automatically detects file types and processes them using appropriate converters to extract text content. For large files, it automatically returns chunked content showing first, middle, and last parts. For images and PDFs with instructions, uses LLM processing if the model supports vision/PDF input.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group to which this tool belongs.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A brief description of the tool.</p> <code>file_store</code> <code>FileStore</code> <p>File storage to read from.</p> <code>llm</code> <code>BaseLLM</code> <p>LLM that will be used to process files.</p> <code>max_size</code> <code>int</code> <p>Maximum size in bytes before chunking (default: 10000).</p> <code>chunk_size</code> <code>int</code> <p>Size of each chunk in bytes (default: 1000).</p> <code>converter_mapping</code> <code>dict[FileType, Node]</code> <p>Mapping of file types to converters.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>class FileReadTool(Node):\n    \"\"\"\n    A tool for reading files from storage with intelligent file processing.\n\n    This tool can be passed to Agents to read files from the configured storage backend.\n    It automatically detects file types and processes them using appropriate converters to extract text content.\n    For large files, it automatically returns chunked content showing first, middle, and last parts.\n    For images and PDFs with instructions, uses LLM processing if the model supports vision/PDF input.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group to which this tool belongs.\n        name (str): The name of the tool.\n        description (str): A brief description of the tool.\n        file_store (FileStore): File storage to read from.\n        llm (BaseLLM): LLM that will be used to process files.\n        max_size (int): Maximum size in bytes before chunking (default: 10000).\n        chunk_size (int): Size of each chunk in bytes (default: 1000).\n        converter_mapping (dict[FileType, Node]): Mapping of file types to converters.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"FileReadTool\"\n    description: str = \"\"\"\n        Reads files from storage based on the provided file path with intelligent file processing.\n        Automatically detects file types (PDF, DOCX, PPTX, HTML, TXT, IMAGE, etc.) and extracts text content.\n        For large files (configurable threshold), returns first, middle, and last chunks as bytes with separators.\n        For images and PDFs with instructions, uses LLM processing if the model supports vision/PDF input.\n\n        Usage Examples:\n            - Read text file: {\"file_path\": \"config.txt\"}\n            - Read PDF: {\"file_path\": \"report.pdf\"}\n            - Read DOCX: {\"file_path\": \"document.docx\"}\n            - Read image: {\"file_path\": \"image.png\"} (extracts text using LLM)\n            - Read large file: {\"file_path\": \"large_data.json\"}\n            - Read image with instructions: {\"file_path\": \"image.png\", \"instructions\": \"Describe the image in detail\"}\n\n        Parameters:\n            - file_path: Path of the file to read\n            - instructions: Optional instructions for LLM processing of images.\n    \"\"\"\n    llm: BaseLLM = Field(..., description=\"LLM that will be used to process files.\")\n    file_store: FileStore = Field(..., description=\"File storage to read from.\")\n    max_size: int = Field(default=10000, description=\"Maximum size in bytes before chunking (default: 10000)\")\n    chunk_size: int = Field(default=1000, description=\"Size of each chunk in bytes (default: 1000)\")\n    converter_mapping: dict[FileType, Node] | None = None\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[FileReadInputSchema]] = FileReadInputSchema\n\n    def init_components(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"\n        Initialize the components of the FileReadTool.\n\n        Args:\n            connection_manager (ConnectionManager, optional): The connection manager to use.\n                Defaults to a new ConnectionManager instance.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n\n        self._setup_converters(connection_manager)\n\n    def _setup_converters(self, connection_manager: ConnectionManager | None = None):\n        \"\"\"Setup internal converter components.\"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n\n        if not self.converter_mapping:\n            self.converter_mapping = {}\n            for file_type, converter_class in DEFAULT_FILE_TYPE_TO_CONVERTER_CLASS_MAP.items():\n                if file_type == FileType.IMAGE and converter_class == LLMImageConverter:\n                    self.converter_mapping[file_type] = converter_class(llm=self.llm)\n                else:\n                    self.converter_mapping[file_type] = converter_class()\n\n        initialized_converters = set()\n        for converter in self.converter_mapping.values():\n            if id(converter) not in initialized_converters:\n                if converter.is_postponed_component_init:\n                    converter.init_components(connection_manager)\n                initialized_converters.add(id(converter))\n                logger.info(f\"Initialized converter: {converter.name}\")\n\n    def _detect_file_type(self, file: BytesIO, filename: str, config: RunnableConfig, **kwargs) -&gt; FileType | None:\n        \"\"\"\n        Detect the file type using custom detection function.\n\n        Args:\n            file: The file to analyze\n            filename: The filename for file type detection\n            config: Runtime configuration\n            **kwargs: Additional arguments\n\n        Returns:\n            FileType: The detected file type, or None if detection fails\n        \"\"\"\n        return detect_file_type(file, filename)\n\n    def _process_file_with_converter(\n        self,\n        file: BytesIO,\n        filename: str,\n        detected_type: FileType,\n        config: RunnableConfig,\n        instructions: str | None = None,\n        **kwargs,\n    ) -&gt; str | None:\n        \"\"\"\n        Process a file using the appropriate converter to extract text content.\n\n        Args:\n            file: The file to process\n            filename: The filename\n            detected_type: The detected file type\n            config: Runtime configuration\n            instructions: Custom instructions for image processing\n            **kwargs: Additional arguments\n\n        Returns:\n            str | None: Extracted text content from the file, or None if not available\n        \"\"\"\n\n        try:\n            if detected_type in self.converter_mapping:\n\n                if detected_type == FileType.IMAGE and instructions:\n                    converter = LLMImageConverter(llm=self.llm, extraction_instruction=instructions)\n                    converter_name = f\"{converter.name} (with custom instructions)\"\n                else:\n                    converter = self.converter_mapping[detected_type]\n                    converter_name = converter.name\n\n                file.seek(0)\n                if not hasattr(file, \"name\"):\n                    file.name = filename\n\n                converter_input = {\"files\": [file]}\n                result = converter.run(\n                    input_data=converter_input,\n                    config=config,\n                    **(kwargs | {\"parent_run_id\": kwargs.get(\"run_id\"), \"run_depends\": []}),\n                )\n\n                if result.status == RunnableStatus.SUCCESS:\n                    documents = result.output.get(\"documents\", [])\n                    if documents:\n                        text_content = \"\\n\\n\".join([doc.content for doc in documents if hasattr(doc, \"content\")])\n                        logger.info(f\"Successfully extracted text using {converter_name}\")\n                        return text_content\n                    else:\n                        logger.warning(f\"No documents extracted by {converter_name}\")\n                else:\n                    logger.warning(f\"Converter {converter_name} failed: {result.error}\")\n\n            else:\n                logger.warning(f\"No converter available for file type: {detected_type}\")\n\n        except Exception as e:\n            logger.warning(f\"File processing failed with converter: {str(e)}\")\n\n    @property\n    def to_dict_exclude_params(self):\n        \"\"\"\n        Property to define which parameters should be excluded when converting the class instance to a dictionary.\n\n        Returns:\n            dict: A dictionary defining the parameters to exclude.\n        \"\"\"\n        return super().to_dict_exclude_params | {\n            \"llm\": True,\n            \"converter_mapping\": True,\n        }\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"llm\"] = self.llm.to_dict(**kwargs)\n        if self.converter_mapping:\n            data[\"converter_mapping\"] = {\n                file_type.value: converter.to_dict(**kwargs) for file_type, converter in self.converter_mapping.items()\n            }\n        return data\n\n    def execute(\n        self,\n        input_data: FileReadInputSchema,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the file read operation and returns the file content.\n        For large files, returns first, middle, and last chunks instead of full content.\n        Automatically detects file type and extracts text content when possible.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        try:\n            if not self.file_store.exists(input_data.file_path):\n                raise ToolExecutionException(\n                    f\"File '{input_data.file_path}' not found\",\n                    recoverable=True,\n                )\n\n            content = self.file_store.retrieve(input_data.file_path)\n            content_size = len(content)\n\n            try:\n                file_io = BytesIO(content)\n                filename = os.path.basename(input_data.file_path)\n\n                detected_type = self._detect_file_type(file_io, filename, config, **kwargs)\n\n                if detected_type:\n                    text_content = self._process_file_with_converter(\n                        file_io, filename, detected_type, config, input_data.instructions, **kwargs\n                    )\n\n                    if text_content:\n                        logger.info(\n                            f\"Tool {self.name} - {self.id}: successfully processed file and extracted text content\"\n                        )\n\n                        # If the extracted text is large, return chunked content\n                        if len(text_content) &gt; self.max_size:\n                            logger.info(\n                                f\"Tool {self.name} - {self.id}: extracted text is large ({len(text_content)} chars),\"\n                                \" returning chunks\"\n                            )\n                            chunked_content = self._create_chunked_text_content(\n                                text_content, self.chunk_size, input_data.file_path\n                            )\n                            return {\"content\": chunked_content}\n                        else:\n                            return {\"content\": text_content}\n                    else:\n                        logger.warning(\n                            f\"Tool {self.name} - {self.id}: no text content extracted from file,\"\n                            \"falling back to raw content\"\n                        )\n                else:\n                    logger.warning(\n                        f\"Tool {self.name} - {self.id}: could not detect file type, falling back to raw content\"\n                    )\n\n            except Exception as e:\n                logger.warning(\n                    f\"Tool {self.name} - {self.id}: file processing failed: {str(e)}, falling back to raw content\"\n                )\n\n            # Fallback to raw content if processing fails or no text extracted\n            # If file is small enough, return full content\n            if content_size &lt;= self.max_size:\n                logger.info(f\"Tool {self.name} - {self.id}: returning full content ({content_size} bytes)\")\n                return {\"content\": content}\n\n            # For large files, return chunked content\n            logger.info(f\"Tool {self.name} - {self.id}: file is large ({content_size} bytes), returning chunks\")\n\n            chunked_content = self._create_chunked_content(content, self.chunk_size, input_data.file_path)\n\n            return {\"content\": chunked_content}\n\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to read file. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to read file. Error: {str(e)}. \"\n                f\"Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n    def _create_chunked_content(self, content: bytes, chunk_size: int, file_path: str) -&gt; bytes:\n        \"\"\"\n        Create chunked content showing first, middle, and last parts of a large file.\n\n        Args:\n            content: The file content as bytes\n            chunk_size: Size of each chunk in bytes\n            file_path: Path of the file being read\n\n        Returns:\n            Concatenated bytes containing first, middle, and last chunks\n        \"\"\"\n        total_size = len(content)\n\n        first_chunk = content[:chunk_size]\n\n        middle_start = total_size // 2 - chunk_size // 2\n        middle_chunk = content[middle_start : middle_start + chunk_size]\n\n        last_chunk = content[-chunk_size:] if total_size &gt; chunk_size else content\n\n        separator = f\"\\n\\n--- CHUNKED FILE: {file_path} ({total_size:,} bytes total) ---\\n\".encode()\n        first_sep = f\"\\n--- FIRST {len(first_chunk):,} BYTES ---\\n\".encode()\n        middle_sep = f\"\\n--- MIDDLE {len(middle_chunk):,} BYTES (from position {middle_start:,}) ---\\n\".encode()\n        last_sep = f\"\\n--- LAST {len(last_chunk):,} BYTES ---\\n\".encode()\n\n        chunked_bytes = (\n            separator\n            + first_sep\n            + first_chunk\n            + middle_sep\n            + middle_chunk\n            + last_sep\n            + last_chunk\n            + b\"\\n\\n--- END OF CHUNKED FILE ---\\n\"\n        )\n\n        return chunked_bytes\n\n    def _create_chunked_text_content(self, content: str, chunk_size: int, file_path: str) -&gt; str:\n        \"\"\"\n        Create chunked text content showing first, middle, and last parts of a large text.\n\n        Args:\n            content: The text content as string\n            chunk_size: Size of each chunk in characters\n            file_path: Path of the file being read\n\n        Returns:\n            str: Concatenated string containing first, middle, and last chunks\n        \"\"\"\n        total_size = len(content)\n\n        first_chunk = content[:chunk_size]\n\n        middle_start = total_size // 2 - chunk_size // 2\n        middle_chunk = content[middle_start : middle_start + chunk_size]\n\n        last_chunk = content[-chunk_size:] if total_size &gt; chunk_size else content\n\n        separator = f\"\\n\\n--- CHUNKED TEXT FILE: {file_path} ({total_size:,} characters total) ---\\n\"\n        first_sep = f\"\\n--- FIRST {len(first_chunk):,} CHARACTERS ---\\n\"\n        middle_sep = f\"\\n--- MIDDLE {len(middle_chunk):,} CHARACTERS (from position {middle_start:,}) ---\\n\"\n        last_sep = f\"\\n--- LAST {len(last_chunk):,} CHARACTERS ---\\n\"\n\n        chunked_text = (\n            separator\n            + first_sep\n            + first_chunk\n            + middle_sep\n            + middle_chunk\n            + last_sep\n            + last_chunk\n            + \"\\n\\n--- END OF CHUNKED TEXT FILE ---\\n\"\n        )\n\n        return chunked_text\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileReadTool.to_dict_exclude_params","title":"<code>to_dict_exclude_params</code>  <code>property</code>","text":"<p>Property to define which parameters should be excluded when converting the class instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary defining the parameters to exclude.</p>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileReadTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the file read operation and returns the file content. For large files, returns first, middle, and last chunks instead of full content. Automatically detects file type and extracts text content when possible.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>def execute(\n    self,\n    input_data: FileReadInputSchema,\n    config: RunnableConfig | None = None,\n    **kwargs,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the file read operation and returns the file content.\n    For large files, returns first, middle, and last chunks instead of full content.\n    Automatically detects file type and extracts text content when possible.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    try:\n        if not self.file_store.exists(input_data.file_path):\n            raise ToolExecutionException(\n                f\"File '{input_data.file_path}' not found\",\n                recoverable=True,\n            )\n\n        content = self.file_store.retrieve(input_data.file_path)\n        content_size = len(content)\n\n        try:\n            file_io = BytesIO(content)\n            filename = os.path.basename(input_data.file_path)\n\n            detected_type = self._detect_file_type(file_io, filename, config, **kwargs)\n\n            if detected_type:\n                text_content = self._process_file_with_converter(\n                    file_io, filename, detected_type, config, input_data.instructions, **kwargs\n                )\n\n                if text_content:\n                    logger.info(\n                        f\"Tool {self.name} - {self.id}: successfully processed file and extracted text content\"\n                    )\n\n                    # If the extracted text is large, return chunked content\n                    if len(text_content) &gt; self.max_size:\n                        logger.info(\n                            f\"Tool {self.name} - {self.id}: extracted text is large ({len(text_content)} chars),\"\n                            \" returning chunks\"\n                        )\n                        chunked_content = self._create_chunked_text_content(\n                            text_content, self.chunk_size, input_data.file_path\n                        )\n                        return {\"content\": chunked_content}\n                    else:\n                        return {\"content\": text_content}\n                else:\n                    logger.warning(\n                        f\"Tool {self.name} - {self.id}: no text content extracted from file,\"\n                        \"falling back to raw content\"\n                    )\n            else:\n                logger.warning(\n                    f\"Tool {self.name} - {self.id}: could not detect file type, falling back to raw content\"\n                )\n\n        except Exception as e:\n            logger.warning(\n                f\"Tool {self.name} - {self.id}: file processing failed: {str(e)}, falling back to raw content\"\n            )\n\n        # Fallback to raw content if processing fails or no text extracted\n        # If file is small enough, return full content\n        if content_size &lt;= self.max_size:\n            logger.info(f\"Tool {self.name} - {self.id}: returning full content ({content_size} bytes)\")\n            return {\"content\": content}\n\n        # For large files, return chunked content\n        logger.info(f\"Tool {self.name} - {self.id}: file is large ({content_size} bytes), returning chunks\")\n\n        chunked_content = self._create_chunked_content(content, self.chunk_size, input_data.file_path)\n\n        return {\"content\": chunked_content}\n\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to read file. Error: {str(e)}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to read file. Error: {str(e)}. \"\n            f\"Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileReadTool.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the FileReadTool.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>The connection manager to use. Defaults to a new ConnectionManager instance.</p> <code>None</code> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None):\n    \"\"\"\n    Initialize the components of the FileReadTool.\n\n    Args:\n        connection_manager (ConnectionManager, optional): The connection manager to use.\n            Defaults to a new ConnectionManager instance.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n\n    self._setup_converters(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileReadTool.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"llm\"] = self.llm.to_dict(**kwargs)\n    if self.converter_mapping:\n        data[\"converter_mapping\"] = {\n            file_type.value: converter.to_dict(**kwargs) for file_type, converter in self.converter_mapping.items()\n        }\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileWriteInputSchema","title":"<code>FileWriteInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema for file write input parameters.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>class FileWriteInputSchema(BaseModel):\n    \"\"\"Schema for file write input parameters.\"\"\"\n\n    file_path: str = Field(..., description=\"Path where the file should be written\")\n    content: bytes | str = Field(..., description=\"File content (string, bytes)\")\n    content_type: str | None = Field(default=None, description=\"MIME type (auto-detected if not provided)\")\n    metadata: str | None = Field(default=None, description=\"Additional metadata for the file\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileWriteTool","title":"<code>FileWriteTool</code>","text":"<p>               Bases: <code>Node</code></p> <p>A tool for writing files to storage.</p> <p>This tool can be passed to Agents to write files to the configured storage backend.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group to which this tool belongs.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A brief description of the tool.</p> <code>file_store</code> <code>FileStore</code> <p>File storage to write to.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>class FileWriteTool(Node):\n    \"\"\"\n    A tool for writing files to storage.\n\n    This tool can be passed to Agents to write files\n    to the configured storage backend.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group to which this tool belongs.\n        name (str): The name of the tool.\n        description (str): A brief description of the tool.\n        file_store (FileStore): File storage to write to.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"FileWriteTool\"\n    description: str = \"\"\"Writes files to storage based on the provided file path and content.\n\n    Usage Examples:\n    - Write text: {\"file_path\": \"readme.txt\", \"content\": \"Hello World\"}\n    - Write JSON: {\"file_path\": \"config.json\", \"content\": {\"key\": \"value\"}}\n    - Overwrite file: {\"file_path\": \"existing.txt\", \"content\": \"new content\"}\"\"\"\n\n    file_store: FileStore = Field(..., description=\"File storage to write to.\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[FileWriteInputSchema]] = FileWriteInputSchema\n\n    def execute(\n        self,\n        input_data: FileWriteInputSchema,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the file write operation and returns the file information.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        try:\n            content_str = input_data.content\n            if input_data.content_type is None:\n                content_type = \"text/plain\"\n            else:\n                content_type = input_data.content_type\n\n            # Store file\n            file_info = self.file_store.store(\n                input_data.file_path,\n                content_str,\n                content_type=content_type,\n            )\n\n            logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(file_info)[:200]}...\")\n            return {\"content\": f\"File '{input_data.file_path}' written successfully\"}\n\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to write file. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to write file. Error: {str(e)}. \"\n                f\"Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.FileWriteTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the file write operation and returns the file information.</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>def execute(\n    self,\n    input_data: FileWriteInputSchema,\n    config: RunnableConfig | None = None,\n    **kwargs,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the file write operation and returns the file information.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    try:\n        content_str = input_data.content\n        if input_data.content_type is None:\n            content_type = \"text/plain\"\n        else:\n            content_type = input_data.content_type\n\n        # Store file\n        file_info = self.file_store.store(\n            input_data.file_path,\n            content_str,\n            content_type=content_type,\n        )\n\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(file_info)[:200]}...\")\n        return {\"content\": f\"File '{input_data.file_path}' written successfully\"}\n\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to write file. Error: {str(e)}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to write file. Error: {str(e)}. \"\n            f\"Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n</code></pre>"},{"location":"dynamiq/nodes/tools/file_tools/#dynamiq.nodes.tools.file_tools.detect_file_type","title":"<code>detect_file_type(file, filename)</code>","text":"<p>Detect the file type based on file extension.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BytesIO</code> <p>The file object (BytesIO)</p> required <code>filename</code> <code>str</code> <p>The filename to extract extension from</p> required <p>Returns:</p> Name Type Description <code>FileType</code> <code>FileType | None</code> <p>The detected file type, or None if not found</p> Source code in <code>dynamiq/nodes/tools/file_tools.py</code> <pre><code>def detect_file_type(file: BytesIO, filename: str) -&gt; FileType | None:\n    \"\"\"\n    Detect the file type based on file extension.\n\n    Args:\n        file: The file object (BytesIO)\n        filename: The filename to extract extension from\n\n    Returns:\n        FileType: The detected file type, or None if not found\n    \"\"\"\n    try:\n        if not filename and hasattr(file, \"name\"):\n            filename = file.name\n\n        if not filename:\n            logger.warning(\"No filename provided for file type detection\")\n            return None\n\n        file_ext = os.path.splitext(filename)[1][1:] if filename else \"\"\n        file_ext = file_ext.lower()\n\n        if not file_ext:\n            logger.warning(f\"No file extension found in filename: {filename}\")\n            return None\n\n        for file_type, extensions in EXTENSION_MAP.items():\n            if file_ext in extensions:\n                logger.info(f\"Detected file type: {file_type} for file: {filename}\")\n                return file_type\n\n        logger.warning(f\"Unknown file extension: {file_ext} for file: {filename}\")\n        return None\n\n    except Exception as e:\n        logger.warning(f\"File type detection failed for {filename}: {str(e)}\")\n        return None\n</code></pre>"},{"location":"dynamiq/nodes/tools/firecrawl/","title":"Firecrawl","text":""},{"location":"dynamiq/nodes/tools/firecrawl/#dynamiq.nodes.tools.firecrawl.Action","title":"<code>Action</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Action to perform before content extraction.</p> Source code in <code>dynamiq/nodes/tools/firecrawl.py</code> <pre><code>class Action(BaseModel):\n    \"\"\"Action to perform before content extraction.\"\"\"\n\n    type: str\n    milliseconds: int | None = None\n    selector: str | None = None\n</code></pre>"},{"location":"dynamiq/nodes/tools/firecrawl/#dynamiq.nodes.tools.firecrawl.FirecrawlTool","title":"<code>FirecrawlTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool for scraping web pages using the Firecrawl service.</p> Source code in <code>dynamiq/nodes/tools/firecrawl.py</code> <pre><code>class FirecrawlTool(ConnectionNode):\n    \"\"\"A tool for scraping web pages using the Firecrawl service.\"\"\"\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Firecrawl Tool\"\n    description: str = DESCRIPTION_FIRECRAWL\n    connection: Firecrawl\n    url: str | None = None\n    input_schema: ClassVar[type[FirecrawlInputSchema]] = FirecrawlInputSchema\n\n    formats: list[str] = Field(default_factory=lambda: [\"markdown\"])\n    only_main_content: bool = Field(default=True, alias=\"onlyMainContent\")\n    include_tags: list[str] | None = Field(default=None, alias=\"includeTags\")\n    exclude_tags: list[str] | None = Field(default=None, alias=\"excludeTags\")\n    headers: dict | None = None\n    wait_for: int = Field(default=0, alias=\"waitFor\")\n    mobile: bool = False\n    skip_tls_verification: bool = Field(default=False, alias=\"skipTlsVerification\")\n    timeout: int = 30000\n    json_options: JsonOptions | None = Field(default=None, alias=\"jsonOptions\")\n    actions: list[Action] | None = None\n    location: LocationSettings | None = None\n    remove_base64_images: bool = Field(default=False, alias=\"removeBase64Images\")\n    block_ads: bool = Field(default=True, alias=\"blockAds\")\n    proxy: str | None = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True, populate_by_name=True)\n\n    def _build_scrape_data(self, url: str) -&gt; dict:\n        \"\"\"Build the request payload for the Firecrawl API.\"\"\"\n        base_data = {\n            \"url\": url,\n            \"formats\": self.formats,\n            \"onlyMainContent\": self.only_main_content,\n        }\n\n        conditional_fields = {\n            \"includeTags\": self.include_tags,\n            \"excludeTags\": self.exclude_tags,\n            \"headers\": self.headers,\n            \"waitFor\": self.wait_for if self.wait_for &gt; 0 else None,\n            \"mobile\": self.mobile if self.mobile else None,\n            \"skipTlsVerification\": self.skip_tls_verification if self.skip_tls_verification else None,\n            \"timeout\": self.timeout if self.timeout != 30000 else None,\n            \"removeBase64Images\": self.remove_base64_images if self.remove_base64_images else None,\n            \"proxy\": self.proxy,\n        }\n\n        if not self.block_ads:\n            conditional_fields[\"blockAds\"] = False\n\n        if self.json_options:\n            conditional_fields[\"jsonOptions\"] = self.json_options.model_dump(exclude_none=True, by_alias=True)\n        if self.actions:\n            conditional_fields[\"actions\"] = [action.model_dump(exclude_none=True) for action in self.actions]\n        if self.location:\n            conditional_fields[\"location\"] = self.location.model_dump(exclude_none=True)\n\n        # Filter out None values and merge with base data\n        filtered_fields = {k: v for k, v in conditional_fields.items() if v is not None}\n        return {**base_data, **filtered_fields}\n\n    def _format_agent_response(self, url: str, data: dict) -&gt; str:\n        \"\"\"Format the response for agent consumption using Markdown.\"\"\"\n        sections = [f\"## Source URL\\n{url}\"]\n\n        format_mappings = {\"content\": \"Scraped Result\", \"markdown\": \"Markdown Content\", \"html\": \"HTML\", \"json\": \"JSON\"}\n\n        for data_key, section_name in format_mappings.items():\n            if data_key in data:\n                if data_key in [\"html\", \"json\"]:\n                    sections.append(f\"## {section_name}\\n{data_key}\\n{data[data_key]}\\n\")\n                else:\n                    sections.append(f\"## {section_name}\\n{data[data_key]}\")\n\n        return \"\\n\\n\".join(sections)\n\n    def execute(\n        self, input_data: FirecrawlInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"Execute the scraping tool with the provided input data.\"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        url = input_data.url or self.url\n        if not url:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get input data.\")\n            raise ValueError(\"URL is required for scraping\")\n\n        scrape_data = self._build_scrape_data(url)\n        connection_url = self.connection.url + \"scrape\"\n\n        try:\n            response = self.client.request(\n                method=self.connection.method,\n                url=connection_url,\n                json=scrape_data,\n                headers=self.connection.headers,\n            )\n            response.raise_for_status()\n            scrape_result = response.json()\n        except Exception as e:\n            logger.error(\n                f\"Tool {self.name} - {self.id}: failed to get results. Error: {e}\"\n            )\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to execute the requested action. Error: {str(e)}. \"\n                f\"Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        data = scrape_result.get(\"data\", {})\n\n        if self.is_optimized_for_agents:\n            result = self._format_agent_response(url, data)\n        else:\n            result = {\"success\": scrape_result.get(\"success\", False), \"url\": url, **data}\n\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n\n        return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/firecrawl/#dynamiq.nodes.tools.firecrawl.FirecrawlTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the scraping tool with the provided input data.</p> Source code in <code>dynamiq/nodes/tools/firecrawl.py</code> <pre><code>def execute(\n    self, input_data: FirecrawlInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"Execute the scraping tool with the provided input data.\"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    url = input_data.url or self.url\n    if not url:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to get input data.\")\n        raise ValueError(\"URL is required for scraping\")\n\n    scrape_data = self._build_scrape_data(url)\n    connection_url = self.connection.url + \"scrape\"\n\n    try:\n        response = self.client.request(\n            method=self.connection.method,\n            url=connection_url,\n            json=scrape_data,\n            headers=self.connection.headers,\n        )\n        response.raise_for_status()\n        scrape_result = response.json()\n    except Exception as e:\n        logger.error(\n            f\"Tool {self.name} - {self.id}: failed to get results. Error: {e}\"\n        )\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to execute the requested action. Error: {str(e)}. \"\n            f\"Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    data = scrape_result.get(\"data\", {})\n\n    if self.is_optimized_for_agents:\n        result = self._format_agent_response(url, data)\n    else:\n        result = {\"success\": scrape_result.get(\"success\", False), \"url\": url, **data}\n\n    logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/firecrawl/#dynamiq.nodes.tools.firecrawl.JsonOptions","title":"<code>JsonOptions</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Options for configuring JSON extraction.</p> Source code in <code>dynamiq/nodes/tools/firecrawl.py</code> <pre><code>class JsonOptions(BaseModel):\n    \"\"\"Options for configuring JSON extraction.\"\"\"\n\n    json_schema: dict | None = Field(default=None, alias=\"schema\")\n    system_prompt: str | None = Field(None, alias=\"systemPrompt\")\n    prompt: str | None = None\n</code></pre>"},{"location":"dynamiq/nodes/tools/firecrawl/#dynamiq.nodes.tools.firecrawl.LocationSettings","title":"<code>LocationSettings</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Settings for location emulation.</p> Source code in <code>dynamiq/nodes/tools/firecrawl.py</code> <pre><code>class LocationSettings(BaseModel):\n    \"\"\"Settings for location emulation.\"\"\"\n\n    country: str = \"US\"\n    languages: list[str] | None = None\n</code></pre>"},{"location":"dynamiq/nodes/tools/function_tool/","title":"Function tool","text":""},{"location":"dynamiq/nodes/tools/function_tool/#dynamiq.nodes.tools.function_tool.FunctionTool","title":"<code>FunctionTool</code>","text":"<p>               Bases: <code>Node</code>, <code>Generic[T]</code></p> <p>A tool node for executing a specified function with the given input data.</p> Source code in <code>dynamiq/nodes/tools/function_tool.py</code> <pre><code>class FunctionTool(Node, Generic[T]):\n    \"\"\"\n    A tool node for executing a specified function with the given input data.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Function Tool\"\n    description: str = Field(\n        default=\"\"\"Executes custom Python functions as workflow tools with automatic schema generation and parameter validation.\n\nKey Capabilities:\n- Automatic input schema generation from function signatures\n- Dynamic parameter validation using function type hints\n- Support for both sync and async function execution\n- Integration with workflow dependency systems\n\nUsage Strategy:\n- Wrap existing utility functions for workflow integration\n- Create custom tool implementations without full tool classes\n- Rapid prototyping of workflow components\n- Build reusable function libraries for specific domains\n\nParameter Guide:\n- Function parameters matching wrapped function signature\n- Automatic schema validation based on function type hints\n- Must return serializable data types for workflow compatibility\n\nExamples:\n- {\"x\": 10, \"y\": 5} (for math functions)\n- {\"text\": \"Hello World\", \"reverse\": true} (for string operations)\n- {\"data\": [1,2,3,4,5], \"operation\": \"sum\"} (for data processing)\"\"\"  # noqa: E501\n    )\n    error_handling: ErrorHandling = Field(\n        default_factory=lambda: ErrorHandling(timeout_seconds=600)\n    )\n\n    def run_func(self, **_: Any) -&gt; Any:\n        \"\"\"\n        Execute the function logic with provided arguments.\n\n        This method must be implemented by subclasses.\n\n        :param kwargs: Arguments to pass to the function.\n        :return: Result of the function execution.\n        \"\"\"\n        raise NotImplementedError(\"run_func must be implemented by subclasses\")\n\n    def execute(self, input_data: dict[str, Any], config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the tool with the provided input data and configuration.\n\n        :param input_data: Dictionary of input data to be passed to the tool.\n        :param config: Optional configuration for the runnable instance.\n        :return: Dictionary with the execution result.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with INPUT DATA:\\n{input_data.model_dump()}\")\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        result = self.run_func(input_data, config=config, **kwargs)\n\n        logger.info(f\"Tool {self.name} - {self.id}: finished with RESULT:\\n{str(result)[:200]}...\")\n        return {\"content\": result}\n\n    def get_schema(self):\n        \"\"\"\n        Generate the schema for the input and output of the tool.\n\n        :return: Dictionary representing the input and output schema.\n        \"\"\"\n        cls = self.__class__\n        run_tool_method = self.run_func\n        if hasattr(cls, \"_original_func\"):\n            run_tool_method = cls._original_func\n\n        signature = inspect.signature(run_tool_method)\n        parameters = signature.parameters\n\n        fields = {}\n        for name, param in parameters.items():\n            if name == \"self\":\n                continue\n            annotation = (\n                param.annotation if param.annotation != inspect.Parameter.empty else Any\n            )\n            default = ... if param.default == inspect.Parameter.empty else param.default\n            fields[name] = (annotation, default)\n\n        input_model = create_model(f\"{cls.__name__}Input\", **fields)\n\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"input_schema\": input_model.model_json_schema(),\n            \"output_schema\": {\n                \"type\": \"object\",\n                \"properties\": {\"content\": {\"type\": \"any\"}},\n            },\n        }\n</code></pre>"},{"location":"dynamiq/nodes/tools/function_tool/#dynamiq.nodes.tools.function_tool.FunctionTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the tool with the provided input data and configuration.</p> <p>:param input_data: Dictionary of input data to be passed to the tool. :param config: Optional configuration for the runnable instance. :return: Dictionary with the execution result.</p> Source code in <code>dynamiq/nodes/tools/function_tool.py</code> <pre><code>def execute(self, input_data: dict[str, Any], config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the tool with the provided input data and configuration.\n\n    :param input_data: Dictionary of input data to be passed to the tool.\n    :param config: Optional configuration for the runnable instance.\n    :return: Dictionary with the execution result.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with INPUT DATA:\\n{input_data.model_dump()}\")\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    result = self.run_func(input_data, config=config, **kwargs)\n\n    logger.info(f\"Tool {self.name} - {self.id}: finished with RESULT:\\n{str(result)[:200]}...\")\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/function_tool/#dynamiq.nodes.tools.function_tool.FunctionTool.get_schema","title":"<code>get_schema()</code>","text":"<p>Generate the schema for the input and output of the tool.</p> <p>:return: Dictionary representing the input and output schema.</p> Source code in <code>dynamiq/nodes/tools/function_tool.py</code> <pre><code>def get_schema(self):\n    \"\"\"\n    Generate the schema for the input and output of the tool.\n\n    :return: Dictionary representing the input and output schema.\n    \"\"\"\n    cls = self.__class__\n    run_tool_method = self.run_func\n    if hasattr(cls, \"_original_func\"):\n        run_tool_method = cls._original_func\n\n    signature = inspect.signature(run_tool_method)\n    parameters = signature.parameters\n\n    fields = {}\n    for name, param in parameters.items():\n        if name == \"self\":\n            continue\n        annotation = (\n            param.annotation if param.annotation != inspect.Parameter.empty else Any\n        )\n        default = ... if param.default == inspect.Parameter.empty else param.default\n        fields[name] = (annotation, default)\n\n    input_model = create_model(f\"{cls.__name__}Input\", **fields)\n\n    return {\n        \"name\": self.name,\n        \"description\": self.description,\n        \"input_schema\": input_model.model_json_schema(),\n        \"output_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\"content\": {\"type\": \"any\"}},\n        },\n    }\n</code></pre>"},{"location":"dynamiq/nodes/tools/function_tool/#dynamiq.nodes.tools.function_tool.FunctionTool.run_func","title":"<code>run_func(**_)</code>","text":"<p>Execute the function logic with provided arguments.</p> <p>This method must be implemented by subclasses.</p> <p>:param kwargs: Arguments to pass to the function. :return: Result of the function execution.</p> Source code in <code>dynamiq/nodes/tools/function_tool.py</code> <pre><code>def run_func(self, **_: Any) -&gt; Any:\n    \"\"\"\n    Execute the function logic with provided arguments.\n\n    This method must be implemented by subclasses.\n\n    :param kwargs: Arguments to pass to the function.\n    :return: Result of the function execution.\n    \"\"\"\n    raise NotImplementedError(\"run_func must be implemented by subclasses\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/function_tool/#dynamiq.nodes.tools.function_tool.function_tool","title":"<code>function_tool(func)</code>","text":"<p>Decorator to convert a function into a FunctionTool subclass.</p> <p>:param func: Function to be converted into a tool. :return: A FunctionTool subclass that wraps the provided function.</p> Source code in <code>dynamiq/nodes/tools/function_tool.py</code> <pre><code>def function_tool(func: Callable[..., T]) -&gt; type[FunctionTool[T]]:\n    \"\"\"\n    Decorator to convert a function into a FunctionTool subclass.\n\n    :param func: Function to be converted into a tool.\n    :return: A FunctionTool subclass that wraps the provided function.\n    \"\"\"\n\n    def create_input_schema(func) -&gt; type[BaseModel]:\n        signature = inspect.signature(func)\n\n        params_dict = {}\n\n        for param in signature.parameters.values():\n            if param.name == \"kwargs\" or param.name == \"config\":\n                continue\n            if param.default is inspect.Parameter.empty:\n                params_dict[param.name] = (param.annotation, ...)\n            else:\n                params_dict[param.name] = (param.annotation, param.default)\n\n        return create_model(\n            \"FunctionToolInputSchema\",\n            **params_dict,\n            __config__=ConfigDict(extra=\"allow\"),\n        )\n\n    class FunctionToolFromDecorator(FunctionTool[T]):\n        name: str = Field(default=func.__name__)\n        description: str = Field(\n            default=(func.__doc__ or \"\") + \"\\nFunction signature:\" + str(inspect.signature(func))\n            or f\"A tool for executing the {func.__name__} function with signature: {str(inspect.signature(func))}\"\n        )\n        _original_func = staticmethod(func)\n        input_schema: ClassVar[type[BaseModel]] = create_input_schema(func)\n\n        def run_func(self, input_data: BaseModel, **kwargs) -&gt; T:\n            return func(**input_data.model_dump(), **kwargs)\n\n    FunctionToolFromDecorator.__name__ = func.__name__\n    FunctionToolFromDecorator.__qualname__ = (\n        f\"FunctionToolFromDecorator({func.__name__})\"\n    )\n    FunctionToolFromDecorator.__module__ = func.__module__\n\n    return FunctionToolFromDecorator\n</code></pre>"},{"location":"dynamiq/nodes/tools/http_api_call/","title":"Http api call","text":""},{"location":"dynamiq/nodes/tools/http_api_call/#dynamiq.nodes.tools.http_api_call.HttpApiCall","title":"<code>HttpApiCall</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A component for sending API requests using requests library.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group the node belongs to.</p> <code>connection</code> <code>Http | None</code> <p>The connection based on sending http requests.A new connection is created if none is provided.</p> <code>success_codes(list[int])</code> <code>Http | None</code> <p>The list of codes when request is successful.</p> <code>timeout</code> <code>float</code> <p>The timeout in seconds.</p> <code>data(dict[str,Any])</code> <code>float</code> <p>The data to send as body of request.</p> <code>headers(dict[str,Any])</code> <code>float</code> <p>The headers of request.</p> <code>payload_type</code> <code>dict[str, Any]</code> <p>Parameter to specify the type of payload data.</p> <code>params(dict[str,Any])</code> <code>dict[str, Any]</code> <p>The additional query params of request.</p> <code>url(str)</code> <code>dict[str, Any]</code> <p>The endpoint url for sending request</p> <code>method(str)</code> <code>dict[str, Any]</code> <p>The HTTP method for sending request.</p> <code>response_type(ResponseType|str)</code> <code>dict[str, Any]</code> <p>The type of response content.</p> Source code in <code>dynamiq/nodes/tools/http_api_call.py</code> <pre><code>class HttpApiCall(ConnectionNode):\n    \"\"\"\n    A component for sending API requests using requests library.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group the node belongs to.\n        connection (HttpConnection | None): The connection based on sending http requests.A new connection\n            is created if none is provided.\n        success_codes(list[int]): The list of codes when request is successful.\n        timeout (float): The timeout in seconds.\n        data(dict[str,Any]): The data to send as body of request.\n        headers(dict[str,Any]): The headers of request.\n        payload_type (dict[str, Any]): Parameter to specify the type of payload data.\n        params(dict[str,Any]): The additional query params of request.\n        url(str): The endpoint url for sending request\n        method(str): The HTTP method for sending request.\n        response_type(ResponseType|str): The type of response content.\n    \"\"\"\n\n    name: str = \"Api Call Tool\"\n    description: str = DESCRIPTION_HTTP\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    connection: HttpConnection\n    success_codes: list[int] = [200]\n    timeout: float = 30\n    payload_type: RequestPayloadType = RequestPayloadType.RAW\n    data: dict[str, Any] = Field(default_factory=dict)\n    headers: dict[str, Any] = Field(default_factory=dict)\n    params: dict[str, Any] = Field(default_factory=dict)\n    url: str = \"\"\n    method: HTTPMethod | None = None\n    response_type: ResponseType | str | None = ResponseType.RAW\n    is_files_allowed: bool = True\n    input_schema: ClassVar[type[HttpApiCallInputSchema]] = HttpApiCallInputSchema\n\n    def execute(self, input_data: HttpApiCallInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"Execute the API call.\n\n        This method takes input data and returns content of API call response.\n\n        Args:\n            input_data (dict[str, Any]): The input data containing(optionally) data, headers, payload_type,\n                params for request.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n             dict: A dictionary with the following keys:\n                - \"content\" (bytes|string|dict[str,Any]): Value containing the result of request.\n                - \"status_code\" (int): The status code of the request.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n        logger.info(f\"Tool {self.name} - {self.id}: started with INPUT DATA:\\n\" f\"{input_data.model_dump()}\")\n\n        data = self.connection.data | self.data | input_data.data\n        payload_type = input_data.payload_type or self.payload_type\n        files = {param: file_io.getvalue() for param, file_io in input_data.files.items()}\n\n        extras = {\"data\": data} if payload_type == RequestPayloadType.RAW else {\"json\": data}\n        url = input_data.url or self.url or self.connection.url\n        if not url:\n            raise ValueError(\"No url provided.\")\n        headers = input_data.headers\n        params = input_data.params\n        method = self.method or self.connection.method\n\n        try:\n            response = self.client.request(\n                method=method,\n                url=url,\n                headers=self.connection.headers | self.headers | headers,\n                params=self.connection.params | self.params | params,\n                timeout=self.timeout,\n                files=files,\n                **extras,\n            )\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Request failed with error: {str(e)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        if response.status_code not in self.success_codes:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results.\")\n            raise ToolExecutionException(\n                f\"Request failed with unexpected status code: {response.status_code} and response: {response.text}. \"\n                f\"Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        response_type = self.response_type\n        if \"response_type\" not in self.model_fields_set and response.headers.get(\"content-type\") == \"application/json\":\n            response_type = ResponseType.JSON\n\n        if response_type == ResponseType.TEXT:\n            content = response.text\n        elif response_type == ResponseType.RAW:\n            content = response.content\n        elif response_type == ResponseType.JSON:\n            content = response.json()\n        else:\n            allowed_types = [item.value for item in ResponseType]\n            raise ValueError(\n                f\"Response type must be one of the following: {', '.join(allowed_types)}\"\n            )\n        logger.info(f\"Tool {self.name} - {self.id}: finished with RESULT:\\n\" f\"{str(content)[:200]}...\")\n        return {\"content\": content, \"status_code\": response.status_code}\n</code></pre>"},{"location":"dynamiq/nodes/tools/http_api_call/#dynamiq.nodes.tools.http_api_call.HttpApiCall.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the API call.</p> <p>This method takes input data and returns content of API call response.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>The input data containing(optionally) data, headers, payload_type, params for request.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary with the following keys: - \"content\" (bytes|string|dict[str,Any]): Value containing the result of request. - \"status_code\" (int): The status code of the request.</p> Source code in <code>dynamiq/nodes/tools/http_api_call.py</code> <pre><code>def execute(self, input_data: HttpApiCallInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"Execute the API call.\n\n    This method takes input data and returns content of API call response.\n\n    Args:\n        input_data (dict[str, Any]): The input data containing(optionally) data, headers, payload_type,\n            params for request.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n         dict: A dictionary with the following keys:\n            - \"content\" (bytes|string|dict[str,Any]): Value containing the result of request.\n            - \"status_code\" (int): The status code of the request.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n    logger.info(f\"Tool {self.name} - {self.id}: started with INPUT DATA:\\n\" f\"{input_data.model_dump()}\")\n\n    data = self.connection.data | self.data | input_data.data\n    payload_type = input_data.payload_type or self.payload_type\n    files = {param: file_io.getvalue() for param, file_io in input_data.files.items()}\n\n    extras = {\"data\": data} if payload_type == RequestPayloadType.RAW else {\"json\": data}\n    url = input_data.url or self.url or self.connection.url\n    if not url:\n        raise ValueError(\"No url provided.\")\n    headers = input_data.headers\n    params = input_data.params\n    method = self.method or self.connection.method\n\n    try:\n        response = self.client.request(\n            method=method,\n            url=url,\n            headers=self.connection.headers | self.headers | headers,\n            params=self.connection.params | self.params | params,\n            timeout=self.timeout,\n            files=files,\n            **extras,\n        )\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n        raise ToolExecutionException(\n            f\"Request failed with error: {str(e)}. Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    if response.status_code not in self.success_codes:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to get results.\")\n        raise ToolExecutionException(\n            f\"Request failed with unexpected status code: {response.status_code} and response: {response.text}. \"\n            f\"Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    response_type = self.response_type\n    if \"response_type\" not in self.model_fields_set and response.headers.get(\"content-type\") == \"application/json\":\n        response_type = ResponseType.JSON\n\n    if response_type == ResponseType.TEXT:\n        content = response.text\n    elif response_type == ResponseType.RAW:\n        content = response.content\n    elif response_type == ResponseType.JSON:\n        content = response.json()\n    else:\n        allowed_types = [item.value for item in ResponseType]\n        raise ValueError(\n            f\"Response type must be one of the following: {', '.join(allowed_types)}\"\n        )\n    logger.info(f\"Tool {self.name} - {self.id}: finished with RESULT:\\n\" f\"{str(content)[:200]}...\")\n    return {\"content\": content, \"status_code\": response.status_code}\n</code></pre>"},{"location":"dynamiq/nodes/tools/http_api_call/#dynamiq.nodes.tools.http_api_call.HttpApiCallInputSchema","title":"<code>HttpApiCallInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/tools/http_api_call.py</code> <pre><code>class HttpApiCallInputSchema(BaseModel):\n    data: dict = Field(default={}, description=\"Parameter to provide payload.\")\n    url: str = Field(default=\"\", description=\"Parameter to provide endpoint url.\")\n    payload_type: RequestPayloadType = Field(default=None, description=\"Parameter to specify the type of payload data.\")\n    headers: dict = Field(default={}, description=\"Parameter to provide headers to the request.\")\n    params: dict = Field(default={}, description=\"Parameter to provide GET parameters in URL.\")\n    files: dict[str, io.BytesIO] = Field(\n        default={},\n        description=\"Parameter to provide files to the request. Maps parameter names to file paths for file uploads. \"\n        \"Provide strings for file IDs from files.\",\n        map_from_storage=True,\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @field_validator(\"data\", \"headers\", \"params\", mode=\"before\")\n    @classmethod\n    def validate_dict_fields(cls, value: Any, field: str) -&gt; Any:\n        if isinstance(value, str):\n            try:\n                return json.loads(value or \"{}\")\n            except json.JSONDecodeError as e:\n                raise ActionParsingException(f\"Invalid JSON string provided for '{field}'. Error: {e}\")\n        elif isinstance(value, dict):\n            return value\n        else:\n            raise ActionParsingException(f\"Expected a dictionary or a JSON string for '{field}'.\")\n\n    @field_validator(\"files\", mode=\"before\")\n    @classmethod\n    def files_validator(cls, input_data: dict[str, str | bytes] | FileMappedInput):\n        \"\"\"Validate and process files.\"\"\"\n        return handle_file_upload(input_data)\n</code></pre>"},{"location":"dynamiq/nodes/tools/http_api_call/#dynamiq.nodes.tools.http_api_call.HttpApiCallInputSchema.files_validator","title":"<code>files_validator(input_data)</code>  <code>classmethod</code>","text":"<p>Validate and process files.</p> Source code in <code>dynamiq/nodes/tools/http_api_call.py</code> <pre><code>@field_validator(\"files\", mode=\"before\")\n@classmethod\ndef files_validator(cls, input_data: dict[str, str | bytes] | FileMappedInput):\n    \"\"\"Validate and process files.\"\"\"\n    return handle_file_upload(input_data)\n</code></pre>"},{"location":"dynamiq/nodes/tools/http_api_call/#dynamiq.nodes.tools.http_api_call.handle_file_upload","title":"<code>handle_file_upload(input_data)</code>","text":"<p>Handles file uploading and converts all inputs to BytesIO objects.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, str | bytes] | FileMappedInput</code> <p>Dictionary mapping parameter names to file objects to upload or FileMappedInput object.</p> required <p>Returns:</p> Type Description <code>dict[str, BytesIO]</code> <p>dict[str, io.BytesIO]: Dictionary mapping parameter names to BytesIO objects.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If invalid file data type is provided.</p> Source code in <code>dynamiq/nodes/tools/http_api_call.py</code> <pre><code>def handle_file_upload(input_data: dict[str, str | bytes] | FileMappedInput) -&gt; dict[str, io.BytesIO]:\n    \"\"\"\n    Handles file uploading and converts all inputs to BytesIO objects.\n\n    Args:\n        input_data: Dictionary mapping parameter names to file objects to upload or FileMappedInput object.\n\n    Returns:\n        dict[str, io.BytesIO]: Dictionary mapping parameter names to BytesIO objects.\n\n    Raises:\n        ValueError: If invalid file data type is provided.\n    \"\"\"\n    files_data = {}\n    if isinstance(input_data, FileMappedInput):\n        files = input_data.input\n        files_map = {getattr(f, \"name\", f\"file_{id(f)}\"): f for f in input_data.files}\n    else:\n        files = input_data\n        files_map = {}\n\n    for param_name, file in files.items():\n        if isinstance(file, bytes):\n            bytes_io = io.BytesIO(file)\n            bytes_io.name = param_name\n            files_data[param_name] = bytes_io\n        elif isinstance(file, io.BytesIO):\n            files_data[param_name] = file\n        elif isinstance(file, FileInfo):\n            bytes_io = io.BytesIO(file.content)\n            bytes_io.name = file.name\n            files_data[param_name] = bytes_io\n        elif isinstance(file, str):\n            if files_map:\n                if file in files_map:\n                    bytes_io = io.BytesIO(files_map[file].getvalue())\n                    bytes_io.name = files_map[file].name\n                    files_data[param_name] = bytes_io\n                else:\n                    raise ValueError(f\"File {file} not found in files.\")\n            else:\n                raise ValueError(\n                    f\"Error: Invalid file data type: {type(file)}. \"\n                    \"If you want to use file path from files, provide FileMappedInput object.\"\n                )\n        else:\n            raise ValueError(f\"Error: Invalid file data type: {type(file)}. Expected bytes, BytesIO, or FileInfo.\")\n\n    return files_data\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/","title":"Human feedback","text":""},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.HumanFeedbackTool","title":"<code>HumanFeedbackTool</code>","text":"<p>               Bases: <code>Node</code></p> <p>A tool for gathering user information through human feedback.</p> <p>This tool prompts the user for input and returns the response. It should be used to check actual information from the user or to gather additional input during a process.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A brief description of the tool's purpose.</p> <code>msg_template</code> <code>str</code> <p>Template of message to send.</p> <code>input_method</code> <code>FeedbackMethod | InputMethodCallable</code> <p>The method used to gather user input.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>class HumanFeedbackTool(Node):\n    \"\"\"\n    A tool for gathering user information through human feedback.\n\n    This tool prompts the user for input and returns the response. It should be used to check actual\n    information from the user or to gather additional input during a process.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group the node belongs to.\n        name (str): The name of the tool.\n        description (str): A brief description of the tool's purpose.\n        msg_template (str): Template of message to send.\n        input_method (FeedbackMethod | InputMethodCallable): The method used to gather user input.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Human Feedback Tool\"\n    description: str = \"\"\"Collects human input.\n    Use for asking clarification questions, getting user confirmation,\n    collecting missing information, or validating content.\"\"\"\n    input_method: FeedbackMethod | InputMethodCallable = FeedbackMethod.CONSOLE\n    input_schema: ClassVar[type[HumanFeedbackInputSchema]] = HumanFeedbackInputSchema\n    msg_template: str = \"{{input}}\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def update_description(self):\n        msg_template = self.msg_template\n        self.description += (\n            f\"\\nThis is the template of message to send: '{msg_template}'.\"\n            \" Parameters will be substituted based on the provided input data.\"\n        )\n        return self\n\n    def input_method_console(self, prompt: str) -&gt; str:\n        \"\"\"\n        Get input from the user using the console input method.\n\n        Args:\n            prompt (str): The prompt to display to the user.\n\n        Returns:\n            str: The user's input.\n        \"\"\"\n        return input(prompt)\n\n    def input_method_streaming(self, prompt: str, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"\n        Get input from the user using the queue streaming input method.\n\n        Args:\n            prompt (str): The prompt to display to the user.\n            config (RunnableConfig, optional): The configuration for the runnable. Defaults to None.\n\n        Returns:\n            str: The user's input.\n        \"\"\"\n        logger.debug(f\"Tool {self.name} - {self.id}: started with prompt {prompt}\")\n\n        streaming = getattr(config.nodes_override.get(self.id), \"streaming\", None) or self.streaming\n\n        event = HFStreamingOutputEventMessage(\n            wf_run_id=config.run_id,\n            entity_id=self.id,\n            data=HFStreamingOutputEventMessageData(prompt=prompt),\n            event=streaming.event,\n            source=StreamingEntitySource(\n                name=self.name,\n                group=self.group,\n                type=self.type,\n            ),\n        )\n        logger.debug(f\"Tool {self.name} - {self.id}: sending output event {event}\")\n        self.run_on_node_execute_stream(callbacks=config.callbacks, event=event, **kwargs)\n        event = self.get_input_streaming_event(\n            event_msg_type=HFStreamingInputEventMessage,\n            event=streaming.event,\n            config=config,\n        )\n        logger.debug(f\"Tool {self.name} - {self.id}: received input event {event}\")\n\n        return event.data.content\n\n    def execute(\n        self, input_data: HumanFeedbackInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the tool with the provided input data and configuration.\n\n        This method prompts the user for input using the specified input method and returns the result.\n\n        Args:\n            input_data (dict[str, Any]): The input data containing the prompt for the user.\n            config (RunnableConfig, optional): The configuration for the runnable. Defaults to None.\n            **kwargs: Additional keyword arguments to be passed to the node execute run.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the user's input under the 'content' key.\n\n        Raises:\n            ValueError: If the input_data does not contain an 'input' key.\n        \"\"\"\n        logger.debug(f\"Tool {self.name} - {self.id}: started with input data {input_data.model_dump()}\")\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        input_text = Template(self.msg_template).render(input_data.model_dump())\n\n        if isinstance(self.input_method, FeedbackMethod):\n            if self.input_method == FeedbackMethod.CONSOLE:\n                result = self.input_method_console(input_text)\n            elif self.input_method == FeedbackMethod.STREAM:\n                streaming = getattr(config.nodes_override.get(self.id), \"streaming\", None) or self.streaming\n                if not streaming.input_streaming_enabled:\n                    raise ValueError(\n                        f\"'{FeedbackMethod.STREAM}' input method requires enabled input and output streaming.\"\n                    )\n\n                result = self.input_method_streaming(prompt=input_text, config=config, **kwargs)\n            else:\n                raise ValueError(f\"Unsupported input method: {self.input_method}\")\n        else:\n            result = self.input_method.get_input(input_text)\n\n        logger.debug(f\"Tool {self.name} - {self.id}: finished with result {result}\")\n        return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.HumanFeedbackTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the tool with the provided input data and configuration.</p> <p>This method prompts the user for input using the specified input method and returns the result.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>The input data containing the prompt for the user.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the runnable. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the node execute run.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the user's input under the 'content' key.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input_data does not contain an 'input' key.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>def execute(\n    self, input_data: HumanFeedbackInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the tool with the provided input data and configuration.\n\n    This method prompts the user for input using the specified input method and returns the result.\n\n    Args:\n        input_data (dict[str, Any]): The input data containing the prompt for the user.\n        config (RunnableConfig, optional): The configuration for the runnable. Defaults to None.\n        **kwargs: Additional keyword arguments to be passed to the node execute run.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the user's input under the 'content' key.\n\n    Raises:\n        ValueError: If the input_data does not contain an 'input' key.\n    \"\"\"\n    logger.debug(f\"Tool {self.name} - {self.id}: started with input data {input_data.model_dump()}\")\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    input_text = Template(self.msg_template).render(input_data.model_dump())\n\n    if isinstance(self.input_method, FeedbackMethod):\n        if self.input_method == FeedbackMethod.CONSOLE:\n            result = self.input_method_console(input_text)\n        elif self.input_method == FeedbackMethod.STREAM:\n            streaming = getattr(config.nodes_override.get(self.id), \"streaming\", None) or self.streaming\n            if not streaming.input_streaming_enabled:\n                raise ValueError(\n                    f\"'{FeedbackMethod.STREAM}' input method requires enabled input and output streaming.\"\n                )\n\n            result = self.input_method_streaming(prompt=input_text, config=config, **kwargs)\n        else:\n            raise ValueError(f\"Unsupported input method: {self.input_method}\")\n    else:\n        result = self.input_method.get_input(input_text)\n\n    logger.debug(f\"Tool {self.name} - {self.id}: finished with result {result}\")\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.HumanFeedbackTool.input_method_console","title":"<code>input_method_console(prompt)</code>","text":"<p>Get input from the user using the console input method.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to display to the user.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The user's input.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>def input_method_console(self, prompt: str) -&gt; str:\n    \"\"\"\n    Get input from the user using the console input method.\n\n    Args:\n        prompt (str): The prompt to display to the user.\n\n    Returns:\n        str: The user's input.\n    \"\"\"\n    return input(prompt)\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.HumanFeedbackTool.input_method_streaming","title":"<code>input_method_streaming(prompt, config, **kwargs)</code>","text":"<p>Get input from the user using the queue streaming input method.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to display to the user.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the runnable. Defaults to None.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The user's input.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>def input_method_streaming(self, prompt: str, config: RunnableConfig, **kwargs) -&gt; str:\n    \"\"\"\n    Get input from the user using the queue streaming input method.\n\n    Args:\n        prompt (str): The prompt to display to the user.\n        config (RunnableConfig, optional): The configuration for the runnable. Defaults to None.\n\n    Returns:\n        str: The user's input.\n    \"\"\"\n    logger.debug(f\"Tool {self.name} - {self.id}: started with prompt {prompt}\")\n\n    streaming = getattr(config.nodes_override.get(self.id), \"streaming\", None) or self.streaming\n\n    event = HFStreamingOutputEventMessage(\n        wf_run_id=config.run_id,\n        entity_id=self.id,\n        data=HFStreamingOutputEventMessageData(prompt=prompt),\n        event=streaming.event,\n        source=StreamingEntitySource(\n            name=self.name,\n            group=self.group,\n            type=self.type,\n        ),\n    )\n    logger.debug(f\"Tool {self.name} - {self.id}: sending output event {event}\")\n    self.run_on_node_execute_stream(callbacks=config.callbacks, event=event, **kwargs)\n    event = self.get_input_streaming_event(\n        event_msg_type=HFStreamingInputEventMessage,\n        event=streaming.event,\n        config=config,\n    )\n    logger.debug(f\"Tool {self.name} - {self.id}: received input event {event}\")\n\n    return event.data.content\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.InputMethodCallable","title":"<code>InputMethodCallable</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for input methods.</p> <p>This class defines the interface for various input methods that can be used to gather user input in the HumanFeedbackTool.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>class InputMethodCallable(ABC):\n    \"\"\"\n    Abstract base class for input methods.\n\n    This class defines the interface for various input methods that can be used\n    to gather user input in the HumanFeedbackTool.\n    \"\"\"\n\n    @abstractmethod\n    def get_input(self, prompt: str, **kwargs) -&gt; str:\n        \"\"\"\n        Get input from the user.\n\n        Args:\n            prompt (str): The prompt to display to the user.\n\n        Returns:\n            str: The user's input.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.InputMethodCallable.get_input","title":"<code>get_input(prompt, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Get input from the user.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to display to the user.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The user's input.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>@abstractmethod\ndef get_input(self, prompt: str, **kwargs) -&gt; str:\n    \"\"\"\n    Get input from the user.\n\n    Args:\n        prompt (str): The prompt to display to the user.\n\n    Returns:\n        str: The user's input.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.MessageSenderTool","title":"<code>MessageSenderTool</code>","text":"<p>               Bases: <code>Node</code></p> <p>A tool for sending messages.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A brief description of the tool's purpose.</p> <code>msg_template</code> <code>str</code> <p>Template of message to send.</p> <code>output_method</code> <code>FeedbackMethod | InputMethodCallable</code> <p>The method used to gather user input.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>class MessageSenderTool(Node):\n    \"\"\"\n    A tool for sending messages.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group the node belongs to.\n        name (str): The name of the tool.\n        description (str): A brief description of the tool's purpose.\n        msg_template (str): Template of message to send.\n        output_method (FeedbackMethod | InputMethodCallable): The method used to gather user input.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Message Sender Tool\"\n    description: str = \"\"\"Sends messages to users.\n    Delivers notifications, status updates,\n    and information to users during workflow execution.\n    Use for progress updates, error notifications, or general user communication.\n    \"\"\"\n    msg_template: str = \"{{input}}\"\n    output_method: FeedbackMethod | OutputMethodCallable = FeedbackMethod.CONSOLE\n    input_schema: ClassVar[type[MessageSenderInputSchema]] = MessageSenderInputSchema\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @model_validator(mode=\"after\")\n    def update_description(self):\n        msg_template = self.msg_template\n        self.description += (\n            f\"\\nThis is the template of message to send: '{msg_template}'.\"\n            \" Parameters will be substituted based on the provided input data.\"\n        )\n        return self\n\n    def output_method_console(self, prompt: str) -&gt; None:\n        \"\"\"\n        Sends message to console.\n\n        Args:\n            prompt (str): The prompt to display to the user.\n        \"\"\"\n        print(prompt)\n\n    def output_method_streaming(self, prompt: str, config: RunnableConfig, **kwargs) -&gt; None:\n        \"\"\"\n        Sends message using streaming method.\n\n        Args:\n            prompt (str): The prompt to display to the user.\n            config (RunnableConfig, optional): The configuration for the runnable. Defaults to None.\n        \"\"\"\n        event = HFStreamingOutputEventMessage(\n            wf_run_id=config.run_id,\n            entity_id=self.id,\n            data=HFStreamingOutputEventMessageData(prompt=prompt),\n            event=self.streaming.event,\n            source=StreamingEntitySource(\n                name=self.name,\n                group=self.group,\n                type=self.type,\n            ),\n        )\n        logger.debug(f\"Tool {self.name} - {self.id}: sending output event {event}\")\n        self.run_on_node_execute_stream(callbacks=config.callbacks, event=event, **kwargs)\n\n    def execute(\n        self, input_data: MessageSenderInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the tool with the provided input data and configuration.\n\n        This method prompts the user for input using the specified input method and returns the result.\n\n        Args:\n            input_data (dict[str, Any]): The input data containing the prompt for the user.\n            config (RunnableConfig, optional): The configuration for the runnable. Defaults to None.\n            **kwargs: Additional keyword arguments to be passed to the node execute run.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the user's input under the 'content' key.\n\n        Raises:\n            ValueError: If the input_data does not contain an 'input' key.\n        \"\"\"\n        logger.debug(f\"Tool {self.name} - {self.id}: started with input data {input_data.model_dump()}\")\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n        input_text = Template(self.msg_template).render(input_data.model_dump())\n\n        if isinstance(self.output_method, FeedbackMethod):\n            if self.output_method == FeedbackMethod.CONSOLE:\n                self.output_method_console(input_text)\n            elif self.output_method == FeedbackMethod.STREAM:\n                self.output_method_streaming(prompt=input_text, config=config, **kwargs)\n            else:\n                raise ValueError(f\"Unsupported feedback method: {self.output_method}\")\n        else:\n            self.output_method.send_message(input_text)\n\n        logger.debug(f\"Tool {self.name} - {self.id}: finished\")\n        return {\"content\": input_text}\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.MessageSenderTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the tool with the provided input data and configuration.</p> <p>This method prompts the user for input using the specified input method and returns the result.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>The input data containing the prompt for the user.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the runnable. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the node execute run.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the user's input under the 'content' key.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input_data does not contain an 'input' key.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>def execute(\n    self, input_data: MessageSenderInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the tool with the provided input data and configuration.\n\n    This method prompts the user for input using the specified input method and returns the result.\n\n    Args:\n        input_data (dict[str, Any]): The input data containing the prompt for the user.\n        config (RunnableConfig, optional): The configuration for the runnable. Defaults to None.\n        **kwargs: Additional keyword arguments to be passed to the node execute run.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the user's input under the 'content' key.\n\n    Raises:\n        ValueError: If the input_data does not contain an 'input' key.\n    \"\"\"\n    logger.debug(f\"Tool {self.name} - {self.id}: started with input data {input_data.model_dump()}\")\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n    input_text = Template(self.msg_template).render(input_data.model_dump())\n\n    if isinstance(self.output_method, FeedbackMethod):\n        if self.output_method == FeedbackMethod.CONSOLE:\n            self.output_method_console(input_text)\n        elif self.output_method == FeedbackMethod.STREAM:\n            self.output_method_streaming(prompt=input_text, config=config, **kwargs)\n        else:\n            raise ValueError(f\"Unsupported feedback method: {self.output_method}\")\n    else:\n        self.output_method.send_message(input_text)\n\n    logger.debug(f\"Tool {self.name} - {self.id}: finished\")\n    return {\"content\": input_text}\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.MessageSenderTool.output_method_console","title":"<code>output_method_console(prompt)</code>","text":"<p>Sends message to console.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to display to the user.</p> required Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>def output_method_console(self, prompt: str) -&gt; None:\n    \"\"\"\n    Sends message to console.\n\n    Args:\n        prompt (str): The prompt to display to the user.\n    \"\"\"\n    print(prompt)\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.MessageSenderTool.output_method_streaming","title":"<code>output_method_streaming(prompt, config, **kwargs)</code>","text":"<p>Sends message using streaming method.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to display to the user.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for the runnable. Defaults to None.</p> required Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>def output_method_streaming(self, prompt: str, config: RunnableConfig, **kwargs) -&gt; None:\n    \"\"\"\n    Sends message using streaming method.\n\n    Args:\n        prompt (str): The prompt to display to the user.\n        config (RunnableConfig, optional): The configuration for the runnable. Defaults to None.\n    \"\"\"\n    event = HFStreamingOutputEventMessage(\n        wf_run_id=config.run_id,\n        entity_id=self.id,\n        data=HFStreamingOutputEventMessageData(prompt=prompt),\n        event=self.streaming.event,\n        source=StreamingEntitySource(\n            name=self.name,\n            group=self.group,\n            type=self.type,\n        ),\n    )\n    logger.debug(f\"Tool {self.name} - {self.id}: sending output event {event}\")\n    self.run_on_node_execute_stream(callbacks=config.callbacks, event=event, **kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.OutputMethodCallable","title":"<code>OutputMethodCallable</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for sending message.</p> <p>This class defines the interface for various output methods that can be used to send user information in the MessageSenderTool.</p> Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>class OutputMethodCallable(ABC):\n    \"\"\"\n    Abstract base class for sending message.\n\n    This class defines the interface for various output methods that can be used\n    to send user information in the MessageSenderTool.\n    \"\"\"\n\n    @abstractmethod\n    def send_message(self, message: str, **kwargs) -&gt; None:\n        \"\"\"\n        Sends message to the user\n\n        Args:\n            message (str): The message to send to the user.\n        \"\"\"\n\n        pass\n</code></pre>"},{"location":"dynamiq/nodes/tools/human_feedback/#dynamiq.nodes.tools.human_feedback.OutputMethodCallable.send_message","title":"<code>send_message(message, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Sends message to the user</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message to send to the user.</p> required Source code in <code>dynamiq/nodes/tools/human_feedback.py</code> <pre><code>@abstractmethod\ndef send_message(self, message: str, **kwargs) -&gt; None:\n    \"\"\"\n    Sends message to the user\n\n    Args:\n        message (str): The message to send to the user.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/nodes/tools/jina/","title":"Jina","text":""},{"location":"dynamiq/nodes/tools/jina/#dynamiq.nodes.tools.jina.JinaScrapeTool","title":"<code>JinaScrapeTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool for scraping web pages, powered by Jina Reader API.</p> <p>This class provides comprehensive web scraping capabilities with advanced customization options for content extraction and filtering.</p> Source code in <code>dynamiq/nodes/tools/jina.py</code> <pre><code>class JinaScrapeTool(ConnectionNode):\n    \"\"\"\n    A tool for scraping web pages, powered by Jina Reader API.\n\n    This class provides comprehensive web scraping capabilities with advanced\n    customization options for content extraction and filtering.\n    \"\"\"\n\n    SCRAPE_PATH: ClassVar[str] = \"https://r.jina.ai/\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Jina Scraper Tool\"\n    description: str = DESCRIPTION_SCRAPE\n    response_format: JinaResponseFormat = JinaResponseFormat.MARKDOWN\n    connection: Jina\n    timeout: int = 60\n    url: str | None = Field(None, description=\"URL to scrape\")\n\n    # Advanced options\n    target_selector: str | None = Field(None, description=\"CSS selector to focus on specific elements\")\n    remove_selector: str | None = Field(None, description=\"CSS selector to exclude elements\")\n    include_links: bool = Field(default=False, description=\"Include links summary\")\n    include_images: bool = Field(default=False, description=\"Include images summary\")\n    generate_alt_text: bool = Field(default=True, description=\"Generate alt text for images\")\n    engine: str = Field(default=\"direct\", description=\"Engine: 'browser' or 'direct'\")\n    no_cache: bool = Field(default=False, description=\"Bypass cache\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[JinaScrapeInputSchema]] = JinaScrapeInputSchema\n\n    def _build_headers(self, input_data: JinaScrapeInputSchema) -&gt; dict[str, str]:\n        \"\"\"Build request headers based on configuration and input parameters.\"\"\"\n        headers = {\n            **self.connection.headers,\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"X-Timeout\": str(self.timeout),\n        }\n\n        if self.response_format != JinaResponseFormat.DEFAULT:\n            headers[\"X-Return-Format\"] = self.response_format.value\n\n        engine = input_data.engine or self.engine\n        if engine in [\"browser\", \"direct\", \"cf-browser-rendering\"]:\n            headers[\"X-Engine\"] = engine\n\n        target_selector = input_data.target_selector or self.target_selector\n        if target_selector:\n            headers[\"X-Target-Selector\"] = target_selector\n\n        remove_selector = input_data.remove_selector or self.remove_selector\n        if remove_selector:\n            headers[\"X-Remove-Selector\"] = remove_selector\n\n        include_links = input_data.include_links if input_data.include_links is not None else self.include_links\n        if include_links:\n            headers[\"X-With-Links-Summary\"] = \"true\"\n\n        include_images = input_data.include_images if input_data.include_images is not None else self.include_images\n        if include_images:\n            headers[\"X-With-Images-Summary\"] = \"true\"\n\n        generate_alt = (\n            input_data.generate_alt_text if input_data.generate_alt_text is not None else self.generate_alt_text\n        )\n        if generate_alt:\n            headers[\"X-With-Generated-Alt\"] = \"true\"\n\n        if self.no_cache:\n            headers[\"X-No-Cache\"] = \"true\"\n\n        return headers\n\n    def _build_request_body(self, input_data: JinaScrapeInputSchema) -&gt; dict[str, Any]:\n        \"\"\"Build request body according to Jina Reader API specification.\"\"\"\n        url = input_data.url or self.url\n        if not url:\n            raise ToolExecutionException(\n                \"No URL provided. Please provide a URL either during node initialization or execution.\",\n                recoverable=True,\n            )\n\n        return {\"url\": url}\n\n    def _parse_response(self, response_data: dict) -&gt; tuple[str, dict, dict]:\n        \"\"\"Parse Jina API response and extract content, links, and images.\"\"\"\n        if \"data\" not in response_data:\n            raise ToolExecutionException(\n                \"Invalid response format from Jina API - missing 'data' field\",\n                recoverable=True,\n            )\n\n        data = response_data[\"data\"]\n        content = data.get(\"content\", \"\")\n        links = data.get(\"links\", {})\n        images = data.get(\"images\", {})\n\n        return content, links, images\n\n    def execute(self, input_data: JinaScrapeInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the web scraping process using the Jina Reader API.\n\n        Args:\n            input_data (JinaScrapeInputSchema): Input data for the tool\n            config (RunnableConfig, optional): Configuration for the runnable\n            **kwargs: Additional arguments\n\n        Returns:\n            dict[str, Any]: Dictionary containing the scraped content and metadata\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        headers = self._build_headers(input_data)\n        request_body = self._build_request_body(input_data)\n\n        try:\n            response = self.client.request(\n                method=\"POST\",\n                url=self.SCRAPE_PATH,\n                headers=headers,\n                json=request_body,\n            )\n            response.raise_for_status()\n\n            if self.response_format in [JinaResponseFormat.PAGESHOT, JinaResponseFormat.SCREENSHOT]:\n                scrape_result = response.content\n                links, images = {}, {}\n            else:\n                response_data = response.json()\n                scrape_result, links, images = self._parse_response(response_data)\n\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {e}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to execute the requested action. \"\n                f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        url = request_body[\"url\"]\n\n        if self.is_optimized_for_agents:\n            result_parts = [f\"## Source URL\\n{url}\", f\"## Scraped Content\\n\\n{scrape_result}\"]\n\n            if links:\n                links_list = [f\"- [{text}]({url})\" for text, url in links.items()]\n                result_parts.append(\"## Links Found\\n\" + \"\\n\".join(links_list))\n\n            if images:\n                images_list = [f\"- {desc}: {url}\" for desc, url in images.items()]\n                result_parts.append(\"## Images Found\\n\" + \"\\n\".join(images_list))\n\n            result = \"\\n\\n\".join(result_parts)\n        else:\n            result = {\n                \"url\": url,\n                \"content\": scrape_result,\n                \"links\": links,\n                \"images\": images,\n                \"metadata\": {\n                    \"response_format\": self.response_format.value,\n                    \"engine_used\": headers.get(\"X-Engine\", \"direct\"),\n                    \"target_selector\": headers.get(\"X-Target-Selector\"),\n                    \"remove_selector\": headers.get(\"X-Remove-Selector\"),\n                },\n            }\n\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n        return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/jina/#dynamiq.nodes.tools.jina.JinaScrapeTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the web scraping process using the Jina Reader API.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>JinaScrapeInputSchema</code> <p>Input data for the tool</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing the scraped content and metadata</p> Source code in <code>dynamiq/nodes/tools/jina.py</code> <pre><code>def execute(self, input_data: JinaScrapeInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the web scraping process using the Jina Reader API.\n\n    Args:\n        input_data (JinaScrapeInputSchema): Input data for the tool\n        config (RunnableConfig, optional): Configuration for the runnable\n        **kwargs: Additional arguments\n\n    Returns:\n        dict[str, Any]: Dictionary containing the scraped content and metadata\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    headers = self._build_headers(input_data)\n    request_body = self._build_request_body(input_data)\n\n    try:\n        response = self.client.request(\n            method=\"POST\",\n            url=self.SCRAPE_PATH,\n            headers=headers,\n            json=request_body,\n        )\n        response.raise_for_status()\n\n        if self.response_format in [JinaResponseFormat.PAGESHOT, JinaResponseFormat.SCREENSHOT]:\n            scrape_result = response.content\n            links, images = {}, {}\n        else:\n            response_data = response.json()\n            scrape_result, links, images = self._parse_response(response_data)\n\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {e}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to execute the requested action. \"\n            f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    url = request_body[\"url\"]\n\n    if self.is_optimized_for_agents:\n        result_parts = [f\"## Source URL\\n{url}\", f\"## Scraped Content\\n\\n{scrape_result}\"]\n\n        if links:\n            links_list = [f\"- [{text}]({url})\" for text, url in links.items()]\n            result_parts.append(\"## Links Found\\n\" + \"\\n\".join(links_list))\n\n        if images:\n            images_list = [f\"- {desc}: {url}\" for desc, url in images.items()]\n            result_parts.append(\"## Images Found\\n\" + \"\\n\".join(images_list))\n\n        result = \"\\n\\n\".join(result_parts)\n    else:\n        result = {\n            \"url\": url,\n            \"content\": scrape_result,\n            \"links\": links,\n            \"images\": images,\n            \"metadata\": {\n                \"response_format\": self.response_format.value,\n                \"engine_used\": headers.get(\"X-Engine\", \"direct\"),\n                \"target_selector\": headers.get(\"X-Target-Selector\"),\n                \"remove_selector\": headers.get(\"X-Remove-Selector\"),\n            },\n        }\n\n    logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/jina/#dynamiq.nodes.tools.jina.JinaSearchTool","title":"<code>JinaSearchTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool for performing web searches using the Jina AI API.</p> <p>This tool accepts various search parameters and returns relevant search results.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group to which this tool belongs.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A brief description of the tool.</p> <code>connection</code> <code>Jina</code> <p>The connection instance for the Jina API.</p> <code>query</code> <code>Optional[str]</code> <p>The search query, can be set during initialization.</p> <code>max_results</code> <code>int</code> <p>Maximum number of results to return.</p> <code>country</code> <code>Optional[str]</code> <p>Two-letter country code for search region.</p> <code>location</code> <code>Optional[str]</code> <p>Geographic location for search origin.</p> <code>language</code> <code>Optional[str]</code> <p>Two-letter language code for results.</p> <code>page</code> <code>int</code> <p>Page offset for pagination.</p> <code>site</code> <code>Optional[str]</code> <p>Domain to limit search to.</p> <code>return_format</code> <code>JinaResponseFormat</code> <p>Response format preference.</p> <code>include_images</code> <code>bool</code> <p>Include images in search results.</p> <code>include_links</code> <code>bool</code> <p>Include link summaries.</p> <code>include_favicons</code> <code>bool</code> <p>Include SERP favicons.</p> <code>include_favicon</code> <code>bool</code> <p>Include individual page favicon.</p> <code>include_full_content</code> <code>bool</code> <p>Include full content of search results.</p> <code>no_cache</code> <code>bool</code> <p>Bypass cache for real-time data.</p> <code>generate_alt_text</code> <code>bool</code> <p>Generate alt text for images.</p> <code>timeout</code> <code>Optional[int]</code> <p>Request timeout in seconds.</p> <code>locale</code> <code>Optional[str]</code> <p>Browser locale setting.</p> <code>cookies</code> <code>Optional[str]</code> <p>Custom cookie settings.</p> <code>proxy_url</code> <code>Optional[str]</code> <p>Proxy URL for requests.</p> Source code in <code>dynamiq/nodes/tools/jina.py</code> <pre><code>class JinaSearchTool(ConnectionNode):\n    \"\"\"\n      A tool for performing web searches using the Jina AI API.\n\n      This tool accepts various search parameters and returns relevant search results.\n\n    Attributes:\n          group (Literal[NodeGroup.TOOLS]): The group to which this tool belongs.\n          name (str): The name of the tool.\n          description (str): A brief description of the tool.\n          connection (Jina): The connection instance for the Jina API.\n          query (Optional[str]): The search query, can be set during initialization.\n          max_results (int): Maximum number of results to return.\n          country (Optional[str]): Two-letter country code for search region.\n          location (Optional[str]): Geographic location for search origin.\n          language (Optional[str]): Two-letter language code for results.\n          page (int): Page offset for pagination.\n          site (Optional[str]): Domain to limit search to.\n          return_format (JinaResponseFormat): Response format preference.\n          include_images (bool): Include images in search results.\n          include_links (bool): Include link summaries.\n          include_favicons (bool): Include SERP favicons.\n          include_favicon (bool): Include individual page favicon.\n          include_full_content (bool): Include full content of search results.\n          no_cache (bool): Bypass cache for real-time data.\n          generate_alt_text (bool): Generate alt text for images.\n          timeout (Optional[int]): Request timeout in seconds.\n          locale (Optional[str]): Browser locale setting.\n          cookies (Optional[str]): Custom cookie settings.\n          proxy_url (Optional[str]): Proxy URL for requests.\n    \"\"\"\n\n    SEARCH_PATH: ClassVar[str] = \"https://s.jina.ai/\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Jina Search Tool\"\n    description: str = DESCRIPTION_SEARCH\n    connection: Jina\n    query: str | None = Field(None, description=\"Search query\")\n    max_results: int = Field(default=5, ge=1, le=100, description=\"Maximum number of search results\")\n\n    country: str | None = Field(None, description=\"Two-letter country code (e.g., 'US', 'GB')\")\n    location: str | None = Field(None, description=\"Geographic location for search origin\")\n    language: str | None = Field(None, description=\"Two-letter language code (e.g., 'en', 'es')\")\n\n    page: int = Field(default=0, ge=0, description=\"Page offset for pagination\")\n\n    site: str | None = Field(None, description=\"Domain to limit search to\")\n    return_format: JinaResponseFormat = Field(default=JinaResponseFormat.DEFAULT, description=\"Response format\")\n\n    include_images: bool = Field(default=False, description=\"Include images in search results\")\n    include_links: bool = Field(default=False, description=\"Include link summaries\")\n    include_favicons: bool = Field(default=False, description=\"Include SERP favicons\")\n    include_favicon: bool = Field(default=False, description=\"Include individual page favicon\")\n    include_full_content: bool = Field(default=False, description=\"Include full content of results\")\n\n    no_cache: bool = Field(default=False, description=\"Bypass cache for real-time data\")\n    generate_alt_text: bool = Field(default=False, description=\"Generate alt text for images\")\n    timeout: int | None = Field(None, description=\"Request timeout in seconds\")\n    locale: str | None = Field(None, description=\"Browser locale setting\")\n    cookies: str | None = Field(None, description=\"Custom cookie settings\")\n    proxy_url: str | None = Field(None, description=\"Proxy URL for requests\")\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    input_schema: ClassVar[type[JinaSearchInputSchema]] = JinaSearchInputSchema\n\n    def _build_headers(self, input_data: JinaSearchInputSchema) -&gt; dict[str, str]:\n        \"\"\"Build request headers based on configuration and input parameters.\"\"\"\n        headers = {\n            **self.connection.headers,\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n        }\n\n        site = input_data.site or self.site\n        if site:\n            headers[\"X-Site\"] = site\n\n        include_links = input_data.include_links if input_data.include_links is not None else self.include_links\n        if include_links:\n            headers[\"X-With-Links-Summary\"] = \"true\"\n\n        include_images = input_data.include_images if input_data.include_images is not None else self.include_images\n        if include_images:\n            headers[\"X-With-Images-Summary\"] = \"true\"\n        else:\n            headers[\"X-Retain-Images\"] = \"none\"\n\n        no_cache = input_data.no_cache if input_data.no_cache is not None else self.no_cache\n        if no_cache:\n            headers[\"X-No-Cache\"] = \"true\"\n\n        generate_alt = (\n            input_data.generate_alt_text if input_data.generate_alt_text is not None else self.generate_alt_text\n        )\n        if generate_alt:\n            headers[\"X-With-Generated-Alt\"] = \"true\"\n\n        include_full = (\n            input_data.include_full_content\n            if input_data.include_full_content is not None\n            else self.include_full_content\n        )\n        if not include_full:\n            headers[\"X-Respond-With\"] = \"no-content\"\n\n        include_favicon = input_data.include_favicon if input_data.include_favicon is not None else self.include_favicon\n        if include_favicon:\n            headers[\"X-With-Favicon\"] = \"true\"\n\n        return_format = input_data.return_format or self.return_format\n        if return_format != JinaResponseFormat.DEFAULT:\n            headers[\"X-Return-Format\"] = return_format.value\n\n        if include_full:\n            headers[\"X-Engine\"] = \"browser\"\n        else:\n            headers[\"X-Engine\"] = \"direct\"\n\n        include_favicons = (\n            input_data.include_favicons if input_data.include_favicons is not None else self.include_favicons\n        )\n        if include_favicons:\n            headers[\"X-With-Favicons\"] = \"true\"\n\n        timeout = input_data.timeout or self.timeout\n        if timeout:\n            headers[\"X-Timeout\"] = str(timeout)\n\n        cookies = input_data.cookies or self.cookies\n        if cookies:\n            headers[\"X-Set-Cookie\"] = cookies\n\n        proxy_url = input_data.proxy_url or self.proxy_url\n        if proxy_url:\n            headers[\"X-Proxy-Url\"] = proxy_url\n\n        locale = input_data.locale or self.locale\n        if locale:\n            headers[\"X-Locale\"] = locale\n\n        return headers\n\n    def _build_request_body(self, input_data: JinaSearchInputSchema) -&gt; dict[str, Any]:\n        \"\"\"Build request body according to Jina API specification.\"\"\"\n        query = input_data.query or self.query\n        if not query:\n            raise ToolExecutionException(\n                \"No query provided. Please provide a query either during node initialization or execution.\",\n                recoverable=True,\n            )\n\n        body = {\"q\": query}\n\n        max_results = input_data.max_results or self.max_results\n        if max_results:\n            body[\"num\"] = max_results\n\n        country = input_data.country or self.country\n        if country:\n            body[\"gl\"] = country\n\n        location = input_data.location or self.location\n        if location:\n            body[\"location\"] = location\n\n        language = input_data.language or self.language\n        if language:\n            body[\"hl\"] = language\n\n        page = input_data.page if input_data.page is not None else self.page\n        if page &gt; 0:\n            body[\"page\"] = page\n\n        return body\n\n    def _format_search_results(self, results: dict[str, Any]) -&gt; str:\n        \"\"\"Format the search results into a readable string format.\"\"\"\n        formatted_results = []\n        for result in results.get(\"data\", []):\n            formatted_results.extend(\n                [\n                    f\"Source: {result.get('url')}\",\n                    f\"Title: {result.get('title')}\",\n                    f\"Description: {result.get('description')}\",\n                    *(\n                        [f\"Content: {result.get('content')}\"]\n                        if self.include_full_content and result.get(\"content\")\n                        else []\n                    ),\n                    \"\",\n                ]\n            )\n        return \"\\n\".join(formatted_results).strip()\n\n    def execute(self, input_data: JinaSearchInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the web search process with full API parameter support.\n\n        Args:\n            input_data (JinaSearchInputSchema): Input data with search parameters.\n            config (RunnableConfig, optional): Configuration for the runnable.\n            **kwargs: Additional arguments passed to the execution context.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the search results.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        headers = self._build_headers(input_data)\n        request_body = self._build_request_body(input_data)\n\n        try:\n            response = self.client.request(\n                method=\"POST\",\n                url=self.SEARCH_PATH,\n                headers=headers,\n                json=request_body,\n            )\n            response.raise_for_status()\n            search_result = response.json()\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {e}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to retrieve search results. \"\n                f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        formatted_results = self._format_search_results(search_result)\n        sources_with_url = [f\"[{result.get('title')}]({result.get('url')})\" for result in search_result.get(\"data\", [])]\n\n        if self.is_optimized_for_agents:\n            result = (\n                \"## Sources with URLs\\n\"\n                + \"\\n\".join(sources_with_url)\n                + f\"\\n\\n## Search results for query '{request_body['q']}'\\n\"\n                + formatted_results\n            )\n        else:\n            images = {}\n            for d in search_result.get(\"data\", []):\n                images.update(d.get(\"images\", {}))\n\n            result = {\n                \"result\": formatted_results,\n                \"sources_with_url\": sources_with_url,\n                \"raw_response\": search_result,\n                \"images\": images,\n                \"query\": request_body[\"q\"],\n                \"request_body\": request_body,\n                \"headers_used\": {k: v for k, v in headers.items() if k.startswith(\"X-\")},\n            }\n\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n        return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/jina/#dynamiq.nodes.tools.jina.JinaSearchTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the web search process with full API parameter support.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>JinaSearchInputSchema</code> <p>Input data with search parameters.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the execution context.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the search results.</p> Source code in <code>dynamiq/nodes/tools/jina.py</code> <pre><code>def execute(self, input_data: JinaSearchInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the web search process with full API parameter support.\n\n    Args:\n        input_data (JinaSearchInputSchema): Input data with search parameters.\n        config (RunnableConfig, optional): Configuration for the runnable.\n        **kwargs: Additional arguments passed to the execution context.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the search results.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    headers = self._build_headers(input_data)\n    request_body = self._build_request_body(input_data)\n\n    try:\n        response = self.client.request(\n            method=\"POST\",\n            url=self.SEARCH_PATH,\n            headers=headers,\n            json=request_body,\n        )\n        response.raise_for_status()\n        search_result = response.json()\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {e}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to retrieve search results. \"\n            f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    formatted_results = self._format_search_results(search_result)\n    sources_with_url = [f\"[{result.get('title')}]({result.get('url')})\" for result in search_result.get(\"data\", [])]\n\n    if self.is_optimized_for_agents:\n        result = (\n            \"## Sources with URLs\\n\"\n            + \"\\n\".join(sources_with_url)\n            + f\"\\n\\n## Search results for query '{request_body['q']}'\\n\"\n            + formatted_results\n        )\n    else:\n        images = {}\n        for d in search_result.get(\"data\", []):\n            images.update(d.get(\"images\", {}))\n\n        result = {\n            \"result\": formatted_results,\n            \"sources_with_url\": sources_with_url,\n            \"raw_response\": search_result,\n            \"images\": images,\n            \"query\": request_body[\"q\"],\n            \"request_body\": request_body,\n            \"headers_used\": {k: v for k, v in headers.items() if k.startswith(\"X-\")},\n        }\n\n    logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/llm_summarizer/","title":"Llm summarizer","text":""},{"location":"dynamiq/nodes/tools/llm_summarizer/#dynamiq.nodes.tools.llm_summarizer.SummarizerTool","title":"<code>SummarizerTool</code>","text":"<p>               Bases: <code>Node</code></p> <p>A tool for summarizing and cleaning up text extracted from HTML.</p> <p>This tool processes input text, typically extracted from HTML, by removing unnecessary content, cleaning up the remaining text, and formatting it into a coherent and well-organized summary.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group this node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A description of the tool's functionality.</p> <code>llm</code> <code>Node</code> <p>The language model node used for text processing.</p> <code>chunk_size</code> <code>int</code> <p>The maximum number of words in each chunk for processing.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Configuration for error handling.</p> <code>prompt_template</code> <code>str</code> <p>The prompt template used for text summarization.</p> Source code in <code>dynamiq/nodes/tools/llm_summarizer.py</code> <pre><code>class SummarizerTool(Node):\n    \"\"\"\n    A tool for summarizing and cleaning up text extracted from HTML.\n\n    This tool processes input text, typically extracted from HTML, by removing unnecessary content,\n    cleaning up the remaining text, and formatting it into a coherent and well-organized summary.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group this node belongs to.\n        name (str): The name of the tool.\n        description (str): A description of the tool's functionality.\n        llm (Node): The language model node used for text processing.\n        chunk_size (int): The maximum number of words in each chunk for processing.\n        error_handling (ErrorHandling): Configuration for error handling.\n        prompt_template (str): The prompt template used for text summarization.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Summarizer Tool\"\n    description: str = \"\"\"Summarizes and cleans up text content using LLM with automatic chunking and noise removal.\n\nKey Capabilities:\n- Intelligent text cleanup removing navigation, buttons, footers\n- Automatic chunking for large documents (4000 words default)\n- LLM-powered summarization with customizable prompts\n- Content structuring with proper headings and formatting\n\nUsage Strategy:\n- Process scraped web content for analysis\n- Clean up extracted HTML text for readability\n- Generate structured summaries from unformatted content\n- Remove noise and irrelevant elements from text data\n\nParameter Guide:\n- input: Raw text content to be summarized and cleaned\n\"\"\"\n    llm: Node\n    chunk_size: int = Field(default=4000, description=\"The maximum number of words in each chunk\")\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=600))\n    prompt_template: str = Field(\n        default=PROMPT_TEMPLATE_SUMMARIZER,\n        description=\"The prompt template for the summarizer\",\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[SummarizerInputSchema]] = SummarizerInputSchema\n\n    def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n        \"\"\"\n        Initialize the components of the tool.\n\n        Args:\n            connection_manager (ConnectionManager, optional): connection manager. Defaults to ConnectionManager.\n        \"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n        if self.llm.is_postponed_component_init:\n            self.llm.init_components(connection_manager)\n\n    def reset_run_state(self):\n        \"\"\"\n        Reset the intermediate steps (run_depends) of the node.\n        \"\"\"\n        self._run_depends = []\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict:\n        \"\"\"\n        Property to define which parameters should be excluded when converting the class instance to a dictionary.\n\n        Returns:\n            dict: A dictionary defining the parameters to exclude.\n        \"\"\"\n        return super().to_dict_exclude_params | {\"llm\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"\n        Convert the tool to a dictionary representation.\n\n        Args:\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary representation of the tool.\n        \"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"llm\"] = self.llm.to_dict(**kwargs)\n        return data\n\n    def _process_chunk(self, chunk: str, config: RunnableConfig, **kwargs) -&gt; str:\n        \"\"\"\n        Process a single chunk of text using the language model.\n\n        Args:\n            chunk (str): The text chunk to process.\n            config (RunnableConfig): The configuration for running the model.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            str: The processed text chunk.\n\n        Raises:\n            ValueError: If the language model execution fails.\n        \"\"\"\n        prompt = self.prompt_template.format(input=chunk)\n        result = self.llm.run(\n            input_data={},\n            prompt=Prompt(messages=[Message(role=\"user\", content=prompt)]),\n            config=config,\n            **(kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}),\n        )\n        self._run_depends = [NodeDependency(node=self.llm).to_dict(for_tracing=True)]\n        if result.status != RunnableStatus.SUCCESS:\n            raise ValueError(\"LLM execution failed\")\n        return result.output[\"content\"]\n\n    def execute(\n        self, input_data: SummarizerInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the summarization tool on the input data.\n\n        This method processes the input text, potentially breaking it into chunks if it exceeds\n        the specified chunk size, and then summarizes each chunk using the language model.\n\n        Args:\n            input_data (dict[str, Any]): A dictionary containing the input text under the 'input' key.\n            config (RunnableConfig, optional): The configuration for running the tool.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the summarized content under the 'content' key.\n\n        Raises:\n            ValueError: If the input_data does not contain an 'input' key.\n        \"\"\"\n        config = ensure_config(config)\n        self.reset_run_state()\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        input_text = input_data.input\n        logger.debug(\n            f\"Tool {self.name} - {self.id}: started with input text length: {len(input_text)}, \"\n            f\"word count: {len(input_text.split())}\"\n        )\n\n        words = input_text.split()\n        if len(words) &gt; self.chunk_size:\n            content_chunks = [\n                \" \".join(words[i : i + self.chunk_size])\n                for i in range(0, len(words), self.chunk_size)\n            ]\n            summaries = [self._process_chunk(chunk, config, **kwargs) for chunk in content_chunks]\n            summary = \"\\n\".join(summaries)\n        else:\n            summary = self._process_chunk(input_text, config, **kwargs)\n\n        logger.debug(\n            f\"Tool {self.name} - {self.id}: finished with result length: {len(summary)}, \"\n            f\"word count: {len(summary.split())}\"\n        )\n        return {\"content\": summary}\n</code></pre>"},{"location":"dynamiq/nodes/tools/llm_summarizer/#dynamiq.nodes.tools.llm_summarizer.SummarizerTool.to_dict_exclude_params","title":"<code>to_dict_exclude_params: dict</code>  <code>property</code>","text":"<p>Property to define which parameters should be excluded when converting the class instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary defining the parameters to exclude.</p>"},{"location":"dynamiq/nodes/tools/llm_summarizer/#dynamiq.nodes.tools.llm_summarizer.SummarizerTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the summarization tool on the input data.</p> <p>This method processes the input text, potentially breaking it into chunks if it exceeds the specified chunk size, and then summarizes each chunk using the language model.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>A dictionary containing the input text under the 'input' key.</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for running the tool.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the summarized content under the 'content' key.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input_data does not contain an 'input' key.</p> Source code in <code>dynamiq/nodes/tools/llm_summarizer.py</code> <pre><code>def execute(\n    self, input_data: SummarizerInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the summarization tool on the input data.\n\n    This method processes the input text, potentially breaking it into chunks if it exceeds\n    the specified chunk size, and then summarizes each chunk using the language model.\n\n    Args:\n        input_data (dict[str, Any]): A dictionary containing the input text under the 'input' key.\n        config (RunnableConfig, optional): The configuration for running the tool.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the summarized content under the 'content' key.\n\n    Raises:\n        ValueError: If the input_data does not contain an 'input' key.\n    \"\"\"\n    config = ensure_config(config)\n    self.reset_run_state()\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    input_text = input_data.input\n    logger.debug(\n        f\"Tool {self.name} - {self.id}: started with input text length: {len(input_text)}, \"\n        f\"word count: {len(input_text.split())}\"\n    )\n\n    words = input_text.split()\n    if len(words) &gt; self.chunk_size:\n        content_chunks = [\n            \" \".join(words[i : i + self.chunk_size])\n            for i in range(0, len(words), self.chunk_size)\n        ]\n        summaries = [self._process_chunk(chunk, config, **kwargs) for chunk in content_chunks]\n        summary = \"\\n\".join(summaries)\n    else:\n        summary = self._process_chunk(input_text, config, **kwargs)\n\n    logger.debug(\n        f\"Tool {self.name} - {self.id}: finished with result length: {len(summary)}, \"\n        f\"word count: {len(summary.split())}\"\n    )\n    return {\"content\": summary}\n</code></pre>"},{"location":"dynamiq/nodes/tools/llm_summarizer/#dynamiq.nodes.tools.llm_summarizer.SummarizerTool.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the tool.</p> <p>Parameters:</p> Name Type Description Default <code>connection_manager</code> <code>ConnectionManager</code> <p>connection manager. Defaults to ConnectionManager.</p> <code>None</code> Source code in <code>dynamiq/nodes/tools/llm_summarizer.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n    \"\"\"\n    Initialize the components of the tool.\n\n    Args:\n        connection_manager (ConnectionManager, optional): connection manager. Defaults to ConnectionManager.\n    \"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n    if self.llm.is_postponed_component_init:\n        self.llm.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/tools/llm_summarizer/#dynamiq.nodes.tools.llm_summarizer.SummarizerTool.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Reset the intermediate steps (run_depends) of the node.</p> Source code in <code>dynamiq/nodes/tools/llm_summarizer.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"\n    Reset the intermediate steps (run_depends) of the node.\n    \"\"\"\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/tools/llm_summarizer/#dynamiq.nodes.tools.llm_summarizer.SummarizerTool.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Convert the tool to a dictionary representation.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the tool.</p> Source code in <code>dynamiq/nodes/tools/llm_summarizer.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"\n    Convert the tool to a dictionary representation.\n\n    Args:\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary representation of the tool.\n    \"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"llm\"] = self.llm.to_dict(**kwargs)\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/","title":"Mcp","text":""},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPServer","title":"<code>MCPServer</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool that manages connections to MCP servers and initializes MCP tools.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>Node group.</p> <code>name</code> <code>str</code> <p>Node name.</p> <code>description</code> <code>str</code> <p>Node description.</p> <code>connection</code> <code>MCPSse | MCPStdio | MCPStreamableHTTP</code> <p>Connection module for the MCP server.</p> <code>include_tools</code> <code>list[str]</code> <p>Names of tools to include. If empty, all tools are included.</p> <code>exclude_tools</code> <code>list[str]</code> <p>Names of tools to exclude.</p> <code>_mcp_tools</code> <code>dict[str, MCPTool]</code> <p>Internal dict of initialized MCP tools.</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>class MCPServer(ConnectionNode):\n    \"\"\"\n    A tool that manages connections to MCP servers and initializes MCP tools.\n\n    Attributes:\n      group (Literal[NodeGroup.TOOLS]): Node group.\n      name (str): Node name.\n      description (str): Node description.\n      connection (MCPSse | MCPStdio | MCPStreamableHTTP): Connection module for the MCP server.\n      include_tools (list[str]): Names of tools to include. If empty, all tools are included.\n      exclude_tools (list[str]): Names of tools to exclude.\n      _mcp_tools (dict[str, MCPTool]): Internal dict of initialized MCP tools.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"MCP Tool\"\n    description: str = \"\"\"Model Context Server integration for\n    dynamic tool discovery and external service connectivity.\n\nKey Capabilities:\n- Dynamic tool discovery and initialization from MCP servers\n- Support for multiple connection types (SSE, stdio, HTTP streaming)\n- Automatic schema generation from MCP tool definitions\n- Tool filtering and selection with include/exclude lists\n\nUsage Strategy:\n- Integrate with external services via MCP protocol\n- Access remote tools and APIs through standardized interface\n- Build distributed tool ecosystems across services\n- Extend workflow capabilities with external service tools\n\"\"\"  # noqa: E501\n    connection: MCPSse | MCPStdio | MCPStreamableHTTP\n\n    include_tools: list[str] = field(default_factory=list)\n    exclude_tools: list[str] = field(default_factory=list)\n    _mcp_tools: dict[str, MCPTool] = PrivateAttr(default_factory=dict)\n\n    async def initialize_tools(self):\n        \"\"\"\n        Initializes the MCP tool list from the client session.\n\n        Returns:\n            None\n        \"\"\"\n        try:\n            async with self.connection.connect() as result:\n                read, write = result[:2]\n                async with ClientSession(read, write) as session:\n                    await session.initialize()\n                    tools = await session.list_tools()\n                    for tool in tools.tools:\n                        self._mcp_tools[tool.name] = MCPTool(\n                            name=tool.name,\n                            description=tool.description or \"MCP Tool\",\n                            json_input_schema=tool.inputSchema,\n                            connection=self.connection,\n                            server_metadata=ServerMetadata(id=self.id, name=self.name, description=self.description),\n                        )\n\n            logger.info(f\"Tool {self.name}: {len(self._mcp_tools)} MCP tools initialized from a server.\")\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to initialize session. Error: {str(e)}\")\n            raise ToolExecutionException(f\"Tool {self.name} - {self.id}: failed to initialize session. Error: {str(e)}\")\n\n    def get_mcp_tools(self, select_all: bool = False) -&gt; list[MCPTool]:\n        \"\"\"\n        Synchronously fetches and initializes MCP tools if not already available.\n\n        Args:\n            select_all (bool): If True, returns all tools regardless of filtering.\n\n        Returns:\n            list[MCPTool]: A list of initialized MCPTool instances.\n        \"\"\"\n        if is_called_from_async_context():\n            with ThreadPoolExecutor() as executor:\n                future = executor.submit(lambda: asyncio.run(self.get_mcp_tools_async(select_all=select_all)))\n                return future.result()\n        return asyncio.run(self.get_mcp_tools_async(select_all=select_all))\n\n    async def get_mcp_tools_async(self, select_all: bool = False) -&gt; list[MCPTool]:\n        \"\"\"\n        Asynchronously fetches and initializes MCP tools if not already available.\n\n        Args:\n            select_all (bool): If True, returns all tools regardless of filtering.\n\n        Returns:\n            list[MCPTool]: A list of initialized MCPTool instances.\n        \"\"\"\n        if not self._mcp_tools:\n            await self.initialize_tools()\n\n        if select_all or not self.include_tools and not self.exclude_tools:\n            return list(self._mcp_tools.values())\n\n        if self.include_tools:\n            return [v for k, v in self._mcp_tools.items() if k in self.include_tools and k not in self.exclude_tools]\n\n        return [v for k, v in self._mcp_tools.items() if k not in self.exclude_tools]\n\n    def execute(self, **kwargs):\n        \"\"\"\n        Disabled for the MCP server. Use `get_mcp_tools()` to access individual tools.\n\n        Raises:\n            NotImplementedError: Always, because this method is not supported.\n        \"\"\"\n        raise NotImplementedError(\"Use `get_mcp_tools()` to access individual tool instances.\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPServer.execute","title":"<code>execute(**kwargs)</code>","text":"<p>Disabled for the MCP server. Use <code>get_mcp_tools()</code> to access individual tools.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Always, because this method is not supported.</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>def execute(self, **kwargs):\n    \"\"\"\n    Disabled for the MCP server. Use `get_mcp_tools()` to access individual tools.\n\n    Raises:\n        NotImplementedError: Always, because this method is not supported.\n    \"\"\"\n    raise NotImplementedError(\"Use `get_mcp_tools()` to access individual tool instances.\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPServer.get_mcp_tools","title":"<code>get_mcp_tools(select_all=False)</code>","text":"<p>Synchronously fetches and initializes MCP tools if not already available.</p> <p>Parameters:</p> Name Type Description Default <code>select_all</code> <code>bool</code> <p>If True, returns all tools regardless of filtering.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[MCPTool]</code> <p>list[MCPTool]: A list of initialized MCPTool instances.</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>def get_mcp_tools(self, select_all: bool = False) -&gt; list[MCPTool]:\n    \"\"\"\n    Synchronously fetches and initializes MCP tools if not already available.\n\n    Args:\n        select_all (bool): If True, returns all tools regardless of filtering.\n\n    Returns:\n        list[MCPTool]: A list of initialized MCPTool instances.\n    \"\"\"\n    if is_called_from_async_context():\n        with ThreadPoolExecutor() as executor:\n            future = executor.submit(lambda: asyncio.run(self.get_mcp_tools_async(select_all=select_all)))\n            return future.result()\n    return asyncio.run(self.get_mcp_tools_async(select_all=select_all))\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPServer.get_mcp_tools_async","title":"<code>get_mcp_tools_async(select_all=False)</code>  <code>async</code>","text":"<p>Asynchronously fetches and initializes MCP tools if not already available.</p> <p>Parameters:</p> Name Type Description Default <code>select_all</code> <code>bool</code> <p>If True, returns all tools regardless of filtering.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[MCPTool]</code> <p>list[MCPTool]: A list of initialized MCPTool instances.</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>async def get_mcp_tools_async(self, select_all: bool = False) -&gt; list[MCPTool]:\n    \"\"\"\n    Asynchronously fetches and initializes MCP tools if not already available.\n\n    Args:\n        select_all (bool): If True, returns all tools regardless of filtering.\n\n    Returns:\n        list[MCPTool]: A list of initialized MCPTool instances.\n    \"\"\"\n    if not self._mcp_tools:\n        await self.initialize_tools()\n\n    if select_all or not self.include_tools and not self.exclude_tools:\n        return list(self._mcp_tools.values())\n\n    if self.include_tools:\n        return [v for k, v in self._mcp_tools.items() if k in self.include_tools and k not in self.exclude_tools]\n\n    return [v for k, v in self._mcp_tools.items() if k not in self.exclude_tools]\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPServer.initialize_tools","title":"<code>initialize_tools()</code>  <code>async</code>","text":"<p>Initializes the MCP tool list from the client session.</p> <p>Returns:</p> Type Description <p>None</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>async def initialize_tools(self):\n    \"\"\"\n    Initializes the MCP tool list from the client session.\n\n    Returns:\n        None\n    \"\"\"\n    try:\n        async with self.connection.connect() as result:\n            read, write = result[:2]\n            async with ClientSession(read, write) as session:\n                await session.initialize()\n                tools = await session.list_tools()\n                for tool in tools.tools:\n                    self._mcp_tools[tool.name] = MCPTool(\n                        name=tool.name,\n                        description=tool.description or \"MCP Tool\",\n                        json_input_schema=tool.inputSchema,\n                        connection=self.connection,\n                        server_metadata=ServerMetadata(id=self.id, name=self.name, description=self.description),\n                    )\n\n        logger.info(f\"Tool {self.name}: {len(self._mcp_tools)} MCP tools initialized from a server.\")\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to initialize session. Error: {str(e)}\")\n        raise ToolExecutionException(f\"Tool {self.name} - {self.id}: failed to initialize session. Error: {str(e)}\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPTool","title":"<code>MCPTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool that interacts with the MCP server, enabling execution of specific server-side functions.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>Node group.</p> <code>name</code> <code>str</code> <p>Node name.</p> <code>description</code> <code>str</code> <p>Node description.</p> <code>input_schema</code> <code>ClassVar[type[BaseModel]]</code> <p>The schema that defines the expected structure of tool's input.</p> <code>connection</code> <code>MCPSse | MCPStdio | MCPStreamableHTTP</code> <p>Connection module for the MCP server.</p> <code>server_metadata</code> <code>ServerMetadata</code> <p>Server metadata for tracing.</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>class MCPTool(ConnectionNode):\n    \"\"\"\n    A tool that interacts with the MCP server, enabling execution of specific server-side functions.\n\n    Attributes:\n      group (Literal[NodeGroup.TOOLS]): Node group.\n      name (str): Node name.\n      description (str): Node description.\n      input_schema (ClassVar[type[BaseModel]]): The schema that defines the expected structure of tool's input.\n      connection (MCPSse | MCPStdio | MCPStreamableHTTP): Connection module for the MCP server.\n      server_metadata (ServerMetadata): Server metadata for tracing.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str\n    description: str\n    input_schema: type[BaseModel]\n    json_input_schema: dict[str, Any]\n    connection: MCPSse | MCPStdio | MCPStreamableHTTP\n    server_metadata: ServerMetadata = field(default_factory=dict)\n\n    def __init__(self, json_input_schema: dict[str, Any], **kwargs):\n        \"\"\"\n        Initializes the MCP tool with a given input schema and additional parameters.\n\n        Args:\n            input_schema (dict[str, Any]): JSON schema to define input fields.\n            **kwargs\n        \"\"\"\n        input_schema = MCPTool.get_input_schema(json_input_schema)\n        json_input_schema = rename_keys_recursive(json_input_schema, {\"type\": \"type_\"})\n        super().__init__(input_schema=input_schema, json_input_schema=json_input_schema, **kwargs)\n\n    @property\n    def to_dict_exclude_params(self):\n        parent_dict = super().to_dict_exclude_params.copy()\n        parent_dict.update(\n            {\n                \"input_schema\": True,\n            }\n        )\n        return parent_dict\n\n    @staticmethod\n    def get_input_schema(schema_dict) -&gt; type[BaseModel]:\n        \"\"\"\n        Creates an input schema based on provided MCP schema.\n\n        Args:\n            schema_dict (dict[str, Any]): A JSON schema dictionary describing the tool's expected input.\n        \"\"\"\n        schema_dict = rename_keys_recursive(schema_dict, {\"type_\": \"type\"})\n\n        for _, props in schema_dict.get(\"properties\", {}).items():\n            enum_values = props.pop(\"enum\", None)\n            if enum_values:\n                description = props.get(\"description\", \"\")\n                enum_description = f\" Allowed values: {', '.join(map(str, enum_values))}.\"\n                props[\"description\"] = description.rstrip() + enum_description\n\n        input_schema = json.dumps(schema_dict)\n\n        with TemporaryDirectory() as tmpdir:\n            out_path = Path(tmpdir) / \"model.py\"\n\n            generate(\n                input_schema,\n                input_file_type=InputFileType.JsonSchema,\n                output=out_path,\n                output_model_type=DataModelType.PydanticV2BaseModel,\n            )\n\n            module_name = \"dynamiq.nodes.tools.MCPTool.mcp_schema\"\n            spec = importlib.util.spec_from_file_location(module_name, out_path)\n            generated_module = importlib.util.module_from_spec(spec)\n            sys.modules[module_name] = generated_module\n            spec.loader.exec_module(generated_module)\n            generated_classes = [\n                cls\n                for _, cls in inspect.getmembers(generated_module, inspect.isclass)\n                if cls.__module__ == generated_module.__name__\n            ]\n\n            model_cls = generated_classes[0]\n            model_cls.model_rebuild()\n            return model_cls\n\n    def execute(self, input_data: BaseModel, config: RunnableConfig | None = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the MCP tool synchronously with the provided input.\n\n        Args:\n            input_data (BaseModel): Input data for the tool execution.\n            config (RunnableConfig, optional): Configuration for the runnable, including callbacks.\n            **kwargs: Additional arguments passed to the execution context.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the tool's output.\n        \"\"\"\n        return asyncio.run(self.execute_async(input_data, config, **kwargs))\n\n    async def execute_async(\n        self, input_data: BaseModel, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the MCP tool asynchronously.\n\n        Args:\n            input_data (BaseModel): Input data for the tool execution.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the tool's output.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        input_dict = input_data.model_dump()\n\n        try:\n            async with self.connection.connect() as result:\n                read, write = result[:2]\n                async with ClientSession(read, write) as session:\n                    await session.initialize()\n                    result = await session.call_tool(self.name, input_dict)\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to call tool from the MCP server.\"\n                f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n        return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPTool.__init__","title":"<code>__init__(json_input_schema, **kwargs)</code>","text":"<p>Initializes the MCP tool with a given input schema and additional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>input_schema</code> <code>dict[str, Any]</code> <p>JSON schema to define input fields.</p> required Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>def __init__(self, json_input_schema: dict[str, Any], **kwargs):\n    \"\"\"\n    Initializes the MCP tool with a given input schema and additional parameters.\n\n    Args:\n        input_schema (dict[str, Any]): JSON schema to define input fields.\n        **kwargs\n    \"\"\"\n    input_schema = MCPTool.get_input_schema(json_input_schema)\n    json_input_schema = rename_keys_recursive(json_input_schema, {\"type\": \"type_\"})\n    super().__init__(input_schema=input_schema, json_input_schema=json_input_schema, **kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the MCP tool synchronously with the provided input.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>BaseModel</code> <p>Input data for the tool execution.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable, including callbacks.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the execution context.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the tool's output.</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>def execute(self, input_data: BaseModel, config: RunnableConfig | None = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the MCP tool synchronously with the provided input.\n\n    Args:\n        input_data (BaseModel): Input data for the tool execution.\n        config (RunnableConfig, optional): Configuration for the runnable, including callbacks.\n        **kwargs: Additional arguments passed to the execution context.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the tool's output.\n    \"\"\"\n    return asyncio.run(self.execute_async(input_data, config, **kwargs))\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPTool.execute_async","title":"<code>execute_async(input_data, config=None, **kwargs)</code>  <code>async</code>","text":"<p>Executes the MCP tool asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>BaseModel</code> <p>Input data for the tool execution.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the tool's output.</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>async def execute_async(\n    self, input_data: BaseModel, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the MCP tool asynchronously.\n\n    Args:\n        input_data (BaseModel): Input data for the tool execution.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the tool's output.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    input_dict = input_data.model_dump()\n\n    try:\n        async with self.connection.connect() as result:\n            read, write = result[:2]\n            async with ClientSession(read, write) as session:\n                await session.initialize()\n                result = await session.call_tool(self.name, input_dict)\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to call tool from the MCP server.\"\n            f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.MCPTool.get_input_schema","title":"<code>get_input_schema(schema_dict)</code>  <code>staticmethod</code>","text":"<p>Creates an input schema based on provided MCP schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema_dict</code> <code>dict[str, Any]</code> <p>A JSON schema dictionary describing the tool's expected input.</p> required Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>@staticmethod\ndef get_input_schema(schema_dict) -&gt; type[BaseModel]:\n    \"\"\"\n    Creates an input schema based on provided MCP schema.\n\n    Args:\n        schema_dict (dict[str, Any]): A JSON schema dictionary describing the tool's expected input.\n    \"\"\"\n    schema_dict = rename_keys_recursive(schema_dict, {\"type_\": \"type\"})\n\n    for _, props in schema_dict.get(\"properties\", {}).items():\n        enum_values = props.pop(\"enum\", None)\n        if enum_values:\n            description = props.get(\"description\", \"\")\n            enum_description = f\" Allowed values: {', '.join(map(str, enum_values))}.\"\n            props[\"description\"] = description.rstrip() + enum_description\n\n    input_schema = json.dumps(schema_dict)\n\n    with TemporaryDirectory() as tmpdir:\n        out_path = Path(tmpdir) / \"model.py\"\n\n        generate(\n            input_schema,\n            input_file_type=InputFileType.JsonSchema,\n            output=out_path,\n            output_model_type=DataModelType.PydanticV2BaseModel,\n        )\n\n        module_name = \"dynamiq.nodes.tools.MCPTool.mcp_schema\"\n        spec = importlib.util.spec_from_file_location(module_name, out_path)\n        generated_module = importlib.util.module_from_spec(spec)\n        sys.modules[module_name] = generated_module\n        spec.loader.exec_module(generated_module)\n        generated_classes = [\n            cls\n            for _, cls in inspect.getmembers(generated_module, inspect.isclass)\n            if cls.__module__ == generated_module.__name__\n        ]\n\n        model_cls = generated_classes[0]\n        model_cls.model_rebuild()\n        return model_cls\n</code></pre>"},{"location":"dynamiq/nodes/tools/mcp/#dynamiq.nodes.tools.mcp.rename_keys_recursive","title":"<code>rename_keys_recursive(data, key_map)</code>","text":"<p>Recursively renames keys in a nested dictionary based on a provided key mapping.</p> Source code in <code>dynamiq/nodes/tools/mcp.py</code> <pre><code>def rename_keys_recursive(data: dict[str, Any] | list[str], key_map: dict[str, str]) -&gt; Any:\n    \"\"\"\n    Recursively renames keys in a nested dictionary based on a provided key mapping.\n    \"\"\"\n    if isinstance(data, dict):\n        return {key_map.get(key, key): rename_keys_recursive(value, key_map) for key, value in data.items()}\n    elif isinstance(data, list):\n        return [rename_keys_recursive(item, key_map) for item in data]\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/tools/python/","title":"Python","text":"<p>thon</p>"},{"location":"dynamiq/nodes/tools/scale_serp/","title":"Scale serp","text":""},{"location":"dynamiq/nodes/tools/scale_serp/#dynamiq.nodes.tools.scale_serp.ScaleSerpInputSchema","title":"<code>ScaleSerpInputSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/nodes/tools/scale_serp.py</code> <pre><code>class ScaleSerpInputSchema(BaseModel):\n    query: str | None = Field(default=None, description=\"Parameter to provide a search query.\")\n    url: str | None = Field(default=None, description=\"Parameter to provide a search url.\")\n    limit: int | None = Field(default=None, description=\"Parameter to specify the number of results to return.\")\n    search_type: SearchType = Field(\n        default=SearchType.WEB, description=\"Type of search to perform (web, news, images, videos)\"\n    )\n    output: str | None = Field(\n        default=None, description=\"Output format for the results (json, html, csv). Defaults to json if not specified.\"\n    )\n    include_html: bool = Field(\n        default=False, description=\"Whether to include HTML content in the results. Defaults to False.\"\n    )\n\n    @model_validator(mode=\"after\")\n    def validate_query_url(self):\n        \"\"\"Validate that either query or url is specified if both are provided\"\"\"\n        if self.url and self.query:\n            raise ValueError(\"Cannot specify both 'query' and 'url' at the same time.\")\n        return self\n</code></pre>"},{"location":"dynamiq/nodes/tools/scale_serp/#dynamiq.nodes.tools.scale_serp.ScaleSerpInputSchema.validate_query_url","title":"<code>validate_query_url()</code>","text":"<p>Validate that either query or url is specified if both are provided</p> Source code in <code>dynamiq/nodes/tools/scale_serp.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_query_url(self):\n    \"\"\"Validate that either query or url is specified if both are provided\"\"\"\n    if self.url and self.query:\n        raise ValueError(\"Cannot specify both 'query' and 'url' at the same time.\")\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/tools/scale_serp/#dynamiq.nodes.tools.scale_serp.ScaleSerpTool","title":"<code>ScaleSerpTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool for performing web searches using the Scale SERP API.</p> <p>This tool accepts a query or URL and returns search results based on the specified search type (organic, news, images, videos). The results include titles, links, and snippets.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group to which this tool belongs.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A brief description of the tool.</p> <code>connection</code> <code>ScaleSerp</code> <p>The connection instance for the Scale SERP API.</p> <code>query</code> <code>str</code> <p>The default search query to use.</p> <code>url</code> <code>str</code> <p>The default URL to search.</p> <code>limit</code> <code>int</code> <p>The default number of search results to return.</p> <code>search_type</code> <code>SearchType</code> <p>The type of search to perform.</p> <code>output</code> <code>str | None</code> <p>The output format for the results (json, html, csv).</p> <code>include_html</code> <code>bool</code> <p>Whether to include HTML content in the results.</p> Source code in <code>dynamiq/nodes/tools/scale_serp.py</code> <pre><code>class ScaleSerpTool(ConnectionNode):\n    \"\"\"\n    A tool for performing web searches using the Scale SERP API.\n\n    This tool accepts a query or URL and returns search results based on the specified\n    search type (organic, news, images, videos). The results include titles, links, and snippets.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group to which this tool belongs.\n        name (str): The name of the tool.\n        description (str): A brief description of the tool.\n        connection (ScaleSerp): The connection instance for the Scale SERP API.\n        query (str): The default search query to use.\n        url (str): The default URL to search.\n        limit (int): The default number of search results to return.\n        search_type (SearchType): The type of search to perform.\n        output (str | None): The output format for the results (json, html, csv).\n        include_html (bool): Whether to include HTML content in the results.\n\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Scale Serp Search Tool\"\n    description: str = DESCRIPTION_SERP\n    connection: ScaleSerp\n\n    query: str = Field(default=\"\", description=\"The default search query to use\")\n    url: str = Field(default=\"\", description=\"The default URL to search\")\n    limit: int = Field(default=10, ge=1, le=1000, description=\"The default number of search results to return\")\n    search_type: SearchType = Field(default=SearchType.WEB, description=\"The type of search to perform\")\n    output: str | None = Field(\n        default=None, description=\"Output format for the results (json, html, csv). Defaults to json if not specified.\"\n    )\n    include_html: bool = Field(\n        default=False, description=\"Whether to include HTML content in the results. Defaults to False.\"\n    )\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[ScaleSerpInputSchema]] = ScaleSerpInputSchema\n\n    def _format_search_results(self, results: dict[str, Any]) -&gt; str:\n        \"\"\"\n        Formats the search results into a human-readable string.\n        \"\"\"\n        content_results = results.get(self.search_type.result_key, [])\n\n        formatted_results = []\n        for result in content_results:\n            formatted_results.extend(\n                [\n                    f\"Title: {result.get('title')}\",\n                    f\"Link: {result.get('link')}\",\n                    f\"Snippet: {result.get('snippet', 'N/A')}\",\n                    \"\",\n                ]\n            )\n\n        return \"\\n\".join(formatted_results).strip()\n\n    def execute(\n        self, input_data: ScaleSerpInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the search using the Scale SERP API and returns the formatted results.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query = input_data.query or self.query\n        url = input_data.url or self.url\n        limit = input_data.limit or self.limit\n        search_type = input_data.search_type or self.search_type\n        output_format = input_data.output or self.output\n        include_html = input_data.include_html if input_data.include_html is not None else self.include_html\n\n        if not query and not url:\n            raise ToolExecutionException(\n                \"Either 'query' or 'url' must be provided in input data or node parameters.\", recoverable=True\n            )\n        try:\n            response = self.client.request(\n                method=self.connection.method,\n                url=urljoin(self.connection.url, \"/search\"),\n                params=self.get_params(\n                    query=query,\n                    url=url,\n                    num=limit,\n                    search_type=search_type,\n                    output=output_format,\n                    include_html=include_html,\n                ),\n            )\n            search_result = response.json()\n            if response.status_code &gt;= 400:\n                error_message = search_result.get(\"request_info\", {}).get(\"message\")\n                logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(error_message)}\")\n                raise ToolExecutionException(\n                    f\"Tool '{self.name}' failed to retrieve search results. \"\n                    f\"Error: {str(error_message)}. Please analyze the error and take appropriate action.\",\n                    recoverable=True,\n                )\n        except ToolExecutionException:\n            raise\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: unexpected error occurred. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' encountered an unexpected error. \"\n                f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        formatted_results = self._format_search_results(search_result)\n        content_results = search_result.get(search_type.result_key, [])\n\n        sources_with_url = [f\"[{result.get('title')}]({result.get('link')})\" for result in content_results]\n\n        if self.is_optimized_for_agents:\n            search_term = query or url\n            return {\n                \"content\": (\n                    \"## Sources with URLs\\n\"\n                    + \"\\n\".join(sources_with_url)\n                    + f\"\\n\\n## Search results for '{search_term}'\\n\"\n                    + formatted_results\n                )\n            }\n\n        return {\n            \"content\": {\n                \"result\": formatted_results,\n                \"sources_with_url\": sources_with_url,\n                \"urls\": [result.get(\"link\") for result in content_results],\n                \"raw_response\": search_result,\n            }\n        }\n\n    def get_params(\n        self,\n        query: str | None = None,\n        url: str | None = None,\n        search_type: SearchType | None = None,\n        output: str | None = None,\n        include_html: bool | None = None,\n        **kwargs,\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Prepare the parameters for the API request.\n        \"\"\"\n        params = {\"api_key\": self.connection.api_key, **kwargs}\n\n        current_search_type = search_type or self.search_type\n\n        if current_search_type != SearchType.WEB:\n            params[\"search_type\"] = current_search_type\n\n        if query:\n            params[\"q\"] = query\n        elif url:\n            params[\"url\"] = url\n\n        if output:\n            params[\"output\"] = output\n\n        if include_html is not None:\n            params[\"include_html\"] = include_html\n\n        return {k: v for k, v in params.items() if v is not None}\n</code></pre>"},{"location":"dynamiq/nodes/tools/scale_serp/#dynamiq.nodes.tools.scale_serp.ScaleSerpTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the search using the Scale SERP API and returns the formatted results.</p> Source code in <code>dynamiq/nodes/tools/scale_serp.py</code> <pre><code>def execute(\n    self, input_data: ScaleSerpInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the search using the Scale SERP API and returns the formatted results.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    query = input_data.query or self.query\n    url = input_data.url or self.url\n    limit = input_data.limit or self.limit\n    search_type = input_data.search_type or self.search_type\n    output_format = input_data.output or self.output\n    include_html = input_data.include_html if input_data.include_html is not None else self.include_html\n\n    if not query and not url:\n        raise ToolExecutionException(\n            \"Either 'query' or 'url' must be provided in input data or node parameters.\", recoverable=True\n        )\n    try:\n        response = self.client.request(\n            method=self.connection.method,\n            url=urljoin(self.connection.url, \"/search\"),\n            params=self.get_params(\n                query=query,\n                url=url,\n                num=limit,\n                search_type=search_type,\n                output=output_format,\n                include_html=include_html,\n            ),\n        )\n        search_result = response.json()\n        if response.status_code &gt;= 400:\n            error_message = search_result.get(\"request_info\", {}).get(\"message\")\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(error_message)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to retrieve search results. \"\n                f\"Error: {str(error_message)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n    except ToolExecutionException:\n        raise\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: unexpected error occurred. Error: {str(e)}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' encountered an unexpected error. \"\n            f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    formatted_results = self._format_search_results(search_result)\n    content_results = search_result.get(search_type.result_key, [])\n\n    sources_with_url = [f\"[{result.get('title')}]({result.get('link')})\" for result in content_results]\n\n    if self.is_optimized_for_agents:\n        search_term = query or url\n        return {\n            \"content\": (\n                \"## Sources with URLs\\n\"\n                + \"\\n\".join(sources_with_url)\n                + f\"\\n\\n## Search results for '{search_term}'\\n\"\n                + formatted_results\n            )\n        }\n\n    return {\n        \"content\": {\n            \"result\": formatted_results,\n            \"sources_with_url\": sources_with_url,\n            \"urls\": [result.get(\"link\") for result in content_results],\n            \"raw_response\": search_result,\n        }\n    }\n</code></pre>"},{"location":"dynamiq/nodes/tools/scale_serp/#dynamiq.nodes.tools.scale_serp.ScaleSerpTool.get_params","title":"<code>get_params(query=None, url=None, search_type=None, output=None, include_html=None, **kwargs)</code>","text":"<p>Prepare the parameters for the API request.</p> Source code in <code>dynamiq/nodes/tools/scale_serp.py</code> <pre><code>def get_params(\n    self,\n    query: str | None = None,\n    url: str | None = None,\n    search_type: SearchType | None = None,\n    output: str | None = None,\n    include_html: bool | None = None,\n    **kwargs,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Prepare the parameters for the API request.\n    \"\"\"\n    params = {\"api_key\": self.connection.api_key, **kwargs}\n\n    current_search_type = search_type or self.search_type\n\n    if current_search_type != SearchType.WEB:\n        params[\"search_type\"] = current_search_type\n\n    if query:\n        params[\"q\"] = query\n    elif url:\n        params[\"url\"] = url\n\n    if output:\n        params[\"output\"] = output\n\n    if include_html is not None:\n        params[\"include_html\"] = include_html\n\n    return {k: v for k, v in params.items() if v is not None}\n</code></pre>"},{"location":"dynamiq/nodes/tools/scale_serp/#dynamiq.nodes.tools.scale_serp.SearchType","title":"<code>SearchType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>dynamiq/nodes/tools/scale_serp.py</code> <pre><code>class SearchType(str, enum.Enum):\n    WEB = \"web\"\n    NEWS = \"news\"\n    IMAGES = \"images\"\n    VIDEOS = \"videos\"\n\n    @property\n    def result_key(self) -&gt; str:\n        \"\"\"Returns the corresponding result key for the search type\"\"\"\n        return {\n            SearchType.WEB: \"organic_results\",\n            SearchType.NEWS: \"news_results\",\n            SearchType.IMAGES: \"image_results\",\n            SearchType.VIDEOS: \"video_results\",\n        }[self]\n</code></pre>"},{"location":"dynamiq/nodes/tools/scale_serp/#dynamiq.nodes.tools.scale_serp.SearchType.result_key","title":"<code>result_key: str</code>  <code>property</code>","text":"<p>Returns the corresponding result key for the search type</p>"},{"location":"dynamiq/nodes/tools/sql_executor/","title":"Sql executor","text":""},{"location":"dynamiq/nodes/tools/sql_executor/#dynamiq.nodes.tools.sql_executor.SQLExecutor","title":"<code>SQLExecutor</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool for SQL query execution.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group to which this tool belongs.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A brief description of the tool.</p> <code>connection</code> <code>PostgreSQL | MySQL | Snowflake | AWSRedshift | DatabricksSQL</code> <p>The connection instance for the</p> <code>query</code> <code>Optional[str]</code> <p>The SQL statement to execute.</p> <code>input_schema</code> <code>SQLInputSchema</code> <p>The input schema for the tool.</p> Source code in <code>dynamiq/nodes/tools/sql_executor.py</code> <pre><code>class SQLExecutor(ConnectionNode):\n    \"\"\"\n    A tool for SQL query execution.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group to which this tool belongs.\n        name (str): The name of the tool.\n        description (str): A brief description of the tool.\n        connection (PostgreSQL|MySQL|Snowflake|AWSRedshift|DatabricksSQL): The connection instance for the\n        specified storage.\n        query (Optional[str]): The SQL statement to execute.\n        input_schema (SQLInputSchema): The input schema for the tool.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"SQL Executor Tool\"\n    description: str = DESCRIPTION_SQL\n    connection: PostgreSQL | MySQL | Snowflake | AWSRedshift | DatabricksSQL\n    query: str | None = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    input_schema: ClassVar[type[SQLInputSchema]] = SQLInputSchema\n\n    def format_results(self, results: list[dict[str, Any]], query: str) -&gt; str:\n        \"\"\"Format the retrieved results.\n\n        Args:\n            query (str): The executed SQL statement.\n            results (list[dict[str,Any]]): List of execution results.\n\n        Returns:\n            str: Formatted content of the query result.\n        \"\"\"\n        formatted_results = []\n        if not results:\n            return f'Query \"{query}\" executed successfully. No results returned.'\n        for i, result in enumerate(results):\n            formatted_result = f\"Row {i + 1}\\n\"\n            formatted_result += \"\\n\".join(f\"{key}: {value}\" for key, value in result.items())\n            formatted_results.append(formatted_result)\n        return \"\\n\\n\".join(formatted_results)\n\n    def execute(self, input_data: SQLInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        query = input_data.query or self.query\n        try:\n            if not query:\n                raise ValueError(\"Query cannot be empty\")\n            cursor = self.client.cursor(\n                **(\n                    self.connection.cursor_params\n                    if not isinstance(self.connection, (PostgreSQL, AWSRedshift, DatabricksSQL))\n                    else {}\n                )\n            )\n            cursor.execute(query)\n            output = cursor.fetchall() if cursor.description is not None else []\n            if isinstance(self.connection, DatabricksSQL):\n                output = [row.asDict(True) for row in output]\n            cursor.close()\n            if self.is_optimized_for_agents:\n                output = self.format_results(output, query)\n            return {\"content\": output}\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool {self.name} failed to execute query {query}. Error: {e}\", recoverable=True\n            )\n</code></pre>"},{"location":"dynamiq/nodes/tools/sql_executor/#dynamiq.nodes.tools.sql_executor.SQLExecutor.format_results","title":"<code>format_results(results, query)</code>","text":"<p>Format the retrieved results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The executed SQL statement.</p> required <code>results</code> <code>list[dict[str, Any]]</code> <p>List of execution results.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted content of the query result.</p> Source code in <code>dynamiq/nodes/tools/sql_executor.py</code> <pre><code>def format_results(self, results: list[dict[str, Any]], query: str) -&gt; str:\n    \"\"\"Format the retrieved results.\n\n    Args:\n        query (str): The executed SQL statement.\n        results (list[dict[str,Any]]): List of execution results.\n\n    Returns:\n        str: Formatted content of the query result.\n    \"\"\"\n    formatted_results = []\n    if not results:\n        return f'Query \"{query}\" executed successfully. No results returned.'\n    for i, result in enumerate(results):\n        formatted_result = f\"Row {i + 1}\\n\"\n        formatted_result += \"\\n\".join(f\"{key}: {value}\" for key, value in result.items())\n        formatted_results.append(formatted_result)\n    return \"\\n\\n\".join(formatted_results)\n</code></pre>"},{"location":"dynamiq/nodes/tools/tavily/","title":"Tavily","text":""},{"location":"dynamiq/nodes/tools/tavily/#dynamiq.nodes.tools.tavily.TavilyTool","title":"<code>TavilyTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>TavilyTool is a ConnectionNode that interfaces with the Tavily search service.</p> <p>All parameters can be set during initialization and optionally overridden during execution.</p> Source code in <code>dynamiq/nodes/tools/tavily.py</code> <pre><code>class TavilyTool(ConnectionNode):\n    \"\"\"\n    TavilyTool is a ConnectionNode that interfaces with the Tavily search service.\n\n    All parameters can be set during initialization and optionally overridden during execution.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Tavily Search Tool\"\n    description: str = DESCRIPTION_TAVILY\n    connection: Tavily\n\n    search_depth: str = Field(default=\"basic\", description=\"The search depth to use.\")\n    topic: str = Field(default=\"general\", description=\"The topic to search for.\")\n    max_results: int = Field(\n        default=5,\n        ge=1,\n        le=100,\n        description=\"The maximum number of search results to return.\",\n    )\n    chunks_per_source: int | None = Field(\n        default=3,\n        ge=1,\n        le=3,\n        description=\"The number of chunks to return per source (default: 3, range: 1-3).\",\n    )\n    time_range: str | None = Field(\n        default=None,\n        description=\"The time range back from the current date to filter results. \"\n        \"Useful when looking for sources that have published data. \"\n        \"Available options are only one of: `day`, `week`, `month`, `year`, `d`, `w`, `m`, `y`.\",\n    )\n    include_images: bool = Field(default=False, description=\"Include images in search results.\")\n    include_answer: bool = Field(default=False, description=\"Include answer in search results.\")\n    include_raw_content: bool = Field(default=False, description=\"Include raw content in search results.\")\n    include_domains: list[str] = Field(default_factory=list, description=\"The domains to include in search results.\")\n    exclude_domains: list[str] = Field(default_factory=list, description=\"The domains to exclude from search results.\")\n    use_cache: bool = Field(\n        default=True,\n        description=\"Use cache for search results.\",\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    input_schema: ClassVar[type[TavilyInputSchema]] = TavilyInputSchema\n\n    def _format_search_results(self, results: dict[str, Any]) -&gt; str:\n        \"\"\"\n        Formats the search results into a readable string format.\n\n        Args:\n            results (dict[str, Any]): The raw search results from Tavily.\n\n        Returns:\n            str: The formatted search results as a string.\n        \"\"\"\n        formatted_results = []\n        for result in results.get(\"results\", []):\n            formatted_results.append(f\"Source: {result.get('url')}\")\n            formatted_results.append(f\"Title: {result.get('title')}\")\n            formatted_results.append(f\"Content: {result.get('content')}\")\n            if result.get(\"raw_content\"):\n                formatted_results.append(f\"Full Content: {result.get('raw_content')}\")\n            formatted_results.append(f\"Relevance Score: {result.get('score')}\")\n            formatted_results.append(\"\")  # Blank line between results\n\n        return \"\\n\".join(formatted_results).strip()\n\n    def execute(self, input_data: TavilyInputSchema, config: RunnableConfig | None = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the search operation using the provided input data.\n        Parameters from input_data override the node's default parameters if provided.\n\n        Args:\n            input_data (TavilyInputSchema): The input data containing the search query and optional parameters.\n            config (RunnableConfig | None): Optional configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, Any]: The result of the search operation.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        search_data = {\n            \"query\": input_data.query,\n            \"search_depth\": self.search_depth,\n            \"topic\": self.topic,\n            \"max_results\": self.max_results,\n            \"include_images\": self.include_images,\n            \"include_answer\": self.include_answer,\n            \"include_raw_content\": self.include_raw_content,\n            \"include_domains\": self.include_domains,\n            \"exclude_domains\": self.exclude_domains,\n            \"use_cache\": self.use_cache,\n            \"chunks_per_source\": self.chunks_per_source,\n            \"time_range\": self.time_range,\n        }\n\n        input_dict = input_data.model_dump(exclude_unset=True)\n        for key, value in input_dict.items():\n            if value is not None:\n                search_data[key] = value\n\n        connection_url = urljoin(self.connection.url, \"/search\")\n\n        try:\n            response = self.client.request(\n                method=self.connection.method,\n                url=connection_url,\n                json={**self.connection.data, **search_data},\n            )\n            response.raise_for_status()\n            search_result = response.json()\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to retrieve search results. \"\n                f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        formatted_results = self._format_search_results(search_result)\n        sources_with_url = [\n            f\"[{result.get('title')}]({result.get('url')})\"\n            for result in search_result.get(\"results\", [])\n        ]\n\n        if self.is_optimized_for_agents:\n            result = (\n                \"## Sources with URLs\\n\"\n                + \"\\n\".join([f\"- {source}\" for source in sources_with_url])\n                + \"\\n\\n## Search results for: \"\n                + f\"'{input_data.query}'\\n\\n\"\n                + formatted_results\n            )\n            if search_result.get(\"answer\", \"\"):\n                result += f\"\\n\\n## Summary Answer\\n\\n{search_result.get('answer')}\"\n        else:\n            result = {\n                \"result\": formatted_results,\n                \"sources_with_url\": sources_with_url,\n                \"raw_response\": search_result,\n                \"images\": search_result.get(\"images\", []),\n                \"answer\": search_result.get(\"answer\", \"\"),\n                \"query\": search_result.get(\"query\", \"\"),\n                \"response_time\": search_result.get(\"response_time\", 0),\n            }\n\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n\n        return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/tavily/#dynamiq.nodes.tools.tavily.TavilyTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the search operation using the provided input data. Parameters from input_data override the node's default parameters if provided.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>TavilyInputSchema</code> <p>The input data containing the search query and optional parameters.</p> required <code>config</code> <code>RunnableConfig | None</code> <p>Optional configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: The result of the search operation.</p> Source code in <code>dynamiq/nodes/tools/tavily.py</code> <pre><code>def execute(self, input_data: TavilyInputSchema, config: RunnableConfig | None = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the search operation using the provided input data.\n    Parameters from input_data override the node's default parameters if provided.\n\n    Args:\n        input_data (TavilyInputSchema): The input data containing the search query and optional parameters.\n        config (RunnableConfig | None): Optional configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, Any]: The result of the search operation.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    search_data = {\n        \"query\": input_data.query,\n        \"search_depth\": self.search_depth,\n        \"topic\": self.topic,\n        \"max_results\": self.max_results,\n        \"include_images\": self.include_images,\n        \"include_answer\": self.include_answer,\n        \"include_raw_content\": self.include_raw_content,\n        \"include_domains\": self.include_domains,\n        \"exclude_domains\": self.exclude_domains,\n        \"use_cache\": self.use_cache,\n        \"chunks_per_source\": self.chunks_per_source,\n        \"time_range\": self.time_range,\n    }\n\n    input_dict = input_data.model_dump(exclude_unset=True)\n    for key, value in input_dict.items():\n        if value is not None:\n            search_data[key] = value\n\n    connection_url = urljoin(self.connection.url, \"/search\")\n\n    try:\n        response = self.client.request(\n            method=self.connection.method,\n            url=connection_url,\n            json={**self.connection.data, **search_data},\n        )\n        response.raise_for_status()\n        search_result = response.json()\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {str(e)}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' failed to retrieve search results. \"\n            f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    formatted_results = self._format_search_results(search_result)\n    sources_with_url = [\n        f\"[{result.get('title')}]({result.get('url')})\"\n        for result in search_result.get(\"results\", [])\n    ]\n\n    if self.is_optimized_for_agents:\n        result = (\n            \"## Sources with URLs\\n\"\n            + \"\\n\".join([f\"- {source}\" for source in sources_with_url])\n            + \"\\n\\n## Search results for: \"\n            + f\"'{input_data.query}'\\n\\n\"\n            + formatted_results\n        )\n        if search_result.get(\"answer\", \"\"):\n            result += f\"\\n\\n## Summary Answer\\n\\n{search_result.get('answer')}\"\n    else:\n        result = {\n            \"result\": formatted_results,\n            \"sources_with_url\": sources_with_url,\n            \"raw_response\": search_result,\n            \"images\": search_result.get(\"images\", []),\n            \"answer\": search_result.get(\"answer\", \"\"),\n            \"query\": search_result.get(\"query\", \"\"),\n            \"response_time\": search_result.get(\"response_time\", 0),\n        }\n\n    logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/thinking_tool/","title":"Thinking tool","text":""},{"location":"dynamiq/nodes/tools/thinking_tool/#dynamiq.nodes.tools.thinking_tool.ThinkingTool","title":"<code>ThinkingTool</code>","text":"<p>               Bases: <code>Node</code></p> <p>A tool for structured thinking and reasoning processes.</p> <p>This tool helps agents process thoughts in a structured way, providing a cognitive scratchpad for complex reasoning, planning, and analysis. The agent's LLM will be used automatically when this tool is called by an agent.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[TOOLS]</code> <p>The group this node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the tool.</p> <code>description</code> <code>str</code> <p>A description of the tool's functionality.</p> <code>llm</code> <code>BaseLLM</code> <p>The LLM to use for processing thoughts.</p> <code>error_handling</code> <code>ErrorHandling</code> <p>Configuration for error handling.</p> <code>prompt_template</code> <code>str</code> <p>The prompt template used for thinking processes.</p> Source code in <code>dynamiq/nodes/tools/thinking_tool.py</code> <pre><code>class ThinkingTool(Node):\n    \"\"\"\n    A tool for structured thinking and reasoning processes.\n\n    This tool helps agents process thoughts in a structured way, providing a cognitive\n    scratchpad for complex reasoning, planning, and analysis. The agent's LLM will be\n    used automatically when this tool is called by an agent.\n\n    Attributes:\n        group (Literal[NodeGroup.TOOLS]): The group this node belongs to.\n        name (str): The name of the tool.\n        description (str): A description of the tool's functionality.\n        llm (BaseLLM): The LLM to use for processing thoughts.\n        error_handling (ErrorHandling): Configuration for error handling.\n        prompt_template (str): The prompt template used for thinking processes.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Thinking Tool\"\n    description: str = \"\"\"Analyzes thoughts and reasoning processes to improve decision-making clarity and identify gaps in logic.\n\nKey Capabilities:\n- Structured analysis of complex thoughts and problems\n- Component breakdown with insights and next steps\n- Context-aware analysis with optional memory support\n- Sequential reasoning validation and action planning\n\nUsage Strategy:\n- Use before making important decisions or actions\n- Analyze complex multi-step problems systematically\n- Validate reasoning logic and identify assumptions\n- Plan next steps in complex workflows with clarity\n\nParameter Guide:\n- thought: The idea, reasoning, or problem to analyze (required)\n- context: Background information or constraints\n- focus: Analysis area (planning, problem-solving, decision-making)\n- memory_enabled: Maintain history of previous thoughts\n\nExamples:\n- {\"thought\": \"Should we implement feature X?\", \"focus\": \"decision-making\"}\n- {\"thought\": \"API integration failed with 401 error\", \"context\": \"OAuth2 auth\"}\n- {\"thought\": \"Choose database solutions\", \"context\": \"100k users, scaling\"}\"\"\"  # noqa E501\n\n    llm: BaseLLM = Field(..., description=\"LLM to use for thinking processes\")\n\n    error_handling: ErrorHandling = Field(default_factory=lambda: ErrorHandling(timeout_seconds=600))\n\n    prompt_template: str = Field(\n        default=THINKING_PROMPT_TEMPLATE, description=\"The prompt template for the thinking process\"\n    )\n\n    memory_enabled: bool = Field(\n        default=False, description=\"Whether to maintain memory of previous thoughts in this session\"\n    )\n    max_thoughts_in_memory: int = Field(\n        default=3,\n        description=\"Number of recent thoughts to keep in memory when memory is enabled\",\n    )\n    max_thought_chars: int = Field(\n        default=300,\n        description=\"Maximum characters of each thought to display in memory when memory is enabled\",\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    input_schema: ClassVar[type[ThinkingInputSchema]] = ThinkingInputSchema\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self._thought_history: list[dict] = []\n\n    def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n        \"\"\"Initialize the components of the tool.\"\"\"\n        connection_manager = connection_manager or ConnectionManager()\n        super().init_components(connection_manager)\n\n        if self.llm.is_postponed_component_init:\n            self.llm.init_components(connection_manager)\n\n    def reset_run_state(self):\n        \"\"\"Reset the intermediate steps (run_depends) of the node.\"\"\"\n        self._run_depends = []\n\n    @property\n    def to_dict_exclude_params(self) -&gt; dict:\n        \"\"\"Property to define which parameters should be excluded when converting to dictionary.\"\"\"\n        return super().to_dict_exclude_params | {\"llm\": True}\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Convert the tool to a dictionary representation.\"\"\"\n        data = super().to_dict(**kwargs)\n        data[\"llm\"] = self.llm.to_dict(**kwargs)\n        return data\n\n    def _build_context_section(self, context: str, focus: str) -&gt; str:\n        \"\"\"Build the context section for the prompt.\"\"\"\n        sections = []\n\n        if context:\n            sections.append(f\"Additional context:\\n{context}\")\n\n        if focus and focus != \"general\":\n            sections.append(f\"Focus area: {focus}\")\n\n        if self.memory_enabled and self._thought_history:\n            recent_thoughts = self._thought_history[-self.max_thoughts_in_memory :]\n            history_text = \"\\n\".join(\n                [\n                    f\"- {i + 1}. {thought['thought'][:self.max_thought_chars]}{'...' if len(thought['thought']) &gt; self.max_thought_chars else ''}\"  # noqa E501\n                    for i, thought in enumerate(recent_thoughts)\n                ]\n            )\n            sections.append(f\"Recent thinking history:\\n{history_text}\")\n\n        return \"\\n\\n\".join(sections) if sections else \"\"\n\n    def execute(\n        self, input_data: ThinkingInputSchema, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Execute the thinking tool on the input data.\n\n        This method processes a thought through structured analysis, helping to clarify,\n        organize, and develop the reasoning around the given input.\n\n        Args:\n            input_data (ThinkingInputSchema): Input containing thought, context, and focus\n            config (RunnableConfig, optional): The configuration for running the tool\n            **kwargs: Additional keyword arguments\n\n        Returns:\n            dict[str, Any]: A dictionary containing the analysis, original thought, and metadata\n        \"\"\"\n        config = ensure_config(config)\n        self.reset_run_state()\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        thought = input_data.thought\n        context = input_data.context\n        focus = input_data.focus\n\n        logger.debug(f\"Tool {self.name} - {self.id}: started thinking process for thought: '{thought[:100]}...'\")\n\n        context_section = self._build_context_section(context, focus)\n\n        prompt_content = self.prompt_template.format(thought=thought, context_section=context_section)\n\n        logger.debug(f\"Tool {self.name} - {self.id}: prompt content:\\n{prompt_content}\")\n\n        result = self.llm.run(\n            input_data={},\n            prompt=Prompt(messages=[Message(role=\"user\", content=prompt_content, static=True)]),\n            config=config,\n            **(kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}),\n        )\n\n        logger.debug(f\"Tool {self.name} - {self.id}: result status: {result.output}\")\n\n        self._run_depends = [NodeDependency(node=self.llm).to_dict()]\n\n        if result.status != RunnableStatus.SUCCESS:\n            raise ValueError(\"LLM execution failed during thinking process\")\n\n        analysis = result.output[\"content\"]\n\n        if self.memory_enabled:\n            self._thought_history.append(\n                {\n                    \"thought\": thought,\n                    \"context\": context,\n                    \"focus\": focus,\n                    \"analysis\": analysis,\n                    \"timestamp\": kwargs.get(\"run_id\", \"unknown\"),\n                }\n            )\n\n        logger.debug(\n            f\"Tool {self.name} - {self.id}: completed thinking process, \" f\"analysis length: {len(analysis)} characters\"\n        )\n\n        return {\n            \"content\": analysis,\n            \"original_thought\": thought,\n            \"context_used\": context,\n            \"focus_area\": focus,\n            \"thinking_session_count\": len(self._thought_history) if self.memory_enabled else None,\n        }\n\n    def clear_memory(self) -&gt; None:\n        \"\"\"Clear the thinking history memory.\"\"\"\n        self._thought_history.clear()\n        logger.debug(f\"Tool {self.name} - {self.id}: cleared thinking history memory\")\n\n    def get_thought_history(self) -&gt; list[dict]:\n        \"\"\"Get the current thought history.\"\"\"\n        return deepcopy(self._thought_history) if self.memory_enabled else []\n</code></pre>"},{"location":"dynamiq/nodes/tools/thinking_tool/#dynamiq.nodes.tools.thinking_tool.ThinkingTool.to_dict_exclude_params","title":"<code>to_dict_exclude_params: dict</code>  <code>property</code>","text":"<p>Property to define which parameters should be excluded when converting to dictionary.</p>"},{"location":"dynamiq/nodes/tools/thinking_tool/#dynamiq.nodes.tools.thinking_tool.ThinkingTool.clear_memory","title":"<code>clear_memory()</code>","text":"<p>Clear the thinking history memory.</p> Source code in <code>dynamiq/nodes/tools/thinking_tool.py</code> <pre><code>def clear_memory(self) -&gt; None:\n    \"\"\"Clear the thinking history memory.\"\"\"\n    self._thought_history.clear()\n    logger.debug(f\"Tool {self.name} - {self.id}: cleared thinking history memory\")\n</code></pre>"},{"location":"dynamiq/nodes/tools/thinking_tool/#dynamiq.nodes.tools.thinking_tool.ThinkingTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the thinking tool on the input data.</p> <p>This method processes a thought through structured analysis, helping to clarify, organize, and develop the reasoning around the given input.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ThinkingInputSchema</code> <p>Input containing thought, context, and focus</p> required <code>config</code> <code>RunnableConfig</code> <p>The configuration for running the tool</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the analysis, original thought, and metadata</p> Source code in <code>dynamiq/nodes/tools/thinking_tool.py</code> <pre><code>def execute(\n    self, input_data: ThinkingInputSchema, config: RunnableConfig | None = None, **kwargs\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Execute the thinking tool on the input data.\n\n    This method processes a thought through structured analysis, helping to clarify,\n    organize, and develop the reasoning around the given input.\n\n    Args:\n        input_data (ThinkingInputSchema): Input containing thought, context, and focus\n        config (RunnableConfig, optional): The configuration for running the tool\n        **kwargs: Additional keyword arguments\n\n    Returns:\n        dict[str, Any]: A dictionary containing the analysis, original thought, and metadata\n    \"\"\"\n    config = ensure_config(config)\n    self.reset_run_state()\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    thought = input_data.thought\n    context = input_data.context\n    focus = input_data.focus\n\n    logger.debug(f\"Tool {self.name} - {self.id}: started thinking process for thought: '{thought[:100]}...'\")\n\n    context_section = self._build_context_section(context, focus)\n\n    prompt_content = self.prompt_template.format(thought=thought, context_section=context_section)\n\n    logger.debug(f\"Tool {self.name} - {self.id}: prompt content:\\n{prompt_content}\")\n\n    result = self.llm.run(\n        input_data={},\n        prompt=Prompt(messages=[Message(role=\"user\", content=prompt_content, static=True)]),\n        config=config,\n        **(kwargs | {\"parent_run_id\": kwargs.get(\"run_id\")}),\n    )\n\n    logger.debug(f\"Tool {self.name} - {self.id}: result status: {result.output}\")\n\n    self._run_depends = [NodeDependency(node=self.llm).to_dict()]\n\n    if result.status != RunnableStatus.SUCCESS:\n        raise ValueError(\"LLM execution failed during thinking process\")\n\n    analysis = result.output[\"content\"]\n\n    if self.memory_enabled:\n        self._thought_history.append(\n            {\n                \"thought\": thought,\n                \"context\": context,\n                \"focus\": focus,\n                \"analysis\": analysis,\n                \"timestamp\": kwargs.get(\"run_id\", \"unknown\"),\n            }\n        )\n\n    logger.debug(\n        f\"Tool {self.name} - {self.id}: completed thinking process, \" f\"analysis length: {len(analysis)} characters\"\n    )\n\n    return {\n        \"content\": analysis,\n        \"original_thought\": thought,\n        \"context_used\": context,\n        \"focus_area\": focus,\n        \"thinking_session_count\": len(self._thought_history) if self.memory_enabled else None,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/tools/thinking_tool/#dynamiq.nodes.tools.thinking_tool.ThinkingTool.get_thought_history","title":"<code>get_thought_history()</code>","text":"<p>Get the current thought history.</p> Source code in <code>dynamiq/nodes/tools/thinking_tool.py</code> <pre><code>def get_thought_history(self) -&gt; list[dict]:\n    \"\"\"Get the current thought history.\"\"\"\n    return deepcopy(self._thought_history) if self.memory_enabled else []\n</code></pre>"},{"location":"dynamiq/nodes/tools/thinking_tool/#dynamiq.nodes.tools.thinking_tool.ThinkingTool.init_components","title":"<code>init_components(connection_manager=None)</code>","text":"<p>Initialize the components of the tool.</p> Source code in <code>dynamiq/nodes/tools/thinking_tool.py</code> <pre><code>def init_components(self, connection_manager: ConnectionManager | None = None) -&gt; None:\n    \"\"\"Initialize the components of the tool.\"\"\"\n    connection_manager = connection_manager or ConnectionManager()\n    super().init_components(connection_manager)\n\n    if self.llm.is_postponed_component_init:\n        self.llm.init_components(connection_manager)\n</code></pre>"},{"location":"dynamiq/nodes/tools/thinking_tool/#dynamiq.nodes.tools.thinking_tool.ThinkingTool.reset_run_state","title":"<code>reset_run_state()</code>","text":"<p>Reset the intermediate steps (run_depends) of the node.</p> Source code in <code>dynamiq/nodes/tools/thinking_tool.py</code> <pre><code>def reset_run_state(self):\n    \"\"\"Reset the intermediate steps (run_depends) of the node.\"\"\"\n    self._run_depends = []\n</code></pre>"},{"location":"dynamiq/nodes/tools/thinking_tool/#dynamiq.nodes.tools.thinking_tool.ThinkingTool.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Convert the tool to a dictionary representation.</p> Source code in <code>dynamiq/nodes/tools/thinking_tool.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Convert the tool to a dictionary representation.\"\"\"\n    data = super().to_dict(**kwargs)\n    data[\"llm\"] = self.llm.to_dict(**kwargs)\n    return data\n</code></pre>"},{"location":"dynamiq/nodes/tools/zenrows/","title":"Zenrows","text":""},{"location":"dynamiq/nodes/tools/zenrows/#dynamiq.nodes.tools.zenrows.ZenRowsTool","title":"<code>ZenRowsTool</code>","text":"<p>               Bases: <code>ConnectionNode</code></p> <p>A tool for scraping web pages, powered by ZenRows.</p> <p>This class is responsible for scraping the content of a web page using ZenRows.</p> Source code in <code>dynamiq/nodes/tools/zenrows.py</code> <pre><code>class ZenRowsTool(ConnectionNode):\n    \"\"\"\n    A tool for scraping web pages, powered by ZenRows.\n\n    This class is responsible for scraping the content of a web page using ZenRows.\n    \"\"\"\n\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    name: str = \"Zenrows Scraper Tool\"\n    description: str = DESCRIPTION_ZENROWS\n    connection: ZenRows\n    url: str | None = None\n    markdown_response: bool = Field(\n        default=True,\n        description=\"If True, the content will be parsed as Markdown instead of HTML.\",\n    )\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    input_schema: ClassVar[type[ZenRowsInputSchema]] = ZenRowsInputSchema\n\n    def execute(self, input_data: ZenRowsInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"\n        Executes the web scraping process.\n\n        Args:\n            input_data (dict[str, Any]): A dictionary containing 'input' key with the URL to scrape.\n            config (RunnableConfig, optional): Configuration for the runnable, including callbacks.\n            kwargs: Additional arguments passed to the execution context.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the URL and the scraped content.\n        \"\"\"\n        logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n        # Ensure the config is set up correctly\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        params = {\n            \"url\": input_data.url,\n            \"markdown_response\": str(self.markdown_response).lower(),\n        }\n        try:\n            response = self.client.request(\n                method=self.connection.method,\n                url=self.connection.url,\n                params={**self.connection.params, **params},\n            )\n            if response.status_code &gt;= 400:\n                error = response.json().get(\"detail\")\n                logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {error}\")\n                raise ToolExecutionException(\n                    f\"Tool '{self.name}' failed to execute the requested action. \"\n                    f\"Error: {error}. Please analyze the error and take appropriate action.\",\n                    recoverable=True,\n                )\n            scrape_result = response.text\n        except ToolExecutionException:\n            raise\n        except Exception as e:\n            logger.error(f\"Tool {self.name} - {self.id}: unexpected error occurred. Error: {str(e)}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' encountered an unexpected error. \"\n                f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n\n        if self.is_optimized_for_agents:\n            result = f\"## Source URL\\n{input_data.url}\\n\\n## Scraped Result\\n\\n{scrape_result}\\n\"\n        else:\n            result = {\"url\": input_data.url, \"content\": scrape_result}\n        logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n        return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/tools/zenrows/#dynamiq.nodes.tools.zenrows.ZenRowsTool.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the web scraping process.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>dict[str, Any]</code> <p>A dictionary containing 'input' key with the URL to scrape.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable, including callbacks.</p> <code>None</code> <code>kwargs</code> <p>Additional arguments passed to the execution context.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the URL and the scraped content.</p> Source code in <code>dynamiq/nodes/tools/zenrows.py</code> <pre><code>def execute(self, input_data: ZenRowsInputSchema, config: RunnableConfig = None, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"\n    Executes the web scraping process.\n\n    Args:\n        input_data (dict[str, Any]): A dictionary containing 'input' key with the URL to scrape.\n        config (RunnableConfig, optional): Configuration for the runnable, including callbacks.\n        kwargs: Additional arguments passed to the execution context.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the URL and the scraped content.\n    \"\"\"\n    logger.info(f\"Tool {self.name} - {self.id}: started with input:\\n{input_data.model_dump()}\")\n\n    # Ensure the config is set up correctly\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    params = {\n        \"url\": input_data.url,\n        \"markdown_response\": str(self.markdown_response).lower(),\n    }\n    try:\n        response = self.client.request(\n            method=self.connection.method,\n            url=self.connection.url,\n            params={**self.connection.params, **params},\n        )\n        if response.status_code &gt;= 400:\n            error = response.json().get(\"detail\")\n            logger.error(f\"Tool {self.name} - {self.id}: failed to get results. Error: {error}\")\n            raise ToolExecutionException(\n                f\"Tool '{self.name}' failed to execute the requested action. \"\n                f\"Error: {error}. Please analyze the error and take appropriate action.\",\n                recoverable=True,\n            )\n        scrape_result = response.text\n    except ToolExecutionException:\n        raise\n    except Exception as e:\n        logger.error(f\"Tool {self.name} - {self.id}: unexpected error occurred. Error: {str(e)}\")\n        raise ToolExecutionException(\n            f\"Tool '{self.name}' encountered an unexpected error. \"\n            f\"Error: {str(e)}. Please analyze the error and take appropriate action.\",\n            recoverable=True,\n        )\n\n    if self.is_optimized_for_agents:\n        result = f\"## Source URL\\n{input_data.url}\\n\\n## Scraped Result\\n\\n{scrape_result}\\n\"\n    else:\n        result = {\"url\": input_data.url, \"content\": scrape_result}\n    logger.info(f\"Tool {self.name} - {self.id}: finished with result:\\n{str(result)[:200]}...\")\n    return {\"content\": result}\n</code></pre>"},{"location":"dynamiq/nodes/utils/utils/","title":"Utils","text":""},{"location":"dynamiq/nodes/utils/utils/#dynamiq.nodes.utils.utils.Input","title":"<code>Input</code>","text":"<p>               Bases: <code>Pass</code></p> <p>A utility node representing the input of workflow.</p> <p>This class inherits from the Pass operator and is used to mark the beginning of a sequence of operations. It is typically used in workflow definitions or process models.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[UTILS]</code> <p>The group the node belongs to, set to UTILS.</p> <code>schema</code> <code>dict[str, Any] | None</code> <p>The JSON schema for the input data.</p> Source code in <code>dynamiq/nodes/utils/utils.py</code> <pre><code>class Input(Pass):\n    \"\"\"\n    A utility node representing the input of workflow.\n\n    This class inherits from the Pass operator and is used to mark the beginning of a sequence of\n    operations. It is typically used in workflow definitions or process models.\n\n    Attributes:\n        group (Literal[NodeGroup.UTILS]): The group the node belongs to, set to UTILS.\n        schema (dict[str, Any] | None): The JSON schema for the input data.\n    \"\"\"\n\n    name: str | None = \"Start\"\n    group: Literal[NodeGroup.UTILS] = NodeGroup.UTILS\n    json_schema: dict[str, Any] | None = Field(\n        default=None,\n        alias=\"schema\",\n        description=\"\"\"Determines input parameters of workflow.\n        Provide it in the properties field format. Example:\n        \"properties\": {\n            \"query\": {\n                \"type\": \"Any\"\n            },\n            \"files\": {\n                \"type\": \"list[files]\"\n            }\n        }\n    \"\"\",\n    )\n    _json_schema_fields: ClassVar[list[str]] = [\"json_schema\"]\n</code></pre>"},{"location":"dynamiq/nodes/utils/utils/#dynamiq.nodes.utils.utils.Output","title":"<code>Output</code>","text":"<p>               Bases: <code>Pass</code></p> <p>A utility node representing the output of workflow.</p> <p>This class inherits from the Pass operator and is used to mark the conclusion of a sequence of operations. It is typically used in workflow definitions or process models.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[UTILS]</code> <p>The group the node belongs to, set to UTILS.</p> <code>schema</code> <code>dict[str, Any] | None</code> <p>The JSON schema for the output data.</p> Source code in <code>dynamiq/nodes/utils/utils.py</code> <pre><code>class Output(Pass):\n    \"\"\"\n    A utility node representing the output of workflow.\n\n    This class inherits from the Pass operator and is used to mark the conclusion of a sequence of\n    operations. It is typically used in workflow definitions or process models.\n\n    Attributes:\n        group (Literal[NodeGroup.UTILS]): The group the node belongs to, set to UTILS.\n        schema (dict[str, Any] | None): The JSON schema for the output data.\n    \"\"\"\n\n    name: str | None = \"End\"\n    group: Literal[NodeGroup.UTILS] = NodeGroup.UTILS\n    json_schema: dict[str, Any] | None = Field(\n        default=None,\n        alias=\"schema\",\n        description=\"\"\"Determines output parameters of workflow.\n        Provide it in the properties field format. Example:\n        \"properties\": {\n            \"query\": {\n                \"type\": \"Any\"\n            }\n        }\n    \"\"\",\n    )\n    _json_schema_fields: ClassVar[list[str]] = [\"json_schema\"]\n</code></pre>"},{"location":"dynamiq/nodes/validators/base/","title":"Base","text":""},{"location":"dynamiq/nodes/validators/base/#dynamiq.nodes.validators.base.BaseValidator","title":"<code>BaseValidator</code>","text":"<p>               Bases: <code>Node</code></p> Source code in <code>dynamiq/nodes/validators/base.py</code> <pre><code>class BaseValidator(Node):\n    group: Literal[NodeGroup.VALIDATORS] = NodeGroup.VALIDATORS\n    name: str | None = \"Validator\"\n    behavior: Behavior | None = Behavior.RETURN\n\n    input_schema: ClassVar[type[ValidatorInputSchema]] = ValidatorInputSchema\n\n    def execute(self, input_data: ValidatorInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"Executes the validation process for a given value.\n\n        Args:\n            input_data (ValidatorInputSchema): The input data containing the value to check.\n            config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            input_data: A dictionary with the following key if behavior is return:\n                - \"valid\" (bool): boolean indicating if the value is valid.\n                - \"content\" (Any): passed value if everything is correct.\n            bool\n\n        Raises:\n            ValueError: If the value is not valid and behavior equal raise type.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n        try:\n            self.validate(input_data.content)\n        except Exception as error:\n            if self.behavior == Behavior.RETURN:\n                return {\"valid\": False, \"content\": input_data.content}\n            raise ValueError(str(error))\n        return {\"valid\": True, \"content\": input_data.content}\n\n    @abstractmethod\n    def validate(self, content):\n        pass\n</code></pre>"},{"location":"dynamiq/nodes/validators/base/#dynamiq.nodes.validators.base.BaseValidator.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Executes the validation process for a given value.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ValidatorInputSchema</code> <p>The input data containing the value to check.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>input_data</code> <p>A dictionary with the following key if behavior is return: - \"valid\" (bool): boolean indicating if the value is valid. - \"content\" (Any): passed value if everything is correct.</p> <p>bool</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value is not valid and behavior equal raise type.</p> Source code in <code>dynamiq/nodes/validators/base.py</code> <pre><code>def execute(self, input_data: ValidatorInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"Executes the validation process for a given value.\n\n    Args:\n        input_data (ValidatorInputSchema): The input data containing the value to check.\n        config (RunnableConfig, optional): Configuration for the execution. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        input_data: A dictionary with the following key if behavior is return:\n            - \"valid\" (bool): boolean indicating if the value is valid.\n            - \"content\" (Any): passed value if everything is correct.\n        bool\n\n    Raises:\n        ValueError: If the value is not valid and behavior equal raise type.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n    try:\n        self.validate(input_data.content)\n    except Exception as error:\n        if self.behavior == Behavior.RETURN:\n            return {\"valid\": False, \"content\": input_data.content}\n        raise ValueError(str(error))\n    return {\"valid\": True, \"content\": input_data.content}\n</code></pre>"},{"location":"dynamiq/nodes/validators/regex_match/","title":"Regex match","text":""},{"location":"dynamiq/nodes/validators/regex_match/#dynamiq.nodes.validators.regex_match.RegexMatch","title":"<code>RegexMatch</code>","text":"<p>               Bases: <code>BaseValidator</code></p> <p>Validates that a value matches a regular expression.</p> <p>Parameters:</p> Name Type Description Default <code>regex</code> <p>A regular expression pattern.</p> required <code>match_type</code> <p>Match type to check input value for a regex search or full-match option.</p> required Source code in <code>dynamiq/nodes/validators/regex_match.py</code> <pre><code>class RegexMatch(BaseValidator):\n    \"\"\"\n    Validates that a value matches a regular expression.\n\n    Args:\n        regex: A regular expression pattern.\n        match_type: Match type to check input value for a regex search or full-match option.\n    \"\"\"\n\n    regex: str\n    match_type: MatchType | None = MatchType.FULL_MATCH\n\n    def validate(self, content: str):\n        \"\"\"\n        Validates if the provided value matches the given regular expression pattern.\n\n        Args:\n            content (str): The value to validate.\n\n        Raises:\n            ValueError: If the provided value does not match the given pattern.\n        \"\"\"\n        compiled_pattern = re.compile(self.regex)\n        match_method = getattr(compiled_pattern, self.match_type)\n        if not match_method(content):\n            raise ValueError(\n                f\"Value does not match the valid pattern. Value: '{content}'. Pattern: '{self.regex}'\",\n            )\n</code></pre>"},{"location":"dynamiq/nodes/validators/regex_match/#dynamiq.nodes.validators.regex_match.RegexMatch.validate","title":"<code>validate(content)</code>","text":"<p>Validates if the provided value matches the given regular expression pattern.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The value to validate.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided value does not match the given pattern.</p> Source code in <code>dynamiq/nodes/validators/regex_match.py</code> <pre><code>def validate(self, content: str):\n    \"\"\"\n    Validates if the provided value matches the given regular expression pattern.\n\n    Args:\n        content (str): The value to validate.\n\n    Raises:\n        ValueError: If the provided value does not match the given pattern.\n    \"\"\"\n    compiled_pattern = re.compile(self.regex)\n    match_method = getattr(compiled_pattern, self.match_type)\n    if not match_method(content):\n        raise ValueError(\n            f\"Value does not match the valid pattern. Value: '{content}'. Pattern: '{self.regex}'\",\n        )\n</code></pre>"},{"location":"dynamiq/nodes/validators/valid_choices/","title":"Valid choices","text":""},{"location":"dynamiq/nodes/validators/valid_choices/#dynamiq.nodes.validators.valid_choices.ValidChoices","title":"<code>ValidChoices</code>","text":"<p>               Bases: <code>BaseValidator</code></p> <p>Class that provides functionality to check if the provided value is within the list of valid choices.</p> <p>Parameters:</p> Name Type Description Default <code>choices(List[Any])</code> <p>A list of values representing the acceptable choices.</p> required Source code in <code>dynamiq/nodes/validators/valid_choices.py</code> <pre><code>class ValidChoices(BaseValidator):\n    \"\"\"\n    Class that provides functionality to check if the provided value is within the list of valid choices.\n\n    Args:\n        choices(List[Any]): A list of values representing the acceptable choices.\n\n    \"\"\"\n\n    choices: list[Any] = None\n\n    def validate(self, content: Any):\n        \"\"\"\n        Validates if the provided value is among the acceptable choices.\n\n        Args:\n            content(Any): The value to validate.\n\n        Raises:\n            ValueError: If the provided value is not in valid choices.\n        \"\"\"\n        if isinstance(content, str):\n            content = content.strip()\n\n        if content not in self.choices:\n            raise ValueError(\n                f\"Value is not in valid choices. Value: '{content}'. Choices: '{self.choices}'.\"\n            )\n</code></pre>"},{"location":"dynamiq/nodes/validators/valid_choices/#dynamiq.nodes.validators.valid_choices.ValidChoices.validate","title":"<code>validate(content)</code>","text":"<p>Validates if the provided value is among the acceptable choices.</p> <p>Parameters:</p> Name Type Description Default <code>content(Any)</code> <p>The value to validate.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided value is not in valid choices.</p> Source code in <code>dynamiq/nodes/validators/valid_choices.py</code> <pre><code>def validate(self, content: Any):\n    \"\"\"\n    Validates if the provided value is among the acceptable choices.\n\n    Args:\n        content(Any): The value to validate.\n\n    Raises:\n        ValueError: If the provided value is not in valid choices.\n    \"\"\"\n    if isinstance(content, str):\n        content = content.strip()\n\n    if content not in self.choices:\n        raise ValueError(\n            f\"Value is not in valid choices. Value: '{content}'. Choices: '{self.choices}'.\"\n        )\n</code></pre>"},{"location":"dynamiq/nodes/validators/valid_json/","title":"Valid json","text":""},{"location":"dynamiq/nodes/validators/valid_json/#dynamiq.nodes.validators.valid_json.ValidJSON","title":"<code>ValidJSON</code>","text":"<p>               Bases: <code>BaseValidator</code></p> <p>Class that provides functionality to check if a value matches a basic JSON structure.</p> Source code in <code>dynamiq/nodes/validators/valid_json.py</code> <pre><code>class ValidJSON(BaseValidator):\n    \"\"\"\n    Class that provides functionality to check if a value matches a basic JSON structure.\n    \"\"\"\n\n    def validate(self, content: str | dict):\n        \"\"\"\n        Validates if the provided string is a properly formatted JSON.\n\n        Args:\n            content(str): The value to check.\n\n        Raises:\n            ValueError: If the value is not a properly formatted JSON.\n\n        \"\"\"\n        try:\n            if not isinstance(content, str):\n                content = json.dumps(content)\n\n            json.loads(content)\n        except (json.decoder.JSONDecodeError, TypeError) as error:\n            raise ValueError(\n                f\"Value is not valid JSON. Value: '{content}'. Error details: {str(error)}\"\n            )\n</code></pre>"},{"location":"dynamiq/nodes/validators/valid_json/#dynamiq.nodes.validators.valid_json.ValidJSON.validate","title":"<code>validate(content)</code>","text":"<p>Validates if the provided string is a properly formatted JSON.</p> <p>Parameters:</p> Name Type Description Default <code>content(str)</code> <p>The value to check.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value is not a properly formatted JSON.</p> Source code in <code>dynamiq/nodes/validators/valid_json.py</code> <pre><code>def validate(self, content: str | dict):\n    \"\"\"\n    Validates if the provided string is a properly formatted JSON.\n\n    Args:\n        content(str): The value to check.\n\n    Raises:\n        ValueError: If the value is not a properly formatted JSON.\n\n    \"\"\"\n    try:\n        if not isinstance(content, str):\n            content = json.dumps(content)\n\n        json.loads(content)\n    except (json.decoder.JSONDecodeError, TypeError) as error:\n        raise ValueError(\n            f\"Value is not valid JSON. Value: '{content}'. Error details: {str(error)}\"\n        )\n</code></pre>"},{"location":"dynamiq/nodes/validators/valid_python/","title":"Valid python","text":""},{"location":"dynamiq/nodes/validators/valid_python/#dynamiq.nodes.validators.valid_python.ValidPython","title":"<code>ValidPython</code>","text":"<p>               Bases: <code>BaseValidator</code></p> <p>Class that provides functionality to check if a value matches a basic Python code standards.</p> Source code in <code>dynamiq/nodes/validators/valid_python.py</code> <pre><code>class ValidPython(BaseValidator):\n    \"\"\"\n    Class that provides functionality to check if a value matches a basic Python code standards.\n    \"\"\"\n\n    def validate(self, content: str):\n        \"\"\"\n        Validates the provided Python code to determine if it is syntactically correct.\n\n        Args:\n            content (str): The Python code to validate.\n\n        Raises:\n            ValueError: Raised if the provided value is not syntactically correct Python code.\n        \"\"\"\n        try:\n            ast.parse(content)\n        except SyntaxError as e:\n            raise ValueError(\n                f\"Value is not valid python code. Value: '{content}'. Error details: {e.msg}\"\n            )\n</code></pre>"},{"location":"dynamiq/nodes/validators/valid_python/#dynamiq.nodes.validators.valid_python.ValidPython.validate","title":"<code>validate(content)</code>","text":"<p>Validates the provided Python code to determine if it is syntactically correct.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The Python code to validate.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Raised if the provided value is not syntactically correct Python code.</p> Source code in <code>dynamiq/nodes/validators/valid_python.py</code> <pre><code>def validate(self, content: str):\n    \"\"\"\n    Validates the provided Python code to determine if it is syntactically correct.\n\n    Args:\n        content (str): The Python code to validate.\n\n    Raises:\n        ValueError: Raised if the provided value is not syntactically correct Python code.\n    \"\"\"\n    try:\n        ast.parse(content)\n    except SyntaxError as e:\n        raise ValueError(\n            f\"Value is not valid python code. Value: '{content}'. Error details: {e.msg}\"\n        )\n</code></pre>"},{"location":"dynamiq/nodes/writers/base/","title":"Base","text":""},{"location":"dynamiq/nodes/writers/base/#dynamiq.nodes.writers.base.Writer","title":"<code>Writer</code>","text":"<p>               Bases: <code>VectorStoreNode</code>, <code>ABC</code></p> Source code in <code>dynamiq/nodes/writers/base.py</code> <pre><code>class Writer(VectorStoreNode, ABC):\n\n    group: Literal[NodeGroup.WRITERS] = NodeGroup.WRITERS\n    input_schema: ClassVar[type[WriterInputSchema]] = WriterInputSchema\n\n    def dry_run_cleanup(self, dry_run_config: DryRunConfig | None = None) -&gt; None:\n        \"\"\"Clean up resources created during dry run.\"\"\"\n\n        self.vector_store.dry_run_cleanup(dry_run_config)\n</code></pre>"},{"location":"dynamiq/nodes/writers/base/#dynamiq.nodes.writers.base.Writer.dry_run_cleanup","title":"<code>dry_run_cleanup(dry_run_config=None)</code>","text":"<p>Clean up resources created during dry run.</p> Source code in <code>dynamiq/nodes/writers/base.py</code> <pre><code>def dry_run_cleanup(self, dry_run_config: DryRunConfig | None = None) -&gt; None:\n    \"\"\"Clean up resources created during dry run.\"\"\"\n\n    self.vector_store.dry_run_cleanup(dry_run_config)\n</code></pre>"},{"location":"dynamiq/nodes/writers/chroma/","title":"Chroma","text":""},{"location":"dynamiq/nodes/writers/chroma/#dynamiq.nodes.writers.chroma.ChromaDocumentWriter","title":"<code>ChromaDocumentWriter</code>","text":"<p>               Bases: <code>Writer</code>, <code>BaseWriterVectorStoreParams</code></p> <p>Document Writer Node using Chroma Vector Store.</p> <p>This class represents a node for writing documents to a Chroma Vector Store.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[WRITERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Chroma | None</code> <p>The connection to the Chroma Vector Store.</p> <code>vector_store</code> <code>ChromaVectorStore | None</code> <p>The Chroma Vector Store instance.</p> Source code in <code>dynamiq/nodes/writers/chroma.py</code> <pre><code>class ChromaDocumentWriter(Writer, BaseWriterVectorStoreParams):\n    \"\"\"\n    Document Writer Node using Chroma Vector Store.\n\n    This class represents a node for writing documents to a Chroma Vector Store.\n\n    Attributes:\n        group (Literal[NodeGroup.WRITERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (Chroma | None): The connection to the Chroma Vector Store.\n        vector_store (ChromaVectorStore | None): The Chroma Vector Store instance.\n    \"\"\"\n\n    name: str = \"ChromaDocumentWriter\"\n    connection: Chroma | None = None\n    vector_store: ChromaVectorStore | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the ChromaDocumentWriter.\n\n        If neither vector_store nor connection is provided in kwargs, a default Chroma connection will be created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Chroma()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return ChromaVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include={\"index_name\", \"create_if_not_exist\"}) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the document writing operation.\n\n        This method writes the documents provided in the input_data to the Chroma Vector Store.\n\n        Args:\n            input_data (WriterInputSchema): An instance containing the input data.\n                Expected to have a 'documents' key with the documents to be written.\n            config (RunnableConfig, optional): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the count of upserted documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = input_data.documents\n\n        output = self.vector_store.write_documents(documents)\n        return {\n            \"upserted_count\": output,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/writers/chroma/#dynamiq.nodes.writers.chroma.ChromaDocumentWriter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the ChromaDocumentWriter.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Chroma connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/writers/chroma.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the ChromaDocumentWriter.\n\n    If neither vector_store nor connection is provided in kwargs, a default Chroma connection will be created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Chroma()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/writers/chroma/#dynamiq.nodes.writers.chroma.ChromaDocumentWriter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document writing operation.</p> <p>This method writes the documents provided in the input_data to the Chroma Vector Store.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>WriterInputSchema</code> <p>An instance containing the input data. Expected to have a 'documents' key with the documents to be written.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the count of upserted documents.</p> Source code in <code>dynamiq/nodes/writers/chroma.py</code> <pre><code>def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the document writing operation.\n\n    This method writes the documents provided in the input_data to the Chroma Vector Store.\n\n    Args:\n        input_data (WriterInputSchema): An instance containing the input data.\n            Expected to have a 'documents' key with the documents to be written.\n        config (RunnableConfig, optional): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the count of upserted documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = input_data.documents\n\n    output = self.vector_store.write_documents(documents)\n    return {\n        \"upserted_count\": output,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/writers/elasticsearch/","title":"Elasticsearch","text":""},{"location":"dynamiq/nodes/writers/elasticsearch/#dynamiq.nodes.writers.elasticsearch.ElasticsearchDocumentWriter","title":"<code>ElasticsearchDocumentWriter</code>","text":"<p>               Bases: <code>Writer</code>, <code>ElasticsearchVectorStoreWriterParams</code></p> <p>Document Writer Node using Elasticsearch Vector Store.</p> <p>This class represents a node for writing documents to an Elasticsearch Vector Store. It supports vector search, BM25 text search, and hybrid search capabilities.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[WRITERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Optional[Elasticsearch]</code> <p>The Elasticsearch connection.</p> <code>vector_store</code> <code>Optional[ElasticsearchVectorStore]</code> <p>The Elasticsearch Vector Store instance.</p> Source code in <code>dynamiq/nodes/writers/elasticsearch.py</code> <pre><code>class ElasticsearchDocumentWriter(Writer, ElasticsearchVectorStoreWriterParams):\n    \"\"\"\n    Document Writer Node using Elasticsearch Vector Store.\n\n    This class represents a node for writing documents to an Elasticsearch Vector Store.\n    It supports vector search, BM25 text search, and hybrid search capabilities.\n\n    Attributes:\n        group (Literal[NodeGroup.WRITERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (Optional[Elasticsearch]): The Elasticsearch connection.\n        vector_store (Optional[ElasticsearchVectorStore]): The Elasticsearch Vector Store instance.\n    \"\"\"\n\n    name: str = \"ElasticsearchDocumentWriter\"\n    connection: Elasticsearch | str | None = None\n    vector_store: ElasticsearchVectorStore | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the ElasticsearchDocumentWriter.\n\n        If neither vector_store nor connection is provided in kwargs, a default Elasticsearch connection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Elasticsearch()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return ElasticsearchVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(ElasticsearchVectorStoreWriterParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def execute(\n        self,\n        input_data: WriterInputSchema,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; dict[str, int]:\n        \"\"\"\n        Execute the document writing operation.\n\n        This method writes the input documents to the Elasticsearch Vector Store.\n        It supports:\n        - Vector embeddings for similarity search\n        - Text content for BM25 search\n        - Metadata for filtering and custom ranking\n        - Custom mappings and analyzers\n        - Index settings and templates\n        - Duplicate handling with configurable policy\n        - Batch operations with configurable size\n\n        Args:\n            input_data (WriterInputSchema): Input data containing the documents to be written.\n            config (Optional[RunnableConfig]): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict[str, int]: A dictionary containing the count of written documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        upserted_count = self.vector_store.write_documents(\n            documents=input_data.documents,\n            policy=DuplicatePolicy.FAIL,\n            content_key=input_data.content_key,\n            embedding_key=input_data.embedding_key,\n        )\n        logger.debug(f\"Upserted {upserted_count} documents to Elasticsearch Vector Store.\")\n\n        return {\n            \"upserted_count\": upserted_count,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/writers/elasticsearch/#dynamiq.nodes.writers.elasticsearch.ElasticsearchDocumentWriter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the ElasticsearchDocumentWriter.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Elasticsearch connection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/writers/elasticsearch.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the ElasticsearchDocumentWriter.\n\n    If neither vector_store nor connection is provided in kwargs, a default Elasticsearch connection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Elasticsearch()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/writers/elasticsearch/#dynamiq.nodes.writers.elasticsearch.ElasticsearchDocumentWriter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document writing operation.</p> <p>This method writes the input documents to the Elasticsearch Vector Store. It supports: - Vector embeddings for similarity search - Text content for BM25 search - Metadata for filtering and custom ranking - Custom mappings and analyzers - Index settings and templates - Duplicate handling with configurable policy - Batch operations with configurable size</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>WriterInputSchema</code> <p>Input data containing the documents to be written.</p> required <code>config</code> <code>Optional[RunnableConfig]</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>dict[str, int]: A dictionary containing the count of written documents.</p> Source code in <code>dynamiq/nodes/writers/elasticsearch.py</code> <pre><code>def execute(\n    self,\n    input_data: WriterInputSchema,\n    config: RunnableConfig | None = None,\n    **kwargs,\n) -&gt; dict[str, int]:\n    \"\"\"\n    Execute the document writing operation.\n\n    This method writes the input documents to the Elasticsearch Vector Store.\n    It supports:\n    - Vector embeddings for similarity search\n    - Text content for BM25 search\n    - Metadata for filtering and custom ranking\n    - Custom mappings and analyzers\n    - Index settings and templates\n    - Duplicate handling with configurable policy\n    - Batch operations with configurable size\n\n    Args:\n        input_data (WriterInputSchema): Input data containing the documents to be written.\n        config (Optional[RunnableConfig]): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict[str, int]: A dictionary containing the count of written documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    upserted_count = self.vector_store.write_documents(\n        documents=input_data.documents,\n        policy=DuplicatePolicy.FAIL,\n        content_key=input_data.content_key,\n        embedding_key=input_data.embedding_key,\n    )\n    logger.debug(f\"Upserted {upserted_count} documents to Elasticsearch Vector Store.\")\n\n    return {\n        \"upserted_count\": upserted_count,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/writers/milvus/","title":"Milvus","text":""},{"location":"dynamiq/nodes/writers/milvus/#dynamiq.nodes.writers.milvus.MilvusDocumentWriter","title":"<code>MilvusDocumentWriter</code>","text":"<p>               Bases: <code>Writer</code>, <code>MilvusWriterVectorStoreParams</code></p> <p>Document Writer Node using Milvus Vector Store.</p> <p>This class represents a node for writing documents to a Milvus Vector Store.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[WRITERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Milvus | None</code> <p>The connection to the Milvus Vector Store.</p> <code>vector_store</code> <code>MilvusVectorStore | None</code> <p>The Milvus Vector Store instance.</p> Source code in <code>dynamiq/nodes/writers/milvus.py</code> <pre><code>class MilvusDocumentWriter(Writer, MilvusWriterVectorStoreParams):\n    \"\"\"\n    Document Writer Node using Milvus Vector Store.\n\n    This class represents a node for writing documents to a Milvus Vector Store.\n\n    Attributes:\n        group (Literal[NodeGroup.WRITERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (Milvus | None): The connection to the Milvus Vector Store.\n        vector_store (MilvusVectorStore | None): The Milvus Vector Store instance.\n    \"\"\"\n\n    name: str = \"MilvusDocumentWriter\"\n    connection: Milvus | None = None\n    vector_store: MilvusVectorStore | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the MilvusDocumentWriter.\n\n        If no vector_store or connection is provided in kwargs, a default Milvus connection will be created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Milvus()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return MilvusVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(MilvusWriterVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the document writing process.\n\n        This method writes the input documents to the Milvus Vector Store.\n\n        Args:\n            input_data (WriterInputSchema): An instance containing the input data.\n                Expected to have a 'documents' key with the documents to be written.\n            config (RunnableConfig, optional): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the number of upserted documents.\n\n        Raises:\n            Any exceptions raised by the vector store's write_documents method.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = input_data.documents\n        content_key = input_data.content_key\n        embedding_key = input_data.embedding_key\n\n        # Write documents to Milvus\n        upserted_count = self.vector_store.write_documents(\n            documents, content_key=content_key, embedding_key=embedding_key\n        )\n        logger.debug(f\"Upserted {upserted_count} documents to Milvus Vector Store.\")\n\n        return {\n            \"upserted_count\": upserted_count,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/writers/milvus/#dynamiq.nodes.writers.milvus.MilvusDocumentWriter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the MilvusDocumentWriter.</p> <p>If no vector_store or connection is provided in kwargs, a default Milvus connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/writers/milvus.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the MilvusDocumentWriter.\n\n    If no vector_store or connection is provided in kwargs, a default Milvus connection will be created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Milvus()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/writers/milvus/#dynamiq.nodes.writers.milvus.MilvusDocumentWriter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document writing process.</p> <p>This method writes the input documents to the Milvus Vector Store.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>WriterInputSchema</code> <p>An instance containing the input data. Expected to have a 'documents' key with the documents to be written.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the number of upserted documents.</p> Source code in <code>dynamiq/nodes/writers/milvus.py</code> <pre><code>def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the document writing process.\n\n    This method writes the input documents to the Milvus Vector Store.\n\n    Args:\n        input_data (WriterInputSchema): An instance containing the input data.\n            Expected to have a 'documents' key with the documents to be written.\n        config (RunnableConfig, optional): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the number of upserted documents.\n\n    Raises:\n        Any exceptions raised by the vector store's write_documents method.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = input_data.documents\n    content_key = input_data.content_key\n    embedding_key = input_data.embedding_key\n\n    # Write documents to Milvus\n    upserted_count = self.vector_store.write_documents(\n        documents, content_key=content_key, embedding_key=embedding_key\n    )\n    logger.debug(f\"Upserted {upserted_count} documents to Milvus Vector Store.\")\n\n    return {\n        \"upserted_count\": upserted_count,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/writers/pgvector/","title":"Pgvector","text":""},{"location":"dynamiq/nodes/writers/pgvector/#dynamiq.nodes.writers.pgvector.PGVectorDocumentWriter","title":"<code>PGVectorDocumentWriter</code>","text":"<p>               Bases: <code>Writer</code>, <code>PGVectorStoreWriterParams</code></p> <p>Document Writer Node using PGVector Vector Store.</p> <p>This class represents a node for writing documents to a PGVector Vector Store.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[WRITERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>PostgreSQL | None</code> <p>The PostgreSQL connection.</p> <code>vector_store</code> <code>PGVectorStore | None</code> <p>The PGVector Vector Store instance.</p> Source code in <code>dynamiq/nodes/writers/pgvector.py</code> <pre><code>class PGVectorDocumentWriter(Writer, PGVectorStoreWriterParams):\n    \"\"\"\n    Document Writer Node using PGVector Vector Store.\n\n    This class represents a node for writing documents to a PGVector Vector Store.\n\n    Attributes:\n        group (Literal[NodeGroup.WRITERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (PostgreSQL | None): The PostgreSQL connection.\n        vector_store (PGVectorStore | None): The PGVector Vector Store instance.\n    \"\"\"\n\n    name: str = \"PGVectorDocumentWriter\"\n    connection: PostgreSQL | str | None = None\n    vector_store: PGVectorStore | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the PGVectorDocumentWriter.\n\n        If neither vector_store nor connection is provided in kwargs, a default PostgreSQL connection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = PostgreSQL()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return PGVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(PGVectorStoreWriterParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the document writing operation.\n\n        This method writes the input documents to the PGVector Vector Store.\n\n        Args:\n            input_data (WriterInputSchema): Input data containing the documents to be written.\n            config (RunnableConfig, optional): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the count of upserted documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = input_data.documents\n        content_key = input_data.content_key\n        embedding_key = input_data.embedding_key\n\n        upserted_count = self.vector_store.write_documents(\n            documents, content_key=content_key, embedding_key=embedding_key\n        )\n        logger.debug(f\"Upserted {upserted_count} documents to PGVector Vector Store.\")\n\n        return {\n            \"upserted_count\": upserted_count,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/writers/pgvector/#dynamiq.nodes.writers.pgvector.PGVectorDocumentWriter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the PGVectorDocumentWriter.</p> <p>If neither vector_store nor connection is provided in kwargs, a default PostgreSQL connection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/writers/pgvector.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the PGVectorDocumentWriter.\n\n    If neither vector_store nor connection is provided in kwargs, a default PostgreSQL connection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = PostgreSQL()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/writers/pgvector/#dynamiq.nodes.writers.pgvector.PGVectorDocumentWriter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document writing operation.</p> <p>This method writes the input documents to the PGVector Vector Store.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>WriterInputSchema</code> <p>Input data containing the documents to be written.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the count of upserted documents.</p> Source code in <code>dynamiq/nodes/writers/pgvector.py</code> <pre><code>def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the document writing operation.\n\n    This method writes the input documents to the PGVector Vector Store.\n\n    Args:\n        input_data (WriterInputSchema): Input data containing the documents to be written.\n        config (RunnableConfig, optional): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the count of upserted documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = input_data.documents\n    content_key = input_data.content_key\n    embedding_key = input_data.embedding_key\n\n    upserted_count = self.vector_store.write_documents(\n        documents, content_key=content_key, embedding_key=embedding_key\n    )\n    logger.debug(f\"Upserted {upserted_count} documents to PGVector Vector Store.\")\n\n    return {\n        \"upserted_count\": upserted_count,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/writers/pinecone/","title":"Pinecone","text":""},{"location":"dynamiq/nodes/writers/pinecone/#dynamiq.nodes.writers.pinecone.PineconeDocumentWriter","title":"<code>PineconeDocumentWriter</code>","text":"<p>               Bases: <code>Writer</code>, <code>PineconeWriterVectorStoreParams</code></p> <p>Document Writer Node using Pinecone Vector Store.</p> <p>This class represents a node for writing documents to a Pinecone Vector Store.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[WRITERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Pinecone | None</code> <p>The Pinecone connection object.</p> <code>vector_store</code> <code>PineconeVectorStore | None</code> <p>The Pinecone Vector Store object.</p> Source code in <code>dynamiq/nodes/writers/pinecone.py</code> <pre><code>class PineconeDocumentWriter(Writer, PineconeWriterVectorStoreParams):\n    \"\"\"\n    Document Writer Node using Pinecone Vector Store.\n\n    This class represents a node for writing documents to a Pinecone Vector Store.\n\n    Attributes:\n        group (Literal[NodeGroup.WRITERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (Pinecone | None): The Pinecone connection object.\n        vector_store (PineconeVectorStore | None): The Pinecone Vector Store object.\n    \"\"\"\n\n    name: str = \"PineconeDocumentWriter\"\n    connection: Pinecone | None = None\n    vector_store: PineconeVectorStore | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the PineconeDocumentWriter.\n\n        If no vector_store or connection is provided in kwargs, a default Pinecone connection will be created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Pinecone()\n        super().__init__(**kwargs)\n\n    @model_validator(mode=\"after\")\n    def check_required_params(self) -&gt; \"PineconeDocumentWriter\":\n        \"\"\"\n        Validate required parameters\n\n        Returns:\n            self: The updated instance.\n        \"\"\"\n        if self.vector_store is None:\n            if self.create_if_not_exist and self.index_type is None:\n                raise ValueError(\"Index type 'pod' or 'serverless' must be specified when creating an index\")\n\n            if self.index_type == PineconeIndexType.POD and (self.environment is None or self.pod_type is None):\n                raise ValueError(\"'environment' and 'pod_type' must be specified for 'pod' index\")\n\n            if self.index_type == PineconeIndexType.SERVERLESS and (self.cloud is None or self.region is None):\n                raise ValueError(\"'cloud' and 'region' must be specified for 'serverless' index\")\n\n        return self\n\n    @property\n    def vector_store_cls(self):\n        return PineconeVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(PineconeWriterVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the document writing process.\n\n        This method writes the input documents to the Pinecone Vector Store.\n\n        Args:\n            input_data (WriterInputSchema): An instance containing the input data.\n                Expected to have a 'documents' key with the documents to be written.\n            config (RunnableConfig, optional): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the number of upserted documents.\n\n        Raises:\n            Any exceptions raised by the vector store's write_documents method.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = input_data.documents\n        content_key = input_data.content_key\n\n        upserted_count = self.vector_store.write_documents(documents, content_key=content_key)\n        logger.debug(f\"Upserted {upserted_count} documents to Pinecone Vector Store.\")\n\n        return {\n            \"upserted_count\": upserted_count,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/writers/pinecone/#dynamiq.nodes.writers.pinecone.PineconeDocumentWriter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the PineconeDocumentWriter.</p> <p>If no vector_store or connection is provided in kwargs, a default Pinecone connection will be created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/writers/pinecone.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the PineconeDocumentWriter.\n\n    If no vector_store or connection is provided in kwargs, a default Pinecone connection will be created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Pinecone()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/writers/pinecone/#dynamiq.nodes.writers.pinecone.PineconeDocumentWriter.check_required_params","title":"<code>check_required_params()</code>","text":"<p>Validate required parameters</p> <p>Returns:</p> Name Type Description <code>self</code> <code>PineconeDocumentWriter</code> <p>The updated instance.</p> Source code in <code>dynamiq/nodes/writers/pinecone.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_required_params(self) -&gt; \"PineconeDocumentWriter\":\n    \"\"\"\n    Validate required parameters\n\n    Returns:\n        self: The updated instance.\n    \"\"\"\n    if self.vector_store is None:\n        if self.create_if_not_exist and self.index_type is None:\n            raise ValueError(\"Index type 'pod' or 'serverless' must be specified when creating an index\")\n\n        if self.index_type == PineconeIndexType.POD and (self.environment is None or self.pod_type is None):\n            raise ValueError(\"'environment' and 'pod_type' must be specified for 'pod' index\")\n\n        if self.index_type == PineconeIndexType.SERVERLESS and (self.cloud is None or self.region is None):\n            raise ValueError(\"'cloud' and 'region' must be specified for 'serverless' index\")\n\n    return self\n</code></pre>"},{"location":"dynamiq/nodes/writers/pinecone/#dynamiq.nodes.writers.pinecone.PineconeDocumentWriter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document writing process.</p> <p>This method writes the input documents to the Pinecone Vector Store.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>WriterInputSchema</code> <p>An instance containing the input data. Expected to have a 'documents' key with the documents to be written.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the number of upserted documents.</p> Source code in <code>dynamiq/nodes/writers/pinecone.py</code> <pre><code>def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the document writing process.\n\n    This method writes the input documents to the Pinecone Vector Store.\n\n    Args:\n        input_data (WriterInputSchema): An instance containing the input data.\n            Expected to have a 'documents' key with the documents to be written.\n        config (RunnableConfig, optional): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the number of upserted documents.\n\n    Raises:\n        Any exceptions raised by the vector store's write_documents method.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = input_data.documents\n    content_key = input_data.content_key\n\n    upserted_count = self.vector_store.write_documents(documents, content_key=content_key)\n    logger.debug(f\"Upserted {upserted_count} documents to Pinecone Vector Store.\")\n\n    return {\n        \"upserted_count\": upserted_count,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/writers/qdrant/","title":"Qdrant","text":""},{"location":"dynamiq/nodes/writers/qdrant/#dynamiq.nodes.writers.qdrant.QdrantDocumentWriter","title":"<code>QdrantDocumentWriter</code>","text":"<p>               Bases: <code>Writer</code>, <code>QdrantWriterVectorStoreParams</code></p> <p>Document Writer Node using Qdrant Vector Store.</p> <p>This class represents a node for writing documents to a Weaviate Vector Store.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[WRITERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Qdrant | None</code> <p>The Qdrant connection.</p> <code>vector_store</code> <code>QdrantVectorStore | None</code> <p>The Qdrant Vector Store instance.</p> Source code in <code>dynamiq/nodes/writers/qdrant.py</code> <pre><code>class QdrantDocumentWriter(Writer, QdrantWriterVectorStoreParams):\n    \"\"\"\n    Document Writer Node using Qdrant Vector Store.\n\n    This class represents a node for writing documents to a Weaviate Vector Store.\n\n    Attributes:\n        group (Literal[NodeGroup.WRITERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (Qdrant | None): The Qdrant connection.\n        vector_store (QdrantVectorStore | None): The Qdrant Vector Store instance.\n    \"\"\"\n\n    name: str = \"QdrantDocumentWriter\"\n    connection: QdrantConnection | None = None\n    vector_store: QdrantVectorStore | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the QdrantDocumentWriter.\n\n        If neither vector_store nor connection is provided in kwargs, a default Qdrant connection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = QdrantConnection()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return QdrantVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(QdrantWriterVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the document writing operation.\n\n        This method writes the input documents to the Qdrant Vector Store.\n\n        Args:\n            input_data (WriterInputSchema): Input data containing the documents to be written.\n            config (RunnableConfig, optional): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the count of upserted documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = input_data.documents\n        content_key = input_data.content_key\n\n        upserted_count = self.vector_store.write_documents(documents, content_key=content_key)\n        logger.debug(f\"Upserted {upserted_count} documents to Qdrant Vector Store.\")\n\n        return {\n            \"upserted_count\": upserted_count,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/writers/qdrant/#dynamiq.nodes.writers.qdrant.QdrantDocumentWriter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the QdrantDocumentWriter.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Qdrant connection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/writers/qdrant.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the QdrantDocumentWriter.\n\n    If neither vector_store nor connection is provided in kwargs, a default Qdrant connection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = QdrantConnection()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/writers/qdrant/#dynamiq.nodes.writers.qdrant.QdrantDocumentWriter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document writing operation.</p> <p>This method writes the input documents to the Qdrant Vector Store.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>WriterInputSchema</code> <p>Input data containing the documents to be written.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the count of upserted documents.</p> Source code in <code>dynamiq/nodes/writers/qdrant.py</code> <pre><code>def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the document writing operation.\n\n    This method writes the input documents to the Qdrant Vector Store.\n\n    Args:\n        input_data (WriterInputSchema): Input data containing the documents to be written.\n        config (RunnableConfig, optional): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the count of upserted documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = input_data.documents\n    content_key = input_data.content_key\n\n    upserted_count = self.vector_store.write_documents(documents, content_key=content_key)\n    logger.debug(f\"Upserted {upserted_count} documents to Qdrant Vector Store.\")\n\n    return {\n        \"upserted_count\": upserted_count,\n    }\n</code></pre>"},{"location":"dynamiq/nodes/writers/weaviate/","title":"Weaviate","text":""},{"location":"dynamiq/nodes/writers/weaviate/#dynamiq.nodes.writers.weaviate.WeaviateDocumentWriter","title":"<code>WeaviateDocumentWriter</code>","text":"<p>               Bases: <code>Writer</code>, <code>WeaviateWriterVectorStoreParams</code></p> <p>Document Writer Node using Weaviate Vector Store.</p> <p>This class represents a node for writing documents to a Weaviate Vector Store.</p> <p>Attributes:</p> Name Type Description <code>group</code> <code>Literal[WRITERS]</code> <p>The group the node belongs to.</p> <code>name</code> <code>str</code> <p>The name of the node.</p> <code>connection</code> <code>Weaviate | None</code> <p>The Weaviate connection.</p> <code>vector_store</code> <code>WeaviateVectorStore | None</code> <p>The Weaviate Vector Store instance.</p> Source code in <code>dynamiq/nodes/writers/weaviate.py</code> <pre><code>class WeaviateDocumentWriter(Writer, WeaviateWriterVectorStoreParams):\n    \"\"\"\n    Document Writer Node using Weaviate Vector Store.\n\n    This class represents a node for writing documents to a Weaviate Vector Store.\n\n    Attributes:\n        group (Literal[NodeGroup.WRITERS]): The group the node belongs to.\n        name (str): The name of the node.\n        connection (Weaviate | None): The Weaviate connection.\n        vector_store (WeaviateVectorStore | None): The Weaviate Vector Store instance.\n    \"\"\"\n\n    name: str = \"WeaviateDocumentWriter\"\n    connection: Weaviate | None = None\n    vector_store: WeaviateVectorStore | None = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the WeaviateDocumentWriter.\n\n        If neither vector_store nor connection is provided in kwargs, a default Weaviate connection is created.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n        \"\"\"\n        if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n            kwargs[\"connection\"] = Weaviate()\n        super().__init__(**kwargs)\n\n    @property\n    def vector_store_cls(self):\n        return WeaviateVectorStore\n\n    @property\n    def vector_store_params(self):\n        return self.model_dump(include=set(WeaviateWriterVectorStoreParams.model_fields)) | {\n            \"connection\": self.connection,\n            \"client\": self.client,\n        }\n\n    def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n        \"\"\"\n        Execute the document writing operation.\n\n        This method writes the input documents to the Weaviate Vector Store.\n\n        Args:\n            input_data (WriterInputSchema): Input data containing the documents to be written.\n            config (RunnableConfig, optional): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            dict: A dictionary containing the count of upserted documents.\n        \"\"\"\n        config = ensure_config(config)\n        self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n        documents = input_data.documents\n        content_key = input_data.content_key\n\n        upserted_count = self.vector_store.write_documents(documents, content_key=content_key)\n        logger.debug(f\"Upserted {upserted_count} documents to Weaviate Vector Store.\")\n\n        return {\n            \"upserted_count\": upserted_count,\n        }\n</code></pre>"},{"location":"dynamiq/nodes/writers/weaviate/#dynamiq.nodes.writers.weaviate.WeaviateDocumentWriter.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the WeaviateDocumentWriter.</p> <p>If neither vector_store nor connection is provided in kwargs, a default Weaviate connection is created.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/nodes/writers/weaviate.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the WeaviateDocumentWriter.\n\n    If neither vector_store nor connection is provided in kwargs, a default Weaviate connection is created.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n    \"\"\"\n    if kwargs.get(\"vector_store\") is None and kwargs.get(\"connection\") is None:\n        kwargs[\"connection\"] = Weaviate()\n    super().__init__(**kwargs)\n</code></pre>"},{"location":"dynamiq/nodes/writers/weaviate/#dynamiq.nodes.writers.weaviate.WeaviateDocumentWriter.execute","title":"<code>execute(input_data, config=None, **kwargs)</code>","text":"<p>Execute the document writing operation.</p> <p>This method writes the input documents to the Weaviate Vector Store.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>WriterInputSchema</code> <p>Input data containing the documents to be written.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the count of upserted documents.</p> Source code in <code>dynamiq/nodes/writers/weaviate.py</code> <pre><code>def execute(self, input_data: WriterInputSchema, config: RunnableConfig = None, **kwargs):\n    \"\"\"\n    Execute the document writing operation.\n\n    This method writes the input documents to the Weaviate Vector Store.\n\n    Args:\n        input_data (WriterInputSchema): Input data containing the documents to be written.\n        config (RunnableConfig, optional): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        dict: A dictionary containing the count of upserted documents.\n    \"\"\"\n    config = ensure_config(config)\n    self.run_on_node_execute_run(config.callbacks, **kwargs)\n\n    documents = input_data.documents\n    content_key = input_data.content_key\n\n    upserted_count = self.vector_store.write_documents(documents, content_key=content_key)\n    logger.debug(f\"Upserted {upserted_count} documents to Weaviate Vector Store.\")\n\n    return {\n        \"upserted_count\": upserted_count,\n    }\n</code></pre>"},{"location":"dynamiq/prompts/prompts/","title":"Prompts","text":""},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.BasePrompt","title":"<code>BasePrompt</code>","text":"<p>               Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>Abstract base class for prompts.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for the prompt, generated using generate_uuid by default.</p> <code>version</code> <code>str | None</code> <p>Version of the prompt, optional.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>class BasePrompt(ABC, BaseModel):\n    \"\"\"\n    Abstract base class for prompts.\n\n    Attributes:\n        id (str): Unique identifier for the prompt, generated using generate_uuid by default.\n        version (str | None): Version of the prompt, optional.\n    \"\"\"\n\n    id: str = Field(default_factory=generate_uuid)\n    version: str | None = None\n\n    @abstractmethod\n    def format_messages(self, **kwargs) -&gt; list[dict]:\n        \"\"\"\n        Abstract method to format messages.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            list[dict]: A list of formatted messages as dictionaries.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def format_tools(self, **kwargs) -&gt; list[dict] | None:\n        \"\"\"\n        Abstract method to format tools.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments.\n\n        Returns:\n            list[dict]: A list of formatted tools as dictionaries.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.BasePrompt.format_messages","title":"<code>format_messages(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to format messages.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of formatted messages as dictionaries.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>@abstractmethod\ndef format_messages(self, **kwargs) -&gt; list[dict]:\n    \"\"\"\n    Abstract method to format messages.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n\n    Returns:\n        list[dict]: A list of formatted messages as dictionaries.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.BasePrompt.format_tools","title":"<code>format_tools(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to format tools.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[dict] | None</code> <p>list[dict]: A list of formatted tools as dictionaries.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>@abstractmethod\ndef format_tools(self, **kwargs) -&gt; list[dict] | None:\n    \"\"\"\n    Abstract method to format tools.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments.\n\n    Returns:\n        list[dict]: A list of formatted tools as dictionaries.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.Message","title":"<code>Message</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a message in a conversation. Attributes:     content (str): The content of the message.     role (MessageRole): The role of the message sender.     metadata (dict | None): Additional metadata for the message, default is None.     static (bool): Determines whether it is possible to pass parameters via this message.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>class Message(BaseModel):\n    \"\"\"\n    Represents a message in a conversation.\n    Attributes:\n        content (str): The content of the message.\n        role (MessageRole): The role of the message sender.\n        metadata (dict | None): Additional metadata for the message, default is None.\n        static (bool): Determines whether it is possible to pass parameters via this message.\n    \"\"\"\n    content: str\n    role: MessageRole = MessageRole.USER\n    metadata: dict | None = None\n    static: bool = Field(default=False, exclude=True)\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        # Import and initialize Jinja2 Template here\n        from jinja2 import Template\n\n        self._Template = Template\n\n    def format_message(self, **kwargs) -&gt; \"Message\":\n        \"Returns formated copy of message\"\n        return Message(\n            role=self.role,\n            content=self._Template(self.content).render(**kwargs),\n        )\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.Message.format_message","title":"<code>format_message(**kwargs)</code>","text":"<p>Returns formated copy of message</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>def format_message(self, **kwargs) -&gt; \"Message\":\n    \"Returns formated copy of message\"\n    return Message(\n        role=self.role,\n        content=self._Template(self.content).render(**kwargs),\n    )\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.Prompt","title":"<code>Prompt</code>","text":"<p>               Bases: <code>BasePrompt</code></p> <p>Concrete implementation of BasePrompt for handling both text and vision messages.</p> <p>Attributes:</p> Name Type Description <code>messages</code> <code>list[Message | VisionMessage]</code> <p>List of Message or VisionMessage objects</p> <code>tools</code> <code>list[Tool]</code> <p>List of functions for which the model may generate JSON inputs.</p> <code>response_format</code> <code>dict[str, Any]</code> <p>JSON schema that specifies the structure of the llm's output.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>class Prompt(BasePrompt):\n    \"\"\"\n    Concrete implementation of BasePrompt for handling both text and vision messages.\n\n    Attributes:\n        messages (list[Message | VisionMessage]): List of Message or VisionMessage objects\n        representing the prompt.\n        tools (list[Tool]): List of functions for which the model may generate JSON inputs.\n        response_format (dict[str, Any]): JSON schema that specifies the structure of the llm's output.\n    \"\"\"\n\n    messages: list[Message | VisionMessage]\n    tools: list[Tool | dict] | None = None\n    response_format: dict[str, Any] | None = None\n    _Template: Any = PrivateAttr()\n\n    model_config = ConfigDict(arbitrary_types_allowed=True, extra=\"allow\")\n\n    def __init__(self, **data):\n        super().__init__(**data)\n\n    def count_tokens(self, model: str) -&gt; int:\n        \"\"\"\n        Counts number of tokens in prompt based on the model name.\n\n        Args:\n            * model (str): Model name.\n\n        Returns:\n            int: Number of tokens.\n        \"\"\"\n        return token_counter(\n            model=model, messages=[message.model_dump(exclude={\"metadata\"}) for message in self.messages]\n        )\n\n    def get_required_parameters(self) -&gt; set[str]:\n        \"\"\"Extracts set of parameters required for messages.\n\n        Returns:\n            set[str]: Set of parameter names.\n        \"\"\"\n        parameters = set()\n\n        env = Environment(autoescape=True)\n        for msg in self.messages:\n            if isinstance(msg, Message):\n                if not msg.static:\n                    parameters |= get_parameters_for_template(msg.content, env=env)\n            elif isinstance(msg, VisionMessage):\n                for content in msg.content:\n                    if isinstance(content, VisionMessageTextContent):\n                        if not msg.static:\n                            parameters |= get_parameters_for_template(content.text, env=env)\n                    elif isinstance(content, VisionMessageImageContent):\n                        parameters |= get_parameters_for_template(content.image_url.url, env=env)\n                    else:\n                        raise ValueError(f\"Invalid content type: {content.type}\")\n            else:\n                raise ValueError(f\"Invalid message type: {type(msg)}\")\n\n        return parameters\n\n    def format_messages(self, **kwargs) -&gt; list[dict]:\n        \"\"\"\n        Formats the messages in the prompt, rendering any templates.\n\n        Args:\n            **kwargs: Arbitrary keyword arguments used for template rendering.\n\n        Returns:\n            list[dict]: A list of formatted messages as dictionaries.\n        \"\"\"\n        out: list[dict] = []\n        for msg in self.messages:\n            if isinstance(msg, Message):\n                if not msg.static:\n                    msg = msg.format_message(**kwargs)\n                out.append(msg.model_dump(exclude={\"metadata\"}))\n            elif isinstance(msg, VisionMessage):\n                out.append(msg.format_message(**kwargs).model_dump(exclude={\"metadata\"}))\n            else:\n                raise ValueError(f\"Invalid message type: {type(msg)}\")\n\n        return out\n\n    def format_tools(self, **kwargs) -&gt; list[dict] | None:\n        out = None\n        if self.tools:\n            out = [tool.model_dump() for tool in self.tools]\n        return out\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.Prompt.count_tokens","title":"<code>count_tokens(model)</code>","text":"<p>Counts number of tokens in prompt based on the model name.</p> <p>Parameters:</p> Name Type Description Default <code>*</code> <code>model (str</code> <p>Model name.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of tokens.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>def count_tokens(self, model: str) -&gt; int:\n    \"\"\"\n    Counts number of tokens in prompt based on the model name.\n\n    Args:\n        * model (str): Model name.\n\n    Returns:\n        int: Number of tokens.\n    \"\"\"\n    return token_counter(\n        model=model, messages=[message.model_dump(exclude={\"metadata\"}) for message in self.messages]\n    )\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.Prompt.format_messages","title":"<code>format_messages(**kwargs)</code>","text":"<p>Formats the messages in the prompt, rendering any templates.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Arbitrary keyword arguments used for template rendering.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of formatted messages as dictionaries.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>def format_messages(self, **kwargs) -&gt; list[dict]:\n    \"\"\"\n    Formats the messages in the prompt, rendering any templates.\n\n    Args:\n        **kwargs: Arbitrary keyword arguments used for template rendering.\n\n    Returns:\n        list[dict]: A list of formatted messages as dictionaries.\n    \"\"\"\n    out: list[dict] = []\n    for msg in self.messages:\n        if isinstance(msg, Message):\n            if not msg.static:\n                msg = msg.format_message(**kwargs)\n            out.append(msg.model_dump(exclude={\"metadata\"}))\n        elif isinstance(msg, VisionMessage):\n            out.append(msg.format_message(**kwargs).model_dump(exclude={\"metadata\"}))\n        else:\n            raise ValueError(f\"Invalid message type: {type(msg)}\")\n\n    return out\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.Prompt.get_required_parameters","title":"<code>get_required_parameters()</code>","text":"<p>Extracts set of parameters required for messages.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>set[str]: Set of parameter names.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>def get_required_parameters(self) -&gt; set[str]:\n    \"\"\"Extracts set of parameters required for messages.\n\n    Returns:\n        set[str]: Set of parameter names.\n    \"\"\"\n    parameters = set()\n\n    env = Environment(autoescape=True)\n    for msg in self.messages:\n        if isinstance(msg, Message):\n            if not msg.static:\n                parameters |= get_parameters_for_template(msg.content, env=env)\n        elif isinstance(msg, VisionMessage):\n            for content in msg.content:\n                if isinstance(content, VisionMessageTextContent):\n                    if not msg.static:\n                        parameters |= get_parameters_for_template(content.text, env=env)\n                elif isinstance(content, VisionMessageImageContent):\n                    parameters |= get_parameters_for_template(content.image_url.url, env=env)\n                else:\n                    raise ValueError(f\"Invalid content type: {content.type}\")\n        else:\n            raise ValueError(f\"Invalid message type: {type(msg)}\")\n\n    return parameters\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.VisionMessage","title":"<code>VisionMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a vision message in a conversation.</p> <p>Attributes:</p> Name Type Description <code>content</code> <code>list[VisionTextMessage | VisionImageMessage]</code> <p>The content of the message.</p> <code>role</code> <code>MessageRole</code> <p>The role of the message sender.</p> <code>static</code> <code>bool</code> <p>Determines whether it is possible to pass parameters via this message.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>class VisionMessage(BaseModel):\n    \"\"\"\n    Represents a vision message in a conversation.\n\n    Attributes:\n        content (list[VisionTextMessage | VisionImageMessage]): The content of the message.\n        role (MessageRole): The role of the message sender.\n        static (bool): Determines whether it is possible to pass parameters via this message.\n    \"\"\"\n\n    content: list[VisionMessageTextContent | VisionMessageImageContent]\n    role: MessageRole = MessageRole.USER\n    static: bool = Field(default=False, exclude=True)\n\n    def parse_bytes_to_base64(self, file_bytes: bytes) -&gt; str:\n        \"\"\"\n        Parses file bytes in base64 format.\n\n        Args:\n            file_bytes (bytes): File bytes.\n\n        Returns:\n            str: Base64 encoded file.\n        \"\"\"\n        extension = filetype.guess_extension(file_bytes)\n        if not extension:\n            extension = \"txt\"\n\n        encoded_str = base64.b64encode(file_bytes).decode(\"utf-8\")\n\n        mime_type, _ = mimetypes.guess_type(f\"file.{extension}\")\n\n        if mime_type is None:\n            mime_type = \"text/plain\"\n\n        return f\"data:{mime_type};base64,{encoded_str}\"\n\n    def parse_image_url_parameters(self, url_template: str, kwargs: dict) -&gt; None:\n        \"\"\"\n        Converts image URL parameters in kwargs to Base64-encoded Data URLs if they contain image data.\n\n        Args:\n            url_template (str): Jinja template for the image URL.\n            kwargs (dict): Dictionary of parameters to be used with the template.\n\n        Raises:\n            KeyError: If a required parameter is missing in kwargs.\n            ValueError: If the file type cannot be determined or unsupported data type is provided.\n        \"\"\"\n        template_params = get_parameters_for_template(url_template)\n\n        for param in template_params:\n            if param not in kwargs:\n                raise KeyError(f\"Missing required parameter: '{param}'\")\n\n            value = kwargs[param]\n\n            # Initialize as unchanged; will be modified if image data is detected\n            processed_value = value\n\n            if isinstance(value, io.BytesIO):\n                image_bytes = value.getvalue()\n                processed_value = self.parse_bytes_to_base64(image_bytes)\n\n            elif isinstance(value, bytes):\n                processed_value = self.parse_bytes_to_base64(value)\n\n            elif isinstance(value, str):\n                pass  # No action needed; assuming it's a regular URL or already a Data URL\n\n            else:\n                # Unsupported data type for image parameter\n                raise ValueError(f\"Unsupported data type for parameter '{param}': {type(value)}\")\n\n            # Update the parameter with the processed value\n            kwargs[param] = processed_value\n\n    def format_message(self, **kwargs):\n        out_msg_content = []\n        for content in self.content:\n            if isinstance(content, VisionMessageTextContent):\n                if not self.static:\n                    out_msg_content.append(\n                        VisionMessageTextContent(\n                            text=self._Template(content.text).render(**kwargs),\n                        )\n                    )\n                else:\n                    out_msg_content.append(content)\n            elif isinstance(content, VisionMessageImageContent):\n                self.parse_image_url_parameters(content.image_url.url, kwargs)\n                out_msg_content.append(\n                    VisionMessageImageContent(\n                        image_url=VisionMessageImageURL(\n                            url=self._Template(content.image_url.url).render(**kwargs),\n                            detail=content.image_url.detail,\n                        )\n                    )\n                )\n            else:\n                raise ValueError(f\"Invalid content type: {content.type}\")\n\n        if len(out_msg_content) == 1 and out_msg_content[0].type == VisionMessageType.TEXT:\n            return Message(role=self.role, content=out_msg_content[0].text)\n\n        return VisionMessage(role=self.role, content=out_msg_content)\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        # Import and initialize Jinja2 Template here\n        from jinja2 import Template\n\n        self._Template = Template\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"\n        Converts the message to a dictionary.\n\n        Returns:\n            dict: The message as a dictionary.\n        \"\"\"\n        return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.VisionMessage.parse_bytes_to_base64","title":"<code>parse_bytes_to_base64(file_bytes)</code>","text":"<p>Parses file bytes in base64 format.</p> <p>Parameters:</p> Name Type Description Default <code>file_bytes</code> <code>bytes</code> <p>File bytes.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Base64 encoded file.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>def parse_bytes_to_base64(self, file_bytes: bytes) -&gt; str:\n    \"\"\"\n    Parses file bytes in base64 format.\n\n    Args:\n        file_bytes (bytes): File bytes.\n\n    Returns:\n        str: Base64 encoded file.\n    \"\"\"\n    extension = filetype.guess_extension(file_bytes)\n    if not extension:\n        extension = \"txt\"\n\n    encoded_str = base64.b64encode(file_bytes).decode(\"utf-8\")\n\n    mime_type, _ = mimetypes.guess_type(f\"file.{extension}\")\n\n    if mime_type is None:\n        mime_type = \"text/plain\"\n\n    return f\"data:{mime_type};base64,{encoded_str}\"\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.VisionMessage.parse_image_url_parameters","title":"<code>parse_image_url_parameters(url_template, kwargs)</code>","text":"<p>Converts image URL parameters in kwargs to Base64-encoded Data URLs if they contain image data.</p> <p>Parameters:</p> Name Type Description Default <code>url_template</code> <code>str</code> <p>Jinja template for the image URL.</p> required <code>kwargs</code> <code>dict</code> <p>Dictionary of parameters to be used with the template.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If a required parameter is missing in kwargs.</p> <code>ValueError</code> <p>If the file type cannot be determined or unsupported data type is provided.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>def parse_image_url_parameters(self, url_template: str, kwargs: dict) -&gt; None:\n    \"\"\"\n    Converts image URL parameters in kwargs to Base64-encoded Data URLs if they contain image data.\n\n    Args:\n        url_template (str): Jinja template for the image URL.\n        kwargs (dict): Dictionary of parameters to be used with the template.\n\n    Raises:\n        KeyError: If a required parameter is missing in kwargs.\n        ValueError: If the file type cannot be determined or unsupported data type is provided.\n    \"\"\"\n    template_params = get_parameters_for_template(url_template)\n\n    for param in template_params:\n        if param not in kwargs:\n            raise KeyError(f\"Missing required parameter: '{param}'\")\n\n        value = kwargs[param]\n\n        # Initialize as unchanged; will be modified if image data is detected\n        processed_value = value\n\n        if isinstance(value, io.BytesIO):\n            image_bytes = value.getvalue()\n            processed_value = self.parse_bytes_to_base64(image_bytes)\n\n        elif isinstance(value, bytes):\n            processed_value = self.parse_bytes_to_base64(value)\n\n        elif isinstance(value, str):\n            pass  # No action needed; assuming it's a regular URL or already a Data URL\n\n        else:\n            # Unsupported data type for image parameter\n            raise ValueError(f\"Unsupported data type for parameter '{param}': {type(value)}\")\n\n        # Update the parameter with the processed value\n        kwargs[param] = processed_value\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.VisionMessage.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Converts the message to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The message as a dictionary.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"\n    Converts the message to a dictionary.\n\n    Returns:\n        dict: The message as a dictionary.\n    \"\"\"\n    return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.VisionMessageImageContent","title":"<code>VisionMessageImageContent</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an image message in a vision conversation.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>VisionMessageType</code> <p>The type of the message, default is \"image_url\".</p> <code>image_url</code> <code>VisionMessageImageURL</code> <p>The image URL class.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>class VisionMessageImageContent(BaseModel):\n    \"\"\"\n    Represents an image message in a vision conversation.\n\n    Attributes:\n        type (VisionMessageType): The type of the message, default is \"image_url\".\n        image_url (VisionMessageImageURL): The image URL class.\n    \"\"\"\n    type: VisionMessageType = VisionMessageType.IMAGE_URL\n    image_url: VisionMessageImageURL\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.VisionMessageImageURL","title":"<code>VisionMessageImageURL</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents an image URL in a vision conversation.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL of the image.</p> <code>detail</code> <code>VisionDetail</code> <p>The detail level of the image, default is \"auto\".</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>class VisionMessageImageURL(BaseModel):\n    \"\"\"\n    Represents an image URL in a vision conversation.\n\n    Attributes:\n        url (str): The URL of the image.\n        detail (VisionDetail): The detail level of the image, default is \"auto\".\n    \"\"\"\n\n    url: str\n    detail: VisionDetail = VisionDetail.AUTO\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.VisionMessageTextContent","title":"<code>VisionMessageTextContent</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a text message in a vision conversation.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>VisionMessageType</code> <p>The type of the message, default is \"text\".</p> <code>text</code> <code>str</code> <p>The text content of the message.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>class VisionMessageTextContent(BaseModel):\n    \"\"\"\n    Represents a text message in a vision conversation.\n\n    Attributes:\n        type (VisionMessageType): The type of the message, default is \"text\".\n        text (str): The text content of the message.\n    \"\"\"\n\n    type: VisionMessageType = VisionMessageType.TEXT\n    text: str\n</code></pre>"},{"location":"dynamiq/prompts/prompts/#dynamiq.prompts.prompts.get_parameters_for_template","title":"<code>get_parameters_for_template(template, env=None)</code>","text":"<p>Extracts set of parameters for template.</p> <p>Parameters:</p> Name Type Description Default <code>template</code> <code>str</code> <p>Template to find parameters for.</p> required <code>env</code> <code>Environment | None</code> <p>(Environment, optional): jinja Environment object.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>set</code> <code>set[str]</code> <p>Set of required parameters.</p> Source code in <code>dynamiq/prompts/prompts.py</code> <pre><code>def get_parameters_for_template(template: str, env: Environment | None = None) -&gt; set[str]:\n    \"\"\"\n    Extracts set of parameters for template.\n\n    Args:\n        template (str): Template to find parameters for.\n        env: (Environment, optional): jinja Environment object.\n\n    Returns:\n        set: Set of required parameters.\n    \"\"\"\n    if not env:\n        env = Environment(autoescape=True)\n    # Parse the template to get its Abstract Syntax Tree\n    ast = env.parse(template)\n\n    # Find and return set of undeclared variables in the template\n    return meta.find_undeclared_variables(ast)\n</code></pre>"},{"location":"dynamiq/runnables/base/","title":"Base","text":""},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.Runnable","title":"<code>Runnable</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for runnable objects.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>class Runnable(ABC):\n    \"\"\"\n    Abstract base class for runnable objects.\n    \"\"\"\n\n    def run(\n        self, input_data: Any, config: RunnableConfig = None, is_async: bool | None = None, **kwargs\n    ) -&gt; RunnableResult | Awaitable[RunnableResult]:\n        \"\"\"Run the workflow with given input data and configuration.\n\n        This method acts as a dispatcher based on whether it's called from an async context:\n        - In synchronous contexts, it calls run_sync\n        - In asynchronous contexts, it calls run_async when awaited\n        - The mode can be explicitly specified with the is_async parameter\n\n        For direct control, use run_sync() or run_async() methods.\n\n        Args:\n            input_data (Any): Input data for the workflow.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            is_async (bool, optional): Force synchronous or asynchronous execution.\n                If None, tries to detect based on calling context.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Union[RunnableResult, Awaitable[RunnableResult]]: Result of the workflow execution\n                or awaitable coroutine leading to the result.\n        \"\"\"\n        if is_async is None:\n            is_async = is_called_from_async_context()\n\n        if is_async:\n            return self.run_async(input_data, config, **kwargs)\n        else:\n            return self.run_sync(input_data, config, **kwargs)\n\n    @abstractmethod\n    def run_sync(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n        \"\"\"\n        Abstract method to run the Runnable object synchronously.\n\n        Args:\n            input_data (Any): The input data for the execution.\n            config (RunnableConfig, optional): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: The result of the execution.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def run_async(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n        \"\"\"\n        Abstract method to run the Runnable object asynchronously.\n\n        Args:\n            input_data (Any): The input data for the execution.\n            config (RunnableConfig, optional): Configuration for the execution.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: The result of the execution.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.Runnable.run","title":"<code>run(input_data, config=None, is_async=None, **kwargs)</code>","text":"<p>Run the workflow with given input data and configuration.</p> <p>This method acts as a dispatcher based on whether it's called from an async context: - In synchronous contexts, it calls run_sync - In asynchronous contexts, it calls run_async when awaited - The mode can be explicitly specified with the is_async parameter</p> <p>For direct control, use run_sync() or run_async() methods.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the workflow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>is_async</code> <code>bool</code> <p>Force synchronous or asynchronous execution. If None, tries to detect based on calling context.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>RunnableResult | Awaitable[RunnableResult]</code> <p>Union[RunnableResult, Awaitable[RunnableResult]]: Result of the workflow execution or awaitable coroutine leading to the result.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>def run(\n    self, input_data: Any, config: RunnableConfig = None, is_async: bool | None = None, **kwargs\n) -&gt; RunnableResult | Awaitable[RunnableResult]:\n    \"\"\"Run the workflow with given input data and configuration.\n\n    This method acts as a dispatcher based on whether it's called from an async context:\n    - In synchronous contexts, it calls run_sync\n    - In asynchronous contexts, it calls run_async when awaited\n    - The mode can be explicitly specified with the is_async parameter\n\n    For direct control, use run_sync() or run_async() methods.\n\n    Args:\n        input_data (Any): Input data for the workflow.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        is_async (bool, optional): Force synchronous or asynchronous execution.\n            If None, tries to detect based on calling context.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Union[RunnableResult, Awaitable[RunnableResult]]: Result of the workflow execution\n            or awaitable coroutine leading to the result.\n    \"\"\"\n    if is_async is None:\n        is_async = is_called_from_async_context()\n\n    if is_async:\n        return self.run_async(input_data, config, **kwargs)\n    else:\n        return self.run_sync(input_data, config, **kwargs)\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.Runnable.run_async","title":"<code>run_async(input_data, config=None, **kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Abstract method to run the Runnable object asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>The input data for the execution.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>RunnableResult</code> <code>RunnableResult</code> <p>The result of the execution.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>@abstractmethod\nasync def run_async(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n    \"\"\"\n    Abstract method to run the Runnable object asynchronously.\n\n    Args:\n        input_data (Any): The input data for the execution.\n        config (RunnableConfig, optional): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        RunnableResult: The result of the execution.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.Runnable.run_sync","title":"<code>run_sync(input_data, config=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to run the Runnable object synchronously.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>The input data for the execution.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the execution.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>RunnableResult</code> <code>RunnableResult</code> <p>The result of the execution.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>@abstractmethod\ndef run_sync(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n    \"\"\"\n    Abstract method to run the Runnable object synchronously.\n\n    Args:\n        input_data (Any): The input data for the execution.\n        config (RunnableConfig, optional): Configuration for the execution.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        RunnableResult: The result of the execution.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.RunnableConfig","title":"<code>RunnableConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration class for Runnable objects.</p> <p>Attributes:</p> Name Type Description <code>callbacks</code> <code>list[BaseCallbackHandler]</code> <p>List of callback handlers.</p> <code>cache</code> <code>CacheConfig | None</code> <p>Cache configuration.</p> <code>max_node_workers</code> <code>int | None</code> <p>Maximum number of node workers.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>class RunnableConfig(BaseModel):\n    \"\"\"\n    Configuration class for Runnable objects.\n\n    Attributes:\n        callbacks (list[BaseCallbackHandler]): List of callback handlers.\n        cache (CacheConfig | None): Cache configuration.\n        max_node_workers (int | None): Maximum number of node workers.\n    \"\"\"\n\n    run_id: str | None = Field(default_factory=generate_uuid)\n    callbacks: list[BaseCallbackHandler] = []\n    cache: CacheConfig | None = None\n    max_node_workers: int | None = None\n    nodes_override: dict[str, NodeRunnableConfig] = {}\n    dry_run: DryRunConfig | None = None\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.RunnableResult","title":"<code>RunnableResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Dataclass representing the result of a Runnable execution.</p> <p>Attributes:</p> Name Type Description <code>status</code> <code>RunnableStatus</code> <p>The status of the execution.</p> <code>input</code> <code>Any</code> <p>The input data of the execution.</p> <code>output</code> <code>Any</code> <p>The output data of the execution.</p> <code>error</code> <code>RunnableResultError | None</code> <p>The error of the execution.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>class RunnableResult(BaseModel):\n    \"\"\"\n    Dataclass representing the result of a Runnable execution.\n\n    Attributes:\n        status (RunnableStatus): The status of the execution.\n        input (Any): The input data of the execution.\n        output (Any): The output data of the execution.\n        error (RunnableResultError | None): The error of the execution.\n    \"\"\"\n\n    status: RunnableStatus\n    input: Any = None\n    output: Any = None\n    error: RunnableResultError | None = None\n\n    def to_depend_dict(\n        self,\n        skip_format_types: set | None = None,\n        force_format_types: set | None = None,\n        **kwargs\n    ) -&gt; dict:\n        \"\"\"\n        Convert the RunnableResult instance to a dictionary that used as dependency context.\n\n        Returns:\n            dict: A dictionary representation of the RunnableResult.\n        \"\"\"\n        if skip_format_types is None:\n            skip_format_types = set()\n        skip_format_types.update({BytesIO, BaseModel, bytes})\n\n        if force_format_types is None:\n            force_format_types = set()\n        force_format_types.update({RunnableResult, RunnableResultError})\n\n        return self.to_dict(skip_format_types, force_format_types, **kwargs)\n\n    def to_tracing_depend_dict(\n        self, skip_format_types: set | None = None, force_format_types: set | None = None, **kwargs\n    ) -&gt; dict:\n        \"\"\"\n        Convert the RunnableResult instance to a dictionary that used as dependency context in tracing.\n\n        Returns:\n            dict: A dictionary representation of the RunnableResult.\n        \"\"\"\n\n        depend_dict = self.to_depend_dict(skip_format_types, force_format_types, **kwargs)\n        depend_dict.pop(\"input\", None)\n\n        return depend_dict\n\n    def to_dict(\n        self,\n        skip_format_types: set | None = None,\n        force_format_types: set | None = None,\n        **kwargs\n    ) -&gt; dict:\n        \"\"\"\n        Convert the RunnableResult instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the RunnableResult.\n        \"\"\"\n\n        data = {\n            \"status\": self.status.value,\n            \"input\": format_value(self.input, skip_format_types, force_format_types),\n            \"output\": format_value(self.output, skip_format_types, force_format_types),\n        }\n        if self.error:\n            data[\"error\"] = format_value(self.error, skip_format_types, force_format_types)\n\n        return data\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.RunnableResult.to_depend_dict","title":"<code>to_depend_dict(skip_format_types=None, force_format_types=None, **kwargs)</code>","text":"<p>Convert the RunnableResult instance to a dictionary that used as dependency context.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the RunnableResult.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>def to_depend_dict(\n    self,\n    skip_format_types: set | None = None,\n    force_format_types: set | None = None,\n    **kwargs\n) -&gt; dict:\n    \"\"\"\n    Convert the RunnableResult instance to a dictionary that used as dependency context.\n\n    Returns:\n        dict: A dictionary representation of the RunnableResult.\n    \"\"\"\n    if skip_format_types is None:\n        skip_format_types = set()\n    skip_format_types.update({BytesIO, BaseModel, bytes})\n\n    if force_format_types is None:\n        force_format_types = set()\n    force_format_types.update({RunnableResult, RunnableResultError})\n\n    return self.to_dict(skip_format_types, force_format_types, **kwargs)\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.RunnableResult.to_dict","title":"<code>to_dict(skip_format_types=None, force_format_types=None, **kwargs)</code>","text":"<p>Convert the RunnableResult instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the RunnableResult.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>def to_dict(\n    self,\n    skip_format_types: set | None = None,\n    force_format_types: set | None = None,\n    **kwargs\n) -&gt; dict:\n    \"\"\"\n    Convert the RunnableResult instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the RunnableResult.\n    \"\"\"\n\n    data = {\n        \"status\": self.status.value,\n        \"input\": format_value(self.input, skip_format_types, force_format_types),\n        \"output\": format_value(self.output, skip_format_types, force_format_types),\n    }\n    if self.error:\n        data[\"error\"] = format_value(self.error, skip_format_types, force_format_types)\n\n    return data\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.RunnableResult.to_tracing_depend_dict","title":"<code>to_tracing_depend_dict(skip_format_types=None, force_format_types=None, **kwargs)</code>","text":"<p>Convert the RunnableResult instance to a dictionary that used as dependency context in tracing.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the RunnableResult.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>def to_tracing_depend_dict(\n    self, skip_format_types: set | None = None, force_format_types: set | None = None, **kwargs\n) -&gt; dict:\n    \"\"\"\n    Convert the RunnableResult instance to a dictionary that used as dependency context in tracing.\n\n    Returns:\n        dict: A dictionary representation of the RunnableResult.\n    \"\"\"\n\n    depend_dict = self.to_depend_dict(skip_format_types, force_format_types, **kwargs)\n    depend_dict.pop(\"input\", None)\n\n    return depend_dict\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.RunnableResultError","title":"<code>RunnableResultError</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>class RunnableResultError(BaseModel):\n    type: type[Exception]\n    message: str\n    recoverable: bool = False\n\n    @classmethod\n    def from_exception(cls, exception: Exception, recoverable: bool = False) -&gt; \"RunnableResultError\":\n        return cls(\n            type=type(exception),\n            message=str(exception),\n            recoverable=recoverable,\n        )\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"\n        Convert the RunnableResultError instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the RunnableResultError.\n        \"\"\"\n        data = self.model_dump(**kwargs)\n        data[\"type\"] = self.type.__name__\n        return data\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.RunnableResultError.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Convert the RunnableResultError instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the RunnableResultError.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"\n    Convert the RunnableResultError instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the RunnableResultError.\n    \"\"\"\n    data = self.model_dump(**kwargs)\n    data[\"type\"] = self.type.__name__\n    return data\n</code></pre>"},{"location":"dynamiq/runnables/base/#dynamiq.runnables.base.RunnableStatus","title":"<code>RunnableStatus</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of possible statuses for a Runnable object.</p> <p>Attributes:</p> Name Type Description <code>UNDEFINED</code> <p>Undefined status.</p> <code>FAILURE</code> <p>Failure status.</p> <code>SUCCESS</code> <p>Success status.</p> <code>SKIP</code> <p>Skip status.</p> Source code in <code>dynamiq/runnables/base.py</code> <pre><code>class RunnableStatus(str, Enum):\n    \"\"\"\n    Enumeration of possible statuses for a Runnable object.\n\n    Attributes:\n        UNDEFINED: Undefined status.\n        FAILURE: Failure status.\n        SUCCESS: Success status.\n        SKIP: Skip status.\n    \"\"\"\n\n    UNDEFINED = \"undefined\"\n    FAILURE = \"failure\"\n    SUCCESS = \"success\"\n    SKIP = \"skip\"\n</code></pre>"},{"location":"dynamiq/serializers/types/","title":"Types","text":""},{"location":"dynamiq/serializers/types/#dynamiq.serializers.types.WorkflowYamlData","title":"<code>WorkflowYamlData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data model for the Workflow YAML.</p> Source code in <code>dynamiq/serializers/types.py</code> <pre><code>class WorkflowYamlData(BaseModel):\n    \"\"\"Data model for the Workflow YAML.\"\"\"\n\n    connections: dict[str, BaseConnection]\n    nodes: dict[str, Node]\n    flows: dict[str, Flow]\n    workflows: dict[str, Workflow]\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"dynamiq/serializers/dumpers/yaml/","title":"Yaml","text":""},{"location":"dynamiq/serializers/dumpers/yaml/#dynamiq.serializers.dumpers.yaml.WorkflowYAMLDumper","title":"<code>WorkflowYAMLDumper</code>","text":"<p>Dumper class for parsing workflow components and save them to YAML.</p> Source code in <code>dynamiq/serializers/dumpers/yaml.py</code> <pre><code>class WorkflowYAMLDumper:\n    \"\"\"Dumper class for parsing workflow components and save them to YAML.\"\"\"\n\n    @classmethod\n    def get_updated_node_data(\n        cls,\n        node_data: dict,\n        connections_data: dict[str, dict],\n        skip_nullable: bool = False,\n    ):\n        \"\"\"\n        Get node init data with and connections components recursively (llms, agents, etc)\n\n        Args:\n            node_data: Dictionary containing node data.\n            connections_data: Dictionary containing connections shared data.\n            skip_nullable: Skip nullable fields.\n\n        Returns:\n            A dictionary of newly created nodes with dependencies.\n        \"\"\"\n        updated_node_init_data = {}\n        for param_name, param_data in node_data.items():\n            if param_name == \"depends\":\n                updated_node_init_data[param_name] = [\n                    {\"node\": dep[\"node\"][\"id\"], \"option\": dep[\"option\"]} for dep in param_data\n                ]\n\n            elif param_name == \"connection\":\n                param_id = None\n                connections_data[param_data[\"id\"]] = cls.get_updated_node_data(\n                    node_data={param_id: param_data}, connections_data=connections_data, skip_nullable=True\n                )[param_id]\n                updated_node_init_data[param_name] = param_data[\"id\"]\n\n            elif isinstance(param_data, dict):\n                updated_param_data = {}\n                for param_name_inner, param_data_inner in param_data.items():\n                    if isinstance(param_data_inner, (dict, list)):\n                        param_data_inner = cls.get_updated_node_data(\n                            node_data={param_name_inner: param_data_inner}, connections_data=connections_data\n                        )[param_name_inner]\n                    elif param_data_inner is None and skip_nullable:\n                        continue\n                    else:\n                        param_data_inner = encode(param_data_inner)\n\n                    updated_param_data[param_name_inner] = param_data_inner\n\n                updated_node_init_data[param_name] = updated_param_data\n\n            elif isinstance(param_data, list):\n                updated_items = []\n                for item in param_data:\n                    if isinstance(item, (dict, list)):\n                        param_id = None\n                        item = cls.get_updated_node_data(node_data={param_id: item}, connections_data=connections_data)[\n                            param_id\n                        ]\n                    elif item is None and skip_nullable:\n                        continue\n                    else:\n                        item = encode(item)\n                    updated_items.append(item)\n                updated_node_init_data[param_name] = updated_items\n\n            else:\n                if param_data is None and skip_nullable:\n                    continue\n                else:\n                    param_data = encode(param_data)\n\n                updated_node_init_data[param_name] = param_data\n\n        return updated_node_init_data\n\n    @classmethod\n    def get_nodes_data_and_connections(\n        cls, nodes: dict[str, Node], connections: dict[str, BaseConnection]\n    ) -&gt; tuple[dict, dict]:\n        \"\"\"\n        Get nodes data prepared for Yaml and connections from the given data.\n\n        Args:\n            nodes: Existing nodes dictionary.\n            connections: Existing connections dictionary.\n\n        Returns:\n            A tuple of parsed nodes and connections\n        \"\"\"\n        nodes_data = {}\n        connections_data = {conn_id: conn.to_dict() for conn_id, conn in connections.items()}\n        for node_id, node in nodes.items():\n            node_data = cls.get_updated_node_data(\n                node_data=node.to_dict(include_secure_params=True, by_alias=True), connections_data=connections_data\n            )\n            nodes_data[node_id] = node_data\n\n        return nodes_data, connections_data\n\n    @classmethod\n    def get_flows_data(cls, flows: dict[str, Flow]):\n        \"\"\"\n        Get flows data prepared for Yaml from the given data.\n\n        Args:\n            flows: Existing flows dictionary.\n\n        Returns:\n            A dictionary of newly created flows\n        \"\"\"\n        flows_data = {}\n        for flow_id, flow in flows.items():\n            flow_data = flow.to_dict(exclude={\"nodes\", \"executor\", \"connection_manager\"})\n            flow_data[\"nodes\"] = [node.id for node in flow.nodes]\n            flows_data[flow_id] = flow_data\n\n        return flows_data\n\n    @classmethod\n    def dump(\n        cls,\n        file_path: str | PathLike,\n        data: WorkflowYamlData,\n    ):\n        \"\"\"\n        Parse data from a WorkflowYamlData and save it to YAML file.\n\n        Args:\n            file_path: Path to the YAML file.\n            data: WorkflowYamlData object.\n        \"\"\"\n        data = cls.parse(data=data)\n        cls.dumps(file_path=file_path, data=data)\n\n    @classmethod\n    def dumps(cls, file_path: str | PathLike | IO[Any], data: dict):\n        \"\"\"\n        Load data from a YAML file.\n\n        Args:\n            file_path: Path to the YAML file.\n            data: Data to dump to the YAML file.\n\n        Raises:\n            WorkflowYAMLDumperException: If the file is not found.\n        \"\"\"\n        from omegaconf import OmegaConf\n\n        try:\n            conf = OmegaConf.create(data)\n            logger.debug(\"Dumped data to config\")\n\n            OmegaConf.save(config=conf, f=file_path)\n        except FileNotFoundError:\n            raise WorkflowYAMLDumperException(f\"File '{file_path}' not found\")\n\n    @classmethod\n    def parse(cls, data: WorkflowYamlData) -&gt; dict:\n        \"\"\"\n        Parse dynamiq workflow data.\n\n        Args:\n            data: WorkflowYamlData object.\n\n        Returns:\n            Parsed dict object.\n\n        Raises:\n            WorkflowYAMLDumperException: If parsing fails.\n        \"\"\"\n\n        try:\n            nodes, connections = cls.get_nodes_data_and_connections(data.nodes, data.connections)\n            flows = cls.get_flows_data(data.flows)\n            wf_data = {\n                \"connections\": connections,\n                \"nodes\": nodes,\n                \"flows\": flows,\n                \"workflows\": {\n                    wf_id: wf.to_dict(exclude={\"flow\"}) | {\"flow\": wf.flow.id} for wf_id, wf in data.workflows.items()\n                },\n            }\n        except Exception as e:\n            logger.exception(\"Failed to parse WorkflowYamlData object with unexpected error\")\n            raise WorkflowYAMLDumperException from e\n\n        return wf_data\n</code></pre>"},{"location":"dynamiq/serializers/dumpers/yaml/#dynamiq.serializers.dumpers.yaml.WorkflowYAMLDumper.dump","title":"<code>dump(file_path, data)</code>  <code>classmethod</code>","text":"<p>Parse data from a WorkflowYamlData and save it to YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | PathLike</code> <p>Path to the YAML file.</p> required <code>data</code> <code>WorkflowYamlData</code> <p>WorkflowYamlData object.</p> required Source code in <code>dynamiq/serializers/dumpers/yaml.py</code> <pre><code>@classmethod\ndef dump(\n    cls,\n    file_path: str | PathLike,\n    data: WorkflowYamlData,\n):\n    \"\"\"\n    Parse data from a WorkflowYamlData and save it to YAML file.\n\n    Args:\n        file_path: Path to the YAML file.\n        data: WorkflowYamlData object.\n    \"\"\"\n    data = cls.parse(data=data)\n    cls.dumps(file_path=file_path, data=data)\n</code></pre>"},{"location":"dynamiq/serializers/dumpers/yaml/#dynamiq.serializers.dumpers.yaml.WorkflowYAMLDumper.dumps","title":"<code>dumps(file_path, data)</code>  <code>classmethod</code>","text":"<p>Load data from a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | PathLike | IO[Any]</code> <p>Path to the YAML file.</p> required <code>data</code> <code>dict</code> <p>Data to dump to the YAML file.</p> required <p>Raises:</p> Type Description <code>WorkflowYAMLDumperException</code> <p>If the file is not found.</p> Source code in <code>dynamiq/serializers/dumpers/yaml.py</code> <pre><code>@classmethod\ndef dumps(cls, file_path: str | PathLike | IO[Any], data: dict):\n    \"\"\"\n    Load data from a YAML file.\n\n    Args:\n        file_path: Path to the YAML file.\n        data: Data to dump to the YAML file.\n\n    Raises:\n        WorkflowYAMLDumperException: If the file is not found.\n    \"\"\"\n    from omegaconf import OmegaConf\n\n    try:\n        conf = OmegaConf.create(data)\n        logger.debug(\"Dumped data to config\")\n\n        OmegaConf.save(config=conf, f=file_path)\n    except FileNotFoundError:\n        raise WorkflowYAMLDumperException(f\"File '{file_path}' not found\")\n</code></pre>"},{"location":"dynamiq/serializers/dumpers/yaml/#dynamiq.serializers.dumpers.yaml.WorkflowYAMLDumper.get_flows_data","title":"<code>get_flows_data(flows)</code>  <code>classmethod</code>","text":"<p>Get flows data prepared for Yaml from the given data.</p> <p>Parameters:</p> Name Type Description Default <code>flows</code> <code>dict[str, Flow]</code> <p>Existing flows dictionary.</p> required <p>Returns:</p> Type Description <p>A dictionary of newly created flows</p> Source code in <code>dynamiq/serializers/dumpers/yaml.py</code> <pre><code>@classmethod\ndef get_flows_data(cls, flows: dict[str, Flow]):\n    \"\"\"\n    Get flows data prepared for Yaml from the given data.\n\n    Args:\n        flows: Existing flows dictionary.\n\n    Returns:\n        A dictionary of newly created flows\n    \"\"\"\n    flows_data = {}\n    for flow_id, flow in flows.items():\n        flow_data = flow.to_dict(exclude={\"nodes\", \"executor\", \"connection_manager\"})\n        flow_data[\"nodes\"] = [node.id for node in flow.nodes]\n        flows_data[flow_id] = flow_data\n\n    return flows_data\n</code></pre>"},{"location":"dynamiq/serializers/dumpers/yaml/#dynamiq.serializers.dumpers.yaml.WorkflowYAMLDumper.get_nodes_data_and_connections","title":"<code>get_nodes_data_and_connections(nodes, connections)</code>  <code>classmethod</code>","text":"<p>Get nodes data prepared for Yaml and connections from the given data.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>dict[str, Node]</code> <p>Existing nodes dictionary.</p> required <code>connections</code> <code>dict[str, BaseConnection]</code> <p>Existing connections dictionary.</p> required <p>Returns:</p> Type Description <code>tuple[dict, dict]</code> <p>A tuple of parsed nodes and connections</p> Source code in <code>dynamiq/serializers/dumpers/yaml.py</code> <pre><code>@classmethod\ndef get_nodes_data_and_connections(\n    cls, nodes: dict[str, Node], connections: dict[str, BaseConnection]\n) -&gt; tuple[dict, dict]:\n    \"\"\"\n    Get nodes data prepared for Yaml and connections from the given data.\n\n    Args:\n        nodes: Existing nodes dictionary.\n        connections: Existing connections dictionary.\n\n    Returns:\n        A tuple of parsed nodes and connections\n    \"\"\"\n    nodes_data = {}\n    connections_data = {conn_id: conn.to_dict() for conn_id, conn in connections.items()}\n    for node_id, node in nodes.items():\n        node_data = cls.get_updated_node_data(\n            node_data=node.to_dict(include_secure_params=True, by_alias=True), connections_data=connections_data\n        )\n        nodes_data[node_id] = node_data\n\n    return nodes_data, connections_data\n</code></pre>"},{"location":"dynamiq/serializers/dumpers/yaml/#dynamiq.serializers.dumpers.yaml.WorkflowYAMLDumper.get_updated_node_data","title":"<code>get_updated_node_data(node_data, connections_data, skip_nullable=False)</code>  <code>classmethod</code>","text":"<p>Get node init data with and connections components recursively (llms, agents, etc)</p> <p>Parameters:</p> Name Type Description Default <code>node_data</code> <code>dict</code> <p>Dictionary containing node data.</p> required <code>connections_data</code> <code>dict[str, dict]</code> <p>Dictionary containing connections shared data.</p> required <code>skip_nullable</code> <code>bool</code> <p>Skip nullable fields.</p> <code>False</code> <p>Returns:</p> Type Description <p>A dictionary of newly created nodes with dependencies.</p> Source code in <code>dynamiq/serializers/dumpers/yaml.py</code> <pre><code>@classmethod\ndef get_updated_node_data(\n    cls,\n    node_data: dict,\n    connections_data: dict[str, dict],\n    skip_nullable: bool = False,\n):\n    \"\"\"\n    Get node init data with and connections components recursively (llms, agents, etc)\n\n    Args:\n        node_data: Dictionary containing node data.\n        connections_data: Dictionary containing connections shared data.\n        skip_nullable: Skip nullable fields.\n\n    Returns:\n        A dictionary of newly created nodes with dependencies.\n    \"\"\"\n    updated_node_init_data = {}\n    for param_name, param_data in node_data.items():\n        if param_name == \"depends\":\n            updated_node_init_data[param_name] = [\n                {\"node\": dep[\"node\"][\"id\"], \"option\": dep[\"option\"]} for dep in param_data\n            ]\n\n        elif param_name == \"connection\":\n            param_id = None\n            connections_data[param_data[\"id\"]] = cls.get_updated_node_data(\n                node_data={param_id: param_data}, connections_data=connections_data, skip_nullable=True\n            )[param_id]\n            updated_node_init_data[param_name] = param_data[\"id\"]\n\n        elif isinstance(param_data, dict):\n            updated_param_data = {}\n            for param_name_inner, param_data_inner in param_data.items():\n                if isinstance(param_data_inner, (dict, list)):\n                    param_data_inner = cls.get_updated_node_data(\n                        node_data={param_name_inner: param_data_inner}, connections_data=connections_data\n                    )[param_name_inner]\n                elif param_data_inner is None and skip_nullable:\n                    continue\n                else:\n                    param_data_inner = encode(param_data_inner)\n\n                updated_param_data[param_name_inner] = param_data_inner\n\n            updated_node_init_data[param_name] = updated_param_data\n\n        elif isinstance(param_data, list):\n            updated_items = []\n            for item in param_data:\n                if isinstance(item, (dict, list)):\n                    param_id = None\n                    item = cls.get_updated_node_data(node_data={param_id: item}, connections_data=connections_data)[\n                        param_id\n                    ]\n                elif item is None and skip_nullable:\n                    continue\n                else:\n                    item = encode(item)\n                updated_items.append(item)\n            updated_node_init_data[param_name] = updated_items\n\n        else:\n            if param_data is None and skip_nullable:\n                continue\n            else:\n                param_data = encode(param_data)\n\n            updated_node_init_data[param_name] = param_data\n\n    return updated_node_init_data\n</code></pre>"},{"location":"dynamiq/serializers/dumpers/yaml/#dynamiq.serializers.dumpers.yaml.WorkflowYAMLDumper.parse","title":"<code>parse(data)</code>  <code>classmethod</code>","text":"<p>Parse dynamiq workflow data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>WorkflowYamlData</code> <p>WorkflowYamlData object.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Parsed dict object.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLDumperException</code> <p>If parsing fails.</p> Source code in <code>dynamiq/serializers/dumpers/yaml.py</code> <pre><code>@classmethod\ndef parse(cls, data: WorkflowYamlData) -&gt; dict:\n    \"\"\"\n    Parse dynamiq workflow data.\n\n    Args:\n        data: WorkflowYamlData object.\n\n    Returns:\n        Parsed dict object.\n\n    Raises:\n        WorkflowYAMLDumperException: If parsing fails.\n    \"\"\"\n\n    try:\n        nodes, connections = cls.get_nodes_data_and_connections(data.nodes, data.connections)\n        flows = cls.get_flows_data(data.flows)\n        wf_data = {\n            \"connections\": connections,\n            \"nodes\": nodes,\n            \"flows\": flows,\n            \"workflows\": {\n                wf_id: wf.to_dict(exclude={\"flow\"}) | {\"flow\": wf.flow.id} for wf_id, wf in data.workflows.items()\n            },\n        }\n    except Exception as e:\n        logger.exception(\"Failed to parse WorkflowYamlData object with unexpected error\")\n        raise WorkflowYAMLDumperException from e\n\n    return wf_data\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/","title":"Yaml","text":""},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader","title":"<code>WorkflowYAMLLoader</code>","text":"<p>Loader class for parsing YAML files and creating workflow components.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>class WorkflowYAMLLoader:\n    \"\"\"Loader class for parsing YAML files and creating workflow components.\"\"\"\n\n    @classmethod\n    def get_entity_by_type(cls, entity_type: str, entity_registry: dict[str, Any] | None = None) -&gt; Any:\n        \"\"\"\n        Try to get entity by type and update mutable shared registry.\n\n        Args:\n            entity_type (str): The type of entity to retrieve.\n            entity_registry (dict[str, Any] | None): A registry of entities.\n\n        Returns:\n            Any: The retrieved entity.\n\n        Raises:\n            WorkflowYAMLLoaderException: If the entity is not valid or cannot be found.\n        \"\"\"\n        if entity_registry is None:\n            entity_registry = {}\n\n        if entity := entity_registry.get(entity_type):\n            return entity\n\n        try:\n            entity = ConnectionManager.get_connection_by_type(entity_type)\n        except ValueError:\n            pass\n\n        if not entity:\n            try:\n                entity = NodeManager.get_node_by_type(entity_type)\n            except ValueError:\n                pass\n\n        if not entity:\n            raise WorkflowYAMLLoaderException(f\"Entity '{entity_type}' is not valid.\")\n\n        entity_registry[entity_type] = entity\n        return entity\n\n    @classmethod\n    def get_connections(cls, data: dict[str, dict], registry: dict[str, Any]) -&gt; dict[str, BaseConnection]:\n        \"\"\"\n        Get connections from the provided data.\n\n        Args:\n            data (dict[str, dict]): The data containing connection information.\n            registry (dict[str, Any]): A registry of entities.\n\n        Returns:\n            dict[str, BaseConnection]: A dictionary of connections.\n\n        Raises:\n            WorkflowYAMLLoaderException: If there's an error in connection data or initialization.\n        \"\"\"\n        connections = {}\n        for conn_id, conn_data in data.get(\"connections\", {}).items():\n            if conn_id in connections:\n                raise WorkflowYAMLLoaderException(f\"Connection '{conn_id}' already exists\")\n            if not (conn_type := conn_data.get(\"type\")):\n                raise WorkflowYAMLLoaderException(f\"Value 'type' not found for connection '{conn_id}'\")\n\n            conn_cls = cls.get_entity_by_type(entity_type=conn_type, entity_registry=registry)\n            conn_init_data = conn_data | {\"id\": conn_id}\n            conn_init_data.pop(\"type\", None)\n            try:\n                connection = conn_cls(**conn_init_data)\n            except Exception as e:\n                raise WorkflowYAMLLoaderException(f\"Connection '{conn_id}' data is invalid. Error: {e}\")\n\n            connections[conn_id] = connection\n\n        return connections\n\n    @classmethod\n    def init_prompt(cls, prompt_init_data: dict) -&gt; Prompt:\n        \"\"\"\n        Initialize a prompt from the provided data.\n\n        Args:\n            prompt_init_data (dict): The data for the prompt.\n\n        Returns:\n            Prompt: The initialized prompt.\n\n        Raises:\n            WorkflowYAMLLoaderException: If the specified prompt is not found.\n        \"\"\"\n        try:\n            return Prompt(**prompt_init_data)\n        except Exception as e:\n            raise WorkflowYAMLLoaderException(f\"Prompt '{prompt_init_data.get('id')}' data is invalid. Error: {e}\")\n\n    @classmethod\n    def get_prompts(cls, data: dict[str, dict]) -&gt; dict[str, Prompt]:\n        \"\"\"\n        Get prompts from the provided data.\n\n        Args:\n            data (dict[str, dict]): The data containing prompt information.\n\n        Returns:\n            dict[str, Prompt]: A dictionary of prompts.\n\n        Raises:\n            WorkflowYAMLLoaderException: If there's an error in prompt data or initialization.\n        \"\"\"\n        prompts = {}\n        for prompt_id, prompt_data in data.get(\"prompts\", {}).items():\n            if prompt_id in prompts:\n                raise WorkflowYAMLLoaderException(f\"Prompt '{prompt_id}' already exists\")\n            prompts[prompt_id] = cls.init_prompt(prompt_data | {\"id\": prompt_id})\n\n        return prompts\n\n    @classmethod\n    def get_node_prompt(cls, node_id: str, node_data: dict, prompts: dict[id, Prompt]) -&gt; Prompt | None:\n        \"\"\"\n        Get the prompt for a node.\n\n        Args:\n            node_id (str): The ID of the node.\n            node_data (dict): The data for the node.\n            prompts (dict[id, Prompt]): A dictionary of available prompts.\n\n        Returns:\n            Prompt | None: The prompt for the node, or None if not found.\n\n        Raises:\n            WorkflowYAMLLoaderException: If the specified prompt is not found.\n        \"\"\"\n        prompt = None\n        if prompt_id := node_data.get(\"prompt\"):\n            prompt = prompts.get(prompt_id)\n            if not prompt:\n                raise WorkflowYAMLLoaderException(f\"Prompt '{prompt_id}' for node '{node_id}' not found\")\n        return prompt\n\n    @classmethod\n    def get_node_connection(\n        cls, node_id: str, node_data: dict, connections: dict[id, BaseConnection]\n    ) -&gt; BaseConnection | None:\n        \"\"\"\n        Get the connection for a node.\n\n        Args:\n            node_id (str): The ID of the node.\n            node_data (dict): The data for the node.\n            connections (dict[id, BaseConnection]): A dictionary of available connections.\n\n        Returns:\n            BaseConnection | None: The connection for the node, or None if not found.\n\n        Raises:\n            WorkflowYAMLLoaderException: If the specified connection is not found.\n        \"\"\"\n        conn = None\n        if conn_id := node_data.get(\"connection\"):\n            conn = connections.get(conn_id)\n            if not conn:\n                raise WorkflowYAMLLoaderException(f\"Connection '{conn_id}' for node '{node_id}' not found\")\n        return conn\n\n    @classmethod\n    def get_node_vector_store_connection(\n        cls, node_id: str, node_data: dict, connections: dict[id, BaseConnection]\n    ) -&gt; Any | None:\n        \"\"\"\n        Get the vector store connection for a node.\n\n        Args:\n            node_id (str): The ID of the node.\n            node_data (dict): The data for the node.\n            connections (dict[id, BaseConnection]): A dictionary of available connections.\n\n        Returns:\n            Any | None: The vector store connection for the node, or None if not found.\n\n        Raises:\n            WorkflowYAMLLoaderException: If the specified vector store connection is not found or\n                                         does not support vector store initialization.\n        \"\"\"\n        if conn := cls.get_node_connection(node_id=node_id, node_data=node_data, connections=connections):\n            if not (conn_to_vs := getattr(conn, \"connect_to_vector_store\", None)) or not callable(conn_to_vs):\n                raise WorkflowYAMLLoaderException(\n                    f\"Vector store connection '{conn.id}' for node '{node_id}' not support vector store initialization\"\n                )\n        return conn\n\n    @classmethod\n    def get_node_flow(cls, node_id: str, node_data: dict, flows: dict[id, Flow]) -&gt; Flow | None:\n        \"\"\"\n        Get the flow for a node.\n\n        Args:\n            node_id (str): The ID of the node.\n            node_data (dict): The data for the node.\n            flows (dict[id, Flow]): A dictionary of available flows.\n\n        Returns:\n            Flow | None: The flow for the node, or None if not found.\n\n        Raises:\n            WorkflowYAMLLoaderException: If the specified flow is not found.\n        \"\"\"\n        flow = None\n        if flow_id := node_data.get(\"flow\"):\n            flow = flows.get(flow_id)\n            if not flow:\n                raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' for node '{node_id}' not found\")\n        return flow\n\n    @classmethod\n    def get_node_flows(cls, node_id: str, node_data: dict, flows: dict[id, Flow]) -&gt; list[Flow]:\n        \"\"\"\n        Get the flows for a node.\n\n        Args:\n            node_id (str): The ID of the node.\n            node_data (dict): The data for the node.\n            flows (dict[id, Flow]): A dictionary of available flows.\n\n        Returns:\n            list[Flow]: A list of flows for the node.\n\n        Raises:\n            WorkflowYAMLLoaderException: If any specified flow is not found.\n        \"\"\"\n        node_flows = []\n        for flow_id in node_data.get(\"flows\", []):\n            node_flow = flows.get(flow_id)\n            if not node_flow:\n                raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' for node '{node_id}' not found\")\n            node_flows.append(node_flow)\n        return node_flows\n\n    @classmethod\n    def get_node_dependencies(cls, node_id: str, node_data: dict, nodes: dict[str, Node]):\n        \"\"\"\n        Get the dependencies for a node.\n\n        Args:\n            node_id (str): The ID of the node.\n            node_data (dict): The data for the node.\n            nodes (dict[str, Node]): A dictionary of available nodes.\n\n        Returns:\n            list[NodeDependency]: A list of node dependencies.\n\n        Raises:\n            WorkflowYAMLLoaderException: If there's an error in dependency data or initialization.\n        \"\"\"\n        node_depends = []\n        for dependency_data in node_data.get(\"depends\", []):\n            dependency_node = nodes.get(dependency_data.get(\"node\"))\n            dependency_init_data = dependency_data | {\"node\": dependency_node}\n            try:\n                dependency = NodeDependency(**dependency_init_data)\n            except Exception as e:\n                raise WorkflowYAMLLoaderException(\n                    f\"Dependency '{dependency_data.get('node')}' data for node '{node_id}' \" f\"is invalid. Error: {e}\"\n                )\n\n            if dependency.option:\n                if not (dep_options := getattr(dependency_node, \"options\", [])):\n                    raise WorkflowYAMLLoaderException(\n                        f\"Dependency '{dependency.node.id}' with option '{dependency.option}' \"\n                        f\"for node '{node_id}' not found\"\n                    )\n\n                if not any(opt.id == dependency.option for opt in dep_options):\n                    raise WorkflowYAMLLoaderException(\n                        f\"Dependency '{dependency.node.id}' with option '{dependency.option}' \"\n                        f\"for node '{node_id}' not found\"\n                    )\n\n            node_depends.append(dependency)\n        return node_depends\n\n    @classmethod\n    def get_updated_node_init_data_with_initialized_nodes(\n        cls,\n        node_init_data: dict,\n        nodes: dict[str, Node],\n        flows: dict[str, Flow],\n        connections: dict[str, BaseConnection],\n        prompts: dict[str, Prompt],\n        registry: dict[str, Any],\n        connection_manager: ConnectionManager | None = None,\n        init_components: bool = False,\n        max_workers: int | None = None,\n    ):\n        \"\"\"\n        Get node init data with initialized nodes components recursively (llms, agents, etc)\n\n        Args:\n            node_init_data: Dictionary containing node data.\n            nodes: Existing nodes dictionary.\n            flows: Existing flows dictionary.\n            connections: Existing connections dictionary.\n            prompts: Existing prompts dictionary.\n            registry: Registry of node types.\n            connection_manager: Optional connection manager.\n            init_components: Flag to initialize components.\n            max_workers: Maximum number of worker threads for node parallel processing.\n\n        Returns:\n            A dictionary of newly created nodes with dependencies.\n        \"\"\"\n        updated_node_init_data = {}\n        kwargs = dict(\n            nodes=nodes,\n            flows=flows,\n            connections=connections,\n            prompts=prompts,\n            registry=registry,\n            connection_manager=connection_manager,\n            init_components=init_components,\n            max_workers=max_workers,\n        )\n        for param_name, param_data in node_init_data.items():\n            # TODO: dummy fix, revisit this!\n            # We had to add this condition because some nodes have a `schema`/`response_format` params,\n            # that have a `type` field that contains types supported by JSON schema (e.g., string, object).\n            if param_name in (\"schema\", \"response_format\"):\n                updated_node_init_data[param_name] = param_data\n\n            elif isinstance(param_data, dict):\n                updated_param_data = {}\n                for param_name_inner, param_data_inner in param_data.items():\n                    if param_name_inner in (\"prompt\", \"schema\", \"response_format\"):\n                        updated_param_data[param_name_inner] = param_data_inner\n                    elif isinstance(param_data_inner, (dict, list)):\n                        param_id = None\n                        updated_param_data[param_name_inner] = cls.get_updated_node_init_data_with_initialized_nodes(\n                            {param_id: param_data_inner}, **kwargs\n                        )[param_id]\n                    else:\n                        updated_param_data[param_name_inner] = param_data_inner\n\n                if \"type\" in updated_param_data:\n                    param_id = updated_param_data.get(\"id\")\n                    updated_param_data = cls.get_nodes_without_depends({param_id: updated_param_data}, **kwargs)[\n                        param_id\n                    ]\n\n                updated_node_init_data[param_name] = updated_param_data\n\n            elif isinstance(param_data, list):\n                updated_items = []\n                for item in param_data:\n                    if isinstance(item, (dict, list)):\n                        param_id = None\n                        updated_items.append(\n                            cls.get_updated_node_init_data_with_initialized_nodes(\n                                node_init_data={param_id: item}, **kwargs\n                            )[param_id]\n                        )\n                    else:\n                        updated_items.append(item)\n                updated_node_init_data[param_name] = updated_items\n\n            else:\n                updated_node_init_data[param_name] = param_data\n\n        return updated_node_init_data\n\n    @classmethod\n    def get_nodes_without_depends(\n        cls,\n        data: dict,\n        nodes: dict[str, Node],\n        flows: dict[str, Flow],\n        connections: dict[str, BaseConnection],\n        prompts: dict[str, Prompt],\n        registry: dict[str, Any],\n        connection_manager: ConnectionManager | None = None,\n        init_components: bool = False,\n        max_workers: int | None = None,\n    ) -&gt; dict[str, Node]:\n        \"\"\"\n        Create nodes without dependencies from the given data.\n        Automatically uses parallel processing for multiple nodes (&gt;1).\n\n        Args:\n            data: Dictionary containing node data.\n            nodes: Existing nodes dictionary.\n            flows: Existing flows dictionary.\n            connections: Existing connections dictionary.\n            prompts: Existing prompts dictionary.\n            registry: Registry of node types.\n            connection_manager: Optional connection manager.\n            init_components: Flag to initialize components.\n            max_workers: Maximum number of worker threads for node parallel processing.\n\n        Returns:\n            A dictionary of newly created nodes without dependencies.\n\n        Raises:\n            WorkflowYAMLLoaderException: If node data is invalid or duplicates are found.\n        \"\"\"\n        new_nodes = {}\n        get_node_kwargs = dict(\n            nodes=nodes,\n            flows=flows,\n            connections=connections,\n            prompts=prompts,\n            registry=registry,\n            connection_manager=connection_manager,\n            init_components=init_components,\n        )\n\n        nodes_to_create = {}\n        for node_id, node_data in data.items():\n            if node_id in nodes:\n                continue\n            if node_id in new_nodes:\n                raise WorkflowYAMLLoaderException(f\"Node '{node_id}' already exists\")\n            nodes_to_create[node_id] = node_data\n\n        if len(nodes_to_create) &lt;= 1:\n            for node_id, node_data in nodes_to_create.items():\n                try:\n                    node_id, node = cls.get_node_without_depends(\n                        node_id=node_id,\n                        node_data=node_data,\n                        **get_node_kwargs,\n                    )\n                    new_nodes[node_id] = node\n                except WorkflowYAMLLoaderException:\n                    raise\n\n            return new_nodes\n\n        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n            future_to_node_id = {\n                executor.submit(\n                    cls.get_node_without_depends,\n                    node_id=node_id,\n                    node_data=node_data,\n                    **get_node_kwargs,\n                ): node_id\n                for node_id, node_data in nodes_to_create.items()\n            }\n\n            for future in as_completed(future_to_node_id):\n                node_id = future_to_node_id[future]\n                try:\n                    result_node_id, node = future.result()\n                    new_nodes[result_node_id] = node\n                except WorkflowYAMLLoaderException:\n                    raise\n                except Exception as e:\n                    raise WorkflowYAMLLoaderException(f\"Node '{node_id}' processing failed. Error: {e}\")\n\n        return new_nodes\n\n    @classmethod\n    def get_node_without_depends(\n        cls,\n        node_id: str,\n        node_data: dict,\n        nodes: dict[str, Node],\n        flows: dict[str, Flow],\n        connections: dict[str, BaseConnection],\n        prompts: dict[str, Prompt],\n        registry: dict[str, Any],\n        connection_manager: ConnectionManager | None = None,\n        init_components: bool = False,\n    ) -&gt; tuple[str, Node]:\n        \"\"\"\n        Create a single node without dependencies from the given data.\n\n        Args:\n            node_id: Node identifier.\n            node_data: Dictionary containing node data.\n            nodes: Existing nodes dictionary.\n            flows: Existing flows dictionary.\n            connections: Existing connections dictionary.\n            prompts: Existing prompts dictionary.\n            registry: Registry of node types.\n            connection_manager: Optional connection manager.\n            init_components: Flag to initialize components.\n\n        Returns:\n            A tuple of (node_id, node).\n\n        Raises:\n            WorkflowYAMLLoaderException: If node data is invalid.\n        \"\"\"\n        if not (node_type := node_data.get(\"type\")):\n            raise WorkflowYAMLLoaderException(f\"Value 'type' for node '{node_id}' not found\")\n\n        node_cls = cls.get_entity_by_type(entity_type=node_type, entity_registry=registry)\n\n        # Init node params\n        node_init_data = node_data.copy()\n        if node_id:\n            node_init_data[\"id\"] = node_id\n        node_init_data.pop(\"type\", None)\n        node_init_data.pop(\"depends\", None)\n\n        if \"is_postponed_component_init\" not in node_init_data:\n            node_init_data[\"is_postponed_component_init\"] = True\n\n        if \"connection\" in node_init_data:\n            get_node_conn = (\n                cls.get_node_vector_store_connection\n                if isinstance(node_cls, ConnectionNode)\n                else cls.get_node_connection\n            )\n            node_init_data[\"connection\"] = get_node_conn(node_id=node_id, node_data=node_data, connections=connections)\n        if prompt_data := node_init_data.get(\"prompt\"):\n            node_init_data[\"prompt\"] = (\n                cls.get_node_prompt(node_id=node_id, node_data=node_data, prompts=prompts)\n                if isinstance(prompt_data, str)\n                else cls.init_prompt(prompt_data)\n            )\n        if \"flow\" in node_init_data:\n            node_init_data[\"flow\"] = cls.get_node_flow(node_id=node_id, node_data=node_data, flows=flows)\n        if \"flows\" in node_init_data:\n            node_init_data[\"flows\"] = cls.get_node_flows(node_id=node_id, node_data=node_data, flows=flows)\n\n        try:\n            node_init_data = cls.get_updated_node_init_data_with_initialized_nodes(\n                node_init_data=node_init_data,\n                nodes=nodes,\n                flows=flows,\n                connections=connections,\n                prompts=prompts,\n                registry=registry,\n                connection_manager=connection_manager,\n                init_components=init_components,\n            )\n\n            node = node_cls(**node_init_data)\n\n            if init_components and getattr(node, \"init_components\", False):\n                node.init_components(connection_manager=connection_manager)\n                node.is_postponed_component_init = False\n\n        except Exception as e:\n            raise WorkflowYAMLLoaderException(f\"Node '{node_id}' data is invalid. Error: {e}\")\n\n        return node_id, node\n\n    @classmethod\n    def get_nodes(\n        cls,\n        nodes_data: dict,\n        nodes: dict[str, Node],\n        flows: dict[str, Flow],\n        connections: dict[str, BaseConnection],\n        prompts: dict[str, Prompt],\n        registry: dict[str, Any],\n        connection_manager: ConnectionManager | None = None,\n        init_components: bool = False,\n        max_workers: int | None = None,\n    ):\n        \"\"\"\n        Create nodes with dependencies from the given data.\n\n        Args:\n            nodes_data: Dictionary containing node data.\n            nodes: Existing nodes dictionary.\n            flows: Existing flows dictionary.\n            connections: Existing connections dictionary.\n            prompts: Existing prompts dictionary.\n            registry: Registry of node types.\n            connection_manager: Optional connection manager.\n            init_components: Flag to initialize components.\n            max_workers: Maximum number of worker threads for node parallel processing.\n\n        Returns:\n            A dictionary of newly created nodes with dependencies.\n        \"\"\"\n\n        new_nodes = cls.get_nodes_without_depends(\n            data=nodes_data,\n            nodes=nodes,\n            flows=flows,\n            connections=connections,\n            prompts=prompts,\n            registry=registry,\n            connection_manager=connection_manager,\n            init_components=init_components,\n            max_workers=max_workers,\n        )\n\n        all_nodes = nodes | new_nodes\n        for node_id, node in new_nodes.items():\n            node.depends = cls.get_node_dependencies(node_id=node_id, node_data=nodes_data[node_id], nodes=all_nodes)\n\n        return new_nodes\n\n    @classmethod\n    def get_dependant_nodes(\n        cls,\n        nodes_data: dict[str, dict],\n        flows_data: dict[str, dict],\n        connections: dict[str, BaseConnection],\n        prompts: dict[str, Prompt],\n        registry: dict[str, Any],\n        connection_manager: ConnectionManager | None = None,\n        init_components: bool = False,\n        max_workers: int | None = None,\n    ) -&gt; dict[str, Node]:\n        \"\"\"\n        Get nodes that are dependent on flows.\n\n        Args:\n            nodes_data: Dictionary containing node data.\n            flows_data: Dictionary containing flow data.\n            connections: Existing connections dictionary.\n            prompts: Existing prompts dictionary.\n            registry: Registry of node types.\n            connection_manager: Optional connection manager.\n            init_components: Flag to initialize components.\n            max_workers: Maximum number of worker threads for node parallel processing.\n\n        Returns:\n            A dictionary of nodes that are dependent on flows.\n        \"\"\"\n        dependant_nodes, dependant_nodes_data = {}, {}\n        dependant_flow_ids = []\n\n        for node_id, node_data in nodes_data.items():\n            if \"flow\" in node_data:\n                dependant_nodes_data[node_id] = node_data\n                dependant_flow_ids.append(node_data[\"flow\"])\n            if \"flows\" in node_data:\n                dependant_nodes_data[node_id] = node_data\n                dependant_flow_ids.extend(node_data[\"flows\"])\n\n        # Get nodes from dependant flows\n        if dependant_flow_ids:\n            dependant_flows_nodes_ids = []\n            for flow_id, flow_data in flows_data.items():\n                if flow_id in dependant_flow_ids:\n                    dependant_flows_nodes_ids.extend(flow_data.get(\"nodes\", []))\n\n            dependant_flows_nodes_data = {\n                node_id: node_data for node_id, node_data in nodes_data.items() if node_id in dependant_flows_nodes_ids\n            }\n\n            dependant_nodes = cls.get_nodes(\n                nodes_data=dependant_flows_nodes_data,\n                nodes={},\n                flows={},\n                connections=connections,\n                prompts=prompts,\n                registry=registry,\n                connection_manager=connection_manager,\n                init_components=init_components,\n                max_workers=max_workers,\n            )\n\n        return dependant_nodes\n\n    @classmethod\n    def get_flows(\n        cls,\n        data: dict,\n        flows: dict[str, Flow],\n        nodes: dict[str, Node],\n        connection_manager: ConnectionManager | None = None,\n    ) -&gt; dict[str, Flow]:\n        \"\"\"\n        Create flows from the given data.\n\n        Args:\n            data: Dictionary containing flow data.\n            flows: Existing flows dictionary.\n            nodes: Existing nodes dictionary.\n            connection_manager: Optional connection manager.\n\n        Returns:\n            A dictionary of newly created flows.\n\n        Raises:\n            WorkflowYAMLLoaderException: If flow data is invalid or duplicates are found.\n        \"\"\"\n        new_flows = {}\n        for flow_id, flow_data in data.items():\n            if flow_id in flows:\n                continue\n\n            if flow_id in new_flows:\n                raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' already exists\")\n\n            flow_node_ids = flow_data.get(\"nodes\", [])\n            flow_node_ids = set(flow_node_ids)\n            dep_node_ids = set()\n            for node_id in flow_node_ids:\n                if node_id not in nodes:\n                    raise WorkflowYAMLLoaderException(f\"Node '{node_id}' for flow '{flow_id}' not found\")\n\n                dep_node_ids.update({dep.node.id for dep in nodes[node_id].depends})\n\n            for node_id in dep_node_ids:\n                if node_id not in flow_node_ids:\n                    raise WorkflowYAMLLoaderException(\n                        f\"Dependency node '{node_id}' in the flow '{flow_id}' node list not found\"\n                    )\n\n            flow_init_data = flow_data | {\n                \"id\": flow_id,\n                \"nodes\": [nodes[node_id] for node_id in flow_node_ids],\n            }\n            if connection_manager:\n                flow_init_data[\"connection_manager\"] = connection_manager\n\n            try:\n                flow = Flow(**flow_init_data)\n            except Exception as e:\n                raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' data is invalid. Error: {e}\")\n\n            new_flows[flow_id] = flow\n        return new_flows\n\n    @classmethod\n    def get_dependant_flows(\n        cls,\n        nodes_data: dict[str, dict],\n        flows_data: dict[str, dict],\n        dependant_nodes: dict[str, Node],\n        connection_manager: ConnectionManager | None = None,\n    ) -&gt; dict[str, Flow]:\n        \"\"\"\n        Get flows that are dependent on nodes.\n\n        Args:\n            nodes_data: Dictionary containing node data.\n            flows_data: Dictionary containing flow data.\n            dependant_nodes: Dictionary of dependent nodes.\n            connection_manager: Optional connection manager.\n\n        Returns:\n            A dictionary of flows that are dependent on nodes.\n        \"\"\"\n        dependant_flows = {}\n        dependant_flow_ids = []\n\n        for node_id, node_data in nodes_data.items():\n            if \"flow\" in node_data:\n                dependant_flow_ids.append(node_data[\"flow\"])\n            if \"flows\" in node_data:\n                dependant_flow_ids.extend(node_data[\"flows\"])\n\n        if dependant_flow_ids:\n            dependant_flows_data = {\n                flow_id: flow_data for flow_id, flow_data in flows_data.items() if flow_id in dependant_flow_ids\n            }\n            dependant_flows = cls.get_flows(\n                data=dependant_flows_data,\n                flows={},\n                nodes=dependant_nodes,\n                connection_manager=connection_manager,\n            )\n\n        return dependant_flows\n\n    @classmethod\n    def get_workflows(cls, data: dict, flows: dict[str, Flow]) -&gt; dict[str, Workflow]:\n        \"\"\"\n        Create workflows from the given data.\n\n        Args:\n            data: Dictionary containing workflow data.\n            flows: Existing flows dictionary.\n\n        Returns:\n            A dictionary of newly created workflows.\n\n        Raises:\n            WorkflowYAMLLoaderException: If workflow data is invalid.\n        \"\"\"\n        workflows = {}\n        for wf_id, wf_data in data.get(\"workflows\", {}).items():\n            if not (flow_id := wf_data.get(\"flow\")):\n                raise WorkflowYAMLLoaderException(f\"Value 'flow' for dynamiq '{wf_id}' not found \")\n            if not (flow := flows.get(flow_id)):\n                raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' for dynamiq '{wf_id}' not found\")\n            if version := wf_data.get(\"version\"):\n                version = str(version)\n\n            try:\n                wf = Workflow(id=wf_id, flow=flow, version=version)\n            except Exception as e:\n                raise WorkflowYAMLLoaderException(f\"Workflow '{wf_id}' data is invalid. Error: {e}\")\n\n            workflows[wf_id] = wf\n        return workflows\n\n    @classmethod\n    def load(\n        cls,\n        file_path: str | PathLike,\n        connection_manager: ConnectionManager | None = None,\n        init_components: bool = False,\n        max_workers: int | None = None,\n    ) -&gt; WorkflowYamlData:\n        \"\"\"\n        Load data from a YAML file and parse it.\n\n        Args:\n            file_path: Path to the YAML file.\n            connection_manager: Optional connection manager.\n            init_components: Flag to initialize components.\n            max_workers: Maximum number of worker threads for node parallel processing.\n\n        Returns:\n            Parsed WorkflowYamlData object.\n        \"\"\"\n        data = cls.loads(file_path)\n        return cls.parse(\n            data=data,\n            connection_manager=connection_manager,\n            init_components=init_components,\n            max_workers=max_workers,\n        )\n\n    @classmethod\n    def loads(cls, file_path: str | PathLike):\n        \"\"\"\n        Load data from a YAML file.\n\n        Args:\n            file_path: Path to the YAML file.\n\n        Returns:\n            Parsed data from the YAML file.\n\n        Raises:\n            WorkflowYAMLLoaderException: If the file is not found.\n        \"\"\"\n        from omegaconf import OmegaConf\n\n        try:\n            conf = OmegaConf.load(file_path)\n            logger.debug(f\"Loaded config from '{file_path}'\")\n\n            data = OmegaConf.to_container(conf, resolve=True)\n        except FileNotFoundError:\n            raise WorkflowYAMLLoaderException(f\"File '{file_path}' not found\")\n\n        return data\n\n    @classmethod\n    def parse(\n        cls,\n        data: dict,\n        connection_manager: ConnectionManager | None = None,\n        init_components: bool = False,\n        max_workers: int | None = None,\n    ) -&gt; WorkflowYamlData:\n        \"\"\"\n        Parse dynamiq workflow data.\n\n        Args:\n            data: Dictionary containing workflow data.\n            connection_manager: Optional connection manager.\n            init_components: Flag to initialize components.\n            max_workers: Maximum number of worker threads for node parallel processing.\n\n        Returns:\n            Parsed WorkflowYamlData object.\n\n        Raises:\n            WorkflowYAMLLoaderException: If parsing fails.\n        \"\"\"\n        nodes, flows = {}, {}\n        # Mutable shared registry that updates with each new entity.\n        node_registry, connection_registry = {}, {}\n        if init_components and connection_manager is None:\n            connection_manager = ConnectionManager()\n\n        try:\n            connections = cls.get_connections(data=data, registry=connection_registry)\n            prompts = cls.get_prompts(data)\n\n            nodes_data = data.get(\"nodes\", {})\n            flows_data = data.get(\"flows\", {})\n\n            dependant_nodes = cls.get_dependant_nodes(\n                nodes_data=nodes_data,\n                flows_data=flows_data,\n                connections=connections,\n                prompts=prompts,\n                registry=node_registry,\n                connection_manager=connection_manager,\n                init_components=init_components,\n                max_workers=max_workers,\n            )\n            nodes.update(dependant_nodes)\n\n            dependant_flows = cls.get_dependant_flows(\n                nodes_data=nodes_data,\n                flows_data=flows_data,\n                dependant_nodes=dependant_nodes,\n                connection_manager=connection_manager,\n            )\n            flows.update(dependant_flows)\n\n            non_dependant_nodes = cls.get_nodes(\n                nodes_data=nodes_data,\n                nodes=nodes,\n                flows=flows,\n                connections=connections,\n                prompts=prompts,\n                registry=node_registry,\n                connection_manager=connection_manager,\n                init_components=init_components,\n                max_workers=max_workers,\n            )\n            nodes.update(non_dependant_nodes)\n\n            non_dependant_flows = cls.get_flows(\n                data=flows_data,\n                flows=flows,\n                nodes=nodes,\n                connection_manager=connection_manager,\n            )\n            flows.update(non_dependant_flows)\n\n            workflows = cls.get_workflows(data, flows)\n        except WorkflowYAMLLoaderException:\n            raise\n        except Exception:\n            logger.exception(\"Failed to parse Yaml data with unexpected error\")\n            raise\n\n        return WorkflowYamlData(\n            connections=connections,\n            nodes=nodes,\n            flows=flows,\n            workflows=workflows,\n        )\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_connections","title":"<code>get_connections(data, registry)</code>  <code>classmethod</code>","text":"<p>Get connections from the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, dict]</code> <p>The data containing connection information.</p> required <code>registry</code> <code>dict[str, Any]</code> <p>A registry of entities.</p> required <p>Returns:</p> Type Description <code>dict[str, BaseConnection]</code> <p>dict[str, BaseConnection]: A dictionary of connections.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If there's an error in connection data or initialization.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_connections(cls, data: dict[str, dict], registry: dict[str, Any]) -&gt; dict[str, BaseConnection]:\n    \"\"\"\n    Get connections from the provided data.\n\n    Args:\n        data (dict[str, dict]): The data containing connection information.\n        registry (dict[str, Any]): A registry of entities.\n\n    Returns:\n        dict[str, BaseConnection]: A dictionary of connections.\n\n    Raises:\n        WorkflowYAMLLoaderException: If there's an error in connection data or initialization.\n    \"\"\"\n    connections = {}\n    for conn_id, conn_data in data.get(\"connections\", {}).items():\n        if conn_id in connections:\n            raise WorkflowYAMLLoaderException(f\"Connection '{conn_id}' already exists\")\n        if not (conn_type := conn_data.get(\"type\")):\n            raise WorkflowYAMLLoaderException(f\"Value 'type' not found for connection '{conn_id}'\")\n\n        conn_cls = cls.get_entity_by_type(entity_type=conn_type, entity_registry=registry)\n        conn_init_data = conn_data | {\"id\": conn_id}\n        conn_init_data.pop(\"type\", None)\n        try:\n            connection = conn_cls(**conn_init_data)\n        except Exception as e:\n            raise WorkflowYAMLLoaderException(f\"Connection '{conn_id}' data is invalid. Error: {e}\")\n\n        connections[conn_id] = connection\n\n    return connections\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_dependant_flows","title":"<code>get_dependant_flows(nodes_data, flows_data, dependant_nodes, connection_manager=None)</code>  <code>classmethod</code>","text":"<p>Get flows that are dependent on nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes_data</code> <code>dict[str, dict]</code> <p>Dictionary containing node data.</p> required <code>flows_data</code> <code>dict[str, dict]</code> <p>Dictionary containing flow data.</p> required <code>dependant_nodes</code> <code>dict[str, Node]</code> <p>Dictionary of dependent nodes.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Flow]</code> <p>A dictionary of flows that are dependent on nodes.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_dependant_flows(\n    cls,\n    nodes_data: dict[str, dict],\n    flows_data: dict[str, dict],\n    dependant_nodes: dict[str, Node],\n    connection_manager: ConnectionManager | None = None,\n) -&gt; dict[str, Flow]:\n    \"\"\"\n    Get flows that are dependent on nodes.\n\n    Args:\n        nodes_data: Dictionary containing node data.\n        flows_data: Dictionary containing flow data.\n        dependant_nodes: Dictionary of dependent nodes.\n        connection_manager: Optional connection manager.\n\n    Returns:\n        A dictionary of flows that are dependent on nodes.\n    \"\"\"\n    dependant_flows = {}\n    dependant_flow_ids = []\n\n    for node_id, node_data in nodes_data.items():\n        if \"flow\" in node_data:\n            dependant_flow_ids.append(node_data[\"flow\"])\n        if \"flows\" in node_data:\n            dependant_flow_ids.extend(node_data[\"flows\"])\n\n    if dependant_flow_ids:\n        dependant_flows_data = {\n            flow_id: flow_data for flow_id, flow_data in flows_data.items() if flow_id in dependant_flow_ids\n        }\n        dependant_flows = cls.get_flows(\n            data=dependant_flows_data,\n            flows={},\n            nodes=dependant_nodes,\n            connection_manager=connection_manager,\n        )\n\n    return dependant_flows\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_dependant_nodes","title":"<code>get_dependant_nodes(nodes_data, flows_data, connections, prompts, registry, connection_manager=None, init_components=False, max_workers=None)</code>  <code>classmethod</code>","text":"<p>Get nodes that are dependent on flows.</p> <p>Parameters:</p> Name Type Description Default <code>nodes_data</code> <code>dict[str, dict]</code> <p>Dictionary containing node data.</p> required <code>flows_data</code> <code>dict[str, dict]</code> <p>Dictionary containing flow data.</p> required <code>connections</code> <code>dict[str, BaseConnection]</code> <p>Existing connections dictionary.</p> required <code>prompts</code> <code>dict[str, Prompt]</code> <p>Existing prompts dictionary.</p> required <code>registry</code> <code>dict[str, Any]</code> <p>Registry of node types.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <code>init_components</code> <code>bool</code> <p>Flag to initialize components.</p> <code>False</code> <code>max_workers</code> <code>int | None</code> <p>Maximum number of worker threads for node parallel processing.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Node]</code> <p>A dictionary of nodes that are dependent on flows.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_dependant_nodes(\n    cls,\n    nodes_data: dict[str, dict],\n    flows_data: dict[str, dict],\n    connections: dict[str, BaseConnection],\n    prompts: dict[str, Prompt],\n    registry: dict[str, Any],\n    connection_manager: ConnectionManager | None = None,\n    init_components: bool = False,\n    max_workers: int | None = None,\n) -&gt; dict[str, Node]:\n    \"\"\"\n    Get nodes that are dependent on flows.\n\n    Args:\n        nodes_data: Dictionary containing node data.\n        flows_data: Dictionary containing flow data.\n        connections: Existing connections dictionary.\n        prompts: Existing prompts dictionary.\n        registry: Registry of node types.\n        connection_manager: Optional connection manager.\n        init_components: Flag to initialize components.\n        max_workers: Maximum number of worker threads for node parallel processing.\n\n    Returns:\n        A dictionary of nodes that are dependent on flows.\n    \"\"\"\n    dependant_nodes, dependant_nodes_data = {}, {}\n    dependant_flow_ids = []\n\n    for node_id, node_data in nodes_data.items():\n        if \"flow\" in node_data:\n            dependant_nodes_data[node_id] = node_data\n            dependant_flow_ids.append(node_data[\"flow\"])\n        if \"flows\" in node_data:\n            dependant_nodes_data[node_id] = node_data\n            dependant_flow_ids.extend(node_data[\"flows\"])\n\n    # Get nodes from dependant flows\n    if dependant_flow_ids:\n        dependant_flows_nodes_ids = []\n        for flow_id, flow_data in flows_data.items():\n            if flow_id in dependant_flow_ids:\n                dependant_flows_nodes_ids.extend(flow_data.get(\"nodes\", []))\n\n        dependant_flows_nodes_data = {\n            node_id: node_data for node_id, node_data in nodes_data.items() if node_id in dependant_flows_nodes_ids\n        }\n\n        dependant_nodes = cls.get_nodes(\n            nodes_data=dependant_flows_nodes_data,\n            nodes={},\n            flows={},\n            connections=connections,\n            prompts=prompts,\n            registry=registry,\n            connection_manager=connection_manager,\n            init_components=init_components,\n            max_workers=max_workers,\n        )\n\n    return dependant_nodes\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_entity_by_type","title":"<code>get_entity_by_type(entity_type, entity_registry=None)</code>  <code>classmethod</code>","text":"<p>Try to get entity by type and update mutable shared registry.</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The type of entity to retrieve.</p> required <code>entity_registry</code> <code>dict[str, Any] | None</code> <p>A registry of entities.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The retrieved entity.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If the entity is not valid or cannot be found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_entity_by_type(cls, entity_type: str, entity_registry: dict[str, Any] | None = None) -&gt; Any:\n    \"\"\"\n    Try to get entity by type and update mutable shared registry.\n\n    Args:\n        entity_type (str): The type of entity to retrieve.\n        entity_registry (dict[str, Any] | None): A registry of entities.\n\n    Returns:\n        Any: The retrieved entity.\n\n    Raises:\n        WorkflowYAMLLoaderException: If the entity is not valid or cannot be found.\n    \"\"\"\n    if entity_registry is None:\n        entity_registry = {}\n\n    if entity := entity_registry.get(entity_type):\n        return entity\n\n    try:\n        entity = ConnectionManager.get_connection_by_type(entity_type)\n    except ValueError:\n        pass\n\n    if not entity:\n        try:\n            entity = NodeManager.get_node_by_type(entity_type)\n        except ValueError:\n            pass\n\n    if not entity:\n        raise WorkflowYAMLLoaderException(f\"Entity '{entity_type}' is not valid.\")\n\n    entity_registry[entity_type] = entity\n    return entity\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_flows","title":"<code>get_flows(data, flows, nodes, connection_manager=None)</code>  <code>classmethod</code>","text":"<p>Create flows from the given data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing flow data.</p> required <code>flows</code> <code>dict[str, Flow]</code> <p>Existing flows dictionary.</p> required <code>nodes</code> <code>dict[str, Node]</code> <p>Existing nodes dictionary.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Flow]</code> <p>A dictionary of newly created flows.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If flow data is invalid or duplicates are found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_flows(\n    cls,\n    data: dict,\n    flows: dict[str, Flow],\n    nodes: dict[str, Node],\n    connection_manager: ConnectionManager | None = None,\n) -&gt; dict[str, Flow]:\n    \"\"\"\n    Create flows from the given data.\n\n    Args:\n        data: Dictionary containing flow data.\n        flows: Existing flows dictionary.\n        nodes: Existing nodes dictionary.\n        connection_manager: Optional connection manager.\n\n    Returns:\n        A dictionary of newly created flows.\n\n    Raises:\n        WorkflowYAMLLoaderException: If flow data is invalid or duplicates are found.\n    \"\"\"\n    new_flows = {}\n    for flow_id, flow_data in data.items():\n        if flow_id in flows:\n            continue\n\n        if flow_id in new_flows:\n            raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' already exists\")\n\n        flow_node_ids = flow_data.get(\"nodes\", [])\n        flow_node_ids = set(flow_node_ids)\n        dep_node_ids = set()\n        for node_id in flow_node_ids:\n            if node_id not in nodes:\n                raise WorkflowYAMLLoaderException(f\"Node '{node_id}' for flow '{flow_id}' not found\")\n\n            dep_node_ids.update({dep.node.id for dep in nodes[node_id].depends})\n\n        for node_id in dep_node_ids:\n            if node_id not in flow_node_ids:\n                raise WorkflowYAMLLoaderException(\n                    f\"Dependency node '{node_id}' in the flow '{flow_id}' node list not found\"\n                )\n\n        flow_init_data = flow_data | {\n            \"id\": flow_id,\n            \"nodes\": [nodes[node_id] for node_id in flow_node_ids],\n        }\n        if connection_manager:\n            flow_init_data[\"connection_manager\"] = connection_manager\n\n        try:\n            flow = Flow(**flow_init_data)\n        except Exception as e:\n            raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' data is invalid. Error: {e}\")\n\n        new_flows[flow_id] = flow\n    return new_flows\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_node_connection","title":"<code>get_node_connection(node_id, node_data, connections)</code>  <code>classmethod</code>","text":"<p>Get the connection for a node.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>str</code> <p>The ID of the node.</p> required <code>node_data</code> <code>dict</code> <p>The data for the node.</p> required <code>connections</code> <code>dict[id, BaseConnection]</code> <p>A dictionary of available connections.</p> required <p>Returns:</p> Type Description <code>BaseConnection | None</code> <p>BaseConnection | None: The connection for the node, or None if not found.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If the specified connection is not found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_node_connection(\n    cls, node_id: str, node_data: dict, connections: dict[id, BaseConnection]\n) -&gt; BaseConnection | None:\n    \"\"\"\n    Get the connection for a node.\n\n    Args:\n        node_id (str): The ID of the node.\n        node_data (dict): The data for the node.\n        connections (dict[id, BaseConnection]): A dictionary of available connections.\n\n    Returns:\n        BaseConnection | None: The connection for the node, or None if not found.\n\n    Raises:\n        WorkflowYAMLLoaderException: If the specified connection is not found.\n    \"\"\"\n    conn = None\n    if conn_id := node_data.get(\"connection\"):\n        conn = connections.get(conn_id)\n        if not conn:\n            raise WorkflowYAMLLoaderException(f\"Connection '{conn_id}' for node '{node_id}' not found\")\n    return conn\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_node_dependencies","title":"<code>get_node_dependencies(node_id, node_data, nodes)</code>  <code>classmethod</code>","text":"<p>Get the dependencies for a node.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>str</code> <p>The ID of the node.</p> required <code>node_data</code> <code>dict</code> <p>The data for the node.</p> required <code>nodes</code> <code>dict[str, Node]</code> <p>A dictionary of available nodes.</p> required <p>Returns:</p> Type Description <p>list[NodeDependency]: A list of node dependencies.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If there's an error in dependency data or initialization.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_node_dependencies(cls, node_id: str, node_data: dict, nodes: dict[str, Node]):\n    \"\"\"\n    Get the dependencies for a node.\n\n    Args:\n        node_id (str): The ID of the node.\n        node_data (dict): The data for the node.\n        nodes (dict[str, Node]): A dictionary of available nodes.\n\n    Returns:\n        list[NodeDependency]: A list of node dependencies.\n\n    Raises:\n        WorkflowYAMLLoaderException: If there's an error in dependency data or initialization.\n    \"\"\"\n    node_depends = []\n    for dependency_data in node_data.get(\"depends\", []):\n        dependency_node = nodes.get(dependency_data.get(\"node\"))\n        dependency_init_data = dependency_data | {\"node\": dependency_node}\n        try:\n            dependency = NodeDependency(**dependency_init_data)\n        except Exception as e:\n            raise WorkflowYAMLLoaderException(\n                f\"Dependency '{dependency_data.get('node')}' data for node '{node_id}' \" f\"is invalid. Error: {e}\"\n            )\n\n        if dependency.option:\n            if not (dep_options := getattr(dependency_node, \"options\", [])):\n                raise WorkflowYAMLLoaderException(\n                    f\"Dependency '{dependency.node.id}' with option '{dependency.option}' \"\n                    f\"for node '{node_id}' not found\"\n                )\n\n            if not any(opt.id == dependency.option for opt in dep_options):\n                raise WorkflowYAMLLoaderException(\n                    f\"Dependency '{dependency.node.id}' with option '{dependency.option}' \"\n                    f\"for node '{node_id}' not found\"\n                )\n\n        node_depends.append(dependency)\n    return node_depends\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_node_flow","title":"<code>get_node_flow(node_id, node_data, flows)</code>  <code>classmethod</code>","text":"<p>Get the flow for a node.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>str</code> <p>The ID of the node.</p> required <code>node_data</code> <code>dict</code> <p>The data for the node.</p> required <code>flows</code> <code>dict[id, Flow]</code> <p>A dictionary of available flows.</p> required <p>Returns:</p> Type Description <code>Flow | None</code> <p>Flow | None: The flow for the node, or None if not found.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If the specified flow is not found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_node_flow(cls, node_id: str, node_data: dict, flows: dict[id, Flow]) -&gt; Flow | None:\n    \"\"\"\n    Get the flow for a node.\n\n    Args:\n        node_id (str): The ID of the node.\n        node_data (dict): The data for the node.\n        flows (dict[id, Flow]): A dictionary of available flows.\n\n    Returns:\n        Flow | None: The flow for the node, or None if not found.\n\n    Raises:\n        WorkflowYAMLLoaderException: If the specified flow is not found.\n    \"\"\"\n    flow = None\n    if flow_id := node_data.get(\"flow\"):\n        flow = flows.get(flow_id)\n        if not flow:\n            raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' for node '{node_id}' not found\")\n    return flow\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_node_flows","title":"<code>get_node_flows(node_id, node_data, flows)</code>  <code>classmethod</code>","text":"<p>Get the flows for a node.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>str</code> <p>The ID of the node.</p> required <code>node_data</code> <code>dict</code> <p>The data for the node.</p> required <code>flows</code> <code>dict[id, Flow]</code> <p>A dictionary of available flows.</p> required <p>Returns:</p> Type Description <code>list[Flow]</code> <p>list[Flow]: A list of flows for the node.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If any specified flow is not found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_node_flows(cls, node_id: str, node_data: dict, flows: dict[id, Flow]) -&gt; list[Flow]:\n    \"\"\"\n    Get the flows for a node.\n\n    Args:\n        node_id (str): The ID of the node.\n        node_data (dict): The data for the node.\n        flows (dict[id, Flow]): A dictionary of available flows.\n\n    Returns:\n        list[Flow]: A list of flows for the node.\n\n    Raises:\n        WorkflowYAMLLoaderException: If any specified flow is not found.\n    \"\"\"\n    node_flows = []\n    for flow_id in node_data.get(\"flows\", []):\n        node_flow = flows.get(flow_id)\n        if not node_flow:\n            raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' for node '{node_id}' not found\")\n        node_flows.append(node_flow)\n    return node_flows\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_node_prompt","title":"<code>get_node_prompt(node_id, node_data, prompts)</code>  <code>classmethod</code>","text":"<p>Get the prompt for a node.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>str</code> <p>The ID of the node.</p> required <code>node_data</code> <code>dict</code> <p>The data for the node.</p> required <code>prompts</code> <code>dict[id, Prompt]</code> <p>A dictionary of available prompts.</p> required <p>Returns:</p> Type Description <code>Prompt | None</code> <p>Prompt | None: The prompt for the node, or None if not found.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If the specified prompt is not found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_node_prompt(cls, node_id: str, node_data: dict, prompts: dict[id, Prompt]) -&gt; Prompt | None:\n    \"\"\"\n    Get the prompt for a node.\n\n    Args:\n        node_id (str): The ID of the node.\n        node_data (dict): The data for the node.\n        prompts (dict[id, Prompt]): A dictionary of available prompts.\n\n    Returns:\n        Prompt | None: The prompt for the node, or None if not found.\n\n    Raises:\n        WorkflowYAMLLoaderException: If the specified prompt is not found.\n    \"\"\"\n    prompt = None\n    if prompt_id := node_data.get(\"prompt\"):\n        prompt = prompts.get(prompt_id)\n        if not prompt:\n            raise WorkflowYAMLLoaderException(f\"Prompt '{prompt_id}' for node '{node_id}' not found\")\n    return prompt\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_node_vector_store_connection","title":"<code>get_node_vector_store_connection(node_id, node_data, connections)</code>  <code>classmethod</code>","text":"<p>Get the vector store connection for a node.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>str</code> <p>The ID of the node.</p> required <code>node_data</code> <code>dict</code> <p>The data for the node.</p> required <code>connections</code> <code>dict[id, BaseConnection]</code> <p>A dictionary of available connections.</p> required <p>Returns:</p> Type Description <code>Any | None</code> <p>Any | None: The vector store connection for the node, or None if not found.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If the specified vector store connection is not found or                          does not support vector store initialization.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_node_vector_store_connection(\n    cls, node_id: str, node_data: dict, connections: dict[id, BaseConnection]\n) -&gt; Any | None:\n    \"\"\"\n    Get the vector store connection for a node.\n\n    Args:\n        node_id (str): The ID of the node.\n        node_data (dict): The data for the node.\n        connections (dict[id, BaseConnection]): A dictionary of available connections.\n\n    Returns:\n        Any | None: The vector store connection for the node, or None if not found.\n\n    Raises:\n        WorkflowYAMLLoaderException: If the specified vector store connection is not found or\n                                     does not support vector store initialization.\n    \"\"\"\n    if conn := cls.get_node_connection(node_id=node_id, node_data=node_data, connections=connections):\n        if not (conn_to_vs := getattr(conn, \"connect_to_vector_store\", None)) or not callable(conn_to_vs):\n            raise WorkflowYAMLLoaderException(\n                f\"Vector store connection '{conn.id}' for node '{node_id}' not support vector store initialization\"\n            )\n    return conn\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_node_without_depends","title":"<code>get_node_without_depends(node_id, node_data, nodes, flows, connections, prompts, registry, connection_manager=None, init_components=False)</code>  <code>classmethod</code>","text":"<p>Create a single node without dependencies from the given data.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>str</code> <p>Node identifier.</p> required <code>node_data</code> <code>dict</code> <p>Dictionary containing node data.</p> required <code>nodes</code> <code>dict[str, Node]</code> <p>Existing nodes dictionary.</p> required <code>flows</code> <code>dict[str, Flow]</code> <p>Existing flows dictionary.</p> required <code>connections</code> <code>dict[str, BaseConnection]</code> <p>Existing connections dictionary.</p> required <code>prompts</code> <code>dict[str, Prompt]</code> <p>Existing prompts dictionary.</p> required <code>registry</code> <code>dict[str, Any]</code> <p>Registry of node types.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <code>init_components</code> <code>bool</code> <p>Flag to initialize components.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[str, Node]</code> <p>A tuple of (node_id, node).</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If node data is invalid.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_node_without_depends(\n    cls,\n    node_id: str,\n    node_data: dict,\n    nodes: dict[str, Node],\n    flows: dict[str, Flow],\n    connections: dict[str, BaseConnection],\n    prompts: dict[str, Prompt],\n    registry: dict[str, Any],\n    connection_manager: ConnectionManager | None = None,\n    init_components: bool = False,\n) -&gt; tuple[str, Node]:\n    \"\"\"\n    Create a single node without dependencies from the given data.\n\n    Args:\n        node_id: Node identifier.\n        node_data: Dictionary containing node data.\n        nodes: Existing nodes dictionary.\n        flows: Existing flows dictionary.\n        connections: Existing connections dictionary.\n        prompts: Existing prompts dictionary.\n        registry: Registry of node types.\n        connection_manager: Optional connection manager.\n        init_components: Flag to initialize components.\n\n    Returns:\n        A tuple of (node_id, node).\n\n    Raises:\n        WorkflowYAMLLoaderException: If node data is invalid.\n    \"\"\"\n    if not (node_type := node_data.get(\"type\")):\n        raise WorkflowYAMLLoaderException(f\"Value 'type' for node '{node_id}' not found\")\n\n    node_cls = cls.get_entity_by_type(entity_type=node_type, entity_registry=registry)\n\n    # Init node params\n    node_init_data = node_data.copy()\n    if node_id:\n        node_init_data[\"id\"] = node_id\n    node_init_data.pop(\"type\", None)\n    node_init_data.pop(\"depends\", None)\n\n    if \"is_postponed_component_init\" not in node_init_data:\n        node_init_data[\"is_postponed_component_init\"] = True\n\n    if \"connection\" in node_init_data:\n        get_node_conn = (\n            cls.get_node_vector_store_connection\n            if isinstance(node_cls, ConnectionNode)\n            else cls.get_node_connection\n        )\n        node_init_data[\"connection\"] = get_node_conn(node_id=node_id, node_data=node_data, connections=connections)\n    if prompt_data := node_init_data.get(\"prompt\"):\n        node_init_data[\"prompt\"] = (\n            cls.get_node_prompt(node_id=node_id, node_data=node_data, prompts=prompts)\n            if isinstance(prompt_data, str)\n            else cls.init_prompt(prompt_data)\n        )\n    if \"flow\" in node_init_data:\n        node_init_data[\"flow\"] = cls.get_node_flow(node_id=node_id, node_data=node_data, flows=flows)\n    if \"flows\" in node_init_data:\n        node_init_data[\"flows\"] = cls.get_node_flows(node_id=node_id, node_data=node_data, flows=flows)\n\n    try:\n        node_init_data = cls.get_updated_node_init_data_with_initialized_nodes(\n            node_init_data=node_init_data,\n            nodes=nodes,\n            flows=flows,\n            connections=connections,\n            prompts=prompts,\n            registry=registry,\n            connection_manager=connection_manager,\n            init_components=init_components,\n        )\n\n        node = node_cls(**node_init_data)\n\n        if init_components and getattr(node, \"init_components\", False):\n            node.init_components(connection_manager=connection_manager)\n            node.is_postponed_component_init = False\n\n    except Exception as e:\n        raise WorkflowYAMLLoaderException(f\"Node '{node_id}' data is invalid. Error: {e}\")\n\n    return node_id, node\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_nodes","title":"<code>get_nodes(nodes_data, nodes, flows, connections, prompts, registry, connection_manager=None, init_components=False, max_workers=None)</code>  <code>classmethod</code>","text":"<p>Create nodes with dependencies from the given data.</p> <p>Parameters:</p> Name Type Description Default <code>nodes_data</code> <code>dict</code> <p>Dictionary containing node data.</p> required <code>nodes</code> <code>dict[str, Node]</code> <p>Existing nodes dictionary.</p> required <code>flows</code> <code>dict[str, Flow]</code> <p>Existing flows dictionary.</p> required <code>connections</code> <code>dict[str, BaseConnection]</code> <p>Existing connections dictionary.</p> required <code>prompts</code> <code>dict[str, Prompt]</code> <p>Existing prompts dictionary.</p> required <code>registry</code> <code>dict[str, Any]</code> <p>Registry of node types.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <code>init_components</code> <code>bool</code> <p>Flag to initialize components.</p> <code>False</code> <code>max_workers</code> <code>int | None</code> <p>Maximum number of worker threads for node parallel processing.</p> <code>None</code> <p>Returns:</p> Type Description <p>A dictionary of newly created nodes with dependencies.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_nodes(\n    cls,\n    nodes_data: dict,\n    nodes: dict[str, Node],\n    flows: dict[str, Flow],\n    connections: dict[str, BaseConnection],\n    prompts: dict[str, Prompt],\n    registry: dict[str, Any],\n    connection_manager: ConnectionManager | None = None,\n    init_components: bool = False,\n    max_workers: int | None = None,\n):\n    \"\"\"\n    Create nodes with dependencies from the given data.\n\n    Args:\n        nodes_data: Dictionary containing node data.\n        nodes: Existing nodes dictionary.\n        flows: Existing flows dictionary.\n        connections: Existing connections dictionary.\n        prompts: Existing prompts dictionary.\n        registry: Registry of node types.\n        connection_manager: Optional connection manager.\n        init_components: Flag to initialize components.\n        max_workers: Maximum number of worker threads for node parallel processing.\n\n    Returns:\n        A dictionary of newly created nodes with dependencies.\n    \"\"\"\n\n    new_nodes = cls.get_nodes_without_depends(\n        data=nodes_data,\n        nodes=nodes,\n        flows=flows,\n        connections=connections,\n        prompts=prompts,\n        registry=registry,\n        connection_manager=connection_manager,\n        init_components=init_components,\n        max_workers=max_workers,\n    )\n\n    all_nodes = nodes | new_nodes\n    for node_id, node in new_nodes.items():\n        node.depends = cls.get_node_dependencies(node_id=node_id, node_data=nodes_data[node_id], nodes=all_nodes)\n\n    return new_nodes\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_nodes_without_depends","title":"<code>get_nodes_without_depends(data, nodes, flows, connections, prompts, registry, connection_manager=None, init_components=False, max_workers=None)</code>  <code>classmethod</code>","text":"<p>Create nodes without dependencies from the given data. Automatically uses parallel processing for multiple nodes (&gt;1).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing node data.</p> required <code>nodes</code> <code>dict[str, Node]</code> <p>Existing nodes dictionary.</p> required <code>flows</code> <code>dict[str, Flow]</code> <p>Existing flows dictionary.</p> required <code>connections</code> <code>dict[str, BaseConnection]</code> <p>Existing connections dictionary.</p> required <code>prompts</code> <code>dict[str, Prompt]</code> <p>Existing prompts dictionary.</p> required <code>registry</code> <code>dict[str, Any]</code> <p>Registry of node types.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <code>init_components</code> <code>bool</code> <p>Flag to initialize components.</p> <code>False</code> <code>max_workers</code> <code>int | None</code> <p>Maximum number of worker threads for node parallel processing.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Node]</code> <p>A dictionary of newly created nodes without dependencies.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If node data is invalid or duplicates are found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_nodes_without_depends(\n    cls,\n    data: dict,\n    nodes: dict[str, Node],\n    flows: dict[str, Flow],\n    connections: dict[str, BaseConnection],\n    prompts: dict[str, Prompt],\n    registry: dict[str, Any],\n    connection_manager: ConnectionManager | None = None,\n    init_components: bool = False,\n    max_workers: int | None = None,\n) -&gt; dict[str, Node]:\n    \"\"\"\n    Create nodes without dependencies from the given data.\n    Automatically uses parallel processing for multiple nodes (&gt;1).\n\n    Args:\n        data: Dictionary containing node data.\n        nodes: Existing nodes dictionary.\n        flows: Existing flows dictionary.\n        connections: Existing connections dictionary.\n        prompts: Existing prompts dictionary.\n        registry: Registry of node types.\n        connection_manager: Optional connection manager.\n        init_components: Flag to initialize components.\n        max_workers: Maximum number of worker threads for node parallel processing.\n\n    Returns:\n        A dictionary of newly created nodes without dependencies.\n\n    Raises:\n        WorkflowYAMLLoaderException: If node data is invalid or duplicates are found.\n    \"\"\"\n    new_nodes = {}\n    get_node_kwargs = dict(\n        nodes=nodes,\n        flows=flows,\n        connections=connections,\n        prompts=prompts,\n        registry=registry,\n        connection_manager=connection_manager,\n        init_components=init_components,\n    )\n\n    nodes_to_create = {}\n    for node_id, node_data in data.items():\n        if node_id in nodes:\n            continue\n        if node_id in new_nodes:\n            raise WorkflowYAMLLoaderException(f\"Node '{node_id}' already exists\")\n        nodes_to_create[node_id] = node_data\n\n    if len(nodes_to_create) &lt;= 1:\n        for node_id, node_data in nodes_to_create.items():\n            try:\n                node_id, node = cls.get_node_without_depends(\n                    node_id=node_id,\n                    node_data=node_data,\n                    **get_node_kwargs,\n                )\n                new_nodes[node_id] = node\n            except WorkflowYAMLLoaderException:\n                raise\n\n        return new_nodes\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        future_to_node_id = {\n            executor.submit(\n                cls.get_node_without_depends,\n                node_id=node_id,\n                node_data=node_data,\n                **get_node_kwargs,\n            ): node_id\n            for node_id, node_data in nodes_to_create.items()\n        }\n\n        for future in as_completed(future_to_node_id):\n            node_id = future_to_node_id[future]\n            try:\n                result_node_id, node = future.result()\n                new_nodes[result_node_id] = node\n            except WorkflowYAMLLoaderException:\n                raise\n            except Exception as e:\n                raise WorkflowYAMLLoaderException(f\"Node '{node_id}' processing failed. Error: {e}\")\n\n    return new_nodes\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_prompts","title":"<code>get_prompts(data)</code>  <code>classmethod</code>","text":"<p>Get prompts from the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, dict]</code> <p>The data containing prompt information.</p> required <p>Returns:</p> Type Description <code>dict[str, Prompt]</code> <p>dict[str, Prompt]: A dictionary of prompts.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If there's an error in prompt data or initialization.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_prompts(cls, data: dict[str, dict]) -&gt; dict[str, Prompt]:\n    \"\"\"\n    Get prompts from the provided data.\n\n    Args:\n        data (dict[str, dict]): The data containing prompt information.\n\n    Returns:\n        dict[str, Prompt]: A dictionary of prompts.\n\n    Raises:\n        WorkflowYAMLLoaderException: If there's an error in prompt data or initialization.\n    \"\"\"\n    prompts = {}\n    for prompt_id, prompt_data in data.get(\"prompts\", {}).items():\n        if prompt_id in prompts:\n            raise WorkflowYAMLLoaderException(f\"Prompt '{prompt_id}' already exists\")\n        prompts[prompt_id] = cls.init_prompt(prompt_data | {\"id\": prompt_id})\n\n    return prompts\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_updated_node_init_data_with_initialized_nodes","title":"<code>get_updated_node_init_data_with_initialized_nodes(node_init_data, nodes, flows, connections, prompts, registry, connection_manager=None, init_components=False, max_workers=None)</code>  <code>classmethod</code>","text":"<p>Get node init data with initialized nodes components recursively (llms, agents, etc)</p> <p>Parameters:</p> Name Type Description Default <code>node_init_data</code> <code>dict</code> <p>Dictionary containing node data.</p> required <code>nodes</code> <code>dict[str, Node]</code> <p>Existing nodes dictionary.</p> required <code>flows</code> <code>dict[str, Flow]</code> <p>Existing flows dictionary.</p> required <code>connections</code> <code>dict[str, BaseConnection]</code> <p>Existing connections dictionary.</p> required <code>prompts</code> <code>dict[str, Prompt]</code> <p>Existing prompts dictionary.</p> required <code>registry</code> <code>dict[str, Any]</code> <p>Registry of node types.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <code>init_components</code> <code>bool</code> <p>Flag to initialize components.</p> <code>False</code> <code>max_workers</code> <code>int | None</code> <p>Maximum number of worker threads for node parallel processing.</p> <code>None</code> <p>Returns:</p> Type Description <p>A dictionary of newly created nodes with dependencies.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_updated_node_init_data_with_initialized_nodes(\n    cls,\n    node_init_data: dict,\n    nodes: dict[str, Node],\n    flows: dict[str, Flow],\n    connections: dict[str, BaseConnection],\n    prompts: dict[str, Prompt],\n    registry: dict[str, Any],\n    connection_manager: ConnectionManager | None = None,\n    init_components: bool = False,\n    max_workers: int | None = None,\n):\n    \"\"\"\n    Get node init data with initialized nodes components recursively (llms, agents, etc)\n\n    Args:\n        node_init_data: Dictionary containing node data.\n        nodes: Existing nodes dictionary.\n        flows: Existing flows dictionary.\n        connections: Existing connections dictionary.\n        prompts: Existing prompts dictionary.\n        registry: Registry of node types.\n        connection_manager: Optional connection manager.\n        init_components: Flag to initialize components.\n        max_workers: Maximum number of worker threads for node parallel processing.\n\n    Returns:\n        A dictionary of newly created nodes with dependencies.\n    \"\"\"\n    updated_node_init_data = {}\n    kwargs = dict(\n        nodes=nodes,\n        flows=flows,\n        connections=connections,\n        prompts=prompts,\n        registry=registry,\n        connection_manager=connection_manager,\n        init_components=init_components,\n        max_workers=max_workers,\n    )\n    for param_name, param_data in node_init_data.items():\n        # TODO: dummy fix, revisit this!\n        # We had to add this condition because some nodes have a `schema`/`response_format` params,\n        # that have a `type` field that contains types supported by JSON schema (e.g., string, object).\n        if param_name in (\"schema\", \"response_format\"):\n            updated_node_init_data[param_name] = param_data\n\n        elif isinstance(param_data, dict):\n            updated_param_data = {}\n            for param_name_inner, param_data_inner in param_data.items():\n                if param_name_inner in (\"prompt\", \"schema\", \"response_format\"):\n                    updated_param_data[param_name_inner] = param_data_inner\n                elif isinstance(param_data_inner, (dict, list)):\n                    param_id = None\n                    updated_param_data[param_name_inner] = cls.get_updated_node_init_data_with_initialized_nodes(\n                        {param_id: param_data_inner}, **kwargs\n                    )[param_id]\n                else:\n                    updated_param_data[param_name_inner] = param_data_inner\n\n            if \"type\" in updated_param_data:\n                param_id = updated_param_data.get(\"id\")\n                updated_param_data = cls.get_nodes_without_depends({param_id: updated_param_data}, **kwargs)[\n                    param_id\n                ]\n\n            updated_node_init_data[param_name] = updated_param_data\n\n        elif isinstance(param_data, list):\n            updated_items = []\n            for item in param_data:\n                if isinstance(item, (dict, list)):\n                    param_id = None\n                    updated_items.append(\n                        cls.get_updated_node_init_data_with_initialized_nodes(\n                            node_init_data={param_id: item}, **kwargs\n                        )[param_id]\n                    )\n                else:\n                    updated_items.append(item)\n            updated_node_init_data[param_name] = updated_items\n\n        else:\n            updated_node_init_data[param_name] = param_data\n\n    return updated_node_init_data\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.get_workflows","title":"<code>get_workflows(data, flows)</code>  <code>classmethod</code>","text":"<p>Create workflows from the given data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing workflow data.</p> required <code>flows</code> <code>dict[str, Flow]</code> <p>Existing flows dictionary.</p> required <p>Returns:</p> Type Description <code>dict[str, Workflow]</code> <p>A dictionary of newly created workflows.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If workflow data is invalid.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef get_workflows(cls, data: dict, flows: dict[str, Flow]) -&gt; dict[str, Workflow]:\n    \"\"\"\n    Create workflows from the given data.\n\n    Args:\n        data: Dictionary containing workflow data.\n        flows: Existing flows dictionary.\n\n    Returns:\n        A dictionary of newly created workflows.\n\n    Raises:\n        WorkflowYAMLLoaderException: If workflow data is invalid.\n    \"\"\"\n    workflows = {}\n    for wf_id, wf_data in data.get(\"workflows\", {}).items():\n        if not (flow_id := wf_data.get(\"flow\")):\n            raise WorkflowYAMLLoaderException(f\"Value 'flow' for dynamiq '{wf_id}' not found \")\n        if not (flow := flows.get(flow_id)):\n            raise WorkflowYAMLLoaderException(f\"Flow '{flow_id}' for dynamiq '{wf_id}' not found\")\n        if version := wf_data.get(\"version\"):\n            version = str(version)\n\n        try:\n            wf = Workflow(id=wf_id, flow=flow, version=version)\n        except Exception as e:\n            raise WorkflowYAMLLoaderException(f\"Workflow '{wf_id}' data is invalid. Error: {e}\")\n\n        workflows[wf_id] = wf\n    return workflows\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.init_prompt","title":"<code>init_prompt(prompt_init_data)</code>  <code>classmethod</code>","text":"<p>Initialize a prompt from the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>prompt_init_data</code> <code>dict</code> <p>The data for the prompt.</p> required <p>Returns:</p> Name Type Description <code>Prompt</code> <code>Prompt</code> <p>The initialized prompt.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If the specified prompt is not found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef init_prompt(cls, prompt_init_data: dict) -&gt; Prompt:\n    \"\"\"\n    Initialize a prompt from the provided data.\n\n    Args:\n        prompt_init_data (dict): The data for the prompt.\n\n    Returns:\n        Prompt: The initialized prompt.\n\n    Raises:\n        WorkflowYAMLLoaderException: If the specified prompt is not found.\n    \"\"\"\n    try:\n        return Prompt(**prompt_init_data)\n    except Exception as e:\n        raise WorkflowYAMLLoaderException(f\"Prompt '{prompt_init_data.get('id')}' data is invalid. Error: {e}\")\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.load","title":"<code>load(file_path, connection_manager=None, init_components=False, max_workers=None)</code>  <code>classmethod</code>","text":"<p>Load data from a YAML file and parse it.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | PathLike</code> <p>Path to the YAML file.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <code>init_components</code> <code>bool</code> <p>Flag to initialize components.</p> <code>False</code> <code>max_workers</code> <code>int | None</code> <p>Maximum number of worker threads for node parallel processing.</p> <code>None</code> <p>Returns:</p> Type Description <code>WorkflowYamlData</code> <p>Parsed WorkflowYamlData object.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef load(\n    cls,\n    file_path: str | PathLike,\n    connection_manager: ConnectionManager | None = None,\n    init_components: bool = False,\n    max_workers: int | None = None,\n) -&gt; WorkflowYamlData:\n    \"\"\"\n    Load data from a YAML file and parse it.\n\n    Args:\n        file_path: Path to the YAML file.\n        connection_manager: Optional connection manager.\n        init_components: Flag to initialize components.\n        max_workers: Maximum number of worker threads for node parallel processing.\n\n    Returns:\n        Parsed WorkflowYamlData object.\n    \"\"\"\n    data = cls.loads(file_path)\n    return cls.parse(\n        data=data,\n        connection_manager=connection_manager,\n        init_components=init_components,\n        max_workers=max_workers,\n    )\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.loads","title":"<code>loads(file_path)</code>  <code>classmethod</code>","text":"<p>Load data from a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | PathLike</code> <p>Path to the YAML file.</p> required <p>Returns:</p> Type Description <p>Parsed data from the YAML file.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If the file is not found.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef loads(cls, file_path: str | PathLike):\n    \"\"\"\n    Load data from a YAML file.\n\n    Args:\n        file_path: Path to the YAML file.\n\n    Returns:\n        Parsed data from the YAML file.\n\n    Raises:\n        WorkflowYAMLLoaderException: If the file is not found.\n    \"\"\"\n    from omegaconf import OmegaConf\n\n    try:\n        conf = OmegaConf.load(file_path)\n        logger.debug(f\"Loaded config from '{file_path}'\")\n\n        data = OmegaConf.to_container(conf, resolve=True)\n    except FileNotFoundError:\n        raise WorkflowYAMLLoaderException(f\"File '{file_path}' not found\")\n\n    return data\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoader.parse","title":"<code>parse(data, connection_manager=None, init_components=False, max_workers=None)</code>  <code>classmethod</code>","text":"<p>Parse dynamiq workflow data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing workflow data.</p> required <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Optional connection manager.</p> <code>None</code> <code>init_components</code> <code>bool</code> <p>Flag to initialize components.</p> <code>False</code> <code>max_workers</code> <code>int | None</code> <p>Maximum number of worker threads for node parallel processing.</p> <code>None</code> <p>Returns:</p> Type Description <code>WorkflowYamlData</code> <p>Parsed WorkflowYamlData object.</p> <p>Raises:</p> Type Description <code>WorkflowYAMLLoaderException</code> <p>If parsing fails.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>@classmethod\ndef parse(\n    cls,\n    data: dict,\n    connection_manager: ConnectionManager | None = None,\n    init_components: bool = False,\n    max_workers: int | None = None,\n) -&gt; WorkflowYamlData:\n    \"\"\"\n    Parse dynamiq workflow data.\n\n    Args:\n        data: Dictionary containing workflow data.\n        connection_manager: Optional connection manager.\n        init_components: Flag to initialize components.\n        max_workers: Maximum number of worker threads for node parallel processing.\n\n    Returns:\n        Parsed WorkflowYamlData object.\n\n    Raises:\n        WorkflowYAMLLoaderException: If parsing fails.\n    \"\"\"\n    nodes, flows = {}, {}\n    # Mutable shared registry that updates with each new entity.\n    node_registry, connection_registry = {}, {}\n    if init_components and connection_manager is None:\n        connection_manager = ConnectionManager()\n\n    try:\n        connections = cls.get_connections(data=data, registry=connection_registry)\n        prompts = cls.get_prompts(data)\n\n        nodes_data = data.get(\"nodes\", {})\n        flows_data = data.get(\"flows\", {})\n\n        dependant_nodes = cls.get_dependant_nodes(\n            nodes_data=nodes_data,\n            flows_data=flows_data,\n            connections=connections,\n            prompts=prompts,\n            registry=node_registry,\n            connection_manager=connection_manager,\n            init_components=init_components,\n            max_workers=max_workers,\n        )\n        nodes.update(dependant_nodes)\n\n        dependant_flows = cls.get_dependant_flows(\n            nodes_data=nodes_data,\n            flows_data=flows_data,\n            dependant_nodes=dependant_nodes,\n            connection_manager=connection_manager,\n        )\n        flows.update(dependant_flows)\n\n        non_dependant_nodes = cls.get_nodes(\n            nodes_data=nodes_data,\n            nodes=nodes,\n            flows=flows,\n            connections=connections,\n            prompts=prompts,\n            registry=node_registry,\n            connection_manager=connection_manager,\n            init_components=init_components,\n            max_workers=max_workers,\n        )\n        nodes.update(non_dependant_nodes)\n\n        non_dependant_flows = cls.get_flows(\n            data=flows_data,\n            flows=flows,\n            nodes=nodes,\n            connection_manager=connection_manager,\n        )\n        flows.update(non_dependant_flows)\n\n        workflows = cls.get_workflows(data, flows)\n    except WorkflowYAMLLoaderException:\n        raise\n    except Exception:\n        logger.exception(\"Failed to parse Yaml data with unexpected error\")\n        raise\n\n    return WorkflowYamlData(\n        connections=connections,\n        nodes=nodes,\n        flows=flows,\n        workflows=workflows,\n    )\n</code></pre>"},{"location":"dynamiq/serializers/loaders/yaml/#dynamiq.serializers.loaders.yaml.WorkflowYAMLLoaderException","title":"<code>WorkflowYAMLLoaderException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised for errors in the WorkflowYAMLDumper.</p> Source code in <code>dynamiq/serializers/loaders/yaml.py</code> <pre><code>class WorkflowYAMLLoaderException(Exception):\n    \"\"\"Exception raised for errors in the WorkflowYAMLDumper.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/","title":"Base","text":"<p>Base file storage interface and common data structures.</p>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileExistsError","title":"<code>FileExistsError</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Raised when trying to create a file that already exists.</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>class FileExistsError(StorageError):\n    \"\"\"Raised when trying to create a file that already exists.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileInfo","title":"<code>FileInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a stored file.</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>class FileInfo(BaseModel):\n    \"\"\"Information about a stored file.\"\"\"\n\n    name: str\n    path: str\n    size: int\n    content_type: str = \"text/plain\"\n    created_at: datetime = Field(default_factory=datetime.now)\n    metadata: dict[str, Any] = Field(default_factory=dict)\n    content: bytes = Field(default=None)\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileNotFoundError","title":"<code>FileNotFoundError</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Raised when a file is not found in storage.</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>class FileNotFoundError(StorageError):\n    \"\"\"Raised when a file is not found in storage.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore","title":"<code>FileStore</code>","text":"<p>               Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>Abstract base class for file storage implementations.</p> <p>This interface provides a unified way to interact with different file storage backends (in-memory, file system, cloud storage, etc.).</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>class FileStore(abc.ABC, BaseModel):\n    \"\"\"Abstract base class for file storage implementations.\n\n    This interface provides a unified way to interact with different\n    file storage backends (in-memory, file system, cloud storage, etc.).\n    \"\"\"\n\n    @computed_field\n    @cached_property\n    def type(self) -&gt; str:\n        \"\"\"Returns the backend type as a string.\"\"\"\n        return f\"{self.__module__.rsplit('.', 1)[0]}.{self.__class__.__name__}\"\n\n    def to_dict(self, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"Convert the FileStore instance to a dictionary.\n\n        Returns:\n            dict: Dictionary representation of the FileStore instance.\n        \"\"\"\n        for param in (\"include_secure_params\", \"for_tracing\"):\n            kwargs.pop(param, None)\n        data = self.model_dump(**kwargs)\n        data[\"type\"] = self.type\n        return data\n\n    @abc.abstractmethod\n    def list_files_bytes(self) -&gt; list[BytesIO]:\n        \"\"\"List files in storage and return the content as bytes in BytesIO objects.\n\n        Returns:\n            List of BytesIO objects\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def store(\n        self,\n        file_path: str | Path,\n        content: str | bytes | BinaryIO,\n        content_type: str = None,\n        metadata: dict[str, Any] = None,\n        overwrite: bool = False,\n    ) -&gt; FileInfo:\n        \"\"\"Store a file in the storage backend.\n\n        Args:\n            file_path: Path where the file should be stored\n            content: File content as string, bytes, or file-like object\n            content_type: MIME type of the file content\n            metadata: Additional metadata to store with the file\n            overwrite: Whether to overwrite existing files\n\n        Returns:\n            FileInfo object with details about the stored file\n\n        Raises:\n            FileExistsError: If file exists and overwrite=False\n            PermissionError: If storage operation is not permitted\n            StorageError: For other storage-related errors\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def retrieve(self, file_path: str | Path) -&gt; bytes:\n        \"\"\"Retrieve file content from storage.\n\n        Args:\n            file_path: Path of the file to retrieve\n\n        Returns:\n            File content as bytes\n\n        Raises:\n            FileNotFoundError: If file doesn't exist\n            PermissionError: If retrieval is not permitted\n            StorageError: For other storage-related errors\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def exists(self, file_path: str | Path) -&gt; bool:\n        \"\"\"Check if a file exists in storage.\n\n        Args:\n            file_path: Path of the file to check\n\n        Returns:\n            True if file exists, False otherwise\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def delete(self, file_path: str | Path) -&gt; bool:\n        \"\"\"Delete a file from storage.\n\n        Args:\n            file_path: Path of the file to delete\n\n        Returns:\n            True if file was deleted, False if it didn't exist\n\n        Raises:\n            PermissionError: If deletion is not permitted\n            StorageError: For other storage-related errors\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def list_files(self, directory: str | Path = \"\", recursive: bool = False, pattern: str = None) -&gt; list[FileInfo]:\n        \"\"\"List files in storage.\n\n        Args:\n            directory: Directory to list (empty string for root)\n            recursive: Whether to list files recursively\n            pattern: Glob pattern to filter files\n\n        Returns:\n            List of FileInfo objects\n        \"\"\"\n        pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore.type","title":"<code>type: str</code>  <code>cached</code> <code>property</code>","text":"<p>Returns the backend type as a string.</p>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore.delete","title":"<code>delete(file_path)</code>  <code>abstractmethod</code>","text":"<p>Delete a file from storage.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path of the file to delete</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if file was deleted, False if it didn't exist</p> <p>Raises:</p> Type Description <code>PermissionError</code> <p>If deletion is not permitted</p> <code>StorageError</code> <p>For other storage-related errors</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>@abc.abstractmethod\ndef delete(self, file_path: str | Path) -&gt; bool:\n    \"\"\"Delete a file from storage.\n\n    Args:\n        file_path: Path of the file to delete\n\n    Returns:\n        True if file was deleted, False if it didn't exist\n\n    Raises:\n        PermissionError: If deletion is not permitted\n        StorageError: For other storage-related errors\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore.exists","title":"<code>exists(file_path)</code>  <code>abstractmethod</code>","text":"<p>Check if a file exists in storage.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path of the file to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if file exists, False otherwise</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>@abc.abstractmethod\ndef exists(self, file_path: str | Path) -&gt; bool:\n    \"\"\"Check if a file exists in storage.\n\n    Args:\n        file_path: Path of the file to check\n\n    Returns:\n        True if file exists, False otherwise\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore.list_files","title":"<code>list_files(directory='', recursive=False, pattern=None)</code>  <code>abstractmethod</code>","text":"<p>List files in storage.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str | Path</code> <p>Directory to list (empty string for root)</p> <code>''</code> <code>recursive</code> <code>bool</code> <p>Whether to list files recursively</p> <code>False</code> <code>pattern</code> <code>str</code> <p>Glob pattern to filter files</p> <code>None</code> <p>Returns:</p> Type Description <code>list[FileInfo]</code> <p>List of FileInfo objects</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>@abc.abstractmethod\ndef list_files(self, directory: str | Path = \"\", recursive: bool = False, pattern: str = None) -&gt; list[FileInfo]:\n    \"\"\"List files in storage.\n\n    Args:\n        directory: Directory to list (empty string for root)\n        recursive: Whether to list files recursively\n        pattern: Glob pattern to filter files\n\n    Returns:\n        List of FileInfo objects\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore.list_files_bytes","title":"<code>list_files_bytes()</code>  <code>abstractmethod</code>","text":"<p>List files in storage and return the content as bytes in BytesIO objects.</p> <p>Returns:</p> Type Description <code>list[BytesIO]</code> <p>List of BytesIO objects</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>@abc.abstractmethod\ndef list_files_bytes(self) -&gt; list[BytesIO]:\n    \"\"\"List files in storage and return the content as bytes in BytesIO objects.\n\n    Returns:\n        List of BytesIO objects\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore.retrieve","title":"<code>retrieve(file_path)</code>  <code>abstractmethod</code>","text":"<p>Retrieve file content from storage.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path of the file to retrieve</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>File content as bytes</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If file doesn't exist</p> <code>PermissionError</code> <p>If retrieval is not permitted</p> <code>StorageError</code> <p>For other storage-related errors</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>@abc.abstractmethod\ndef retrieve(self, file_path: str | Path) -&gt; bytes:\n    \"\"\"Retrieve file content from storage.\n\n    Args:\n        file_path: Path of the file to retrieve\n\n    Returns:\n        File content as bytes\n\n    Raises:\n        FileNotFoundError: If file doesn't exist\n        PermissionError: If retrieval is not permitted\n        StorageError: For other storage-related errors\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore.store","title":"<code>store(file_path, content, content_type=None, metadata=None, overwrite=False)</code>  <code>abstractmethod</code>","text":"<p>Store a file in the storage backend.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path where the file should be stored</p> required <code>content</code> <code>str | bytes | BinaryIO</code> <p>File content as string, bytes, or file-like object</p> required <code>content_type</code> <code>str</code> <p>MIME type of the file content</p> <code>None</code> <code>metadata</code> <code>dict[str, Any]</code> <p>Additional metadata to store with the file</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite existing files</p> <code>False</code> <p>Returns:</p> Type Description <code>FileInfo</code> <p>FileInfo object with details about the stored file</p> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If file exists and overwrite=False</p> <code>PermissionError</code> <p>If storage operation is not permitted</p> <code>StorageError</code> <p>For other storage-related errors</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>@abc.abstractmethod\ndef store(\n    self,\n    file_path: str | Path,\n    content: str | bytes | BinaryIO,\n    content_type: str = None,\n    metadata: dict[str, Any] = None,\n    overwrite: bool = False,\n) -&gt; FileInfo:\n    \"\"\"Store a file in the storage backend.\n\n    Args:\n        file_path: Path where the file should be stored\n        content: File content as string, bytes, or file-like object\n        content_type: MIME type of the file content\n        metadata: Additional metadata to store with the file\n        overwrite: Whether to overwrite existing files\n\n    Returns:\n        FileInfo object with details about the stored file\n\n    Raises:\n        FileExistsError: If file exists and overwrite=False\n        PermissionError: If storage operation is not permitted\n        StorageError: For other storage-related errors\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStore.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Convert the FileStore instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>Dictionary representation of the FileStore instance.</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"Convert the FileStore instance to a dictionary.\n\n    Returns:\n        dict: Dictionary representation of the FileStore instance.\n    \"\"\"\n    for param in (\"include_secure_params\", \"for_tracing\"):\n        kwargs.pop(param, None)\n    data = self.model_dump(**kwargs)\n    data[\"type\"] = self.type\n    return data\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStoreConfig","title":"<code>FileStoreConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for file storage.</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>class FileStoreConfig(BaseModel):\n    \"\"\"Configuration for file storage.\"\"\"\n\n    enabled: bool = False\n    backend: FileStore = Field(..., description=\"File storage to use.\")\n    agent_file_write_enabled: bool = Field(\n        default=False, description=\"Whether the agent is permitted to write files to the file store.\"\n    )\n    config: dict[str, Any] = Field(default_factory=dict)\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def to_dict(self, **kwargs) -&gt; dict[str, Any]:\n        \"\"\"Convert the FileStoreConfig instance to a dictionary.\"\"\"\n        for_tracing = kwargs.pop(\"for_tracing\", False)\n        if for_tracing and not self.enabled:\n            return {\"enabled\": False}\n        kwargs.pop(\"include_secure_params\", None)\n        config_data = self.model_dump(exclude={\"backend\"}, **kwargs)\n        config_data[\"backend\"] = self.backend.to_dict()\n        return config_data\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.FileStoreConfig.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Convert the FileStoreConfig instance to a dictionary.</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict[str, Any]:\n    \"\"\"Convert the FileStoreConfig instance to a dictionary.\"\"\"\n    for_tracing = kwargs.pop(\"for_tracing\", False)\n    if for_tracing and not self.enabled:\n        return {\"enabled\": False}\n    kwargs.pop(\"include_secure_params\", None)\n    config_data = self.model_dump(exclude={\"backend\"}, **kwargs)\n    config_data[\"backend\"] = self.backend.to_dict()\n    return config_data\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.PermissionError","title":"<code>PermissionError</code>","text":"<p>               Bases: <code>StorageError</code></p> <p>Raised when permission is denied for a storage operation.</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>class PermissionError(StorageError):\n    \"\"\"Raised when permission is denied for a storage operation.\"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/storages/file/base/#dynamiq.storages.file.base.StorageError","title":"<code>StorageError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for storage operations.</p> Source code in <code>dynamiq/storages/file/base.py</code> <pre><code>class StorageError(Exception):\n    \"\"\"Base exception for storage operations.\"\"\"\n\n    def __init__(self, message: str, operation: str = None, path: str = None):\n        self.message = message\n        self.operation = operation\n        self.path = path\n        super().__init__(self.message)\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/","title":"In memory","text":"<p>In-memory file storage implementation.</p>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore","title":"<code>InMemoryFileStore</code>","text":"<p>               Bases: <code>FileStore</code></p> <p>In-memory file storage implementation.</p> <p>This implementation stores files in memory using Python dictionaries. Files are lost when the process terminates.</p> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>class InMemoryFileStore(FileStore):\n    \"\"\"In-memory file storage implementation.\n\n    This implementation stores files in memory using Python dictionaries.\n    Files are lost when the process terminates.\n\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize the in-memory storage.\n\n        Args:\n            **kwargs: Additional keyword arguments (ignored)\n        \"\"\"\n        super().__init__(**kwargs)\n        self._files: dict[str, dict[str, Any]] = {}\n\n    def list_files_bytes(self) -&gt; list[BytesIO]:\n        \"\"\"List files in storage and return the content as bytes in BytesIO objects.\n\n        Returns:\n            List of BytesIO objects\n        \"\"\"\n        files = []\n\n        for file_path in self._files.keys():\n            file = BytesIO(self._files[file_path][\"content\"])\n            file.name = file_path\n            file.description = self._files[file_path][\"metadata\"].get(\"description\", \"\")\n            file.content_type = self._files[file_path][\"content_type\"]\n            files.append(file)\n\n        return files\n\n    def is_empty(self) -&gt; bool:\n        \"\"\"Check if the file store is empty.\"\"\"\n        return len(self._files) == 0\n\n    def store(\n        self,\n        file_path: str | Path,\n        content: str | bytes | BinaryIO,\n        content_type: str = None,\n        metadata: dict[str, Any] = None,\n        overwrite: bool = False,\n    ) -&gt; FileInfo:\n        \"\"\"Store a file in memory.\"\"\"\n        file_path = str(file_path)\n\n        if file_path in self._files and not overwrite:\n            logger.info(f\"File '{file_path}' already exists. Skipping...\")\n            return self._create_file_info(file_path, self._files[file_path])\n\n        # Convert content to bytes\n        if isinstance(content, str):\n            content_bytes = content.encode(\"utf-8\")\n        elif isinstance(content, bytes):\n            content_bytes = content\n        elif hasattr(content, \"read\"):  # BinaryIO-like object\n            content_bytes = content.read()\n            if hasattr(content, \"seek\"):\n                content.seek(0)  # Reset position for future reads\n        else:\n            raise StorageError(f\"Unsupported content type: {type(content)}\", operation=\"store\", path=file_path)\n\n        if content_type is None:\n            content_type, _ = mimetypes.guess_type(file_path)\n            if content_type is None:\n                content_type = \"application/octet-stream\"\n\n        now = datetime.now()\n        file_info = {\n            \"content\": content_bytes,\n            \"size\": len(content_bytes),\n            \"content_type\": content_type,\n            \"created_at\": now,\n            \"metadata\": metadata or {},\n        }\n\n        self._files[file_path] = file_info\n\n        return self._create_file_info(file_path, file_info)\n\n    def retrieve(self, file_path: str | Path) -&gt; bytes:\n        \"\"\"Retrieve file content as bytes.\"\"\"\n        file_path = str(file_path)\n\n        if file_path not in self._files:\n            raise FileNotFoundError(f\"File '{file_path}' not found\", operation=\"retrieve\", path=file_path)\n\n        return self._files[file_path][\"content\"]\n\n    def exists(self, file_path: str | Path) -&gt; bool:\n        \"\"\"Check if file exists.\"\"\"\n        return str(file_path) in self._files\n\n    def delete(self, file_path: str | Path) -&gt; bool:\n        \"\"\"Delete a file.\"\"\"\n        file_path = str(file_path)\n\n        if file_path in self._files:\n            del self._files[file_path]\n            return True\n\n        return False\n\n    def list_files(\n        self,\n        directory: str | Path = \"\",\n        recursive: bool = False,\n    ) -&gt; list[FileInfo]:\n        \"\"\"List files in storage.\"\"\"\n        directory = str(directory)\n        files_list = []\n\n        for file_path in self._files.keys():\n            if directory and not file_path.startswith(directory):\n                continue\n\n            if not recursive:\n                rel_path = file_path[len(directory) :].lstrip(\"/\")\n                if \"/\" in rel_path:\n                    continue\n\n            files_list.append(self._create_file_info(file_path, self._files[file_path]))\n\n        return files_list\n\n    def _create_file_info(self, file_path: str, file_data: dict[str, Any]) -&gt; FileInfo:\n        \"\"\"Create a FileInfo object from internal file data.\"\"\"\n        return FileInfo(\n            name=os.path.basename(file_path),\n            path=file_path,\n            size=file_data[\"size\"],\n            content_type=file_data[\"content_type\"],\n            created_at=file_data[\"created_at\"],\n            metadata=file_data.get(\"metadata\", {}),\n            content=file_data[\"content\"],\n        )\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the in-memory storage.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments (ignored)</p> <code>{}</code> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize the in-memory storage.\n\n    Args:\n        **kwargs: Additional keyword arguments (ignored)\n    \"\"\"\n    super().__init__(**kwargs)\n    self._files: dict[str, dict[str, Any]] = {}\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore.delete","title":"<code>delete(file_path)</code>","text":"<p>Delete a file.</p> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>def delete(self, file_path: str | Path) -&gt; bool:\n    \"\"\"Delete a file.\"\"\"\n    file_path = str(file_path)\n\n    if file_path in self._files:\n        del self._files[file_path]\n        return True\n\n    return False\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore.exists","title":"<code>exists(file_path)</code>","text":"<p>Check if file exists.</p> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>def exists(self, file_path: str | Path) -&gt; bool:\n    \"\"\"Check if file exists.\"\"\"\n    return str(file_path) in self._files\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore.is_empty","title":"<code>is_empty()</code>","text":"<p>Check if the file store is empty.</p> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Check if the file store is empty.\"\"\"\n    return len(self._files) == 0\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore.list_files","title":"<code>list_files(directory='', recursive=False)</code>","text":"<p>List files in storage.</p> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>def list_files(\n    self,\n    directory: str | Path = \"\",\n    recursive: bool = False,\n) -&gt; list[FileInfo]:\n    \"\"\"List files in storage.\"\"\"\n    directory = str(directory)\n    files_list = []\n\n    for file_path in self._files.keys():\n        if directory and not file_path.startswith(directory):\n            continue\n\n        if not recursive:\n            rel_path = file_path[len(directory) :].lstrip(\"/\")\n            if \"/\" in rel_path:\n                continue\n\n        files_list.append(self._create_file_info(file_path, self._files[file_path]))\n\n    return files_list\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore.list_files_bytes","title":"<code>list_files_bytes()</code>","text":"<p>List files in storage and return the content as bytes in BytesIO objects.</p> <p>Returns:</p> Type Description <code>list[BytesIO]</code> <p>List of BytesIO objects</p> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>def list_files_bytes(self) -&gt; list[BytesIO]:\n    \"\"\"List files in storage and return the content as bytes in BytesIO objects.\n\n    Returns:\n        List of BytesIO objects\n    \"\"\"\n    files = []\n\n    for file_path in self._files.keys():\n        file = BytesIO(self._files[file_path][\"content\"])\n        file.name = file_path\n        file.description = self._files[file_path][\"metadata\"].get(\"description\", \"\")\n        file.content_type = self._files[file_path][\"content_type\"]\n        files.append(file)\n\n    return files\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore.retrieve","title":"<code>retrieve(file_path)</code>","text":"<p>Retrieve file content as bytes.</p> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>def retrieve(self, file_path: str | Path) -&gt; bytes:\n    \"\"\"Retrieve file content as bytes.\"\"\"\n    file_path = str(file_path)\n\n    if file_path not in self._files:\n        raise FileNotFoundError(f\"File '{file_path}' not found\", operation=\"retrieve\", path=file_path)\n\n    return self._files[file_path][\"content\"]\n</code></pre>"},{"location":"dynamiq/storages/file/in_memory/#dynamiq.storages.file.in_memory.InMemoryFileStore.store","title":"<code>store(file_path, content, content_type=None, metadata=None, overwrite=False)</code>","text":"<p>Store a file in memory.</p> Source code in <code>dynamiq/storages/file/in_memory.py</code> <pre><code>def store(\n    self,\n    file_path: str | Path,\n    content: str | bytes | BinaryIO,\n    content_type: str = None,\n    metadata: dict[str, Any] = None,\n    overwrite: bool = False,\n) -&gt; FileInfo:\n    \"\"\"Store a file in memory.\"\"\"\n    file_path = str(file_path)\n\n    if file_path in self._files and not overwrite:\n        logger.info(f\"File '{file_path}' already exists. Skipping...\")\n        return self._create_file_info(file_path, self._files[file_path])\n\n    # Convert content to bytes\n    if isinstance(content, str):\n        content_bytes = content.encode(\"utf-8\")\n    elif isinstance(content, bytes):\n        content_bytes = content\n    elif hasattr(content, \"read\"):  # BinaryIO-like object\n        content_bytes = content.read()\n        if hasattr(content, \"seek\"):\n            content.seek(0)  # Reset position for future reads\n    else:\n        raise StorageError(f\"Unsupported content type: {type(content)}\", operation=\"store\", path=file_path)\n\n    if content_type is None:\n        content_type, _ = mimetypes.guess_type(file_path)\n        if content_type is None:\n            content_type = \"application/octet-stream\"\n\n    now = datetime.now()\n    file_info = {\n        \"content\": content_bytes,\n        \"size\": len(content_bytes),\n        \"content_type\": content_type,\n        \"created_at\": now,\n        \"metadata\": metadata or {},\n    }\n\n    self._files[file_path] = file_info\n\n    return self._create_file_info(file_path, file_info)\n</code></pre>"},{"location":"dynamiq/storages/vector/base/","title":"Base","text":""},{"location":"dynamiq/storages/vector/base/#dynamiq.storages.vector.base.BaseVectorStore","title":"<code>BaseVectorStore</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for all vector stores.</p> <p>This abstract class provides a consistent interface for all vector store implementations, including common methods for document deletion by file ID(s).</p> Source code in <code>dynamiq/storages/vector/base.py</code> <pre><code>class BaseVectorStore(ABC):\n    \"\"\"Base class for all vector stores.\n\n    This abstract class provides a consistent interface for all vector store implementations,\n    including common methods for document deletion by file ID(s).\n    \"\"\"\n\n    @abstractmethod\n    def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n        \"\"\"\n        Delete documents from the vector store based on the provided filters.\n\n        Args:\n            filters (dict[str, Any]): Filters to select documents to delete.\n        \"\"\"\n        pass\n\n    def delete_documents_by_file_id(self, file_id: str) -&gt; None:\n        \"\"\"\n        Delete documents from the vector store based on the provided file ID.\n        File ID should be located in the metadata of the document.\n\n        Args:\n            file_id (str): The file ID to filter by.\n        \"\"\"\n        filters = create_file_id_filter(file_id)\n        self.delete_documents_by_filters(filters)\n\n    def delete_documents_by_file_ids(self, file_ids: list[str], batch_size: int = 500) -&gt; None:\n        \"\"\"\n        Delete documents from the vector store based on the provided list of file IDs.\n        File IDs should be located in the metadata of the documents.\n\n        Args:\n            file_ids (list[str]): The list of file IDs to filter by.\n            batch_size (int): Maximum number of file IDs to process in a single batch. Defaults to 500.\n        \"\"\"\n        if not file_ids:\n            logger.warning(\"No file IDs provided. No documents will be deleted.\")\n            return\n\n        if len(file_ids) &gt; batch_size:\n            for i in range(0, len(file_ids), batch_size):\n                batch = file_ids[i : i + batch_size]\n                filters = create_file_ids_filter(batch)\n                self.delete_documents_by_filters(filters)\n                logger.debug(f\"Deleted documents batch {i//batch_size + 1} with {len(batch)} file IDs\")\n        else:\n            filters = create_file_ids_filter(file_ids)\n            self.delete_documents_by_filters(filters)\n</code></pre>"},{"location":"dynamiq/storages/vector/base/#dynamiq.storages.vector.base.BaseVectorStore.delete_documents_by_file_id","title":"<code>delete_documents_by_file_id(file_id)</code>","text":"<p>Delete documents from the vector store based on the provided file ID. File ID should be located in the metadata of the document.</p> <p>Parameters:</p> Name Type Description Default <code>file_id</code> <code>str</code> <p>The file ID to filter by.</p> required Source code in <code>dynamiq/storages/vector/base.py</code> <pre><code>def delete_documents_by_file_id(self, file_id: str) -&gt; None:\n    \"\"\"\n    Delete documents from the vector store based on the provided file ID.\n    File ID should be located in the metadata of the document.\n\n    Args:\n        file_id (str): The file ID to filter by.\n    \"\"\"\n    filters = create_file_id_filter(file_id)\n    self.delete_documents_by_filters(filters)\n</code></pre>"},{"location":"dynamiq/storages/vector/base/#dynamiq.storages.vector.base.BaseVectorStore.delete_documents_by_file_ids","title":"<code>delete_documents_by_file_ids(file_ids, batch_size=500)</code>","text":"<p>Delete documents from the vector store based on the provided list of file IDs. File IDs should be located in the metadata of the documents.</p> <p>Parameters:</p> Name Type Description Default <code>file_ids</code> <code>list[str]</code> <p>The list of file IDs to filter by.</p> required <code>batch_size</code> <code>int</code> <p>Maximum number of file IDs to process in a single batch. Defaults to 500.</p> <code>500</code> Source code in <code>dynamiq/storages/vector/base.py</code> <pre><code>def delete_documents_by_file_ids(self, file_ids: list[str], batch_size: int = 500) -&gt; None:\n    \"\"\"\n    Delete documents from the vector store based on the provided list of file IDs.\n    File IDs should be located in the metadata of the documents.\n\n    Args:\n        file_ids (list[str]): The list of file IDs to filter by.\n        batch_size (int): Maximum number of file IDs to process in a single batch. Defaults to 500.\n    \"\"\"\n    if not file_ids:\n        logger.warning(\"No file IDs provided. No documents will be deleted.\")\n        return\n\n    if len(file_ids) &gt; batch_size:\n        for i in range(0, len(file_ids), batch_size):\n            batch = file_ids[i : i + batch_size]\n            filters = create_file_ids_filter(batch)\n            self.delete_documents_by_filters(filters)\n            logger.debug(f\"Deleted documents batch {i//batch_size + 1} with {len(batch)} file IDs\")\n    else:\n        filters = create_file_ids_filter(file_ids)\n        self.delete_documents_by_filters(filters)\n</code></pre>"},{"location":"dynamiq/storages/vector/base/#dynamiq.storages.vector.base.BaseVectorStore.delete_documents_by_filters","title":"<code>delete_documents_by_filters(filters)</code>  <code>abstractmethod</code>","text":"<p>Delete documents from the vector store based on the provided filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any]</code> <p>Filters to select documents to delete.</p> required Source code in <code>dynamiq/storages/vector/base.py</code> <pre><code>@abstractmethod\ndef delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Delete documents from the vector store based on the provided filters.\n\n    Args:\n        filters (dict[str, Any]): Filters to select documents to delete.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"dynamiq/storages/vector/base/#dynamiq.storages.vector.base.BaseVectorStoreParams","title":"<code>BaseVectorStoreParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base parameters for vector store.</p> <p>Attributes:</p> Name Type Description <code>index_name</code> <code>str</code> <p>Name of the index. Defaults to \"default\".</p> <code>content_key</code> <code>str</code> <p>Key for content field. Defaults to \"content\".</p> Source code in <code>dynamiq/storages/vector/base.py</code> <pre><code>class BaseVectorStoreParams(BaseModel):\n    \"\"\"Base parameters for vector store.\n\n    Attributes:\n        index_name (str): Name of the index. Defaults to \"default\".\n        content_key (str): Key for content field. Defaults to \"content\".\n    \"\"\"\n    index_name: str = \"default\"\n    content_key: str = \"content\"\n</code></pre>"},{"location":"dynamiq/storages/vector/base/#dynamiq.storages.vector.base.BaseWriterVectorStoreParams","title":"<code>BaseWriterVectorStoreParams</code>","text":"<p>               Bases: <code>BaseVectorStoreParams</code></p> <p>Parameters for writer vector store.</p> <p>Attributes:</p> Name Type Description <code>create_if_not_exist</code> <code>bool</code> <p>Flag to create index if it does not exist. Defaults to True.</p> Source code in <code>dynamiq/storages/vector/base.py</code> <pre><code>class BaseWriterVectorStoreParams(BaseVectorStoreParams):\n    \"\"\"Parameters for writer vector store.\n\n    Attributes:\n        create_if_not_exist (bool): Flag to create index if it does not exist. Defaults to True.\n    \"\"\"\n\n    create_if_not_exist: bool = False\n</code></pre>"},{"location":"dynamiq/storages/vector/exceptions/","title":"Exceptions","text":""},{"location":"dynamiq/storages/vector/exceptions/#dynamiq.storages.vector.exceptions.VectorStoreDuplicateDocumentException","title":"<code>VectorStoreDuplicateDocumentException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when attempting to add a duplicate document to the vector store.</p> <p>This exception is thrown when a document with the same identifier or content is already present in the vector store and an attempt is made to add it again.</p> Source code in <code>dynamiq/storages/vector/exceptions.py</code> <pre><code>class VectorStoreDuplicateDocumentException(Exception):\n    \"\"\"\n    Exception raised when attempting to add a duplicate document to the vector store.\n\n    This exception is thrown when a document with the same identifier or content is already present\n    in the vector store and an attempt is made to add it again.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/storages/vector/exceptions/#dynamiq.storages.vector.exceptions.VectorStoreException","title":"<code>VectorStoreException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for vector store related errors.</p> <p>This exception is raised when a general error occurs in the vector store operations.</p> Source code in <code>dynamiq/storages/vector/exceptions.py</code> <pre><code>class VectorStoreException(Exception):\n    \"\"\"\n    Base exception class for vector store related errors.\n\n    This exception is raised when a general error occurs in the vector store operations.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/storages/vector/exceptions/#dynamiq.storages.vector.exceptions.VectorStoreFilterException","title":"<code>VectorStoreFilterException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when there's an error in filtering operations on the vector store.</p> <p>This exception is thrown when an invalid filter is applied or when there's an issue with the filtering process in the vector store.</p> Source code in <code>dynamiq/storages/vector/exceptions.py</code> <pre><code>class VectorStoreFilterException(Exception):\n    \"\"\"\n    Exception raised when there's an error in filtering operations on the vector store.\n\n    This exception is thrown when an invalid filter is applied or when there's an issue with the\n    filtering process in the vector store.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"dynamiq/storages/vector/policies/","title":"Policies","text":""},{"location":"dynamiq/storages/vector/policies/#dynamiq.storages.vector.policies.DuplicatePolicy","title":"<code>DuplicatePolicy</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration of policies for handling duplicate items.</p> <p>Attributes:</p> Name Type Description <code>NONE</code> <code>str</code> <p>No specific policy for handling duplicates.</p> <code>SKIP</code> <code>str</code> <p>Skip duplicate items without modifying existing ones.</p> <code>OVERWRITE</code> <code>str</code> <p>Overwrite existing items with duplicate entries.</p> <code>FAIL</code> <code>str</code> <p>Raise an error when encountering duplicate items.</p> Source code in <code>dynamiq/storages/vector/policies.py</code> <pre><code>class DuplicatePolicy(str, Enum):\n    \"\"\"\n    Enumeration of policies for handling duplicate items.\n\n    Attributes:\n        NONE (str): No specific policy for handling duplicates.\n        SKIP (str): Skip duplicate items without modifying existing ones.\n        OVERWRITE (str): Overwrite existing items with duplicate entries.\n        FAIL (str): Raise an error when encountering duplicate items.\n    \"\"\"\n\n    NONE = \"none\"\n    SKIP = \"skip\"\n    OVERWRITE = \"overwrite\"\n    FAIL = \"fail\"\n</code></pre>"},{"location":"dynamiq/storages/vector/utils/","title":"Utils","text":""},{"location":"dynamiq/storages/vector/utils/#dynamiq.storages.vector.utils.create_file_id_filter","title":"<code>create_file_id_filter(file_id)</code>","text":"<p>Create filters for Pinecone query based on file_id.</p> <p>Parameters:</p> Name Type Description Default <code>file_id</code> <code>str</code> <p>The file ID to filter by.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The filter conditions.</p> Source code in <code>dynamiq/storages/vector/utils.py</code> <pre><code>def create_file_id_filter(file_id: str) -&gt; dict:\n    \"\"\"\n    Create filters for Pinecone query based on file_id.\n\n    Args:\n        file_id (str): The file ID to filter by.\n\n    Returns:\n        dict: The filter conditions.\n    \"\"\"\n    return {\n        \"operator\": \"AND\",\n        \"conditions\": [\n            {\"field\": \"file_id\", \"operator\": \"==\", \"value\": file_id},\n        ],\n    }\n</code></pre>"},{"location":"dynamiq/storages/vector/utils/#dynamiq.storages.vector.utils.create_file_ids_filter","title":"<code>create_file_ids_filter(file_ids)</code>","text":"<p>Create filters for Pinecone query based on multiple file_ids.</p> <p>Parameters:</p> Name Type Description Default <code>file_ids</code> <code>list[str]</code> <p>The list of file IDs to filter by.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The filter conditions.</p> Source code in <code>dynamiq/storages/vector/utils.py</code> <pre><code>def create_file_ids_filter(file_ids: list[str]) -&gt; dict:\n    \"\"\"\n    Create filters for Pinecone query based on multiple file_ids.\n\n    Args:\n        file_ids (list[str]): The list of file IDs to filter by.\n\n    Returns:\n        dict: The filter conditions.\n    \"\"\"\n    return {\n        \"operator\": \"AND\",\n        \"conditions\": [\n            {\"field\": \"file_id\", \"operator\": \"in\", \"value\": file_ids},\n        ],\n    }\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/","title":"Chroma","text":""},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore","title":"<code>ChromaVectorStore</code>","text":"<p>               Bases: <code>BaseVectorStore</code>, <code>DryRunMixin</code></p> <p>Vector store using Chroma.</p> <p>This class provides an interface to interact with a Chroma vector store for document storage and retrieval.</p> <p>Attributes:</p> Name Type Description <code>client</code> <code>ClientAPI</code> <p>The Chroma client API instance.</p> <code>index_name</code> <code>str</code> <p>The name of the index or collection in the vector store.</p> <code>_collection</code> <p>The Chroma collection object.</p> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>class ChromaVectorStore(BaseVectorStore, DryRunMixin):\n    \"\"\"\n    Vector store using Chroma.\n\n    This class provides an interface to interact with a Chroma vector store for document storage and\n    retrieval.\n\n    Attributes:\n        client (ClientAPI): The Chroma client API instance.\n        index_name (str): The name of the index or collection in the vector store.\n        _collection: The Chroma collection object.\n    \"\"\"\n\n    def __init__(\n        self,\n        connection: Chroma | None = None,\n        client: Optional[\"ClientAPI\"] = None,\n        index_name: str = \"default\",\n        create_if_not_exist: bool = False,\n        dry_run_config: DryRunConfig | None = None,\n    ):\n        \"\"\"\n        Initialize the ChromaVectorStore.\n\n        Args:\n            connection (Chroma | None): A Chroma connection object. Defaults to None.\n            client (Optional[ClientAPI]): A Chroma client API instance. Defaults to None.\n            index_name (str): The name of the index or collection. Defaults to \"default\".\n            create_if_not_exist (bool): Whether to create the collection if it doesn't exist. Defaults to False.\n            dry_run_config (DryRunConfig | None): Configuration for dry run mode. Defaults to None.\n        \"\"\"\n        super().__init__(dry_run_config=dry_run_config)\n\n        self.client = client\n        if self.client is None:\n            connection = connection or Chroma()\n            self.client = connection.connect()\n        self.index_name = index_name\n        if create_if_not_exist:\n            collection_exists = self.client.get_collection(name=index_name)\n            if not collection_exists:\n                self._collection = self.client.create_collection(name=index_name)\n                self._track_collection(index_name)\n            else:\n                self._collection = self.client.get_collection(name=index_name)\n        else:\n            self._collection = self.client.get_collection(name=index_name)\n\n    def count_documents(self) -&gt; int:\n        \"\"\"\n        Get the number of documents in the collection.\n\n        Returns:\n            int: The number of documents in the collection.\n        \"\"\"\n        return self._collection.count()\n\n    def write_documents(self, documents: list[Document]) -&gt; int:\n        \"\"\"\n        Write (or overwrite) documents into the store.\n\n        This method processes a list of documents and writes them into the vector store.\n\n        Args:\n            documents (list[Document]): A list of Document objects to be written into the document\n                store.\n\n        Raises:\n            ValueError: If an item in the documents list is not an instance of the Document class.\n\n        Returns:\n            int: The number of documents successfully written to the document store.\n        \"\"\"\n        for doc in documents:\n            if not isinstance(doc, Document):\n                msg = (\n                    \"param 'documents' must contain a list of objects of type Document\"\n                )\n                raise ValueError(msg)\n\n            data = {\"ids\": [doc.id], \"documents\": [doc.content]}\n\n            if doc.metadata:\n                data[\"metadatas\"] = [doc.metadata]\n\n            if doc.embedding:\n                data[\"embeddings\"] = [doc.embedding]\n\n            self._collection.add(**data)\n            self._track_documents([doc.id])\n\n        return len(documents)\n\n    def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n        \"\"\"\n        Delete documents from the vector store based on their IDs.\n\n        Args:\n            document_ids (list[str]): A list containing the IDs of documents to be deleted from the store.\n            delete_all (bool): A flag to delete all documents from the store. Defaults to False.\n        \"\"\"\n\n        if delete_all and self._collection is not None:\n            self.client.delete_collection(name=self.index_name)\n            self._collection = self.client.get_or_create_collection(\n                name=self.index_name\n            )\n        else:\n            if not document_ids:\n                logger.warning(\n                    \"No document IDs provided. No documents will be deleted.\"\n                )\n            else:\n                self._collection.delete(ids=document_ids)\n\n    def delete_documents_by_filters(self, filters: dict[str, Any] | None = None) -&gt; None:\n        \"\"\"\n        Delete documents from the vector store based on the provided filters.\n\n        Args:\n            filters (dict[str, Any] | None): The filters to apply to the document list. Defaults to\n                None.\n        \"\"\"\n        if filters is None:\n            raise ValueError(\"No filters provided. No documents will be deleted.\")\n        else:\n            ids, where, where_document = self._normalize_filters(filters)\n            self._collection.delete(ids=ids, where=where, where_document=where_document)\n\n    def delete_collection(self, collection_name: str | None = None):\n        \"\"\"\n        Delete a Chroma collection.\n\n        Args:\n            collection_name (str | None): Name of the collection to delete.\n        \"\"\"\n        try:\n            collection_to_delete = collection_name or self.index_name\n            self.client.delete_collection(name=collection_to_delete)\n            logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n        except Exception as e:\n            logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n            raise\n\n    def search_embeddings(\n        self,\n        query_embeddings: list[list[float]],\n        top_k: int,\n        filters: dict[str, Any] | None = None,\n    ) -&gt; list[list[Document]]:\n        \"\"\"\n        Perform vector search on the stored documents using query embeddings.\n\n        Args:\n            query_embeddings (list[list[float]]): A list of embeddings to use as queries.\n            top_k (int): The maximum number of documents to retrieve.\n            filters (dict[str, Any] | None): A dictionary of filters to apply to the search.\n                Defaults to None.\n\n        Returns:\n            list[list[Document]]: A list of lists containing documents that match the given filters,\n                for each query embedding provided.\n        \"\"\"\n        if filters is None:\n            results = self._collection.query(\n                query_embeddings=query_embeddings,\n                n_results=top_k,\n                include=[\"embeddings\", \"documents\", \"metadatas\", \"distances\"],\n            )\n        else:\n            chroma_filters = self._normalize_filters(filters=filters)\n            results = self._collection.query(\n                query_embeddings=query_embeddings,\n                n_results=top_k,\n                where=chroma_filters[1],\n                where_document=chroma_filters[2],\n                include=[\"embeddings\", \"documents\", \"metadatas\", \"distances\"],\n            )\n\n        return self._query_result_to_documents(results)\n\n    def filter_documents(self, filters: dict[str, Any] | None = None) -&gt; list[Document]:\n        \"\"\"\n        Retrieve documents that match the provided filters.\n\n        Filters can be defined in two formats:\n        1. Old format: Nested dictionaries with logical operators and comparison operators.\n        2. New format: Nested dictionaries of Comparison and Logic types.\n\n        For the new format:\n        Comparison dictionaries must contain the following keys:\n        - 'field': The name of one of the metadata fields of a document (e.g., 'metadata.years').\n        - 'operator': One of '==', '!=', '&gt;', '&gt;=', '&lt;', '&lt;=', 'in', 'not in'.\n        - 'value': A single value or (for 'in' and 'not in') a list of values.\n\n        Logic dictionaries must contain the following keys:\n        - 'operator': One of 'NOT', 'OR', 'AND'.\n        - 'conditions': A list of Comparison or Logic dictionaries.\n\n        Example of new format:\n        {\n            \"operator\": \"AND\",\n            \"conditions\": [\n              {\n                \"field\": \"metadata.years\",\n                \"operator\": \"==\",\n                \"value\": \"2019\"\n              },\n              {\n                \"field\": \"metadata.companies\",\n                \"operator\": \"in\",\n                \"value\": [\"BMW\", \"Mercedes\"]\n              }\n            ]\n        }\n\n        Args:\n            filters (Dict[str, Any] | None): The filters to apply to the document list.\n            filters (dict[str, Any] | None): The filters to apply to the document list. Defaults to\n                None.\n\n        Returns:\n            list[Document]: A list of Document instances that match the given filters.\n        \"\"\"\n        if filters:\n            ids, where, where_document = self._normalize_filters(filters)\n            kwargs: dict[str, Any] = {\"where\": where}\n\n            if ids:\n                kwargs[\"ids\"] = ids\n            if where_document:\n                kwargs[\"where_document\"] = where_document\n\n            result = self._collection.get(**kwargs)\n        else:\n            raise ValueError(\n                \"No filters provided. No documents will be retrieved with filters.\"\n            )\n\n        return self._get_result_to_documents(result)\n\n    def list_documents(self) -&gt; list[Document]:\n        \"\"\"\n        List all documents in the collection.\n\n        Returns:\n            list[Document]: A list of Document instances representing all documents in the collection.\n        \"\"\"\n        result = self._collection.get()\n        return self._get_result_to_documents(result)\n\n    @staticmethod\n    def _normalize_filters(\n        filters: dict[str, Any]\n    ) -&gt; tuple[list[str], dict[str, Any], dict[str, Any]]:\n        \"\"\"\n        Translate filters to Chroma filters.\n\n        Args:\n            filters (Dict[str, Any]): The filters to normalize.\n\n        Returns:\n            Tuple[List[str], Dict[str, Any], Dict[str, Any]]: A tuple containing:\n                - A list of document IDs\n                - A dictionary of 'where' conditions\n                - A dictionary of 'where_document' conditions\n\n        Raises:\n            TypeError: If the 'filters' parameter is not a dictionary.\n            ValueError: If the filter structure is invalid or contains unsupported operators.\n        \"\"\"\n        if not isinstance(filters, dict):\n            raise TypeError(\"'filters' parameter must be a dictionary\")\n\n        # Check if it's the new format\n        if \"operator\" in filters or \"conditions\" in filters:\n            processed_filters = ChromaVectorStore._process_filter_node(filters)\n        else:\n            # It's the old format, use the old processing method\n            return ChromaVectorStore._process_old_filters(filters)\n\n        ids = []\n        where_document = {}\n\n        # Extract 'id' and 'content' filters if present\n        if \"metadata.id\" in processed_filters:\n            ids = processed_filters[\"metadata.id\"].get(\"$eq\", [])\n            del processed_filters[\"metadata.id\"]\n\n        if \"content\" in processed_filters:\n            where_document[\"$contains\"] = processed_filters[\"content\"].get(\"$eq\", \"\")\n            del processed_filters[\"content\"]\n\n        where = processed_filters\n\n        if \"$and\" in where and \"$or\" not in where:\n            and_conditions = where[\"$and\"]\n            if len(and_conditions) == 1:\n                where = and_conditions[0]\n        if \"$or\" in where and \"$and\" not in where:\n            or_conditions = where[\"$or\"]\n            if len(or_conditions) == 1:\n                where = or_conditions[0]\n\n        try:\n            if where:\n                from chromadb.api.types import validate_where\n\n                validate_where(where)\n            if where_document:\n                from chromadb.api.types import validate_where_document\n\n                validate_where_document(where_document)\n        except ValueError as e:\n            raise ValueError(e) from e\n\n        return ids, where, where_document\n\n    @staticmethod\n    def _process_old_filters(\n        filters: dict[str, Any]\n    ) -&gt; tuple[list[str], dict[str, Any], dict[str, Any]]:\n        \"\"\"\n        Process filters in the old format.\n        \"\"\"\n        ids = []\n        where = defaultdict(list)\n        where_document = defaultdict(list)\n        keys_to_remove = []\n\n        for field, value in filters.items():\n            if field == \"content\":\n                keys_to_remove.append(field)\n                where_document[\"$contains\"] = value\n            elif field == \"id\":\n                keys_to_remove.append(field)\n                ids.append(value)\n            elif isinstance(value, (list, tuple)):\n                keys_to_remove.append(field)\n                if len(value) == 0:\n                    continue\n                if len(value) == 1:\n                    where[field] = value[0]\n                    continue\n                for v in value:\n                    where[\"$or\"].append({field: v})\n\n        for k in keys_to_remove:\n            del filters[k]\n\n        final_where = dict(filters)\n        final_where.update(dict(where))\n\n        return ids, final_where, dict(where_document)\n\n    @staticmethod\n    def _process_filter_node(node: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"\n        Process a single node in the filter structure.\n\n        Args:\n            node (Dict[str, Any]): A dictionary representing a filter node.\n\n        Returns:\n            Dict[str, Any]: The processed filter node.\n\n        Raises:\n            ValueError: If the node structure is invalid.\n        \"\"\"\n        if \"operator\" in node and \"conditions\" in node:  # Logic node\n            return ChromaVectorStore._process_logic_node(node)\n        elif (\n            \"field\" in node and \"operator\" in node and \"value\" in node\n        ):  # Comparison node\n            return ChromaVectorStore._process_comparison_node(node)\n        else:\n            raise ValueError(\"Invalid filter node structure\")\n\n    @staticmethod\n    def _process_logic_node(node: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"\n        Process a logic node in the filter structure.\n\n        Args:\n            node (Dict[str, Any]): A dictionary representing a logic node.\n\n        Returns:\n            Dict[str, Any]: The processed logic node.\n        \"\"\"\n        operator = node[\"operator\"].lower()\n        conditions = [\n            ChromaVectorStore._process_filter_node(condition)\n            for condition in node[\"conditions\"]\n        ]\n        return {f\"${operator}\": conditions}\n\n    @staticmethod\n    def _process_comparison_node(node: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"\n        Process a comparison node in the filter structure.\n\n        Args:\n            node (Dict[str, Any]): A dictionary representing a comparison node.\n\n        Returns:\n            Dict[str, Any]: The processed comparison node.\n\n        Raises:\n            ValueError: If the operator is unsupported.\n        \"\"\"\n        field = node[\"field\"]\n        operator = node[\"operator\"]\n        value = node[\"value\"]\n\n        chroma_operator = CHROMA_OPERATOR_MAPPING.get(operator)\n\n        if chroma_operator is None:\n            raise ValueError(f\"Unsupported operator: {operator}\")\n\n        return {field: {chroma_operator: value}}\n\n    @staticmethod\n    def _query_result_to_documents(result: \"QueryResult\") -&gt; list[list[Document]]:\n        \"\"\"\n        Convert Chroma query results into Dynamiq Documents.\n\n        Args:\n            result (QueryResult): The result from a Chroma query operation.\n\n        Returns:\n            list[list[Document]]: A list of lists containing Document objects created from the\n                Chroma query result.\n        \"\"\"\n        return_value: list[list[Document]] = []\n        documents = result.get(\"documents\")\n        if documents is None:\n            return return_value\n\n        for i, answers in enumerate(documents):\n            converted_answers = []\n            for j in range(len(answers)):\n                document_dict: dict[str, Any] = {\n                    \"id\": result[\"ids\"][i][j],\n                    \"content\": documents[i][j],\n                }\n\n                if metadatas := result.get(\"metadatas\"):\n                    document_dict[\"metadata\"] = dict(metadatas[i][j])\n\n                if embeddings := result.get(\"embeddings\"):\n                    document_dict[\"embedding\"] = embeddings[i][j]\n\n                if distances := result.get(\"distances\"):\n                    document_dict[\"score\"] = distances[i][j]\n\n                converted_answers.append(Document(**document_dict))\n            return_value.append(converted_answers)\n\n        return return_value\n\n    @staticmethod\n    def _get_result_to_documents(result: \"QueryResult\") -&gt; list[Document]:\n        \"\"\"\n        Convert Chroma get result into Dynamiq Documents.\n\n        Args:\n            result (GetResult): The result from a Chroma get operation.\n\n        Returns:\n            list[Document]: A list containing Document objects created from the\n                Chroma get result.\n        \"\"\"\n        return_value: list[Document] = []\n        documents = result.get(\"documents\")\n        if documents is None:\n            return return_value\n\n        for i, content in enumerate(documents):\n            document_dict: dict[str, Any] = {\n                \"id\": result[\"ids\"][i],\n                \"content\": content,\n            }\n\n            if metadatas := result.get(\"metadatas\"):\n                document_dict[\"metadata\"] = dict(metadatas[i])\n\n            if embeddings := result.get(\"embeddings\"):\n                document_dict[\"embedding\"] = embeddings[i]\n\n            if distances := result.get(\"distances\"):\n                document_dict[\"score\"] = distances[i]\n\n            return_value.append(Document(**document_dict))\n        return return_value\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.__init__","title":"<code>__init__(connection=None, client=None, index_name='default', create_if_not_exist=False, dry_run_config=None)</code>","text":"<p>Initialize the ChromaVectorStore.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Chroma | None</code> <p>A Chroma connection object. Defaults to None.</p> <code>None</code> <code>client</code> <code>Optional[ClientAPI]</code> <p>A Chroma client API instance. Defaults to None.</p> <code>None</code> <code>index_name</code> <code>str</code> <p>The name of the index or collection. Defaults to \"default\".</p> <code>'default'</code> <code>create_if_not_exist</code> <code>bool</code> <p>Whether to create the collection if it doesn't exist. Defaults to False.</p> <code>False</code> <code>dry_run_config</code> <code>DryRunConfig | None</code> <p>Configuration for dry run mode. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def __init__(\n    self,\n    connection: Chroma | None = None,\n    client: Optional[\"ClientAPI\"] = None,\n    index_name: str = \"default\",\n    create_if_not_exist: bool = False,\n    dry_run_config: DryRunConfig | None = None,\n):\n    \"\"\"\n    Initialize the ChromaVectorStore.\n\n    Args:\n        connection (Chroma | None): A Chroma connection object. Defaults to None.\n        client (Optional[ClientAPI]): A Chroma client API instance. Defaults to None.\n        index_name (str): The name of the index or collection. Defaults to \"default\".\n        create_if_not_exist (bool): Whether to create the collection if it doesn't exist. Defaults to False.\n        dry_run_config (DryRunConfig | None): Configuration for dry run mode. Defaults to None.\n    \"\"\"\n    super().__init__(dry_run_config=dry_run_config)\n\n    self.client = client\n    if self.client is None:\n        connection = connection or Chroma()\n        self.client = connection.connect()\n    self.index_name = index_name\n    if create_if_not_exist:\n        collection_exists = self.client.get_collection(name=index_name)\n        if not collection_exists:\n            self._collection = self.client.create_collection(name=index_name)\n            self._track_collection(index_name)\n        else:\n            self._collection = self.client.get_collection(name=index_name)\n    else:\n        self._collection = self.client.get_collection(name=index_name)\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.count_documents","title":"<code>count_documents()</code>","text":"<p>Get the number of documents in the collection.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents in the collection.</p> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def count_documents(self) -&gt; int:\n    \"\"\"\n    Get the number of documents in the collection.\n\n    Returns:\n        int: The number of documents in the collection.\n    \"\"\"\n    return self._collection.count()\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.delete_collection","title":"<code>delete_collection(collection_name=None)</code>","text":"<p>Delete a Chroma collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str | None</code> <p>Name of the collection to delete.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def delete_collection(self, collection_name: str | None = None):\n    \"\"\"\n    Delete a Chroma collection.\n\n    Args:\n        collection_name (str | None): Name of the collection to delete.\n    \"\"\"\n    try:\n        collection_to_delete = collection_name or self.index_name\n        self.client.delete_collection(name=collection_to_delete)\n        logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n    except Exception as e:\n        logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.delete_documents","title":"<code>delete_documents(document_ids=None, delete_all=False)</code>","text":"<p>Delete documents from the vector store based on their IDs.</p> <p>Parameters:</p> Name Type Description Default <code>document_ids</code> <code>list[str]</code> <p>A list containing the IDs of documents to be deleted from the store.</p> <code>None</code> <code>delete_all</code> <code>bool</code> <p>A flag to delete all documents from the store. Defaults to False.</p> <code>False</code> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n    \"\"\"\n    Delete documents from the vector store based on their IDs.\n\n    Args:\n        document_ids (list[str]): A list containing the IDs of documents to be deleted from the store.\n        delete_all (bool): A flag to delete all documents from the store. Defaults to False.\n    \"\"\"\n\n    if delete_all and self._collection is not None:\n        self.client.delete_collection(name=self.index_name)\n        self._collection = self.client.get_or_create_collection(\n            name=self.index_name\n        )\n    else:\n        if not document_ids:\n            logger.warning(\n                \"No document IDs provided. No documents will be deleted.\"\n            )\n        else:\n            self._collection.delete(ids=document_ids)\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.delete_documents_by_filters","title":"<code>delete_documents_by_filters(filters=None)</code>","text":"<p>Delete documents from the vector store based on the provided filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any] | None</code> <p>The filters to apply to the document list. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def delete_documents_by_filters(self, filters: dict[str, Any] | None = None) -&gt; None:\n    \"\"\"\n    Delete documents from the vector store based on the provided filters.\n\n    Args:\n        filters (dict[str, Any] | None): The filters to apply to the document list. Defaults to\n            None.\n    \"\"\"\n    if filters is None:\n        raise ValueError(\"No filters provided. No documents will be deleted.\")\n    else:\n        ids, where, where_document = self._normalize_filters(filters)\n        self._collection.delete(ids=ids, where=where, where_document=where_document)\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.filter_documents","title":"<code>filter_documents(filters=None)</code>","text":"<p>Retrieve documents that match the provided filters.</p> <p>Filters can be defined in two formats: 1. Old format: Nested dictionaries with logical operators and comparison operators. 2. New format: Nested dictionaries of Comparison and Logic types.</p> <p>For the new format: Comparison dictionaries must contain the following keys: - 'field': The name of one of the metadata fields of a document (e.g., 'metadata.years'). - 'operator': One of '==', '!=', '&gt;', '&gt;=', '&lt;', '&lt;=', 'in', 'not in'. - 'value': A single value or (for 'in' and 'not in') a list of values.</p> <p>Logic dictionaries must contain the following keys: - 'operator': One of 'NOT', 'OR', 'AND'. - 'conditions': A list of Comparison or Logic dictionaries.</p> <p>Example of new format: {     \"operator\": \"AND\",     \"conditions\": [       {         \"field\": \"metadata.years\",         \"operator\": \"==\",         \"value\": \"2019\"       },       {         \"field\": \"metadata.companies\",         \"operator\": \"in\",         \"value\": [\"BMW\", \"Mercedes\"]       }     ] }</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>Dict[str, Any] | None</code> <p>The filters to apply to the document list.</p> <code>None</code> <code>filters</code> <code>dict[str, Any] | None</code> <p>The filters to apply to the document list. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: A list of Document instances that match the given filters.</p> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def filter_documents(self, filters: dict[str, Any] | None = None) -&gt; list[Document]:\n    \"\"\"\n    Retrieve documents that match the provided filters.\n\n    Filters can be defined in two formats:\n    1. Old format: Nested dictionaries with logical operators and comparison operators.\n    2. New format: Nested dictionaries of Comparison and Logic types.\n\n    For the new format:\n    Comparison dictionaries must contain the following keys:\n    - 'field': The name of one of the metadata fields of a document (e.g., 'metadata.years').\n    - 'operator': One of '==', '!=', '&gt;', '&gt;=', '&lt;', '&lt;=', 'in', 'not in'.\n    - 'value': A single value or (for 'in' and 'not in') a list of values.\n\n    Logic dictionaries must contain the following keys:\n    - 'operator': One of 'NOT', 'OR', 'AND'.\n    - 'conditions': A list of Comparison or Logic dictionaries.\n\n    Example of new format:\n    {\n        \"operator\": \"AND\",\n        \"conditions\": [\n          {\n            \"field\": \"metadata.years\",\n            \"operator\": \"==\",\n            \"value\": \"2019\"\n          },\n          {\n            \"field\": \"metadata.companies\",\n            \"operator\": \"in\",\n            \"value\": [\"BMW\", \"Mercedes\"]\n          }\n        ]\n    }\n\n    Args:\n        filters (Dict[str, Any] | None): The filters to apply to the document list.\n        filters (dict[str, Any] | None): The filters to apply to the document list. Defaults to\n            None.\n\n    Returns:\n        list[Document]: A list of Document instances that match the given filters.\n    \"\"\"\n    if filters:\n        ids, where, where_document = self._normalize_filters(filters)\n        kwargs: dict[str, Any] = {\"where\": where}\n\n        if ids:\n            kwargs[\"ids\"] = ids\n        if where_document:\n            kwargs[\"where_document\"] = where_document\n\n        result = self._collection.get(**kwargs)\n    else:\n        raise ValueError(\n            \"No filters provided. No documents will be retrieved with filters.\"\n        )\n\n    return self._get_result_to_documents(result)\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.list_documents","title":"<code>list_documents()</code>","text":"<p>List all documents in the collection.</p> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: A list of Document instances representing all documents in the collection.</p> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def list_documents(self) -&gt; list[Document]:\n    \"\"\"\n    List all documents in the collection.\n\n    Returns:\n        list[Document]: A list of Document instances representing all documents in the collection.\n    \"\"\"\n    result = self._collection.get()\n    return self._get_result_to_documents(result)\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.search_embeddings","title":"<code>search_embeddings(query_embeddings, top_k, filters=None)</code>","text":"<p>Perform vector search on the stored documents using query embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>query_embeddings</code> <code>list[list[float]]</code> <p>A list of embeddings to use as queries.</p> required <code>top_k</code> <code>int</code> <p>The maximum number of documents to retrieve.</p> required <code>filters</code> <code>dict[str, Any] | None</code> <p>A dictionary of filters to apply to the search. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[list[Document]]</code> <p>list[list[Document]]: A list of lists containing documents that match the given filters, for each query embedding provided.</p> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def search_embeddings(\n    self,\n    query_embeddings: list[list[float]],\n    top_k: int,\n    filters: dict[str, Any] | None = None,\n) -&gt; list[list[Document]]:\n    \"\"\"\n    Perform vector search on the stored documents using query embeddings.\n\n    Args:\n        query_embeddings (list[list[float]]): A list of embeddings to use as queries.\n        top_k (int): The maximum number of documents to retrieve.\n        filters (dict[str, Any] | None): A dictionary of filters to apply to the search.\n            Defaults to None.\n\n    Returns:\n        list[list[Document]]: A list of lists containing documents that match the given filters,\n            for each query embedding provided.\n    \"\"\"\n    if filters is None:\n        results = self._collection.query(\n            query_embeddings=query_embeddings,\n            n_results=top_k,\n            include=[\"embeddings\", \"documents\", \"metadatas\", \"distances\"],\n        )\n    else:\n        chroma_filters = self._normalize_filters(filters=filters)\n        results = self._collection.query(\n            query_embeddings=query_embeddings,\n            n_results=top_k,\n            where=chroma_filters[1],\n            where_document=chroma_filters[2],\n            include=[\"embeddings\", \"documents\", \"metadatas\", \"distances\"],\n        )\n\n    return self._query_result_to_documents(results)\n</code></pre>"},{"location":"dynamiq/storages/vector/chroma/chroma/#dynamiq.storages.vector.chroma.chroma.ChromaVectorStore.write_documents","title":"<code>write_documents(documents)</code>","text":"<p>Write (or overwrite) documents into the store.</p> <p>This method processes a list of documents and writes them into the vector store.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>A list of Document objects to be written into the document store.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If an item in the documents list is not an instance of the Document class.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents successfully written to the document store.</p> Source code in <code>dynamiq/storages/vector/chroma/chroma.py</code> <pre><code>def write_documents(self, documents: list[Document]) -&gt; int:\n    \"\"\"\n    Write (or overwrite) documents into the store.\n\n    This method processes a list of documents and writes them into the vector store.\n\n    Args:\n        documents (list[Document]): A list of Document objects to be written into the document\n            store.\n\n    Raises:\n        ValueError: If an item in the documents list is not an instance of the Document class.\n\n    Returns:\n        int: The number of documents successfully written to the document store.\n    \"\"\"\n    for doc in documents:\n        if not isinstance(doc, Document):\n            msg = (\n                \"param 'documents' must contain a list of objects of type Document\"\n            )\n            raise ValueError(msg)\n\n        data = {\"ids\": [doc.id], \"documents\": [doc.content]}\n\n        if doc.metadata:\n            data[\"metadatas\"] = [doc.metadata]\n\n        if doc.embedding:\n            data[\"embeddings\"] = [doc.embedding]\n\n        self._collection.add(**data)\n        self._track_documents([doc.id])\n\n    return len(documents)\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/","title":"Elasticsearch","text":""},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchSimilarityMetric","title":"<code>ElasticsearchSimilarityMetric</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Supported similarity metrics for Elasticsearch.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>class ElasticsearchSimilarityMetric(str, Enum):\n    \"\"\"Supported similarity metrics for Elasticsearch.\"\"\"\n\n    COSINE = \"cosine\"\n    DOT_PRODUCT = \"dot_product\"\n    L2 = \"l2_norm\"\n    MAX_INNER_PRODUCT = \"max_inner_product\"\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore","title":"<code>ElasticsearchVectorStore</code>","text":"<p>               Bases: <code>BaseVectorStore</code>, <code>DryRunMixin</code></p> <p>Vector store using Elasticsearch for dense vector search.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>class ElasticsearchVectorStore(BaseVectorStore, DryRunMixin):\n    \"\"\"Vector store using Elasticsearch for dense vector search.\"\"\"\n\n    def __init__(\n        self,\n        connection: Elasticsearch | None = None,\n        client: Optional[\"ElasticsearchClient\"] | None = None,\n        index_name: str = \"default\",\n        dimension: int = 1536,\n        similarity: ElasticsearchSimilarityMetric = ElasticsearchSimilarityMetric.COSINE,\n        create_if_not_exist: bool = False,\n        content_key: str = \"content\",\n        embedding_key: str = \"embedding\",\n        batch_size: int = 100,\n        index_settings: dict | None = None,\n        mapping_settings: dict | None = None,\n        dry_run_config: DryRunConfig | None = None,\n    ):\n        \"\"\"\n        Initialize ElasticsearchVectorStore.\n\n        Args:\n            connection (Optional[Elasticsearch]): Elasticsearch connection. Defaults to None.\n            client (Optional[ElasticsearchClient]): Elasticsearch client. Defaults to None.\n            index_name (str): Name of the index. Defaults to \"default\".\n            dimension (int): Dimension of vectors. Defaults to 1536.\n            similarity (ElasticsearchSimilarityMetric): Similarity metric.\n                        Defaults to ElasticsearchSimilarityMetric.COSINE.\n            create_if_not_exist (bool): Whether to create the index if it does not exist. Defaults to False.\n            content_key (str): Key for content field. Defaults to \"content\".\n            embedding_key (str): Key for embedding field. Defaults to \"embedding\".\n            batch_size (int): Batch size for write operations. Defaults to 100.\n            index_settings (Optional[dict]): Custom index settings. Defaults to None.\n            mapping_settings (Optional[dict]): Custom mapping settings. Defaults to None.\n            dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n        \"\"\"\n        super().__init__(dry_run_config=dry_run_config)\n\n        if client is None:\n            if connection is None:\n                connection = Elasticsearch()\n            self.client = connection.connect()\n        else:\n            self.client = client\n\n        self.index_name = index_name\n        self.dimension = dimension\n        self.similarity = similarity\n        self.content_key = content_key\n        self.embedding_key = embedding_key\n        self.batch_size = batch_size\n        self.index_settings = index_settings or {}\n        self.mapping_settings = mapping_settings or {}\n\n        if not self.client.indices.exists(index=self.index_name):\n            if create_if_not_exist:\n                logger.info(f\"Index {self.index_name} does not exist. Creating a new index.\")\n                self._create_index_if_not_exists()\n                self._track_collection(self.index_name)\n            else:\n                raise ValueError(\n                    f\"Index {self.index_name} does not exist. Set 'create_if_not_exist' to True to create it.\"\n                )\n        else:\n            logger.info(f\"Collection {self.index_name} already exists. Skipping creation.\")\n\n        logger.debug(f\"ElasticsearchVectorStore initialized with index: {self.index_name}\")\n\n    def _create_index_if_not_exists(self) -&gt; None:\n        \"\"\"Create the index if it doesn't exist.\"\"\"\n        # Base mapping\n        mapping = {\n            \"mappings\": {\n                \"properties\": {\n                    self.content_key: {\"type\": \"text\"},\n                    \"metadata\": {\"type\": \"object\"},\n                    self.embedding_key: {\n                        \"type\": \"dense_vector\",\n                        \"dims\": self.dimension,\n                        \"index\": True,\n                        \"similarity\": self.similarity,\n                    },\n                }\n            }\n        }\n\n        # Add custom mapping settings if provided\n        if self.mapping_settings:\n            mapping[\"mappings\"].update(self.mapping_settings)\n\n        # Add index settings if provided\n        if self.index_settings:\n            mapping[\"settings\"] = self.index_settings\n\n        self.client.indices.create(index=self.index_name, body=mapping)\n\n    def delete_collection(self, collection_name: str | None = None) -&gt; None:\n        \"\"\"\n        Delete the collection in the database.\n\n        Args:\n            collection_name (str | None): Name of the collection to delete.\n        \"\"\"\n        try:\n            collection_to_delete = collection_name or self.index_name\n            self.client.indices.delete(index=collection_to_delete)\n            logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n        except Exception as e:\n            logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n            raise\n\n    def _handle_duplicate_documents(\n        self, documents: list[Document], policy: DuplicatePolicy = DuplicatePolicy.FAIL\n    ) -&gt; list[Document]:\n        \"\"\"\n        Handle duplicate documents based on policy.\n\n        Args:\n            documents (list[Document]): List of documents to check for duplicates.\n            policy (DuplicatePolicy): Policy for handling duplicates. Defaults to DuplicatePolicy.FAIL.\n\n        Returns:\n            list[Document]: List of documents after applying the specified policy.\n\n        Raises:\n            VectorStoreException: If duplicates are found and the policy is set to FAIL.\n        \"\"\"\n        if policy == DuplicatePolicy.OVERWRITE:\n            return documents\n\n        # Get unique documents\n        unique_docs = {}\n        for doc in documents:\n            if doc.id in unique_docs:\n                logger.warning(f\"Duplicate document ID found: {doc.id}\")\n            unique_docs[doc.id] = doc\n\n        if policy in {DuplicatePolicy.SKIP, DuplicatePolicy.FAIL}:\n            # Check which documents already exist\n            existing_ids = set()\n            for doc_id in unique_docs.keys():\n                try:\n                    self.retrieve_document_by_file_id(file_id=doc_id)\n                    existing_ids.add(doc_id)\n                except NotFoundError:\n                    pass\n\n            if policy == DuplicatePolicy.FAIL and existing_ids:\n                raise VectorStoreException(f\"Documents with IDs {existing_ids} already exist\")\n\n            # Remove existing documents\n            return [doc for doc in documents if doc.id not in existing_ids]\n\n        return list(unique_docs.values())\n\n    def write_documents(\n        self,\n        documents: list[Document],\n        policy: DuplicatePolicy = DuplicatePolicy.FAIL,\n        batch_size: int | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; int:\n        \"\"\"\n        Write documents to Elasticsearch.\n\n        Args:\n            documents (list[Document]): List of documents to write.\n            policy (DuplicatePolicy): Policy for handling duplicate documents. Defaults to DuplicatePolicy.FAIL.\n            batch_size (Optional[int]): Size of batches for bulk operations. Defaults to None.\n            content_key (Optional[str]): The field used to store content in the storage. Defaults to None.\n            embedding_key (Optional[str]): The field used to store embeddings in the storage. Defaults to None.\n\n        Returns:\n            int: Number of documents successfully written.\n\n        Raises:\n            ValueError: If the provided documents are invalid.\n            VectorStoreException: If duplicates are found when using the FAIL policy.\n        \"\"\"\n        if not documents:\n            return 0\n\n        if not isinstance(documents[0], Document):\n            raise ValueError(\"Documents must be of type Document\")\n\n        # Handle duplicates\n        documents = self._handle_duplicate_documents(documents, policy)\n        if not documents:\n            return 0\n\n        # Process in batches\n        batch_size = batch_size or self.batch_size\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n        total_written = 0\n\n        for i in range(0, len(documents), batch_size):\n            batch = documents[i : i + batch_size]\n            operations = []\n            for doc in batch:\n                operations.extend(\n                    [\n                        {\"index\": {\"_index\": self.index_name, \"_id\": doc.id}},\n                        {\n                            content_key: doc.content,\n                            \"metadata\": doc.metadata,\n                            embedding_key: doc.embedding,\n                        },\n                    ]\n                )\n                self._track_documents([doc.id for doc in batch])\n\n            if operations:\n                result = self.client.bulk(operations=operations, refresh=True)\n                total_written += sum(\n                    item.get(\"index\", {}).get(\"_shards\", {}).get(\"successful\", 0)\n                    for item in result.raw.get(\"items\", [])\n                )\n\n        return total_written\n\n    def _scale_score(self, score: float, similarity: ElasticsearchSimilarityMetric) -&gt; float:\n        \"\"\"\n        Scale the score based on the similarity metric.\n\n        Args:\n            score (float): Raw score from Elasticsearch.\n            similarity (ElasticsearchSimilarityMetric): Similarity metric used.\n\n        Returns:\n            float: Scaled score between 0 and 1, depending on the similarity metric used.\n        \"\"\"\n        if similarity == ElasticsearchSimilarityMetric.COSINE:\n            # Elasticsearch cosine scores are between -1 and 1\n            return (score + 1) / 2\n        elif similarity == ElasticsearchSimilarityMetric.DOT_PRODUCT:\n            # Normalize dot product using sigmoid\n            return float(1 / (1 + np.exp(-score / 100)))\n        else:  # L2\n            # L2 distance is inverse - smaller is better\n            # Convert to similarity score\n            return 1 / (1 + score)\n\n    def _embedding_retrieval(\n        self,\n        query_embedding: list[float],\n        top_k: int = 10,\n        num_candidates: int = 500,\n        exclude_document_embeddings: bool = True,\n        filters: dict[str, Any] | None = None,\n        scale_scores: bool = False,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Retrieve documents by vector similarity.\n\n        Args:\n            query_embedding (List[float]): Query vector.\n            top_k (int): Number of results. Defaults to 10.\n            num_candidates (int): Number of candidates to consider in the retriever. Defaults to 500.\n            exclude_document_embeddings (bool): Exclude embeddings in response. Defaults to True.\n            filters (dict[str, Any] | None): Metadata filters. Defaults to None.\n            scale_scores (bool): Whether to scale scores to 0-1 range. Defaults to False.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store embeddings in the storage.\n\n        Returns:\n            List[Document]: Retrieved documents.\n\n        Raises:\n            ValueError: If query_embedding is invalid.\n        \"\"\"\n        if not query_embedding:\n            raise ValueError(\"query_embedding must not be empty\")\n\n        embedding_key = embedding_key or self.embedding_key\n        # Build the query\n        query = {\n            \"knn\": {\n                \"field\": embedding_key,\n                \"query_vector\": query_embedding,\n                \"k\": top_k,\n                \"num_candidates\": num_candidates,\n            }\n        }\n\n        if filters:\n            # Normalise filters to Elasticsearch format\n            filters = _normalize_filters(filters)\n            query[\"knn\"][\"filter\"] = {\"bool\": filters}\n\n        # Execute search\n        response = self.client.search(\n            index=self.index_name,\n            query=query,\n            size=top_k,\n            _source_excludes=([embedding_key] if exclude_document_embeddings else None),\n        )\n        content_key = content_key or self.content_key\n\n        # Convert results to Documents with optional score scaling\n        documents = []\n        for hit in response[\"hits\"][\"hits\"]:\n            score = hit[\"_score\"]\n            if scale_scores:\n                score = self._scale_score(score, self.similarity)\n\n            if content_key not in hit[\"_source\"]:\n                continue\n\n            doc = Document(\n                id=hit[\"_id\"],\n                content=hit[\"_source\"][content_key],\n                metadata=hit[\"_source\"][\"metadata\"],\n                score=score,\n            )\n            if not exclude_document_embeddings:\n                doc.embedding = hit[\"_source\"][embedding_key]\n            documents.append(doc)\n\n        return documents\n\n    def retrieve_document_by_file_id(\n        self,\n        file_id: str,\n        include_embeddings: bool = False,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ):\n        embedding_key = embedding_key or self.embedding_key\n        content_key = content_key or self.content_key\n\n        response = self.client.get(\n            index=self.index_name,\n            id=file_id,\n            _source_excludes=([embedding_key] if not include_embeddings else None),\n        )\n\n        # Convert result to Document\n        doc = Document(\n            id=response[\"_id\"],\n            content=response[\"_source\"][content_key],\n            metadata=response[\"_source\"][\"metadata\"],\n        )\n        if include_embeddings:\n            doc.embedding = response[\"_source\"][embedding_key]\n\n        return doc\n\n    def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n        \"\"\"\n        Delete documents from the store.\n\n        Args:\n            document_ids (Optional[List[str]]): IDs to delete. Defaults to None.\n            delete_all (bool): Delete all documents. Defaults to False.\n        \"\"\"\n        if delete_all:\n            self.client.delete_by_query(index=self.index_name, query={\"match_all\": {}}, refresh=True)\n        elif document_ids:\n            operations = []\n            for doc_id in document_ids:\n                operations.append({\"delete\": {\"_index\": self.index_name, \"_id\": doc_id}})\n            if operations:\n                self.client.bulk(operations=operations, refresh=True)\n        else:\n            logger.warning(\"No document IDs provided. No documents will be deleted.\")\n\n    def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n        \"\"\"Delete documents matching filters.\n\n        Args:\n            filters (dict[str, Any]): Metadata filters.\n        \"\"\"\n        if not filters:\n            logger.warning(\"No filters provided. No documents will be deleted.\")\n            return\n\n        filters = _normalize_filters(filters)\n        bool_query = {\"bool\": filters}\n\n        self.client.delete_by_query(index=self.index_name, query=bool_query, refresh=True)\n\n    def list_documents(\n        self,\n        top_k: int | None = 100,\n        include_embeddings: bool = False,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n        scale_scores: bool = False,\n    ) -&gt; list[Document]:\n        \"\"\"\n        List documents in the Pinecone vector store.\n\n        Args:\n            top_k (Optional[int]): Maximal number of documents to retrieve. Defaults to 100.\n            include_embeddings (bool): Whether to include embeddings in the results. Defaults to False.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store embeddings in the storage.\n            scale_scores (bool): Whether to scale scores to 0-1 range. Defaults to False.\n\n        Returns:\n            list[Document]: List of Document objects retrieved.\n        \"\"\"\n        embedding_key = embedding_key or self.embedding_key\n        content_key = content_key or self.content_key\n\n        response = self.client.search(\n            index=self.index_name,\n            query={\"match_all\": {}},\n            size=top_k,\n            _source_excludes=([embedding_key] if not include_embeddings else None),\n        )\n\n        # Convert results to Documents with optional score scaling\n        all_documents = []\n        for hit in response[\"hits\"][\"hits\"]:\n            score = hit[\"_score\"]\n            if scale_scores:\n                score = self._scale_score(score, self.similarity)\n\n            if content_key not in hit[\"_source\"]:\n                continue\n\n            doc = Document(\n                id=hit[\"_id\"],\n                content=hit[\"_source\"][content_key],\n                metadata=hit[\"_source\"][\"metadata\"],\n                score=score,\n            )\n            if include_embeddings:\n                doc.embedding = hit[\"_source\"][embedding_key]\n            all_documents.append(doc)\n\n        return all_documents\n\n    def count_documents(self) -&gt; int:\n        \"\"\"\n        Count the number of documents in the store.\n\n        Returns:\n            int: The number of documents in the store.\n        \"\"\"\n        response = self.client.count(\n            index=self.index_name,\n            query={\"match_all\": {}},\n        )\n        return response.get(\"count\", 0)\n\n    def get_field_statistics(self, field: str) -&gt; dict[str, Any]:\n        \"\"\"\n        Get statistics for a numeric field.\n\n        Args:\n            field (str): Full field name (must be numeric)\n\n        Returns:\n            Dictionary with min, max, avg, sum\n        \"\"\"\n        response = self.client.search(\n            index=self.index_name,\n            body={\"size\": 0, \"aggs\": {\"stats\": {\"stats\": {\"field\": field}}}},\n        )\n        return response[\"aggregations\"][\"stats\"]\n\n    def update_document_by_file_id(\n        self,\n        file_id: str,\n        content: str | None = None,\n        metadata: dict[str, Any] | None = None,\n        embedding: list[float] | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; None:\n        \"\"\"Update an existing document.\n\n        Args:\n            file_id (str): Document ID\n            content (Optional[str]): Update content\n            metadata (Optional[dict[str, Any]]): Update field metadata or add new fields\n            embedding (Optional[list[float]]): New embedding vector\n            content_key (Optional[str]): Key for content field.\n            embedding_key (Optional[str]): The field used to store embeddings in the storage.\n        \"\"\"\n        update_fields = {}\n        if content is not None:\n            update_fields[content_key or self.content_key] = content\n        if metadata is not None:\n            update_fields[\"metadata\"] = metadata\n        if embedding is not None:\n            update_fields[embedding_key or self.embedding_key] = embedding\n\n        if update_fields:\n            self.client.update(index=self.index_name, id=file_id, body={\"doc\": update_fields}, refresh=True)\n\n    def update_documents_batch(\n        self,\n        documents: list[Document],\n        batch_size: int | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; int:\n        \"\"\"\n        Update multiple documents in batches.\n\n        Args:\n            documents (list[Document]): List of documents to update.\n            batch_size (Optional[int]): Size of batches for bulk operations.\n            content_key (Optional[str]): Key for content field.\n            embedding_key (Optional[str]): The field used to store embeddings in the storage.\n\n        Returns:\n            int: Number of documents successfully updated.\n\n        \"\"\"\n        batch_size = batch_size or self.batch_size\n        total_updated = 0\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n\n        def generate_actions(docs, content_key, embedding_key):\n            for i, doc in enumerate(docs):\n                docs[i] = {\n                    \"_op_type\": \"update\",\n                    \"_index\": \"documents\",\n                    \"_id\": doc.id,\n                    \"doc\": {\n                        content_key: doc.content,\n                        \"metadata\": doc.metadata,\n                        embedding_key: doc.embedding,\n                    },\n                }\n            return docs\n\n        for i in range(0, len(documents), batch_size):\n            sub_set_docs = documents[i : i + batch_size]\n            batch = generate_actions(sub_set_docs, content_key, embedding_key)\n            success, failed = bulk(self.client, batch, refresh=True, raise_on_error=True)\n            total_updated += success\n        return total_updated\n\n    def create_alias(\n        self,\n        alias_name: str,\n        index_names: list[str] | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Create an alias for one or more indices.\n\n        Args:\n            alias_name (str): Name of the alias.\n            index_names (Optional[list[str]]): List of indices to include in the alias. Defaults to None.\n        \"\"\"\n        index_names = index_names or [self.index_name]\n        actions = []\n        for index in index_names:\n            actions.append({\"add\": {\"index\": index, \"alias\": alias_name}})\n        self.client.indices.update_aliases({\"actions\": actions})\n\n    def close(self) -&gt; None:\n        \"\"\"Close the client connection.\"\"\"\n        if hasattr(self, \"client\"):\n            self.client.close()\n\n    def __del__(self):\n        \"\"\"Cleanup on deletion.\"\"\"\n        self.close()\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.__del__","title":"<code>__del__()</code>","text":"<p>Cleanup on deletion.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def __del__(self):\n    \"\"\"Cleanup on deletion.\"\"\"\n    self.close()\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.__init__","title":"<code>__init__(connection=None, client=None, index_name='default', dimension=1536, similarity=ElasticsearchSimilarityMetric.COSINE, create_if_not_exist=False, content_key='content', embedding_key='embedding', batch_size=100, index_settings=None, mapping_settings=None, dry_run_config=None)</code>","text":"<p>Initialize ElasticsearchVectorStore.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[Elasticsearch]</code> <p>Elasticsearch connection. Defaults to None.</p> <code>None</code> <code>client</code> <code>Optional[Elasticsearch]</code> <p>Elasticsearch client. Defaults to None.</p> <code>None</code> <code>index_name</code> <code>str</code> <p>Name of the index. Defaults to \"default\".</p> <code>'default'</code> <code>dimension</code> <code>int</code> <p>Dimension of vectors. Defaults to 1536.</p> <code>1536</code> <code>similarity</code> <code>ElasticsearchSimilarityMetric</code> <p>Similarity metric.         Defaults to ElasticsearchSimilarityMetric.COSINE.</p> <code>COSINE</code> <code>create_if_not_exist</code> <code>bool</code> <p>Whether to create the index if it does not exist. Defaults to False.</p> <code>False</code> <code>content_key</code> <code>str</code> <p>Key for content field. Defaults to \"content\".</p> <code>'content'</code> <code>embedding_key</code> <code>str</code> <p>Key for embedding field. Defaults to \"embedding\".</p> <code>'embedding'</code> <code>batch_size</code> <code>int</code> <p>Batch size for write operations. Defaults to 100.</p> <code>100</code> <code>index_settings</code> <code>Optional[dict]</code> <p>Custom index settings. Defaults to None.</p> <code>None</code> <code>mapping_settings</code> <code>Optional[dict]</code> <p>Custom mapping settings. Defaults to None.</p> <code>None</code> <code>dry_run_config</code> <code>Optional[DryRunConfig]</code> <p>Configuration for dry run mode. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def __init__(\n    self,\n    connection: Elasticsearch | None = None,\n    client: Optional[\"ElasticsearchClient\"] | None = None,\n    index_name: str = \"default\",\n    dimension: int = 1536,\n    similarity: ElasticsearchSimilarityMetric = ElasticsearchSimilarityMetric.COSINE,\n    create_if_not_exist: bool = False,\n    content_key: str = \"content\",\n    embedding_key: str = \"embedding\",\n    batch_size: int = 100,\n    index_settings: dict | None = None,\n    mapping_settings: dict | None = None,\n    dry_run_config: DryRunConfig | None = None,\n):\n    \"\"\"\n    Initialize ElasticsearchVectorStore.\n\n    Args:\n        connection (Optional[Elasticsearch]): Elasticsearch connection. Defaults to None.\n        client (Optional[ElasticsearchClient]): Elasticsearch client. Defaults to None.\n        index_name (str): Name of the index. Defaults to \"default\".\n        dimension (int): Dimension of vectors. Defaults to 1536.\n        similarity (ElasticsearchSimilarityMetric): Similarity metric.\n                    Defaults to ElasticsearchSimilarityMetric.COSINE.\n        create_if_not_exist (bool): Whether to create the index if it does not exist. Defaults to False.\n        content_key (str): Key for content field. Defaults to \"content\".\n        embedding_key (str): Key for embedding field. Defaults to \"embedding\".\n        batch_size (int): Batch size for write operations. Defaults to 100.\n        index_settings (Optional[dict]): Custom index settings. Defaults to None.\n        mapping_settings (Optional[dict]): Custom mapping settings. Defaults to None.\n        dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n    \"\"\"\n    super().__init__(dry_run_config=dry_run_config)\n\n    if client is None:\n        if connection is None:\n            connection = Elasticsearch()\n        self.client = connection.connect()\n    else:\n        self.client = client\n\n    self.index_name = index_name\n    self.dimension = dimension\n    self.similarity = similarity\n    self.content_key = content_key\n    self.embedding_key = embedding_key\n    self.batch_size = batch_size\n    self.index_settings = index_settings or {}\n    self.mapping_settings = mapping_settings or {}\n\n    if not self.client.indices.exists(index=self.index_name):\n        if create_if_not_exist:\n            logger.info(f\"Index {self.index_name} does not exist. Creating a new index.\")\n            self._create_index_if_not_exists()\n            self._track_collection(self.index_name)\n        else:\n            raise ValueError(\n                f\"Index {self.index_name} does not exist. Set 'create_if_not_exist' to True to create it.\"\n            )\n    else:\n        logger.info(f\"Collection {self.index_name} already exists. Skipping creation.\")\n\n    logger.debug(f\"ElasticsearchVectorStore initialized with index: {self.index_name}\")\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.close","title":"<code>close()</code>","text":"<p>Close the client connection.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the client connection.\"\"\"\n    if hasattr(self, \"client\"):\n        self.client.close()\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.count_documents","title":"<code>count_documents()</code>","text":"<p>Count the number of documents in the store.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents in the store.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def count_documents(self) -&gt; int:\n    \"\"\"\n    Count the number of documents in the store.\n\n    Returns:\n        int: The number of documents in the store.\n    \"\"\"\n    response = self.client.count(\n        index=self.index_name,\n        query={\"match_all\": {}},\n    )\n    return response.get(\"count\", 0)\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.create_alias","title":"<code>create_alias(alias_name, index_names=None)</code>","text":"<p>Create an alias for one or more indices.</p> <p>Parameters:</p> Name Type Description Default <code>alias_name</code> <code>str</code> <p>Name of the alias.</p> required <code>index_names</code> <code>Optional[list[str]]</code> <p>List of indices to include in the alias. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def create_alias(\n    self,\n    alias_name: str,\n    index_names: list[str] | None = None,\n) -&gt; None:\n    \"\"\"\n    Create an alias for one or more indices.\n\n    Args:\n        alias_name (str): Name of the alias.\n        index_names (Optional[list[str]]): List of indices to include in the alias. Defaults to None.\n    \"\"\"\n    index_names = index_names or [self.index_name]\n    actions = []\n    for index in index_names:\n        actions.append({\"add\": {\"index\": index, \"alias\": alias_name}})\n    self.client.indices.update_aliases({\"actions\": actions})\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.delete_collection","title":"<code>delete_collection(collection_name=None)</code>","text":"<p>Delete the collection in the database.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str | None</code> <p>Name of the collection to delete.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def delete_collection(self, collection_name: str | None = None) -&gt; None:\n    \"\"\"\n    Delete the collection in the database.\n\n    Args:\n        collection_name (str | None): Name of the collection to delete.\n    \"\"\"\n    try:\n        collection_to_delete = collection_name or self.index_name\n        self.client.indices.delete(index=collection_to_delete)\n        logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n    except Exception as e:\n        logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.delete_documents","title":"<code>delete_documents(document_ids=None, delete_all=False)</code>","text":"<p>Delete documents from the store.</p> <p>Parameters:</p> Name Type Description Default <code>document_ids</code> <code>Optional[List[str]]</code> <p>IDs to delete. Defaults to None.</p> <code>None</code> <code>delete_all</code> <code>bool</code> <p>Delete all documents. Defaults to False.</p> <code>False</code> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n    \"\"\"\n    Delete documents from the store.\n\n    Args:\n        document_ids (Optional[List[str]]): IDs to delete. Defaults to None.\n        delete_all (bool): Delete all documents. Defaults to False.\n    \"\"\"\n    if delete_all:\n        self.client.delete_by_query(index=self.index_name, query={\"match_all\": {}}, refresh=True)\n    elif document_ids:\n        operations = []\n        for doc_id in document_ids:\n            operations.append({\"delete\": {\"_index\": self.index_name, \"_id\": doc_id}})\n        if operations:\n            self.client.bulk(operations=operations, refresh=True)\n    else:\n        logger.warning(\"No document IDs provided. No documents will be deleted.\")\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.delete_documents_by_filters","title":"<code>delete_documents_by_filters(filters)</code>","text":"<p>Delete documents matching filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any]</code> <p>Metadata filters.</p> required Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n    \"\"\"Delete documents matching filters.\n\n    Args:\n        filters (dict[str, Any]): Metadata filters.\n    \"\"\"\n    if not filters:\n        logger.warning(\"No filters provided. No documents will be deleted.\")\n        return\n\n    filters = _normalize_filters(filters)\n    bool_query = {\"bool\": filters}\n\n    self.client.delete_by_query(index=self.index_name, query=bool_query, refresh=True)\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.get_field_statistics","title":"<code>get_field_statistics(field)</code>","text":"<p>Get statistics for a numeric field.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>Full field name (must be numeric)</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with min, max, avg, sum</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def get_field_statistics(self, field: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get statistics for a numeric field.\n\n    Args:\n        field (str): Full field name (must be numeric)\n\n    Returns:\n        Dictionary with min, max, avg, sum\n    \"\"\"\n    response = self.client.search(\n        index=self.index_name,\n        body={\"size\": 0, \"aggs\": {\"stats\": {\"stats\": {\"field\": field}}}},\n    )\n    return response[\"aggregations\"][\"stats\"]\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.list_documents","title":"<code>list_documents(top_k=100, include_embeddings=False, content_key=None, embedding_key=None, scale_scores=False)</code>","text":"<p>List documents in the Pinecone vector store.</p> <p>Parameters:</p> Name Type Description Default <code>top_k</code> <code>Optional[int]</code> <p>Maximal number of documents to retrieve. Defaults to 100.</p> <code>100</code> <code>include_embeddings</code> <code>bool</code> <p>Whether to include embeddings in the results. Defaults to False.</p> <code>False</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store embeddings in the storage.</p> <code>None</code> <code>scale_scores</code> <code>bool</code> <p>Whether to scale scores to 0-1 range. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: List of Document objects retrieved.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def list_documents(\n    self,\n    top_k: int | None = 100,\n    include_embeddings: bool = False,\n    content_key: str | None = None,\n    embedding_key: str | None = None,\n    scale_scores: bool = False,\n) -&gt; list[Document]:\n    \"\"\"\n    List documents in the Pinecone vector store.\n\n    Args:\n        top_k (Optional[int]): Maximal number of documents to retrieve. Defaults to 100.\n        include_embeddings (bool): Whether to include embeddings in the results. Defaults to False.\n        content_key (Optional[str]): The field used to store content in the storage.\n        embedding_key (Optional[str]): The field used to store embeddings in the storage.\n        scale_scores (bool): Whether to scale scores to 0-1 range. Defaults to False.\n\n    Returns:\n        list[Document]: List of Document objects retrieved.\n    \"\"\"\n    embedding_key = embedding_key or self.embedding_key\n    content_key = content_key or self.content_key\n\n    response = self.client.search(\n        index=self.index_name,\n        query={\"match_all\": {}},\n        size=top_k,\n        _source_excludes=([embedding_key] if not include_embeddings else None),\n    )\n\n    # Convert results to Documents with optional score scaling\n    all_documents = []\n    for hit in response[\"hits\"][\"hits\"]:\n        score = hit[\"_score\"]\n        if scale_scores:\n            score = self._scale_score(score, self.similarity)\n\n        if content_key not in hit[\"_source\"]:\n            continue\n\n        doc = Document(\n            id=hit[\"_id\"],\n            content=hit[\"_source\"][content_key],\n            metadata=hit[\"_source\"][\"metadata\"],\n            score=score,\n        )\n        if include_embeddings:\n            doc.embedding = hit[\"_source\"][embedding_key]\n        all_documents.append(doc)\n\n    return all_documents\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.update_document_by_file_id","title":"<code>update_document_by_file_id(file_id, content=None, metadata=None, embedding=None, content_key=None, embedding_key=None)</code>","text":"<p>Update an existing document.</p> <p>Parameters:</p> Name Type Description Default <code>file_id</code> <code>str</code> <p>Document ID</p> required <code>content</code> <code>Optional[str]</code> <p>Update content</p> <code>None</code> <code>metadata</code> <code>Optional[dict[str, Any]]</code> <p>Update field metadata or add new fields</p> <code>None</code> <code>embedding</code> <code>Optional[list[float]]</code> <p>New embedding vector</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>Key for content field.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store embeddings in the storage.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def update_document_by_file_id(\n    self,\n    file_id: str,\n    content: str | None = None,\n    metadata: dict[str, Any] | None = None,\n    embedding: list[float] | None = None,\n    content_key: str | None = None,\n    embedding_key: str | None = None,\n) -&gt; None:\n    \"\"\"Update an existing document.\n\n    Args:\n        file_id (str): Document ID\n        content (Optional[str]): Update content\n        metadata (Optional[dict[str, Any]]): Update field metadata or add new fields\n        embedding (Optional[list[float]]): New embedding vector\n        content_key (Optional[str]): Key for content field.\n        embedding_key (Optional[str]): The field used to store embeddings in the storage.\n    \"\"\"\n    update_fields = {}\n    if content is not None:\n        update_fields[content_key or self.content_key] = content\n    if metadata is not None:\n        update_fields[\"metadata\"] = metadata\n    if embedding is not None:\n        update_fields[embedding_key or self.embedding_key] = embedding\n\n    if update_fields:\n        self.client.update(index=self.index_name, id=file_id, body={\"doc\": update_fields}, refresh=True)\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.update_documents_batch","title":"<code>update_documents_batch(documents, batch_size=None, content_key=None, embedding_key=None)</code>","text":"<p>Update multiple documents in batches.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>List of documents to update.</p> required <code>batch_size</code> <code>Optional[int]</code> <p>Size of batches for bulk operations.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>Key for content field.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store embeddings in the storage.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of documents successfully updated.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def update_documents_batch(\n    self,\n    documents: list[Document],\n    batch_size: int | None = None,\n    content_key: str | None = None,\n    embedding_key: str | None = None,\n) -&gt; int:\n    \"\"\"\n    Update multiple documents in batches.\n\n    Args:\n        documents (list[Document]): List of documents to update.\n        batch_size (Optional[int]): Size of batches for bulk operations.\n        content_key (Optional[str]): Key for content field.\n        embedding_key (Optional[str]): The field used to store embeddings in the storage.\n\n    Returns:\n        int: Number of documents successfully updated.\n\n    \"\"\"\n    batch_size = batch_size or self.batch_size\n    total_updated = 0\n    content_key = content_key or self.content_key\n    embedding_key = embedding_key or self.embedding_key\n\n    def generate_actions(docs, content_key, embedding_key):\n        for i, doc in enumerate(docs):\n            docs[i] = {\n                \"_op_type\": \"update\",\n                \"_index\": \"documents\",\n                \"_id\": doc.id,\n                \"doc\": {\n                    content_key: doc.content,\n                    \"metadata\": doc.metadata,\n                    embedding_key: doc.embedding,\n                },\n            }\n        return docs\n\n    for i in range(0, len(documents), batch_size):\n        sub_set_docs = documents[i : i + batch_size]\n        batch = generate_actions(sub_set_docs, content_key, embedding_key)\n        success, failed = bulk(self.client, batch, refresh=True, raise_on_error=True)\n        total_updated += success\n    return total_updated\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStore.write_documents","title":"<code>write_documents(documents, policy=DuplicatePolicy.FAIL, batch_size=None, content_key=None, embedding_key=None)</code>","text":"<p>Write documents to Elasticsearch.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>List of documents to write.</p> required <code>policy</code> <code>DuplicatePolicy</code> <p>Policy for handling duplicate documents. Defaults to DuplicatePolicy.FAIL.</p> <code>FAIL</code> <code>batch_size</code> <code>Optional[int]</code> <p>Size of batches for bulk operations. Defaults to None.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage. Defaults to None.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store embeddings in the storage. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of documents successfully written.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided documents are invalid.</p> <code>VectorStoreException</code> <p>If duplicates are found when using the FAIL policy.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>def write_documents(\n    self,\n    documents: list[Document],\n    policy: DuplicatePolicy = DuplicatePolicy.FAIL,\n    batch_size: int | None = None,\n    content_key: str | None = None,\n    embedding_key: str | None = None,\n) -&gt; int:\n    \"\"\"\n    Write documents to Elasticsearch.\n\n    Args:\n        documents (list[Document]): List of documents to write.\n        policy (DuplicatePolicy): Policy for handling duplicate documents. Defaults to DuplicatePolicy.FAIL.\n        batch_size (Optional[int]): Size of batches for bulk operations. Defaults to None.\n        content_key (Optional[str]): The field used to store content in the storage. Defaults to None.\n        embedding_key (Optional[str]): The field used to store embeddings in the storage. Defaults to None.\n\n    Returns:\n        int: Number of documents successfully written.\n\n    Raises:\n        ValueError: If the provided documents are invalid.\n        VectorStoreException: If duplicates are found when using the FAIL policy.\n    \"\"\"\n    if not documents:\n        return 0\n\n    if not isinstance(documents[0], Document):\n        raise ValueError(\"Documents must be of type Document\")\n\n    # Handle duplicates\n    documents = self._handle_duplicate_documents(documents, policy)\n    if not documents:\n        return 0\n\n    # Process in batches\n    batch_size = batch_size or self.batch_size\n    content_key = content_key or self.content_key\n    embedding_key = embedding_key or self.embedding_key\n    total_written = 0\n\n    for i in range(0, len(documents), batch_size):\n        batch = documents[i : i + batch_size]\n        operations = []\n        for doc in batch:\n            operations.extend(\n                [\n                    {\"index\": {\"_index\": self.index_name, \"_id\": doc.id}},\n                    {\n                        content_key: doc.content,\n                        \"metadata\": doc.metadata,\n                        embedding_key: doc.embedding,\n                    },\n                ]\n            )\n            self._track_documents([doc.id for doc in batch])\n\n        if operations:\n            result = self.client.bulk(operations=operations, refresh=True)\n            total_written += sum(\n                item.get(\"index\", {}).get(\"_shards\", {}).get(\"successful\", 0)\n                for item in result.raw.get(\"items\", [])\n            )\n\n    return total_written\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStoreParams","title":"<code>ElasticsearchVectorStoreParams</code>","text":"<p>               Bases: <code>BaseVectorStoreParams</code></p> <p>Parameters for Elasticsearch vector store.</p> <p>Attributes:</p> Name Type Description <code>index_name</code> <code>str</code> <p>Name of the index. Defaults to \"default\".</p> <code>content_key</code> <code>str</code> <p>Key for content field. Defaults to \"content\".</p> <code>dimension</code> <code>int</code> <p>Dimension of the vectors. Defaults to 1536.</p> <code>similarity</code> <code>str</code> <p>Similarity metric to use. Defaults to \"cosine\".</p> <code>embedding_key</code> <code>str</code> <p>Key for embedding field. Defaults to \"embedding\".</p> <code>batch_size</code> <code>int</code> <p>Batch size for writing operations. Defaults to 100.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>class ElasticsearchVectorStoreParams(BaseVectorStoreParams):\n    \"\"\"Parameters for Elasticsearch vector store.\n\n    Attributes:\n        index_name (str): Name of the index. Defaults to \"default\".\n        content_key (str): Key for content field. Defaults to \"content\".\n        dimension (int): Dimension of the vectors. Defaults to 1536.\n        similarity (str): Similarity metric to use. Defaults to \"cosine\".\n        embedding_key (str): Key for embedding field. Defaults to \"embedding\".\n        batch_size (int): Batch size for writing operations. Defaults to 100.\n    \"\"\"\n    similarity: ElasticsearchSimilarityMetric = ElasticsearchSimilarityMetric.COSINE\n    embedding_key: str = \"embedding\"\n    batch_size: int = 100\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/elasticsearch/#dynamiq.storages.vector.elasticsearch.elasticsearch.ElasticsearchVectorStoreWriterParams","title":"<code>ElasticsearchVectorStoreWriterParams</code>","text":"<p>               Bases: <code>ElasticsearchVectorStoreParams</code>, <code>BaseWriterVectorStoreParams</code></p> <p>Parameters for Elasticsearch vector store writer.</p> Source code in <code>dynamiq/storages/vector/elasticsearch/elasticsearch.py</code> <pre><code>class ElasticsearchVectorStoreWriterParams(ElasticsearchVectorStoreParams, BaseWriterVectorStoreParams):\n    \"\"\"Parameters for Elasticsearch vector store writer.\"\"\"\n    dimension: int = 1536\n</code></pre>"},{"location":"dynamiq/storages/vector/elasticsearch/filters/","title":"Filters","text":""},{"location":"dynamiq/storages/vector/milvus/filter/","title":"Filter","text":""},{"location":"dynamiq/storages/vector/milvus/filter/#dynamiq.storages.vector.milvus.filter.Filter","title":"<code>Filter</code>","text":"Source code in <code>dynamiq/storages/vector/milvus/filter.py</code> <pre><code>class Filter:\n    LOGICAL_OPERATORS = {\"AND\": \" and \", \"OR\": \" or \", \"NOT\": \"not \"}\n    COMPARISON_OPERATORS = {\n        \"==\": \"==\",\n        \"!=\": \"!=\",\n        \"&gt;\": \"&gt;\",\n        \"&gt;=\": \"&gt;=\",\n        \"&lt;\": \"&lt;\",\n        \"&lt;=\": \"&lt;=\",\n        \"in\": \"in\",\n        \"not in\": \"not in\",\n    }\n\n    def __init__(self, filter_criteria: dict[str, Any]):\n        \"\"\"\n        Initializes the Filter object with filter criteria.\n\n        Args:\n            filter_criteria (Dict[str, Any]): The filters to apply.\n        \"\"\"\n        self.filter_criteria = filter_criteria\n\n    def build_filter_expression(self) -&gt; str:\n        \"\"\"\n        Builds the filter expression string from the filter criteria.\n\n        Returns:\n            str: The constructed filter expression string compatible with the database.\n        \"\"\"\n        return self._parse_filter(self.filter_criteria)\n\n    def _parse_filter(self, filter_term: dict[str, Any]) -&gt; str:\n        \"\"\"\n        Recursively parse the filter criteria to build a Milvus-compatible filter expression.\n\n        Args:\n            filter_term (Dict[str, Any]): The filter dictionary to parse.\n\n        Returns:\n            str: A Milvus-compatible filter expression.\n        \"\"\"\n        # Handle logical operators with nested conditions\n        if \"operator\" in filter_term and \"conditions\" in filter_term:\n            operator = filter_term[\"operator\"]\n            if operator not in self.LOGICAL_OPERATORS:\n                raise ValueError(f\"Unsupported logical operator: {operator}\")\n\n            # Process each condition recursively\n            sub_expressions = [self._parse_filter(cond) for cond in filter_term[\"conditions\"]]\n            return f\"({self.LOGICAL_OPERATORS[operator].join(sub_expressions)})\"\n\n        # Handle comparison conditions\n        elif \"field\" in filter_term and \"operator\" in filter_term and \"value\" in filter_term:\n            field = filter_term[\"field\"]\n            operator = filter_term[\"operator\"]\n            value = filter_term[\"value\"]\n\n            # Build comparison expression\n            return self._build_comparison_expression(field, operator, value)\n\n        else:\n            raise ValueError(\"Invalid filter structure\")\n\n    def _build_comparison_expression(self, field: str, operator: str, value: Any) -&gt; str:\n        \"\"\"\n        Constructs a comparison expression based on field, operator, and value.\n\n        Args:\n            field (str): The field to filter on.\n            operator (str): The comparison operator.\n            value (Any): The value to compare against.\n\n        Returns:\n            str: A Milvus-compatible comparison expression.\n        \"\"\"\n        if operator not in self.COMPARISON_OPERATORS:\n            raise ValueError(f\"Unsupported comparison operator: {operator}\")\n\n        if operator == \"in\" and isinstance(value, list):\n            return f\"{field} in {value}\"\n        elif operator == \"not in\" and isinstance(value, list):\n            return f\"{field} not in {value}\"\n        elif isinstance(value, str):\n            return f'{field} {self.COMPARISON_OPERATORS[operator]} \"{value}\"'\n        else:\n            return f\"{field} {self.COMPARISON_OPERATORS[operator]} {value}\"\n\n    @staticmethod\n    def from_dict(filter_dict: dict[str, Any]) -&gt; \"Filter\":\n        \"\"\"\n        Creates a Filter instance from a dictionary.\n\n        Args:\n            filter_dict (Dict[str, Any]): Dictionary defining filter criteria.\n\n        Returns:\n            Filter: The Filter instance.\n        \"\"\"\n        return Filter(filter_dict)\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/filter/#dynamiq.storages.vector.milvus.filter.Filter.__init__","title":"<code>__init__(filter_criteria)</code>","text":"<p>Initializes the Filter object with filter criteria.</p> <p>Parameters:</p> Name Type Description Default <code>filter_criteria</code> <code>Dict[str, Any]</code> <p>The filters to apply.</p> required Source code in <code>dynamiq/storages/vector/milvus/filter.py</code> <pre><code>def __init__(self, filter_criteria: dict[str, Any]):\n    \"\"\"\n    Initializes the Filter object with filter criteria.\n\n    Args:\n        filter_criteria (Dict[str, Any]): The filters to apply.\n    \"\"\"\n    self.filter_criteria = filter_criteria\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/filter/#dynamiq.storages.vector.milvus.filter.Filter.build_filter_expression","title":"<code>build_filter_expression()</code>","text":"<p>Builds the filter expression string from the filter criteria.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The constructed filter expression string compatible with the database.</p> Source code in <code>dynamiq/storages/vector/milvus/filter.py</code> <pre><code>def build_filter_expression(self) -&gt; str:\n    \"\"\"\n    Builds the filter expression string from the filter criteria.\n\n    Returns:\n        str: The constructed filter expression string compatible with the database.\n    \"\"\"\n    return self._parse_filter(self.filter_criteria)\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/filter/#dynamiq.storages.vector.milvus.filter.Filter.from_dict","title":"<code>from_dict(filter_dict)</code>  <code>staticmethod</code>","text":"<p>Creates a Filter instance from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>filter_dict</code> <code>Dict[str, Any]</code> <p>Dictionary defining filter criteria.</p> required <p>Returns:</p> Name Type Description <code>Filter</code> <code>Filter</code> <p>The Filter instance.</p> Source code in <code>dynamiq/storages/vector/milvus/filter.py</code> <pre><code>@staticmethod\ndef from_dict(filter_dict: dict[str, Any]) -&gt; \"Filter\":\n    \"\"\"\n    Creates a Filter instance from a dictionary.\n\n    Args:\n        filter_dict (Dict[str, Any]): Dictionary defining filter criteria.\n\n    Returns:\n        Filter: The Filter instance.\n    \"\"\"\n    return Filter(filter_dict)\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/","title":"Milvus","text":""},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore","title":"<code>MilvusVectorStore</code>","text":"<p>               Bases: <code>BaseVectorStore</code>, <code>DryRunMixin</code></p> <p>Vector store using Milvus.</p> Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>class MilvusVectorStore(BaseVectorStore, DryRunMixin):\n    \"\"\"Vector store using Milvus.\"\"\"\n\n    def __init__(\n        self,\n        connection: Milvus | None = None,\n        client: Optional[\"MilvusClient\"] = None,\n        index_name: str = \"default\",\n        metric_type: str = \"COSINE\",\n        index_type: str = \"AUTOINDEX\",\n        dimension: int = 1536,\n        create_if_not_exist: bool = False,\n        content_key: str = \"content\",\n        embedding_key: str = \"embedding\",\n        dry_run_config: DryRunConfig | None = None,\n    ):\n        \"\"\"\n        Initialize a MilvusVectorStore instance.\n\n        Args:\n            connection (Milvus | None): A Milvus connection object. Defaults to None.\n            client (Optional[MilvusClient]): A Milvus client. Defaults to None.\n            index_name (str): The name of the index to use. Defaults to \"default\".\n            metric_type (str): The metric type to use for the index. Defaults to \"COSINE\".\n            index_type (str): The index type to use for the index. Defaults to \"AUTOINDEX\".\n            dimension (int): The dimension of the vectors. Defaults to 1536.\n            create_if_not_exist (bool): Whether to create the collection if it does not exist. Defaults to False.\n            content_key (str): The field used to store content in the storage. Defaults to \"content\".\n            embedding_key (str): The field used to store vector in the storage. Defaults to \"embedding\".\n            dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n        \"\"\"\n        super().__init__(dry_run_config=dry_run_config)\n\n        self.client = client\n        if self.client is None:\n            connection = connection or Milvus()\n            self.client = connection.connect()\n        self.index_name = index_name\n        self.metric_type = metric_type\n        self.index_type = index_type\n        self.content_key = content_key\n        self.embedding_key = embedding_key\n        self.dimension = dimension\n        self.create_if_not_exist = create_if_not_exist\n        self.schema = self.client.create_schema(auto_id=False, enable_dynamic_field=True)\n        self.schema.add_field(field_name=\"id\", datatype=DataType.VARCHAR, is_primary=True, max_length=65_535)\n        self.schema.add_field(\n            field_name=self.content_key, datatype=DataType.VARCHAR, max_length=65_535, enable_analyzer=True\n        )\n        self.schema.add_field(field_name=self.embedding_key, datatype=DataType.FLOAT_VECTOR, dim=self.dimension)\n        self.schema.add_field(field_name=\"sparse\", datatype=DataType.SPARSE_FLOAT_VECTOR)\n\n        bm25_function = Function(\n            name=\"text_bm25_emb\",\n            input_field_names=[self.content_key],\n            output_field_names=[\"sparse\"],\n            function_type=FunctionType.BM25,\n        )\n        self.schema.add_function(bm25_function)\n\n        self.index_params = self.client.prepare_index_params()\n        self.index_params.add_index(field_name=\"id\")\n        self.index_params.add_index(\n            field_name=self.embedding_key, index_type=self.index_type, metric_type=self.metric_type\n        )\n        self.index_params.add_index(field_name=\"sparse\", index_type=\"SPARSE_INVERTED_INDEX\", metric_type=\"BM25\")\n\n        if not self.client.has_collection(self.index_name):\n            if self.create_if_not_exist:\n                logger.info(f\"Collection {self.index_name} does not exist. Creating a new collection.\")\n                self.client.create_collection(\n                    collection_name=self.index_name, schema=self.schema, index_params=self.index_params\n                )\n                self._track_collection(self.index_name)\n            else:\n                raise ValueError(\n                    f\"Collection {self.index_name} does not exist. Set 'create_if_not_exist' to True to create it.\"\n                )\n        else:\n            logger.info(f\"Collection {self.index_name} already exists. Skipping creation.\")\n\n        self.client.load_collection(self.index_name)\n\n    def count_documents(self) -&gt; int:\n        \"\"\"\n        Get the number of documents in the collection.\n\n        Returns:\n            int: The number of documents in the collection.\n        \"\"\"\n        return self.client.get_collection_stats(self.index_name)[\"row_count\"]\n\n    def write_documents(\n        self, documents: list[Document], content_key: str | None = None, embedding_key: str | None = None\n    ) -&gt; int:\n        \"\"\"\n        Write (or overwrite) documents into the Milvus store.\n\n        This method processes a list of Document objects and writes them into the vector store.\n\n        Args:\n            documents (List[Document]): A list of Document objects to be written into the document store.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store vector in the storage.\n\n        Raises:\n            ValueError: If an item in the documents list is not an instance of the Document class.\n\n        Returns:\n            int: The number of documents successfully written to the document store.\n        \"\"\"\n        data_to_upsert = []\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n        for doc in documents:\n            if not isinstance(doc, Document):\n                raise ValueError(\"All items in 'documents' must be of type Document.\")\n\n            document_data = {\n                \"id\": doc.id,\n                embedding_key: doc.embedding,\n                content_key: doc.content,\n            }\n\n            if doc.metadata:\n                document_data.update(doc.metadata)\n\n            data_to_upsert.append(document_data)\n\n        self._track_documents([doc.id for doc in documents])\n\n        response = self.client.upsert(\n            collection_name=self.index_name,\n            data=data_to_upsert,\n        )\n        return response[\"upsert_count\"]\n\n    def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n        \"\"\"\n        Delete documents from the Milvus vector store based on their IDs.\n\n        Args:\n            document_ids (List[str]): A list containing the IDs of documents to be deleted from the store.\n            delete_all (bool): A flag to delete all documents from the store. Defaults to False.\n\n        Raises:\n            ValueError: If neither document_ids nor delete_all is provided.\n        \"\"\"\n        if delete_all:\n            self.client.drop_collection(collection_name=self.index_name)\n            self.client.create_collection(\n                collection_name=self.index_name, schema=self.schema, index_params=self.index_params\n            )\n            self.client.load_collection(self.index_name)\n            logger.info(f\"All documents in the collection {self.index_name} have been deleted.\")\n        elif document_ids:\n            response = self.client.delete(collection_name=self.index_name, ids=document_ids)\n            logger.info(f\"Deleted {len(response)} documents from collection {self.index_name}.\")\n        else:\n            raise ValueError(\"Either `document_ids` or `delete_all` must be provided.\")\n\n    def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n        \"\"\"\n        Delete documents based on filters.\n\n        Args:\n            filters (Dict[str, Any]): Filter criteria for deleting documents.\n        \"\"\"\n        if not filters:\n            raise ValueError(\"Filters must be provided to delete documents.\")\n\n        filter_expression = Filter(filters).build_filter_expression()\n\n        delete_result = self.client.delete(collection_name=self.index_name, filter=filter_expression)\n\n        logger.info(f\"Deleted {len(delete_result)} entities from collection {self.index_name} based on filters.\")\n\n    def delete_collection(self, collection_name: str | None = None):\n        \"\"\"\n        Delete a Milvus collection.\n\n        Args:\n            collection_name (str | None): Name of the collection to delete.\n        \"\"\"\n        try:\n            collection_to_delete = collection_name or self.index_name\n            self.client.drop_collection(collection_name=collection_to_delete)\n            logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n        except Exception as e:\n            logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n            raise\n\n    def list_documents(\n        self, limit: int = 1000, content_key: str | None = None, embedding_key: str | None = None\n    ) -&gt; list[Document]:\n        \"\"\"\n        List all documents in the collection up to a specified limit.\n\n        Args:\n            limit (int): Maximum number of documents to retrieve. Defaults to 1000.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store vector in the storage.\n\n        Returns:\n            List[Document]: A list of Document instances representing all documents in the collection.\n        \"\"\"\n        if not self.client.has_collection(self.index_name):\n            raise ValueError(f\"Collection '{self.index_name}' does not exist.\")\n\n        result = self.client.query(collection_name=self.index_name, filter=\"\", output_fields=[\"*\"], limit=limit)\n\n        return self._get_result_to_documents(result, content_key=content_key, embedding_key=embedding_key)\n\n    def _embedding_retrieval(\n        self,\n        query_embeddings: list[list[float]],\n        top_k: int,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n        return_embeddings: bool = False,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Perform vector search on the stored documents using query embeddings.\n\n        Args:\n            query_embeddings (list[list[float]]): A list of embeddings to use as queries.\n            top_k (int): The maximum number of documents to retrieve.\n            filters (dict[str, Any] | None): A dictionary of filters to apply to the search. Defaults to None.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store vector in the storage.\n            return_embeddings (bool): Whether to return the embeddings of the retrieved documents.\n\n        Returns:\n            List[Document]: A list of Document objects containing the retrieved documents.\n        \"\"\"\n        search_params = {\"metric_type\": self.metric_type, \"params\": {}}\n\n        filter_expression = Filter(filters).build_filter_expression() if filters else \"\"\n\n        results = self.client.search(\n            collection_name=self.index_name,\n            data=query_embeddings,\n            limit=top_k,\n            filter=filter_expression,\n            output_fields=[\"*\"],\n            anns_field=embedding_key or self.embedding_key,\n            search_params=search_params,\n        )\n\n        return self._convert_query_result_to_documents(\n            results[0], content_key=content_key, embedding_key=embedding_key, return_embeddings=return_embeddings\n        )\n\n    def _convert_query_result_to_documents(\n        self,\n        result: list[dict[str, Any]],\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n        return_embeddings: bool = False,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Convert Milvus search results to Document objects.\n\n        Args:\n            result (List[Dict[str, Any]]): The result from a Milvus search operation.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store vector in the storage.\n            return_embeddings (bool): Whether to return the embeddings of the retrieved documents.\n\n        Returns:\n            List[Document]: A list of Document instances created from the Milvus search result.\n        \"\"\"\n        documents = []\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n        for hit in result:\n            entity = hit.get(\"entity\", {})\n            content = entity.get(content_key, \"\")\n            embedding = entity.get(embedding_key, [])\n            metadata = {k: v for k, v in entity.items() if k not in (content_key, embedding_key)}\n\n            doc = Document(\n                id=str(hit.get(\"id\", \"\")),\n                content=content,\n                metadata=metadata,\n                score=hit.get(\"distance\", None),\n            )\n            if return_embeddings:\n                doc.embedding = embedding\n\n            documents.append(doc)\n\n        return documents\n\n    def filter_documents(\n        self, filters: dict[str, Any] | None = None, content_key: str | None = None, embedding_key: str | None = None\n    ) -&gt; list[Document]:\n        \"\"\"\n        Retrieve documents that match the provided filters.\n\n        Args:\n            filters (Dict[str, Any] | None): The filters to apply to the document list.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store vector in the storage.\n\n        Returns:\n            list[Document]: A list of Document instances that match the given filters.\n\n        Raises:\n            ValueError: If no filters are provided.\n        \"\"\"\n        if not filters:\n            raise ValueError(\"No filters provided. No documents will be retrieved with filters.\")\n\n        filter_expression = Filter(filters).build_filter_expression()\n\n        result = self.client.query(\n            collection_name=self.index_name,\n            filter=filter_expression,\n            output_fields=[\"*\"],\n        )\n        return self._get_result_to_documents(result, content_key=content_key, embedding_key=embedding_key)\n\n    def _get_result_to_documents(\n        self, result: list[dict[str, Any]], content_key: str | None = None, embedding_key: str | None = None\n    ) -&gt; list[Document]:\n        \"\"\"\n        Convert Milvus query result into Documents.\n\n        Args:\n            result (List[Dict[str, Any]]): The result from a Milvus query operation.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store vector in the storage.\n\n        Returns:\n            List[Document]: A list containing Document objects created from the Milvus query result.\n        \"\"\"\n        documents = []\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n        for entry in result:\n            document_dict: dict[str, Any] = {\n                \"id\": str(entry.get(\"id\", \"\")),\n                \"content\": entry.get(content_key, \"\"),\n                \"embedding\": entry.get(embedding_key, []),\n            }\n            metadata = {k: v for k, v in entry.items() if k not in (\"id\", content_key, embedding_key)}\n\n            if metadata:\n                document_dict[\"metadata\"] = metadata\n\n            try:\n                documents.append(Document(**document_dict))\n            except Exception as e:\n                logger.error(f\"Error creating Document: {e}, data: {document_dict}\")\n\n        return documents\n\n    def _hybrid_retrieval(\n        self,\n        query: str,\n        query_embeddings: list[list[float]],\n        top_k: int,\n        top_k_dense: int | None = None,\n        top_k_sparse: int | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n        return_embeddings: bool = False,\n        drop_ratio_build: float = 0.0,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Perform a hybrid search using both dense (vector-based) and sparse (text-based) retrieval techniques.\n\n        Args:\n            query (str): The textual query used for sparse search (BM25).\n            query_embeddings (list[list[float]]): A list of embeddings representing the query for dense search.\n            top_k (int): The maximum number of documents to retrieve with hybrid search.\n            top_k_dense (int | None, optional): The number of top results to retrieve from the dense search.\n                If None, defaults to `top_k`.\n            top_k_sparse (int | None, optional): The number of top results to retrieve from the sparse search.\n                If None, defaults to `top_k`.\n            content_key (Optional[str]): The field used to store content in the storage.\n            embedding_key (Optional[str]): The field used to store vector in the storage.\n            return_embeddings (bool): Whether to return the embeddings of the retrieved documents.\n            drop_ratio_build (float): The ratio of small vector values to be dropped during indexing during text search.\n\n        Returns:\n            List[Document]: A list of Document objects containing the retrieved documents.\n        \"\"\"\n\n        search_param_1 = {\n            \"data\": query_embeddings,\n            \"anns_field\": embedding_key or self.embedding_key,\n            \"param\": {\n                \"metric_type\": self.metric_type,\n            },\n            \"limit\": top_k_dense or top_k,\n        }\n        request_1 = AnnSearchRequest(**search_param_1)\n\n        search_param_2 = {\n            \"data\": [query],\n            \"anns_field\": \"sparse\",\n            \"param\": {\"metric_type\": \"BM25\", \"params\": {\"drop_ratio_build\": drop_ratio_build}},\n            \"limit\": top_k_sparse or top_k,\n        }\n        request_2 = AnnSearchRequest(**search_param_2)\n\n        ranker = RRFRanker()\n        results = self.client.hybrid_search(\n            collection_name=self.index_name,\n            output_fields=[\"*\"],\n            reqs=[request_1, request_2],\n            ranker=ranker,\n            limit=top_k,\n        )\n\n        return self._convert_query_result_to_documents(\n            results[0], content_key=content_key, embedding_key=embedding_key, return_embeddings=return_embeddings\n        )\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore.__init__","title":"<code>__init__(connection=None, client=None, index_name='default', metric_type='COSINE', index_type='AUTOINDEX', dimension=1536, create_if_not_exist=False, content_key='content', embedding_key='embedding', dry_run_config=None)</code>","text":"<p>Initialize a MilvusVectorStore instance.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Milvus | None</code> <p>A Milvus connection object. Defaults to None.</p> <code>None</code> <code>client</code> <code>Optional[MilvusClient]</code> <p>A Milvus client. Defaults to None.</p> <code>None</code> <code>index_name</code> <code>str</code> <p>The name of the index to use. Defaults to \"default\".</p> <code>'default'</code> <code>metric_type</code> <code>str</code> <p>The metric type to use for the index. Defaults to \"COSINE\".</p> <code>'COSINE'</code> <code>index_type</code> <code>str</code> <p>The index type to use for the index. Defaults to \"AUTOINDEX\".</p> <code>'AUTOINDEX'</code> <code>dimension</code> <code>int</code> <p>The dimension of the vectors. Defaults to 1536.</p> <code>1536</code> <code>create_if_not_exist</code> <code>bool</code> <p>Whether to create the collection if it does not exist. Defaults to False.</p> <code>False</code> <code>content_key</code> <code>str</code> <p>The field used to store content in the storage. Defaults to \"content\".</p> <code>'content'</code> <code>embedding_key</code> <code>str</code> <p>The field used to store vector in the storage. Defaults to \"embedding\".</p> <code>'embedding'</code> <code>dry_run_config</code> <code>Optional[DryRunConfig]</code> <p>Configuration for dry run mode. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>def __init__(\n    self,\n    connection: Milvus | None = None,\n    client: Optional[\"MilvusClient\"] = None,\n    index_name: str = \"default\",\n    metric_type: str = \"COSINE\",\n    index_type: str = \"AUTOINDEX\",\n    dimension: int = 1536,\n    create_if_not_exist: bool = False,\n    content_key: str = \"content\",\n    embedding_key: str = \"embedding\",\n    dry_run_config: DryRunConfig | None = None,\n):\n    \"\"\"\n    Initialize a MilvusVectorStore instance.\n\n    Args:\n        connection (Milvus | None): A Milvus connection object. Defaults to None.\n        client (Optional[MilvusClient]): A Milvus client. Defaults to None.\n        index_name (str): The name of the index to use. Defaults to \"default\".\n        metric_type (str): The metric type to use for the index. Defaults to \"COSINE\".\n        index_type (str): The index type to use for the index. Defaults to \"AUTOINDEX\".\n        dimension (int): The dimension of the vectors. Defaults to 1536.\n        create_if_not_exist (bool): Whether to create the collection if it does not exist. Defaults to False.\n        content_key (str): The field used to store content in the storage. Defaults to \"content\".\n        embedding_key (str): The field used to store vector in the storage. Defaults to \"embedding\".\n        dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n    \"\"\"\n    super().__init__(dry_run_config=dry_run_config)\n\n    self.client = client\n    if self.client is None:\n        connection = connection or Milvus()\n        self.client = connection.connect()\n    self.index_name = index_name\n    self.metric_type = metric_type\n    self.index_type = index_type\n    self.content_key = content_key\n    self.embedding_key = embedding_key\n    self.dimension = dimension\n    self.create_if_not_exist = create_if_not_exist\n    self.schema = self.client.create_schema(auto_id=False, enable_dynamic_field=True)\n    self.schema.add_field(field_name=\"id\", datatype=DataType.VARCHAR, is_primary=True, max_length=65_535)\n    self.schema.add_field(\n        field_name=self.content_key, datatype=DataType.VARCHAR, max_length=65_535, enable_analyzer=True\n    )\n    self.schema.add_field(field_name=self.embedding_key, datatype=DataType.FLOAT_VECTOR, dim=self.dimension)\n    self.schema.add_field(field_name=\"sparse\", datatype=DataType.SPARSE_FLOAT_VECTOR)\n\n    bm25_function = Function(\n        name=\"text_bm25_emb\",\n        input_field_names=[self.content_key],\n        output_field_names=[\"sparse\"],\n        function_type=FunctionType.BM25,\n    )\n    self.schema.add_function(bm25_function)\n\n    self.index_params = self.client.prepare_index_params()\n    self.index_params.add_index(field_name=\"id\")\n    self.index_params.add_index(\n        field_name=self.embedding_key, index_type=self.index_type, metric_type=self.metric_type\n    )\n    self.index_params.add_index(field_name=\"sparse\", index_type=\"SPARSE_INVERTED_INDEX\", metric_type=\"BM25\")\n\n    if not self.client.has_collection(self.index_name):\n        if self.create_if_not_exist:\n            logger.info(f\"Collection {self.index_name} does not exist. Creating a new collection.\")\n            self.client.create_collection(\n                collection_name=self.index_name, schema=self.schema, index_params=self.index_params\n            )\n            self._track_collection(self.index_name)\n        else:\n            raise ValueError(\n                f\"Collection {self.index_name} does not exist. Set 'create_if_not_exist' to True to create it.\"\n            )\n    else:\n        logger.info(f\"Collection {self.index_name} already exists. Skipping creation.\")\n\n    self.client.load_collection(self.index_name)\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore.count_documents","title":"<code>count_documents()</code>","text":"<p>Get the number of documents in the collection.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents in the collection.</p> Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>def count_documents(self) -&gt; int:\n    \"\"\"\n    Get the number of documents in the collection.\n\n    Returns:\n        int: The number of documents in the collection.\n    \"\"\"\n    return self.client.get_collection_stats(self.index_name)[\"row_count\"]\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore.delete_collection","title":"<code>delete_collection(collection_name=None)</code>","text":"<p>Delete a Milvus collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str | None</code> <p>Name of the collection to delete.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>def delete_collection(self, collection_name: str | None = None):\n    \"\"\"\n    Delete a Milvus collection.\n\n    Args:\n        collection_name (str | None): Name of the collection to delete.\n    \"\"\"\n    try:\n        collection_to_delete = collection_name or self.index_name\n        self.client.drop_collection(collection_name=collection_to_delete)\n        logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n    except Exception as e:\n        logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore.delete_documents","title":"<code>delete_documents(document_ids=None, delete_all=False)</code>","text":"<p>Delete documents from the Milvus vector store based on their IDs.</p> <p>Parameters:</p> Name Type Description Default <code>document_ids</code> <code>List[str]</code> <p>A list containing the IDs of documents to be deleted from the store.</p> <code>None</code> <code>delete_all</code> <code>bool</code> <p>A flag to delete all documents from the store. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither document_ids nor delete_all is provided.</p> Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n    \"\"\"\n    Delete documents from the Milvus vector store based on their IDs.\n\n    Args:\n        document_ids (List[str]): A list containing the IDs of documents to be deleted from the store.\n        delete_all (bool): A flag to delete all documents from the store. Defaults to False.\n\n    Raises:\n        ValueError: If neither document_ids nor delete_all is provided.\n    \"\"\"\n    if delete_all:\n        self.client.drop_collection(collection_name=self.index_name)\n        self.client.create_collection(\n            collection_name=self.index_name, schema=self.schema, index_params=self.index_params\n        )\n        self.client.load_collection(self.index_name)\n        logger.info(f\"All documents in the collection {self.index_name} have been deleted.\")\n    elif document_ids:\n        response = self.client.delete(collection_name=self.index_name, ids=document_ids)\n        logger.info(f\"Deleted {len(response)} documents from collection {self.index_name}.\")\n    else:\n        raise ValueError(\"Either `document_ids` or `delete_all` must be provided.\")\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore.delete_documents_by_filters","title":"<code>delete_documents_by_filters(filters)</code>","text":"<p>Delete documents based on filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>Dict[str, Any]</code> <p>Filter criteria for deleting documents.</p> required Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Delete documents based on filters.\n\n    Args:\n        filters (Dict[str, Any]): Filter criteria for deleting documents.\n    \"\"\"\n    if not filters:\n        raise ValueError(\"Filters must be provided to delete documents.\")\n\n    filter_expression = Filter(filters).build_filter_expression()\n\n    delete_result = self.client.delete(collection_name=self.index_name, filter=filter_expression)\n\n    logger.info(f\"Deleted {len(delete_result)} entities from collection {self.index_name} based on filters.\")\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore.filter_documents","title":"<code>filter_documents(filters=None, content_key=None, embedding_key=None)</code>","text":"<p>Retrieve documents that match the provided filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>Dict[str, Any] | None</code> <p>The filters to apply to the document list.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store vector in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: A list of Document instances that match the given filters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no filters are provided.</p> Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>def filter_documents(\n    self, filters: dict[str, Any] | None = None, content_key: str | None = None, embedding_key: str | None = None\n) -&gt; list[Document]:\n    \"\"\"\n    Retrieve documents that match the provided filters.\n\n    Args:\n        filters (Dict[str, Any] | None): The filters to apply to the document list.\n        content_key (Optional[str]): The field used to store content in the storage.\n        embedding_key (Optional[str]): The field used to store vector in the storage.\n\n    Returns:\n        list[Document]: A list of Document instances that match the given filters.\n\n    Raises:\n        ValueError: If no filters are provided.\n    \"\"\"\n    if not filters:\n        raise ValueError(\"No filters provided. No documents will be retrieved with filters.\")\n\n    filter_expression = Filter(filters).build_filter_expression()\n\n    result = self.client.query(\n        collection_name=self.index_name,\n        filter=filter_expression,\n        output_fields=[\"*\"],\n    )\n    return self._get_result_to_documents(result, content_key=content_key, embedding_key=embedding_key)\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore.list_documents","title":"<code>list_documents(limit=1000, content_key=None, embedding_key=None)</code>","text":"<p>List all documents in the collection up to a specified limit.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>Maximum number of documents to retrieve. Defaults to 1000.</p> <code>1000</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store vector in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>List[Document]: A list of Document instances representing all documents in the collection.</p> Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>def list_documents(\n    self, limit: int = 1000, content_key: str | None = None, embedding_key: str | None = None\n) -&gt; list[Document]:\n    \"\"\"\n    List all documents in the collection up to a specified limit.\n\n    Args:\n        limit (int): Maximum number of documents to retrieve. Defaults to 1000.\n        content_key (Optional[str]): The field used to store content in the storage.\n        embedding_key (Optional[str]): The field used to store vector in the storage.\n\n    Returns:\n        List[Document]: A list of Document instances representing all documents in the collection.\n    \"\"\"\n    if not self.client.has_collection(self.index_name):\n        raise ValueError(f\"Collection '{self.index_name}' does not exist.\")\n\n    result = self.client.query(collection_name=self.index_name, filter=\"\", output_fields=[\"*\"], limit=limit)\n\n    return self._get_result_to_documents(result, content_key=content_key, embedding_key=embedding_key)\n</code></pre>"},{"location":"dynamiq/storages/vector/milvus/milvus/#dynamiq.storages.vector.milvus.milvus.MilvusVectorStore.write_documents","title":"<code>write_documents(documents, content_key=None, embedding_key=None)</code>","text":"<p>Write (or overwrite) documents into the Milvus store.</p> <p>This method processes a list of Document objects and writes them into the vector store.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>List[Document]</code> <p>A list of Document objects to be written into the document store.</p> required <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store vector in the storage.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an item in the documents list is not an instance of the Document class.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents successfully written to the document store.</p> Source code in <code>dynamiq/storages/vector/milvus/milvus.py</code> <pre><code>def write_documents(\n    self, documents: list[Document], content_key: str | None = None, embedding_key: str | None = None\n) -&gt; int:\n    \"\"\"\n    Write (or overwrite) documents into the Milvus store.\n\n    This method processes a list of Document objects and writes them into the vector store.\n\n    Args:\n        documents (List[Document]): A list of Document objects to be written into the document store.\n        content_key (Optional[str]): The field used to store content in the storage.\n        embedding_key (Optional[str]): The field used to store vector in the storage.\n\n    Raises:\n        ValueError: If an item in the documents list is not an instance of the Document class.\n\n    Returns:\n        int: The number of documents successfully written to the document store.\n    \"\"\"\n    data_to_upsert = []\n    content_key = content_key or self.content_key\n    embedding_key = embedding_key or self.embedding_key\n    for doc in documents:\n        if not isinstance(doc, Document):\n            raise ValueError(\"All items in 'documents' must be of type Document.\")\n\n        document_data = {\n            \"id\": doc.id,\n            embedding_key: doc.embedding,\n            content_key: doc.content,\n        }\n\n        if doc.metadata:\n            document_data.update(doc.metadata)\n\n        data_to_upsert.append(document_data)\n\n    self._track_documents([doc.id for doc in documents])\n\n    response = self.client.upsert(\n        collection_name=self.index_name,\n        data=data_to_upsert,\n    )\n    return response[\"upsert_count\"]\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/filters/","title":"Filters","text":""},{"location":"dynamiq/storages/vector/pgvector/pgvector/","title":"Pgvector","text":""},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore","title":"<code>PGVectorStore</code>","text":"<p>               Bases: <code>BaseVectorStore</code>, <code>DryRunMixin</code></p> <p>Vector store using pgvector.</p> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>class PGVectorStore(BaseVectorStore, DryRunMixin):\n    \"\"\"Vector store using pgvector.\"\"\"\n\n    def __init__(\n        self,\n        connection: PostgreSQL | str | None = None,\n        client: Optional[\"PsycopgConnection\"] = None,\n        create_extension: bool = True,\n        table_name: str = DEFAULT_TABLE_NAME,\n        schema_name: str = DEFAULT_SCHEMA_NAME,\n        dimension: int = 1536,\n        vector_function: PGVectorVectorFunction = PGVectorVectorFunction.COSINE_SIMILARITY,\n        index_method: PGVectorIndexMethod = PGVectorIndexMethod.EXACT,\n        index_name: str = DEFAULT_INDEX_NAME,\n        create_if_not_exist: bool = False,\n        content_key: str = \"content\",\n        embedding_key: str = \"embedding\",\n        keyword_index_name: str = DEFAULT_KEYWORD_INDEX_NAME,\n        language: str = DEFAULT_LANGUAGE,\n        dry_run_config: DryRunConfig | None = None,\n    ):\n        \"\"\"\n        Initialize a PGVectorStore instance.\n\n        Args:\n            connection (PostgreSQL | str): PostgreSQL connection instance. Defaults to None.\n            client (Optional[PostgreSQL]): PostgreSQL client instance. Defaults to None.\n            create_extension (bool): Whether to create the vector extension (if it does not exist). Defaults to True.\n            table_name (str): Name of the table in the database. Defaults to None.\n            schema_name (str): Name of the schema in the database. Defaults to None.\n            dimension (int): Dimension of the embeddings. Defaults to 1536.\n            vector_function (PGVectorVectorFunction): The vector function to use for similarity calculations.\n                Defaults to 'cosine_similarity'.\n            index_method (PGVectorIndexMethod): The index method to use for the vector store.\n                Defaults to 'exact_nearest_neighbor_search'.\n            index_name (str): Name of the index to create. Defaults to None.\n            create_if_not_exist (bool): Whether to create the table and index if they do not exist. Defaults to False.\n            content_key (Optional[str]): The field used to store content in the storage. Defaults to 'content'.\n            embedding_key (Optional[str]): The field used to store embeddings in the storage. Defaults to 'embedding'.\n            dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n        \"\"\"\n        super().__init__(dry_run_config=dry_run_config)\n\n        if vector_function not in PGVectorVectorFunction:\n            raise ValueError(f\"vector_function must be one of {list(PGVectorVectorFunction)}\")\n        if index_method is not None and index_method not in PGVectorIndexMethod:\n            raise ValueError(f\"index_method must be one of {list(PGVectorIndexMethod)}\")\n\n        if client is None or client.closed:\n            if isinstance(connection, str):\n                self.connection_string = connection\n                self._conn = psycopg.connect(self.connection_string)\n                self.client = self._conn\n            elif isinstance(connection, PostgreSQL):\n                self._conn = connection.connect()\n                self.connection_string = connection.conn_params\n                self.client = self._conn\n            else:\n                raise ValueError(\"connection must be a string or PostgreSQL object\")\n        else:\n            self._conn = client\n\n        self.create_extension = create_extension\n        if self.create_extension:\n            self._conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n            self._conn.commit()\n\n        register_vector(self._conn)\n\n        self.table_name = table_name\n        self.schema_name = schema_name\n        self.dimension = dimension\n        self.index_method = index_method\n        self.vector_function = vector_function\n        self.keyword_index_name = keyword_index_name\n        self.language = language\n\n        self.content_key = content_key\n        self.embedding_key = embedding_key\n\n        self.create_if_not_exist = create_if_not_exist\n\n        if (\n            self.index_method == PGVectorIndexMethod.IVFFLAT\n            and self.vector_function == PGVectorVectorFunction.L1_DISTANCE\n        ):\n            msg = \"IVFFLAT index does not support L1 distance metric\"\n            raise VectorStoreException(msg)\n\n        if self.create_if_not_exist:\n            with self._get_connection() as conn:\n\n                if not self._check_if_table_exists(conn) and not self._check_if_schema_exists(conn):\n                    self._track_collection(f\"{self.schema_name}.{self.table_name}\")\n\n                self._create_schema(conn)\n                self._create_tables(conn)\n                if self.index_method in [PGVectorIndexMethod.IVFFLAT, PGVectorIndexMethod.HNSW]:\n                    self.index_name = index_name or f\"{self.index_method}_index\"\n                    self._create_index(conn)\n                self._create_keyword_index(conn)\n        else:\n            if not self._check_if_schema_exists(self._conn):\n                msg = f\"Schema '{self.schema_name}' does not exist\"\n                raise VectorStoreException(msg)\n            if not self._check_if_table_exists(self._conn):\n                msg = f\"Table '{self.table_name}' does not exist\"\n                raise VectorStoreException(msg)\n\n        logger.debug(f\"PGVectorStore initialized with table_name: {self.table_name}\")\n\n    @contextmanager\n    def _get_connection(self):\n        \"\"\"Context manager for handling a single connection\"\"\"\n\n        import psycopg\n\n        if self._conn is None or self._conn.closed:\n            if self.client is None:\n                self._conn = psycopg.connect(self.connection_string)\n            else:\n                self._conn = self.client\n        try:\n            yield self._conn\n        except Exception as e:\n            self._conn.rollback()\n            raise e\n\n    def _check_if_schema_exists(self, conn: psycopg.Connection) -&gt; bool:\n        \"\"\"\n        Check if the schema exists in the database.\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n\n        Returns:\n            bool: True if the schema exists, False otherwise.\n        \"\"\"\n\n        query = SQL(\n            \"\"\"\n            SELECT EXISTS (\n                SELECT 1\n                FROM information_schema.schemata\n                WHERE schema_name = %s\n            );\n            \"\"\"\n        )\n\n        with conn.cursor() as cur:\n            result = self._execute_sql_query(query, (self.schema_name,), cursor=cur).fetchone()\n            return bool(result[\"exists\"])\n\n    def _check_if_table_exists(self, conn: psycopg.Connection) -&gt; bool:\n        \"\"\"\n        Check if the table exists in the database.\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n\n        Returns:\n            bool: True if the table exists, False otherwise.\n        \"\"\"\n\n        query = SQL(\n            \"\"\"\n            SELECT EXISTS (\n                SELECT 1\n                FROM information_schema.tables\n                WHERE table_schema = %s\n                AND table_name = %s\n            );\n            \"\"\"\n        )\n\n        with conn.cursor() as cur:\n            result = self._execute_sql_query(query, (self.schema_name, self.table_name), cursor=cur).fetchone()\n            return bool(result[\"exists\"])\n\n    def _execute_sql_query(self, sql_query: Any, params: tuple | None = None, cursor: Cursor | None = None) -&gt; Any:\n        \"\"\"\n        Internal method to execute a SQL query.\n\n        Args:\n            sql_query (Any): The SQL query to execute.\n            params (tuple | None): The parameters to pass to the query. Defaults to None.\n            cursor (Cursor | None): The cursor to use for the query. Defaults to None.\n\n        Raises:\n            VectorStoreException: If an error occurs while executing the query.\n\n        Returns:\n            Any: The result of the query.\n        \"\"\"\n\n        params = params or ()\n\n        sql_query_str = sql_query.as_string(cursor) if not isinstance(sql_query, str) else sql_query\n\n        try:\n            result = cursor.execute(sql_query, params)\n        except Exception as e:\n            self._conn.rollback()\n            msg = f\"Encountered an error while executing SQL query: {sql_query_str} with params: {params}. \\nError: {e}\"\n            raise VectorStoreException(msg)\n\n        return result\n\n    def _create_tables(\n        self,\n        conn: psycopg.Connection,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Internal method to create the tables in the database (if they do not exist).\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n            content_key (str | None): The field used to store content in the storage. Defaults to None.\n            embedding_key (str | None): The field used to store embeddings in the storage. Defaults to None.\n        \"\"\"\n\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n\n        query = SQL(\n            \"\"\"\n            CREATE TABLE IF NOT EXISTS {schema_name}.{table_name} (\n                id VARCHAR(128) PRIMARY KEY,\n                {content_key} TEXT,\n                metadata JSONB,\n                {embedding_key} vector({dimension})\n            );\n            \"\"\"\n        ).format(\n            schema_name=Identifier(self.schema_name),\n            table_name=Identifier(self.table_name),\n            content_key=Identifier(content_key),\n            embedding_key=Identifier(embedding_key),\n            dimension=self.dimension,\n        )\n\n        with conn.cursor() as cur:\n            self._execute_sql_query(query, cursor=cur)\n            conn.commit()\n\n    def _drop_tables(self, conn: psycopg.Connection) -&gt; None:\n        \"\"\"\n        Internal method to drop the tables in the database (if they exist).\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n        \"\"\"\n\n        query = SQL(\n            \"\"\"\n            DROP TABLE IF EXISTS {schema_name}.{table_name};\n            \"\"\"\n        ).format(\n            schema_name=Identifier(self.schema_name),\n            table_name=Identifier(self.table_name),\n        )\n\n        with conn.cursor() as cur:\n            self._execute_sql_query(query, cursor=cur)\n            conn.commit()\n\n    def _create_index(\n        self,\n        conn: psycopg.Connection,\n        embedding_key: str | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Internal method to create the index in the database (if it does not exist).\n        Should only be called if the index method is either `ivfflat` or `hnsw`.\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n            embedding_key (str | None): The field used to store embeddings in the storage. Defaults to None.\n\n        Raises:\n            ValueError: If the index method is not valid.\n        \"\"\"\n\n        embedding_key = embedding_key or self.embedding_key\n\n        if self.index_method not in PGVectorIndexMethod:\n            msg = f\"Invalid index method: {self.index_method}\"\n            raise ValueError(msg)\n\n        vector_ops = VECTOR_FUNCTION_TO_POSTGRESQL_OPS[self.vector_function]\n        query = SQL(\n            \"\"\"\n            CREATE INDEX IF NOT EXISTS {index_name}\n            ON {schema_name}.{table_name} USING {index_method} ({embedding} {vector_ops});\n            \"\"\"\n        ).format(\n            index_name=Identifier(f\"{self.table_name}_{self.index_method}_index\"),\n            schema_name=Identifier(self.schema_name),\n            table_name=Identifier(self.table_name),\n            index_method=Identifier(self.index_method),\n            vector_ops=Identifier(vector_ops),\n            embedding=Identifier(embedding_key),\n        )\n\n        with conn.cursor() as cur:\n            self._execute_sql_query(query, cursor=cur)\n            conn.commit()\n\n    def _create_keyword_index(\n        self,\n        conn: psycopg.Connection,\n        content_key: str | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Internal method to create the keyword index in the database (if it does not exist).\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n            content_key (str | None): The field used to store content in the storage. Defaults to None.\n        \"\"\"\n\n        content_key = content_key or self.content_key\n\n        check_if_keyword_index_exists_query = SQL(\n            \"\"\"\n            SELECT 1\n            FROM pg_indexes\n            WHERE schemaname = {schema_name}\n            AND tablename = {table_name}\n            AND indexname = {index_name};\n            \"\"\"\n        ).format(\n            schema_name=SQLLiteral(self.schema_name),\n            table_name=SQLLiteral(self.table_name),\n            index_name=SQLLiteral(self.keyword_index_name),\n        )\n\n        create_keyword_index_query = SQL(\n            \"\"\"\n            CREATE INDEX {index_name}\n            ON {schema_name}.{table_name}\n            USING gin(to_tsvector({language}, {content_key}));\n            \"\"\"\n        ).format(\n            index_name=Identifier(self.keyword_index_name),\n            schema_name=Identifier(self.schema_name),\n            table_name=Identifier(self.table_name),\n            content_key=Identifier(content_key),\n            language=SQLLiteral(self.language),\n        )\n\n        with conn.cursor() as cur:\n            index_exists = bool(self._execute_sql_query(check_if_keyword_index_exists_query, cursor=cur).fetchone())\n            if not index_exists:\n                self._execute_sql_query(create_keyword_index_query, cursor=cur)\n                conn.commit()\n\n    def _drop_index(self, conn: psycopg.Connection) -&gt; None:\n        \"\"\"\n        Internal method to drop the index in the database (if it exists).\n        Should only be called if the index method is either `ivfflat` or `hnsw`.\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n\n        Raises:\n            ValueError: If the index method is not valid.\n        \"\"\"\n        if self.index_method not in PGVectorIndexMethod:\n            msg = f\"Invalid index method: {self.index_method}\"\n            raise ValueError(msg)\n\n        query = SQL(\n            \"\"\"\n            DROP INDEX IF EXISTS {index_name};\n            \"\"\"\n        ).format(\n            index_name=Identifier(f\"{self.table_name}_{self.index_method}_index\"),\n        )\n\n        with conn.cursor() as cur:\n            self._execute_sql_query(query, cursor=cur)\n            conn.commit()\n\n    def _create_schema(self, conn: psycopg.Connection) -&gt; None:\n        \"\"\"\n        Internal method to create the schema in the database (if it does not exist).\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n        \"\"\"\n\n        query = SQL(\n            \"\"\"\n            CREATE SCHEMA IF NOT EXISTS {schema_name};\n            \"\"\"\n        ).format(\n            schema_name=Identifier(self.schema_name),\n        )\n\n        with conn.cursor() as cur:\n            self._execute_sql_query(query, cursor=cur)\n            conn.commit()\n\n    def _drop_schema(self, conn: psycopg.Connection) -&gt; None:\n        \"\"\"\n        Internal method to drop the schema in the database (if it exists).\n\n        Args:\n            conn (psycopg.Connection): The connection to the database.\n        \"\"\"\n\n        query = SQL(\n            \"\"\"\n            DROP SCHEMA IF EXISTS {schema_name} CASCADE;\n            \"\"\"\n        ).format(\n            schema_name=Identifier(self.schema_name),\n        )\n\n        with conn.cursor() as cur:\n            self._execute_sql_query(query, cursor=cur)\n            conn.commit()\n\n    def delete_collection(self, collection_name: str | None = None) -&gt; None:\n        \"\"\"\n        Delete the collection in the database.\n\n        Args:\n            collection_name (str | None): Name of the collection to delete.\n        \"\"\"\n        try:\n            with self._get_connection() as conn:\n                self._drop_tables(conn)\n                if self.schema_name and self.schema_name != DEFAULT_SCHEMA_NAME:\n                    self._drop_schema(conn)\n        except Exception as e:\n            logger.error(f\"Failed to delete collection '{self.schema_name}.{self.table_name}': {e}\")\n            raise\n\n    def count_documents(self) -&gt; int:\n        \"\"\"\n        Count the number of documents in the store.\n\n        Returns:\n            int: The number of documents in the store.\n        \"\"\"\n\n        with self._get_connection() as conn:\n            with conn.cursor() as cur:\n                query = SQL(\"SELECT COUNT(*) FROM {schema_name}.{table_name}\").format(\n                    schema_name=Identifier(self.schema_name), table_name=Identifier(self.table_name)\n                )\n                result = self._execute_sql_query(query, cursor=cur)\n                return result.fetchone()[0]\n\n    def write_documents(\n        self, documents: list[Document], content_key: str | None = None, embedding_key: str | None = None\n    ) -&gt; int:\n        \"\"\"\n        Write documents to the pgvector vector store.\n\n        Args:\n            documents (list[Document]): List of Document objects to write.\n\n        Returns:\n            int: Number of documents successfully written.\n\n        Raises:\n            ValueError: If documents are not of type Document.\n        \"\"\"\n\n        if not documents:\n            return 0\n\n        if len(documents) &gt; 0 and not isinstance(documents[0], Document):\n            msg = \"param 'documents' must contain a list of objects of type Document\"\n            raise ValueError(msg)\n\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n\n        with self._get_connection() as conn:\n            with conn.cursor() as cur:\n                written = 0\n                for doc in documents:\n                    query = SQL(\n                        \"\"\"\n                        INSERT INTO {schema_name}.{table_name} (id, {content_key}, metadata, {embedding_key})\n                        VALUES (%s, %s, %s, %s)\n                        ON CONFLICT (id) DO UPDATE\n                        SET {content_key} = EXCLUDED.{content_key},\n                        metadata = EXCLUDED.metadata,\n                        {embedding_key} = EXCLUDED.{embedding_key};\n                        \"\"\"\n                    ).format(\n                        schema_name=Identifier(self.schema_name),\n                        table_name=Identifier(self.table_name),\n                        content_key=Identifier(content_key),\n                        embedding_key=Identifier(embedding_key),\n                    )\n                    self._execute_sql_query(\n                        query, (doc.id, doc.content, Jsonb(doc.metadata), doc.embedding), cursor=cur\n                    )\n                    self._track_documents([doc.id])\n                    written += 1\n                conn.commit()\n                return written\n\n    def delete_documents_by_filters(self, filters: dict[str, Any], top_k: int = 1000) -&gt; None:\n        \"\"\"\n        Delete documents from the pgvector vector store using filters.\n\n        Args:\n            filters (dict[str, Any]): Filters to select documents to delete.\n        \"\"\"\n        if filters:\n            with self._get_connection() as conn:\n                with conn.cursor() as cur:\n                    sql_where_clause, params = _convert_filters_to_query(filters)\n                    query = SQL(\"DELETE FROM {schema_name}.{table_name}\").format(\n                        schema_name=Identifier(self.schema_name),\n                        table_name=Identifier(self.table_name),\n                        sql_where_clause=sql_where_clause,\n                    )\n                    query += sql_where_clause\n                    self._execute_sql_query(query, params, cursor=cur)\n                    conn.commit()\n        else:\n            logger.warning(\"No filters provided. No documents will be deleted.\")\n\n    def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n        \"\"\"\n        Delete documents from the pgvector vector store.\n\n        Args:\n            document_ids (list[str]): List of document IDs to delete. Defaults to None.\n            delete_all (bool): If True, delete all documents. Defaults to False.\n        \"\"\"\n        if delete_all:\n            with self._get_connection() as conn:\n                with conn.cursor() as cur:\n                    query = SQL(\"DELETE FROM {schema_name}.{table_name}\").format(\n                        schema_name=Identifier(self.schema_name), table_name=Identifier(self.table_name)\n                    )\n                    self._execute_sql_query(query, cursor=cur)\n                    conn.commit()\n        else:\n            if not document_ids:\n                logger.warning(\"No document IDs provided. No documents will be deleted.\")\n            else:\n                with self._get_connection() as conn:\n                    with conn.cursor() as cur:\n                        query = SQL(\"DELETE FROM {schema_name}.{table_name} WHERE id = ANY(%s::text[])\").format(\n                            schema_name=Identifier(self.schema_name), table_name=Identifier(self.table_name)\n                        )\n                        self._execute_sql_query(query, (document_ids,), cursor=cur)\n                        conn.commit()\n\n    def list_documents(\n        self, include_embeddings: bool = False, content_key: str | None = None, embedding_key: str | None = None\n    ) -&gt; list[Document]:\n        \"\"\"\n        List documents in the pgvector vector store.\n\n        Args:\n            include_embeddings (bool): Whether to include embeddings in the results. Defaults to False.\n            content_key (str): The field used to store content in the storage. Defaults to None.\n            embedding_key (str): The field used to store embeddings in the storage. Defaults to None.\n\n        Returns:\n            list[Document]: List of Document objects retrieved.\n        \"\"\"\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n\n        select_fields = f\"id, {content_key}, metadata\" + (f\", {embedding_key}\" if include_embeddings else \"\")\n        with self._get_connection() as conn:\n            with conn.cursor(row_factory=dict_row) as cur:\n                query = SQL(\"SELECT {select_fields} FROM {schema_name}.{table_name}\").format(\n                    select_fields=SQL(select_fields),\n                    schema_name=Identifier(self.schema_name),\n                    table_name=Identifier(self.table_name),\n                )\n                result = self._execute_sql_query(query, cursor=cur)\n                records = result.fetchall()\n\n                documents = self._convert_query_result_to_documents(records)\n                return documents\n\n    def _convert_query_result_to_documents(\n        self,\n        query_result: dict[str, Any],\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Convert pgvector query results to Document objects.\n\n        Args:\n            query_result (dict[str, Any]): The query result from pgvector.\n            content_key (str): The field used to store content in the storage. Defaults to None.\n            embedding_key (str): The field used to store embeddings in the storage. Defaults to None.\n\n        Returns:\n            list[Document]: List of Document objects created from the query result.\n        \"\"\"\n        documents = []\n\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n\n        for doc in query_result:\n            document = Document(\n                id=doc[\"id\"],\n                content=doc[content_key],\n                metadata=doc[\"metadata\"],\n            )\n\n            if doc.get(embedding_key) is not None:\n                document.embedding = self._convert_pg_embedding_to_list(doc[embedding_key])\n            else:\n                document.embedding = None\n\n            if doc.get(\"score\") is not None:\n                document.score = doc[\"score\"]\n\n                if isinstance(doc[\"score\"], Decimal):\n                    document.score = float(doc[\"score\"])\n            else:\n                document.score = None\n\n            documents.append(document)\n        return documents\n\n    def _convert_pg_embedding_to_list(self, pg_embedding: Any) -&gt; list[float]:\n        \"\"\"\n        Helper method to convert a pgvector embedding type to a list of floats.\n        e.g. '[0.1,0.2,0.3]' -&gt; [0.1, 0.2, 0.3]\n\n        Args:\n            pg_embedding (Any): The pgvector embedding.\n\n        Returns:\n            list[float]: The embedding as a list of floats.\n        \"\"\"\n\n        if isinstance(pg_embedding, str):\n            return [float(x) for x in pg_embedding.strip(\"[]\").split(\",\") if x]\n        return pg_embedding\n\n    def _convert_query_embedding_to_pgvector_format(self, query_embedding: list[float]) -&gt; str:\n        \"\"\"\n        Helper method to convert query embedding to pgvector format.\n        e.g. [0.1, 0.2, 0.3] -&gt; '[0.1,0.2,0.3]'\n\n        Args:\n            query_embedding (list[float]): The query embedding vector.\n\n        Returns:\n            str: The query embedding in pgvector format (e.g. '[0.1,0.2,0.3]').\n        \"\"\"\n        return f\"'[{','.join(str(el) for el in query_embedding)}]'\"\n\n    def _embedding_retrieval(\n        self,\n        query_embedding: list[float],\n        top_k: int = 10,\n        exclude_document_embeddings: bool = True,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Retrieve documents similar to the given query embedding.\n\n        Args:\n            query_embedding (list[float]): The query embedding vector.\n            filters (dict[str, Any] | None): Filters for the query. Defaults to None.\n            top_k (int): Maximum number of documents to retrieve. Defaults to 10.\n            exclude_document_embeddings (bool): Whether to exclude embeddings in results. Defaults to True.\n            content_key (str): The field used to store content in the storage. Defaults to None.\n            embedding_key (str): The field used to store embeddings in the storage. Defaults to None.\n\n        Returns:\n            list[Document]: List of retrieved Document objects.\n\n        Raises:\n            ValueError: If query_embedding is empty or filter format is incorrect.\n        \"\"\"\n        if not query_embedding:\n            msg = \"query_embedding must be a non-empty list\"\n            raise ValueError(msg)\n\n        if len(query_embedding) != self.dimension:\n            msg = f\"query_embedding must be of dimension {self.dimension}\"\n            raise ValueError(msg)\n\n        vector_function = self.vector_function\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n\n        if vector_function not in PGVectorVectorFunction:\n            msg = f\"Invalid vector function: {vector_function}\"\n            raise ValueError(msg)\n\n        query_embedding = self._convert_query_embedding_to_pgvector_format(query_embedding)\n\n        # Generate the score calculation based on the vector function\n        score_definition = VECTOR_FUNCTION_TO_SCORE_DEFINITION[vector_function].format(\n            embedding_key=embedding_key, query_embedding=query_embedding\n        )\n        score_definition = f\"{score_definition} AS score\"\n\n        # Do not select the embeddings if exclude_document_embeddings is True\n        select_fields = f\"id, {content_key}, metadata\" if exclude_document_embeddings else \"*\"\n\n        # Build the base SELECT query with score\n        base_select = SQL(\"SELECT {fields}, {score} FROM {schema_name}.{table_name}\").format(\n            fields=SQL(select_fields),\n            score=SQL(score_definition),\n            schema_name=Identifier(self.schema_name),\n            table_name=Identifier(self.table_name),\n        )\n\n        # Handle filters if they exist\n        where_clause = SQL(\"\")\n        params = ()\n        if filters:\n            where_clause, params = _convert_filters_to_query(filters)\n\n        # Determine sort order based on vector function type\n        is_distance_metric = vector_function in [\"l2_distance\", \"l1_distance\"]\n\n        # Sort by score in ascending order if using a distance metric\n        # as the smaller the distance, the more similar the vectors are\n        sort_order = \"ASC\" if is_distance_metric else \"DESC\"\n\n        # Build the ORDER BY and LIMIT clause\n        order_by = SQL(\" ORDER BY score {sort_order} LIMIT {limit}\").format(\n            sort_order=SQL(sort_order), limit=SQLLiteral(top_k)\n        )\n\n        # Combine all parts into final query\n        sql_query = base_select + where_clause + order_by\n\n        with self._get_connection() as conn:\n            with conn.cursor(row_factory=dict_row) as cur:\n                result = self._execute_sql_query(sql_query, params, cursor=cur)\n                records = result.fetchall()\n\n                documents = self._convert_query_result_to_documents(records)\n                return documents\n\n    def _keyword_retrieval(\n        self,\n        query: str,\n        top_k: int = 10,\n        exclude_document_embeddings: bool = True,\n        filters: dict[str, Any] | None = None,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Retrieve documents similar to the given query using keyword search.\n\n        Args:\n            query (str): The query string.\n            filters (dict[str, Any] | None): Filters for the query. Defaults to None.\n            top_k (int): Maximum number of documents to retrieve. Defaults to 10.\n            exclude_document_embeddings (bool): Whether to exclude embeddings in results. Defaults to True.\n            content_key (str): The field used to store content in the storage. Defaults to None.\n            embedding_key (str): The field used to store embeddings in the storage. Defaults to None.\n\n        Returns:\n            list[Document]: List of retrieved Document objects.\n\n        Raises:\n            ValueError: If query is empty or filter format is incorrect.\n        \"\"\"\n        if not query:\n            msg = \"query must be provided for keyword retrieval\"\n            raise ValueError(msg)\n\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n\n        # Do not select the embeddings if exclude_document_embeddings is True\n        select_fields = f\"id, {content_key}, metadata\" if exclude_document_embeddings else \"*\"\n\n        # Build the base SELECT query with score\n        base_select = SQL(\n            \"\"\"\n            SELECT {fields}, ts_rank_cd(to_tsvector({language}, {content_key}), query) AS score\n            FROM {schema_name}.{table_name}, plainto_tsquery({language}, %s) query\n            WHERE to_tsvector({language}, {content_key}) @@ query\n            \"\"\"\n        ).format(\n            fields=SQL(select_fields),\n            schema_name=Identifier(self.schema_name),\n            table_name=Identifier(self.table_name),\n            language=SQLLiteral(self.language),\n            content_key=Identifier(content_key),\n        )\n\n        # Handle filters if they exist\n        where_clause = SQL(\"\")\n        params = ()\n        if filters:\n            where_clause, params = _convert_filters_to_query(filters)\n\n            where_clause = SQL(where_clause.as_string().replace(\"WHERE\", \"AND\"))\n\n        # Build the ORDER BY and LIMIT clause\n        order_by = SQL(\" ORDER BY score DESC LIMIT {limit}\").format(limit=SQLLiteral(top_k))\n\n        # Combine all parts into final query\n        sql_query = base_select + where_clause + order_by\n\n        with self._get_connection() as conn:\n            with conn.cursor(row_factory=dict_row) as cur:\n                result = self._execute_sql_query(sql_query, (query, *params), cursor=cur)\n                records = result.fetchall()\n\n                documents = self._convert_query_result_to_documents(records)\n                return documents\n\n    def _hybrid_retrieval(\n        self,\n        query: str,\n        query_embedding: list[float],\n        top_k: int = 10,\n        exclude_document_embeddings: bool = True,\n        keyword_rank_constant: int = 40,\n        top_k_subquery_multiplier: int = 4,\n        filters: dict[str, Any] | None = None,\n        alpha: float = 0.5,\n        content_key: str | None = None,\n        embedding_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Retrieve documents similar to the given query using a hybrid approach.\n\n        Args:\n            query (str): The query string.\n            query_embedding (list[float] | None): The query embedding vector. Defaults to None.\n            filters (dict[str, Any] | None): Filters for the query. Defaults to None.\n            top_k (int): Maximum number of documents to retrieve. Defaults to 10.\n            alpha (float): The weight to give to the keyword search. Defaults to 0.5.\n            content_key (str): The field used to store content in the storage. Defaults to None.\n            embedding_key (str): The field used to store embeddings in the storage. Defaults to None.\n\n        Returns:\n            list[Document]: List of retrieved Document objects.\n\n        Raises:\n            ValueError: If query_embedding is empty or filter format is incorrect.\n        \"\"\"\n\n        if not query:\n            msg = \"query must be provided for hybrid retrieval\"\n            raise ValueError(msg)\n\n        if query_embedding and len(query_embedding) != self.dimension:\n            msg = f\"query_embedding must be of dimension {self.dimension}\"\n            raise ValueError(msg)\n\n        vector_function = self.vector_function\n        content_key = content_key or self.content_key\n        embedding_key = embedding_key or self.embedding_key\n        query = query or self.query\n\n        # If alpha is 0, perform purely keyword search\n        if alpha == 0:\n            return self._keyword_retrieval(\n                query,\n                top_k=top_k,\n                exclude_document_embeddings=exclude_document_embeddings,\n                filters=filters,\n                content_key=content_key,\n                embedding_key=embedding_key,\n            )\n        # If alpha is 1, perform purely embedding search\n        elif alpha == 1:\n            return self._embedding_retrieval(\n                query_embedding,\n                top_k=top_k,\n                exclude_document_embeddings=exclude_document_embeddings,\n                filters=filters,\n                content_key=content_key,\n                embedding_key=embedding_key,\n            )\n\n        query_embedding = self._convert_query_embedding_to_pgvector_format(query_embedding)\n\n        # Generate the score calculation based on the vector function\n        score_definition = VECTOR_FUNCTION_TO_SCORE_DEFINITION[vector_function].format(\n            embedding_key=embedding_key, query_embedding=query_embedding\n        )\n\n        # Determine sort order based on vector function type\n        is_distance_metric = vector_function in [\"l2_distance\", \"l1_distance\"]\n\n        # Sort by score in ascending order if using a distance metric\n        # as the smaller the distance, the more similar the vectors are\n        sort_order = \"ASC\" if is_distance_metric else \"DESC\"\n\n        # Set the limit for the subquery to top_k multiplied by a constant to ensure enough results\n        top_k_subquery_limit = top_k * top_k_subquery_multiplier\n\n        # Extract the filters from the query\n        where_clause = SQL(\"\")\n        where_clause_for_keyword_search = SQL(\"\")\n        params = ()\n        if filters:\n            where_clause, params = _convert_filters_to_query(filters)\n\n            where_clause_for_keyword_search = SQL(where_clause.as_string().replace(\"WHERE\", \"AND\"))\n\n        # Build the semantic search query with rank and filters\n        semantic_search_query = SQL(\n            \"\"\"\n            WITH semantic_search AS (\n                SELECT *, RANK() OVER (ORDER BY {score_definition} {sort_order}) AS rank\n                FROM {schema_name}.{table_name}\n                {where_clause}\n                LIMIT {top_k_limit}\n            ),\n            \"\"\"\n        ).format(\n            score_definition=SQL(score_definition),\n            schema_name=Identifier(self.schema_name),\n            table_name=Identifier(self.table_name),\n            top_k_limit=SQLLiteral(top_k_subquery_limit),\n            sort_order=SQL(sort_order),\n            where_clause=where_clause,\n        )\n\n        # Build the keyword search query with filters\n        keyword_search_query = SQL(\n            \"\"\"\n            keyword_search AS (\n                SELECT *, RANK() OVER (ORDER BY ts_rank_cd(to_tsvector({language}, {content_key}), query) DESC) AS rank\n                FROM {schema_name}.{table_name}, plainto_tsquery({language}, {query}) query\n                WHERE to_tsvector('english', {content_key}) @@ query\n                {where_clause_for_keyword_search}\n                LIMIT {top_k_limit}\n            )\n            \"\"\"\n        ).format(\n            schema_name=Identifier(self.schema_name),\n            table_name=Identifier(self.table_name),\n            content_key=Identifier(content_key),\n            language=SQLLiteral(self.language),\n            query=SQLLiteral(query),\n            top_k_limit=SQLLiteral(top_k_subquery_limit),\n            where_clause_for_keyword_search=where_clause_for_keyword_search,\n        )\n\n        embedding_key_select = (\n            \"\"\n            if exclude_document_embeddings\n            else \"COALESCE(semantic_search.{embedding_key}, keyword_search.{embedding_key}) AS {embedding_key},\"\n        )\n\n        # Build the final query to merge the results and sort them by score\n        merge_query = SQL(\n            \"\"\"\n            SELECT\n                COALESCE(semantic_search.id, keyword_search.id) AS id,\n                COALESCE(semantic_search.{content_key}, keyword_search.{content_key}) AS {content_key},\n                COALESCE(semantic_search.metadata, keyword_search.metadata) AS metadata,\n                {embedding_key_select}\n                COALESCE({alpha} / ({k} + semantic_search.rank), 0.0) +\n                COALESCE((1 - {alpha}) / ({k} + keyword_search.rank), 0.0) AS score\n            FROM semantic_search\n            FULL OUTER JOIN keyword_search ON semantic_search.id = keyword_search.id\n            ORDER BY score DESC\n            LIMIT {top_k}\n            \"\"\"\n        ).format(\n            content_key=Identifier(content_key),\n            top_k=SQLLiteral(top_k),\n            alpha=SQLLiteral(alpha),\n            k=SQLLiteral(keyword_rank_constant),\n            embedding_key_select=SQL(embedding_key_select),\n        )\n\n        sql_query = semantic_search_query + keyword_search_query + merge_query\n\n        params = params + params\n\n        with self._get_connection() as conn:\n            with conn.cursor(row_factory=dict_row) as cur:\n                result = self._execute_sql_query(sql_query, params, cursor=cur)\n                records = result.fetchall()\n\n                documents = self._convert_query_result_to_documents(records)\n                return documents\n\n    def close(self):\n        \"\"\"Close the connection to the PostgreSQL database.\"\"\"\n        if hasattr(self, \"_conn\") and self._conn is not None and not self._conn.closed:\n            self._conn.close()\n\n    def __del__(self):\n        \"\"\"Close the connection when the object is deleted.\"\"\"\n        self.close()\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.__del__","title":"<code>__del__()</code>","text":"<p>Close the connection when the object is deleted.</p> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def __del__(self):\n    \"\"\"Close the connection when the object is deleted.\"\"\"\n    self.close()\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.__init__","title":"<code>__init__(connection=None, client=None, create_extension=True, table_name=DEFAULT_TABLE_NAME, schema_name=DEFAULT_SCHEMA_NAME, dimension=1536, vector_function=PGVectorVectorFunction.COSINE_SIMILARITY, index_method=PGVectorIndexMethod.EXACT, index_name=DEFAULT_INDEX_NAME, create_if_not_exist=False, content_key='content', embedding_key='embedding', keyword_index_name=DEFAULT_KEYWORD_INDEX_NAME, language=DEFAULT_LANGUAGE, dry_run_config=None)</code>","text":"<p>Initialize a PGVectorStore instance.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>PostgreSQL | str</code> <p>PostgreSQL connection instance. Defaults to None.</p> <code>None</code> <code>client</code> <code>Optional[PostgreSQL]</code> <p>PostgreSQL client instance. Defaults to None.</p> <code>None</code> <code>create_extension</code> <code>bool</code> <p>Whether to create the vector extension (if it does not exist). Defaults to True.</p> <code>True</code> <code>table_name</code> <code>str</code> <p>Name of the table in the database. Defaults to None.</p> <code>DEFAULT_TABLE_NAME</code> <code>schema_name</code> <code>str</code> <p>Name of the schema in the database. Defaults to None.</p> <code>DEFAULT_SCHEMA_NAME</code> <code>dimension</code> <code>int</code> <p>Dimension of the embeddings. Defaults to 1536.</p> <code>1536</code> <code>vector_function</code> <code>PGVectorVectorFunction</code> <p>The vector function to use for similarity calculations. Defaults to 'cosine_similarity'.</p> <code>COSINE_SIMILARITY</code> <code>index_method</code> <code>PGVectorIndexMethod</code> <p>The index method to use for the vector store. Defaults to 'exact_nearest_neighbor_search'.</p> <code>EXACT</code> <code>index_name</code> <code>str</code> <p>Name of the index to create. Defaults to None.</p> <code>DEFAULT_INDEX_NAME</code> <code>create_if_not_exist</code> <code>bool</code> <p>Whether to create the table and index if they do not exist. Defaults to False.</p> <code>False</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage. Defaults to 'content'.</p> <code>'content'</code> <code>embedding_key</code> <code>Optional[str]</code> <p>The field used to store embeddings in the storage. Defaults to 'embedding'.</p> <code>'embedding'</code> <code>dry_run_config</code> <code>Optional[DryRunConfig]</code> <p>Configuration for dry run mode. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def __init__(\n    self,\n    connection: PostgreSQL | str | None = None,\n    client: Optional[\"PsycopgConnection\"] = None,\n    create_extension: bool = True,\n    table_name: str = DEFAULT_TABLE_NAME,\n    schema_name: str = DEFAULT_SCHEMA_NAME,\n    dimension: int = 1536,\n    vector_function: PGVectorVectorFunction = PGVectorVectorFunction.COSINE_SIMILARITY,\n    index_method: PGVectorIndexMethod = PGVectorIndexMethod.EXACT,\n    index_name: str = DEFAULT_INDEX_NAME,\n    create_if_not_exist: bool = False,\n    content_key: str = \"content\",\n    embedding_key: str = \"embedding\",\n    keyword_index_name: str = DEFAULT_KEYWORD_INDEX_NAME,\n    language: str = DEFAULT_LANGUAGE,\n    dry_run_config: DryRunConfig | None = None,\n):\n    \"\"\"\n    Initialize a PGVectorStore instance.\n\n    Args:\n        connection (PostgreSQL | str): PostgreSQL connection instance. Defaults to None.\n        client (Optional[PostgreSQL]): PostgreSQL client instance. Defaults to None.\n        create_extension (bool): Whether to create the vector extension (if it does not exist). Defaults to True.\n        table_name (str): Name of the table in the database. Defaults to None.\n        schema_name (str): Name of the schema in the database. Defaults to None.\n        dimension (int): Dimension of the embeddings. Defaults to 1536.\n        vector_function (PGVectorVectorFunction): The vector function to use for similarity calculations.\n            Defaults to 'cosine_similarity'.\n        index_method (PGVectorIndexMethod): The index method to use for the vector store.\n            Defaults to 'exact_nearest_neighbor_search'.\n        index_name (str): Name of the index to create. Defaults to None.\n        create_if_not_exist (bool): Whether to create the table and index if they do not exist. Defaults to False.\n        content_key (Optional[str]): The field used to store content in the storage. Defaults to 'content'.\n        embedding_key (Optional[str]): The field used to store embeddings in the storage. Defaults to 'embedding'.\n        dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n    \"\"\"\n    super().__init__(dry_run_config=dry_run_config)\n\n    if vector_function not in PGVectorVectorFunction:\n        raise ValueError(f\"vector_function must be one of {list(PGVectorVectorFunction)}\")\n    if index_method is not None and index_method not in PGVectorIndexMethod:\n        raise ValueError(f\"index_method must be one of {list(PGVectorIndexMethod)}\")\n\n    if client is None or client.closed:\n        if isinstance(connection, str):\n            self.connection_string = connection\n            self._conn = psycopg.connect(self.connection_string)\n            self.client = self._conn\n        elif isinstance(connection, PostgreSQL):\n            self._conn = connection.connect()\n            self.connection_string = connection.conn_params\n            self.client = self._conn\n        else:\n            raise ValueError(\"connection must be a string or PostgreSQL object\")\n    else:\n        self._conn = client\n\n    self.create_extension = create_extension\n    if self.create_extension:\n        self._conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n        self._conn.commit()\n\n    register_vector(self._conn)\n\n    self.table_name = table_name\n    self.schema_name = schema_name\n    self.dimension = dimension\n    self.index_method = index_method\n    self.vector_function = vector_function\n    self.keyword_index_name = keyword_index_name\n    self.language = language\n\n    self.content_key = content_key\n    self.embedding_key = embedding_key\n\n    self.create_if_not_exist = create_if_not_exist\n\n    if (\n        self.index_method == PGVectorIndexMethod.IVFFLAT\n        and self.vector_function == PGVectorVectorFunction.L1_DISTANCE\n    ):\n        msg = \"IVFFLAT index does not support L1 distance metric\"\n        raise VectorStoreException(msg)\n\n    if self.create_if_not_exist:\n        with self._get_connection() as conn:\n\n            if not self._check_if_table_exists(conn) and not self._check_if_schema_exists(conn):\n                self._track_collection(f\"{self.schema_name}.{self.table_name}\")\n\n            self._create_schema(conn)\n            self._create_tables(conn)\n            if self.index_method in [PGVectorIndexMethod.IVFFLAT, PGVectorIndexMethod.HNSW]:\n                self.index_name = index_name or f\"{self.index_method}_index\"\n                self._create_index(conn)\n            self._create_keyword_index(conn)\n    else:\n        if not self._check_if_schema_exists(self._conn):\n            msg = f\"Schema '{self.schema_name}' does not exist\"\n            raise VectorStoreException(msg)\n        if not self._check_if_table_exists(self._conn):\n            msg = f\"Table '{self.table_name}' does not exist\"\n            raise VectorStoreException(msg)\n\n    logger.debug(f\"PGVectorStore initialized with table_name: {self.table_name}\")\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.close","title":"<code>close()</code>","text":"<p>Close the connection to the PostgreSQL database.</p> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def close(self):\n    \"\"\"Close the connection to the PostgreSQL database.\"\"\"\n    if hasattr(self, \"_conn\") and self._conn is not None and not self._conn.closed:\n        self._conn.close()\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.count_documents","title":"<code>count_documents()</code>","text":"<p>Count the number of documents in the store.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents in the store.</p> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def count_documents(self) -&gt; int:\n    \"\"\"\n    Count the number of documents in the store.\n\n    Returns:\n        int: The number of documents in the store.\n    \"\"\"\n\n    with self._get_connection() as conn:\n        with conn.cursor() as cur:\n            query = SQL(\"SELECT COUNT(*) FROM {schema_name}.{table_name}\").format(\n                schema_name=Identifier(self.schema_name), table_name=Identifier(self.table_name)\n            )\n            result = self._execute_sql_query(query, cursor=cur)\n            return result.fetchone()[0]\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.delete_collection","title":"<code>delete_collection(collection_name=None)</code>","text":"<p>Delete the collection in the database.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str | None</code> <p>Name of the collection to delete.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def delete_collection(self, collection_name: str | None = None) -&gt; None:\n    \"\"\"\n    Delete the collection in the database.\n\n    Args:\n        collection_name (str | None): Name of the collection to delete.\n    \"\"\"\n    try:\n        with self._get_connection() as conn:\n            self._drop_tables(conn)\n            if self.schema_name and self.schema_name != DEFAULT_SCHEMA_NAME:\n                self._drop_schema(conn)\n    except Exception as e:\n        logger.error(f\"Failed to delete collection '{self.schema_name}.{self.table_name}': {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.delete_documents","title":"<code>delete_documents(document_ids=None, delete_all=False)</code>","text":"<p>Delete documents from the pgvector vector store.</p> <p>Parameters:</p> Name Type Description Default <code>document_ids</code> <code>list[str]</code> <p>List of document IDs to delete. Defaults to None.</p> <code>None</code> <code>delete_all</code> <code>bool</code> <p>If True, delete all documents. Defaults to False.</p> <code>False</code> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n    \"\"\"\n    Delete documents from the pgvector vector store.\n\n    Args:\n        document_ids (list[str]): List of document IDs to delete. Defaults to None.\n        delete_all (bool): If True, delete all documents. Defaults to False.\n    \"\"\"\n    if delete_all:\n        with self._get_connection() as conn:\n            with conn.cursor() as cur:\n                query = SQL(\"DELETE FROM {schema_name}.{table_name}\").format(\n                    schema_name=Identifier(self.schema_name), table_name=Identifier(self.table_name)\n                )\n                self._execute_sql_query(query, cursor=cur)\n                conn.commit()\n    else:\n        if not document_ids:\n            logger.warning(\"No document IDs provided. No documents will be deleted.\")\n        else:\n            with self._get_connection() as conn:\n                with conn.cursor() as cur:\n                    query = SQL(\"DELETE FROM {schema_name}.{table_name} WHERE id = ANY(%s::text[])\").format(\n                        schema_name=Identifier(self.schema_name), table_name=Identifier(self.table_name)\n                    )\n                    self._execute_sql_query(query, (document_ids,), cursor=cur)\n                    conn.commit()\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.delete_documents_by_filters","title":"<code>delete_documents_by_filters(filters, top_k=1000)</code>","text":"<p>Delete documents from the pgvector vector store using filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any]</code> <p>Filters to select documents to delete.</p> required Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def delete_documents_by_filters(self, filters: dict[str, Any], top_k: int = 1000) -&gt; None:\n    \"\"\"\n    Delete documents from the pgvector vector store using filters.\n\n    Args:\n        filters (dict[str, Any]): Filters to select documents to delete.\n    \"\"\"\n    if filters:\n        with self._get_connection() as conn:\n            with conn.cursor() as cur:\n                sql_where_clause, params = _convert_filters_to_query(filters)\n                query = SQL(\"DELETE FROM {schema_name}.{table_name}\").format(\n                    schema_name=Identifier(self.schema_name),\n                    table_name=Identifier(self.table_name),\n                    sql_where_clause=sql_where_clause,\n                )\n                query += sql_where_clause\n                self._execute_sql_query(query, params, cursor=cur)\n                conn.commit()\n    else:\n        logger.warning(\"No filters provided. No documents will be deleted.\")\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.list_documents","title":"<code>list_documents(include_embeddings=False, content_key=None, embedding_key=None)</code>","text":"<p>List documents in the pgvector vector store.</p> <p>Parameters:</p> Name Type Description Default <code>include_embeddings</code> <code>bool</code> <p>Whether to include embeddings in the results. Defaults to False.</p> <code>False</code> <code>content_key</code> <code>str</code> <p>The field used to store content in the storage. Defaults to None.</p> <code>None</code> <code>embedding_key</code> <code>str</code> <p>The field used to store embeddings in the storage. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: List of Document objects retrieved.</p> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def list_documents(\n    self, include_embeddings: bool = False, content_key: str | None = None, embedding_key: str | None = None\n) -&gt; list[Document]:\n    \"\"\"\n    List documents in the pgvector vector store.\n\n    Args:\n        include_embeddings (bool): Whether to include embeddings in the results. Defaults to False.\n        content_key (str): The field used to store content in the storage. Defaults to None.\n        embedding_key (str): The field used to store embeddings in the storage. Defaults to None.\n\n    Returns:\n        list[Document]: List of Document objects retrieved.\n    \"\"\"\n    content_key = content_key or self.content_key\n    embedding_key = embedding_key or self.embedding_key\n\n    select_fields = f\"id, {content_key}, metadata\" + (f\", {embedding_key}\" if include_embeddings else \"\")\n    with self._get_connection() as conn:\n        with conn.cursor(row_factory=dict_row) as cur:\n            query = SQL(\"SELECT {select_fields} FROM {schema_name}.{table_name}\").format(\n                select_fields=SQL(select_fields),\n                schema_name=Identifier(self.schema_name),\n                table_name=Identifier(self.table_name),\n            )\n            result = self._execute_sql_query(query, cursor=cur)\n            records = result.fetchall()\n\n            documents = self._convert_query_result_to_documents(records)\n            return documents\n</code></pre>"},{"location":"dynamiq/storages/vector/pgvector/pgvector/#dynamiq.storages.vector.pgvector.pgvector.PGVectorStore.write_documents","title":"<code>write_documents(documents, content_key=None, embedding_key=None)</code>","text":"<p>Write documents to the pgvector vector store.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>List of Document objects to write.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of documents successfully written.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If documents are not of type Document.</p> Source code in <code>dynamiq/storages/vector/pgvector/pgvector.py</code> <pre><code>def write_documents(\n    self, documents: list[Document], content_key: str | None = None, embedding_key: str | None = None\n) -&gt; int:\n    \"\"\"\n    Write documents to the pgvector vector store.\n\n    Args:\n        documents (list[Document]): List of Document objects to write.\n\n    Returns:\n        int: Number of documents successfully written.\n\n    Raises:\n        ValueError: If documents are not of type Document.\n    \"\"\"\n\n    if not documents:\n        return 0\n\n    if len(documents) &gt; 0 and not isinstance(documents[0], Document):\n        msg = \"param 'documents' must contain a list of objects of type Document\"\n        raise ValueError(msg)\n\n    content_key = content_key or self.content_key\n    embedding_key = embedding_key or self.embedding_key\n\n    with self._get_connection() as conn:\n        with conn.cursor() as cur:\n            written = 0\n            for doc in documents:\n                query = SQL(\n                    \"\"\"\n                    INSERT INTO {schema_name}.{table_name} (id, {content_key}, metadata, {embedding_key})\n                    VALUES (%s, %s, %s, %s)\n                    ON CONFLICT (id) DO UPDATE\n                    SET {content_key} = EXCLUDED.{content_key},\n                    metadata = EXCLUDED.metadata,\n                    {embedding_key} = EXCLUDED.{embedding_key};\n                    \"\"\"\n                ).format(\n                    schema_name=Identifier(self.schema_name),\n                    table_name=Identifier(self.table_name),\n                    content_key=Identifier(content_key),\n                    embedding_key=Identifier(embedding_key),\n                )\n                self._execute_sql_query(\n                    query, (doc.id, doc.content, Jsonb(doc.metadata), doc.embedding), cursor=cur\n                )\n                self._track_documents([doc.id])\n                written += 1\n            conn.commit()\n            return written\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/filters/","title":"Filters","text":""},{"location":"dynamiq/storages/vector/pinecone/pinecone/","title":"Pinecone","text":""},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeIndexType","title":"<code>PineconeIndexType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Pinecone index deployment types.</p> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>class PineconeIndexType(str, enum.Enum):\n    \"\"\"Pinecone index deployment types.\"\"\"\n\n    SERVERLESS = \"serverless\"\n    POD = \"pod\"\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeSimilarityMetric","title":"<code>PineconeSimilarityMetric</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Supported Pinecone similarity metrics.</p> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>class PineconeSimilarityMetric(str, enum.Enum):\n    \"\"\"Supported Pinecone similarity metrics.\"\"\"\n\n    COSINE = \"cosine\"\n    EUCLIDEAN = \"euclidean\"\n    DOT_PRODUCT = \"dotproduct\"\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore","title":"<code>PineconeVectorStore</code>","text":"<p>               Bases: <code>BaseVectorStore</code>, <code>DryRunMixin</code></p> <p>Vector store using Pinecone.</p> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>class PineconeVectorStore(BaseVectorStore, DryRunMixin):\n    \"\"\"Vector store using Pinecone.\"\"\"\n\n    def __init__(\n        self,\n        connection: Pinecone | None = None,\n        client: Optional[\"PineconeClient\"] = None,\n        index_name: str = \"default\",\n        namespace: str = \"default\",\n        batch_size: int = 100,\n        dimension: int = 1536,\n        metric: PineconeSimilarityMetric = PineconeSimilarityMetric.COSINE,\n        create_if_not_exist: bool = False,\n        index_type: PineconeIndexType | None = None,\n        cloud: str | None = None,\n        region: str | None = None,\n        environment: str | None = None,\n        pod_type: str | None = None,\n        pods: int = 1,\n        content_key: str = \"content\",\n        dry_run_config: DryRunConfig | None = None,\n        **index_creation_kwargs,\n    ):\n        \"\"\"\n        Initialize a PineconeVectorStore instance.\n\n        Args:\n            connection (Optional[Pinecone]): Pinecone connection instance. Defaults to None.\n            client (Optional[PineconeClient]): Pinecone client instance. Defaults to None.\n            index_name (str): Name of the Pinecone index. Defaults to None.\n            namespace (str): Namespace for the index. Defaults to 'default'.\n            batch_size (int): Size of batches for operations. Defaults to 100.\n            dimension (int): Number of dimensions for vectors. Defaults to 1536.\n            metric (PineconeSimilarityMetric): Metric for calculating vector similarity. Defaults to 'cosine'.\n            content_key (Optional[str]): The field used to store content in the storage. Defaults to 'content'.\n            dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n            **index_creation_kwargs: Additional arguments for index creation.\n        \"\"\"\n        super().__init__(dry_run_config=dry_run_config)\n\n        self.client = client\n        if self.client is None:\n            if connection is None:\n                connection = Pinecone()\n            self.client = connection.connect()\n\n        self.index_name = validate_pinecone_index_name(index_name)\n        self.namespace = namespace\n        self.index_type = index_type\n        self.content_key = content_key\n\n        self.create_if_not_exist = create_if_not_exist\n\n        self.batch_size = batch_size\n\n        self.metric = metric\n        self.dimension = dimension\n        self.cloud = cloud\n        self.region = region\n        self.environment = environment\n        self.pod_type = pod_type\n        self.pods = pods\n\n        self.index_creation_kwargs = index_creation_kwargs\n\n        self._spec = self._get_spec()\n        self._dummy_vector = [-10.0] * dimension\n        self._index = self.connect_to_index()\n        logger.debug(f\"PineconeVectorStore initialized with index {self.index_name} and namespace {self.namespace}.\")\n\n    def _get_spec(self):\n        \"\"\"\n        Returns the serverless or pod specification for the Pinecone service.\n\n        Returns:\n            ServerlessSpec | PodSpec | None: The serverless or pod specification.\n        \"\"\"\n        if self.index_type == PineconeIndexType.SERVERLESS:\n            return self.serverless_spec\n        elif self.index_type == PineconeIndexType.POD:\n            return self.pod_spec\n\n    @property\n    def serverless_spec(self):\n        \"\"\"\n        Returns the serverless specification for the Pinecone service.\n\n        Returns:\n            ServerlessSpec: The serverless specification.\n        \"\"\"\n        # Import in runtime to save memory\n        from pinecone import ServerlessSpec\n\n        if self.cloud is None or self.region is None:\n            raise ValueError(\"'cloud' and 'region' must be specified for 'serverless' index\")\n        return ServerlessSpec(cloud=self.cloud, region=self.region)\n\n    @property\n    def pod_spec(self):\n        \"\"\"\n        Returns the pod specification for the Pinecone service.\n\n        Returns:\n            PodSpec: The pod specification.\n        \"\"\"\n        # Import in runtime to save memory\n        from pinecone import PodSpec\n\n        if self.environment is None or self.pod_type is None:\n            raise ValueError(\"'environment' and 'pod_type' must be specified for 'pod' index\")\n\n        return PodSpec(environment=self.environment, pod_type=self.pod_type, pods=self.pods)\n\n    def connect_to_index(self):\n        \"\"\"\n        Create or connect to an existing Pinecone index.\n\n        Returns:\n            The initialized Pinecone index object.\n        \"\"\"\n        try:\n            index = self.client.Index(name=self.index_name)\n            return index\n        except NotFoundException:\n            if self.create_if_not_exist and self.index_type is not None:\n                logger.debug(f\"Index {self.index_name} does not exist. Creating a new index.\")\n                self.client.create_index(\n                    name=self.index_name,\n                    spec=self._spec,\n                    dimension=self.dimension,\n                    metric=self.metric.value,\n                    **self.index_creation_kwargs,\n                )\n                self._track_collection(self.index_name)\n                return self.client.Index(name=self.index_name)\n\n            raise ValueError(\n                f\"Index {self.index_name} does not exist. \"\n                f\"'create_if_not_exist' must be set to True and 'index_type' must be specified.\"\n            )\n\n    def _set_dimension(self, dimension: int):\n        \"\"\"\n        Set the dimension for the index, with a warning if it differs from the actual dimension.\n\n        Args:\n            dimension (int): The desired dimension.\n\n        Returns:\n            int: The actual dimension of the index.\n        \"\"\"\n        actual_dimension = self._index.describe_index_stats().get(\"dimension\")\n        if actual_dimension and actual_dimension != dimension:\n            logger.warning(\n                f\"Dimension of index {self.index_name} is {actual_dimension}, but {dimension} was specified. \"\n                \"The specified dimension will be ignored. \"\n                \"If you need an index with a different dimension, please create a new one.\"\n            )\n        return actual_dimension or dimension\n\n    def delete_index(self, index_name: str | None = None):\n        \"\"\"Delete the entire index.\n\n        Args:\n            index_name (str): Name of the index to delete.\n        \"\"\"\n        try:\n            index_to_delete = index_name or self.index_name\n            self._index.delete(delete_all=True, namespace=self.namespace)\n            self.client.delete_index(index_name=index_to_delete)\n            logger.info(f\"Deleted index '{index_to_delete}'.\")\n        except Exception as e:\n            logger.error(f\"Failed to delete index '{index_to_delete}': {e}\")\n            raise\n\n    def delete_collection(self, collection_name: str | None = None):\n        \"\"\"\n        Delete a Pinecone collection (index).\n\n        Args:\n            collection_name (str | None): Name of the collection to delete. Defaults to None.\n        \"\"\"\n        try:\n            collection_to_delete = collection_name or self.index_name\n            self.delete_index(index_name=collection_to_delete)\n            logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n        except Exception as e:\n            logger.error(f\"Failed to delete index '{collection_name}': {e}\")\n            raise\n\n    def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n        \"\"\"\n        Delete documents from the Pinecone vector store.\n\n        Args:\n            document_ids (list[str]): List of document IDs to delete. Defaults to None.\n            delete_all (bool): If True, delete all documents. Defaults to False.\n        \"\"\"\n        if delete_all and self._index is not None:\n            self._index.delete(delete_all=True, namespace=self.namespace)\n            self._index = self.connect_to_index()\n        else:\n            if not document_ids:\n                logger.warning(\n                    \"No document IDs provided. No documents will be deleted.\"\n                )\n            else:\n                self._index.delete(ids=document_ids, namespace=self.namespace)\n\n    def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n        \"\"\"\n        Delete documents from the Pinecone vector store using filters.\n\n        Args:\n            filters (dict[str, Any]): Filters to select documents to delete.\n        \"\"\"\n        filters = _normalize_filters(filters)\n        self._index.delete(filter=filters, namespace=self.namespace)\n\n    def list_documents(self, include_embeddings: bool = False, content_key: str | None = None) -&gt; list[Document]:\n        \"\"\"\n        List documents in the Pinecone vector store.\n\n        Args:\n            include_embeddings (bool): Whether to include embeddings in the results. Defaults to False.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            list[Document]: List of Document objects retrieved.\n        \"\"\"\n\n        all_documents = []\n        for batch_doc_ids in self._index.list(namespace=self.namespace):\n            response = self._index.fetch(ids=batch_doc_ids, namespace=self.namespace)\n\n            documents = []\n            for pinecone_doc in response[\"vectors\"].values():\n                content = pinecone_doc[\"metadata\"].pop(content_key or self.content_key, \"\")\n\n                embedding = None\n                if include_embeddings and pinecone_doc[\"values\"] != self._dummy_vector:\n                    embedding = pinecone_doc[\"values\"]\n\n                doc = Document(\n                    id=pinecone_doc[\"id\"],\n                    content=content,\n                    metadata=pinecone_doc[\"metadata\"],\n                    embedding=embedding,\n                    score=None,\n                )\n                documents.append(doc)\n\n            all_documents.extend(documents)\n        return all_documents\n\n    def count_documents(self) -&gt; int:\n        \"\"\"\n        Count the number of documents in the store.\n\n        Returns:\n            int: The number of documents in the store.\n        \"\"\"\n        try:\n            count = self._index.describe_index_stats()[\"namespaces\"][self.namespace][\n                \"vector_count\"\n            ]\n        except KeyError:\n            count = 0\n        return count\n\n    def write_documents(self, documents: list[Document], content_key: str | None = None) -&gt; int:\n        \"\"\"\n        Write documents to the Pinecone vector store.\n\n        Args:\n            documents (list[Document]): List of Document objects to write.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            int: Number of documents successfully written.\n\n        Raises:\n            ValueError: If documents are not of type Document.\n        \"\"\"\n        if len(documents) &gt; 0 and not isinstance(documents[0], Document):\n            msg = \"param 'documents' must contain a list of objects of type Document\"\n            raise ValueError(msg)\n\n        self._track_documents([doc.id for doc in documents])\n\n        documents_for_pinecone = self._convert_documents_to_pinecone_format(\n            documents, content_key=content_key or self.content_key\n        )\n\n        result = self._index.upsert(\n            vectors=documents_for_pinecone,\n            namespace=self.namespace,\n            batch_size=self.batch_size,\n        )\n\n        written_docs = result[\"upserted_count\"]\n        return written_docs\n\n    def _convert_documents_to_pinecone_format(\n        self,\n        documents: list[Document],\n        content_key: str | None = None,\n    ) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        Convert Document objects to Pinecone-compatible format.\n\n        Args:\n            documents (list[Document]): List of Document objects to convert.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            list[dict[str, Any]]: List of documents in Pinecone-compatible format.\n        \"\"\"\n        documents_for_pinecone = []\n        for document in documents:\n            embedding = copy(document.embedding)\n            if embedding is None:\n                logger.warning(\n                    f\"Document {document.id} has no embedding. A dummy embedding will be used.\"\n                )\n                embedding = self._dummy_vector\n            doc_for_pinecone = {\n                \"id\": document.id,\n                \"values\": embedding,\n                \"metadata\": dict(document.metadata or {}),\n            }\n\n            if document.content is not None:\n                doc_for_pinecone[\"metadata\"][content_key] = document.content\n\n            documents_for_pinecone.append(doc_for_pinecone)\n        return documents_for_pinecone\n\n    def _embedding_retrieval(\n        self,\n        query_embedding: list[float],\n        *,\n        namespace: str | None = None,\n        filters: dict[str, Any] | None = None,\n        top_k: int = 10,\n        exclude_document_embeddings: bool = True,\n        content_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Retrieve documents similar to the given query embedding.\n\n        Args:\n            query_embedding (list[float]): The query embedding vector.\n            namespace (str | None): The namespace to query. Defaults to None.\n            filters (dict[str, Any] | None): Filters for the query. Defaults to None.\n            top_k (int): Maximum number of documents to retrieve. Defaults to 10.\n            exclude_document_embeddings (bool): Whether to exclude embeddings in results. Defaults to True.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            list[Document]: List of retrieved Document objects.\n\n        Raises:\n            ValueError: If query_embedding is empty or filter format is incorrect.\n        \"\"\"\n        if not query_embedding:\n            msg = \"query_embedding must be a non-empty list of floats\"\n            raise ValueError(msg)\n\n        filters = _normalize_filters(filters) if filters else None\n\n        result = self._index.query(\n            vector=query_embedding,\n            top_k=top_k,\n            namespace=namespace or self.namespace,\n            filter=filters,\n            include_values=not exclude_document_embeddings,\n            include_metadata=True,\n        )\n\n        return self._convert_query_result_to_documents(result, content_key=content_key or self.content_key)\n\n    def _convert_query_result_to_documents(\n        self, query_result: dict[str, Any], content_key: str | None = None\n    ) -&gt; list[Document]:\n        \"\"\"\n        Convert Pinecone query results to Document objects.\n\n        Args:\n            query_result (dict[str, Any]): The query result from Pinecone.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            list[Document]: List of Document objects created from the query result.\n        \"\"\"\n        pinecone_docs = query_result[\"matches\"]\n        documents = []\n        for pinecone_doc in pinecone_docs:\n            content = pinecone_doc[\"metadata\"].pop(content_key, \"\")\n\n            embedding = None\n            if pinecone_doc[\"values\"] != self._dummy_vector:\n                embedding = pinecone_doc[\"values\"]\n\n            doc = Document(\n                id=pinecone_doc[\"id\"],\n                content=content,\n                metadata=pinecone_doc[\"metadata\"],\n                embedding=embedding,\n                score=pinecone_doc[\"score\"],\n            )\n            documents.append(doc)\n\n        return documents\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.pod_spec","title":"<code>pod_spec</code>  <code>property</code>","text":"<p>Returns the pod specification for the Pinecone service.</p> <p>Returns:</p> Name Type Description <code>PodSpec</code> <p>The pod specification.</p>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.serverless_spec","title":"<code>serverless_spec</code>  <code>property</code>","text":"<p>Returns the serverless specification for the Pinecone service.</p> <p>Returns:</p> Name Type Description <code>ServerlessSpec</code> <p>The serverless specification.</p>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.__init__","title":"<code>__init__(connection=None, client=None, index_name='default', namespace='default', batch_size=100, dimension=1536, metric=PineconeSimilarityMetric.COSINE, create_if_not_exist=False, index_type=None, cloud=None, region=None, environment=None, pod_type=None, pods=1, content_key='content', dry_run_config=None, **index_creation_kwargs)</code>","text":"<p>Initialize a PineconeVectorStore instance.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Optional[Pinecone]</code> <p>Pinecone connection instance. Defaults to None.</p> <code>None</code> <code>client</code> <code>Optional[Pinecone]</code> <p>Pinecone client instance. Defaults to None.</p> <code>None</code> <code>index_name</code> <code>str</code> <p>Name of the Pinecone index. Defaults to None.</p> <code>'default'</code> <code>namespace</code> <code>str</code> <p>Namespace for the index. Defaults to 'default'.</p> <code>'default'</code> <code>batch_size</code> <code>int</code> <p>Size of batches for operations. Defaults to 100.</p> <code>100</code> <code>dimension</code> <code>int</code> <p>Number of dimensions for vectors. Defaults to 1536.</p> <code>1536</code> <code>metric</code> <code>PineconeSimilarityMetric</code> <p>Metric for calculating vector similarity. Defaults to 'cosine'.</p> <code>COSINE</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage. Defaults to 'content'.</p> <code>'content'</code> <code>dry_run_config</code> <code>Optional[DryRunConfig]</code> <p>Configuration for dry run mode. Defaults to None.</p> <code>None</code> <code>**index_creation_kwargs</code> <p>Additional arguments for index creation.</p> <code>{}</code> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def __init__(\n    self,\n    connection: Pinecone | None = None,\n    client: Optional[\"PineconeClient\"] = None,\n    index_name: str = \"default\",\n    namespace: str = \"default\",\n    batch_size: int = 100,\n    dimension: int = 1536,\n    metric: PineconeSimilarityMetric = PineconeSimilarityMetric.COSINE,\n    create_if_not_exist: bool = False,\n    index_type: PineconeIndexType | None = None,\n    cloud: str | None = None,\n    region: str | None = None,\n    environment: str | None = None,\n    pod_type: str | None = None,\n    pods: int = 1,\n    content_key: str = \"content\",\n    dry_run_config: DryRunConfig | None = None,\n    **index_creation_kwargs,\n):\n    \"\"\"\n    Initialize a PineconeVectorStore instance.\n\n    Args:\n        connection (Optional[Pinecone]): Pinecone connection instance. Defaults to None.\n        client (Optional[PineconeClient]): Pinecone client instance. Defaults to None.\n        index_name (str): Name of the Pinecone index. Defaults to None.\n        namespace (str): Namespace for the index. Defaults to 'default'.\n        batch_size (int): Size of batches for operations. Defaults to 100.\n        dimension (int): Number of dimensions for vectors. Defaults to 1536.\n        metric (PineconeSimilarityMetric): Metric for calculating vector similarity. Defaults to 'cosine'.\n        content_key (Optional[str]): The field used to store content in the storage. Defaults to 'content'.\n        dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n        **index_creation_kwargs: Additional arguments for index creation.\n    \"\"\"\n    super().__init__(dry_run_config=dry_run_config)\n\n    self.client = client\n    if self.client is None:\n        if connection is None:\n            connection = Pinecone()\n        self.client = connection.connect()\n\n    self.index_name = validate_pinecone_index_name(index_name)\n    self.namespace = namespace\n    self.index_type = index_type\n    self.content_key = content_key\n\n    self.create_if_not_exist = create_if_not_exist\n\n    self.batch_size = batch_size\n\n    self.metric = metric\n    self.dimension = dimension\n    self.cloud = cloud\n    self.region = region\n    self.environment = environment\n    self.pod_type = pod_type\n    self.pods = pods\n\n    self.index_creation_kwargs = index_creation_kwargs\n\n    self._spec = self._get_spec()\n    self._dummy_vector = [-10.0] * dimension\n    self._index = self.connect_to_index()\n    logger.debug(f\"PineconeVectorStore initialized with index {self.index_name} and namespace {self.namespace}.\")\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.connect_to_index","title":"<code>connect_to_index()</code>","text":"<p>Create or connect to an existing Pinecone index.</p> <p>Returns:</p> Type Description <p>The initialized Pinecone index object.</p> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def connect_to_index(self):\n    \"\"\"\n    Create or connect to an existing Pinecone index.\n\n    Returns:\n        The initialized Pinecone index object.\n    \"\"\"\n    try:\n        index = self.client.Index(name=self.index_name)\n        return index\n    except NotFoundException:\n        if self.create_if_not_exist and self.index_type is not None:\n            logger.debug(f\"Index {self.index_name} does not exist. Creating a new index.\")\n            self.client.create_index(\n                name=self.index_name,\n                spec=self._spec,\n                dimension=self.dimension,\n                metric=self.metric.value,\n                **self.index_creation_kwargs,\n            )\n            self._track_collection(self.index_name)\n            return self.client.Index(name=self.index_name)\n\n        raise ValueError(\n            f\"Index {self.index_name} does not exist. \"\n            f\"'create_if_not_exist' must be set to True and 'index_type' must be specified.\"\n        )\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.count_documents","title":"<code>count_documents()</code>","text":"<p>Count the number of documents in the store.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents in the store.</p> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def count_documents(self) -&gt; int:\n    \"\"\"\n    Count the number of documents in the store.\n\n    Returns:\n        int: The number of documents in the store.\n    \"\"\"\n    try:\n        count = self._index.describe_index_stats()[\"namespaces\"][self.namespace][\n            \"vector_count\"\n        ]\n    except KeyError:\n        count = 0\n    return count\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.delete_collection","title":"<code>delete_collection(collection_name=None)</code>","text":"<p>Delete a Pinecone collection (index).</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str | None</code> <p>Name of the collection to delete. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def delete_collection(self, collection_name: str | None = None):\n    \"\"\"\n    Delete a Pinecone collection (index).\n\n    Args:\n        collection_name (str | None): Name of the collection to delete. Defaults to None.\n    \"\"\"\n    try:\n        collection_to_delete = collection_name or self.index_name\n        self.delete_index(index_name=collection_to_delete)\n        logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n    except Exception as e:\n        logger.error(f\"Failed to delete index '{collection_name}': {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.delete_documents","title":"<code>delete_documents(document_ids=None, delete_all=False)</code>","text":"<p>Delete documents from the Pinecone vector store.</p> <p>Parameters:</p> Name Type Description Default <code>document_ids</code> <code>list[str]</code> <p>List of document IDs to delete. Defaults to None.</p> <code>None</code> <code>delete_all</code> <code>bool</code> <p>If True, delete all documents. Defaults to False.</p> <code>False</code> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n    \"\"\"\n    Delete documents from the Pinecone vector store.\n\n    Args:\n        document_ids (list[str]): List of document IDs to delete. Defaults to None.\n        delete_all (bool): If True, delete all documents. Defaults to False.\n    \"\"\"\n    if delete_all and self._index is not None:\n        self._index.delete(delete_all=True, namespace=self.namespace)\n        self._index = self.connect_to_index()\n    else:\n        if not document_ids:\n            logger.warning(\n                \"No document IDs provided. No documents will be deleted.\"\n            )\n        else:\n            self._index.delete(ids=document_ids, namespace=self.namespace)\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.delete_documents_by_filters","title":"<code>delete_documents_by_filters(filters)</code>","text":"<p>Delete documents from the Pinecone vector store using filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any]</code> <p>Filters to select documents to delete.</p> required Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Delete documents from the Pinecone vector store using filters.\n\n    Args:\n        filters (dict[str, Any]): Filters to select documents to delete.\n    \"\"\"\n    filters = _normalize_filters(filters)\n    self._index.delete(filter=filters, namespace=self.namespace)\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.delete_index","title":"<code>delete_index(index_name=None)</code>","text":"<p>Delete the entire index.</p> <p>Parameters:</p> Name Type Description Default <code>index_name</code> <code>str</code> <p>Name of the index to delete.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def delete_index(self, index_name: str | None = None):\n    \"\"\"Delete the entire index.\n\n    Args:\n        index_name (str): Name of the index to delete.\n    \"\"\"\n    try:\n        index_to_delete = index_name or self.index_name\n        self._index.delete(delete_all=True, namespace=self.namespace)\n        self.client.delete_index(index_name=index_to_delete)\n        logger.info(f\"Deleted index '{index_to_delete}'.\")\n    except Exception as e:\n        logger.error(f\"Failed to delete index '{index_to_delete}': {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.list_documents","title":"<code>list_documents(include_embeddings=False, content_key=None)</code>","text":"<p>List documents in the Pinecone vector store.</p> <p>Parameters:</p> Name Type Description Default <code>include_embeddings</code> <code>bool</code> <p>Whether to include embeddings in the results. Defaults to False.</p> <code>False</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: List of Document objects retrieved.</p> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def list_documents(self, include_embeddings: bool = False, content_key: str | None = None) -&gt; list[Document]:\n    \"\"\"\n    List documents in the Pinecone vector store.\n\n    Args:\n        include_embeddings (bool): Whether to include embeddings in the results. Defaults to False.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        list[Document]: List of Document objects retrieved.\n    \"\"\"\n\n    all_documents = []\n    for batch_doc_ids in self._index.list(namespace=self.namespace):\n        response = self._index.fetch(ids=batch_doc_ids, namespace=self.namespace)\n\n        documents = []\n        for pinecone_doc in response[\"vectors\"].values():\n            content = pinecone_doc[\"metadata\"].pop(content_key or self.content_key, \"\")\n\n            embedding = None\n            if include_embeddings and pinecone_doc[\"values\"] != self._dummy_vector:\n                embedding = pinecone_doc[\"values\"]\n\n            doc = Document(\n                id=pinecone_doc[\"id\"],\n                content=content,\n                metadata=pinecone_doc[\"metadata\"],\n                embedding=embedding,\n                score=None,\n            )\n            documents.append(doc)\n\n        all_documents.extend(documents)\n    return all_documents\n</code></pre>"},{"location":"dynamiq/storages/vector/pinecone/pinecone/#dynamiq.storages.vector.pinecone.pinecone.PineconeVectorStore.write_documents","title":"<code>write_documents(documents, content_key=None)</code>","text":"<p>Write documents to the Pinecone vector store.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>List of Document objects to write.</p> required <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of documents successfully written.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If documents are not of type Document.</p> Source code in <code>dynamiq/storages/vector/pinecone/pinecone.py</code> <pre><code>def write_documents(self, documents: list[Document], content_key: str | None = None) -&gt; int:\n    \"\"\"\n    Write documents to the Pinecone vector store.\n\n    Args:\n        documents (list[Document]): List of Document objects to write.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        int: Number of documents successfully written.\n\n    Raises:\n        ValueError: If documents are not of type Document.\n    \"\"\"\n    if len(documents) &gt; 0 and not isinstance(documents[0], Document):\n        msg = \"param 'documents' must contain a list of objects of type Document\"\n        raise ValueError(msg)\n\n    self._track_documents([doc.id for doc in documents])\n\n    documents_for_pinecone = self._convert_documents_to_pinecone_format(\n        documents, content_key=content_key or self.content_key\n    )\n\n    result = self._index.upsert(\n        vectors=documents_for_pinecone,\n        namespace=self.namespace,\n        batch_size=self.batch_size,\n    )\n\n    written_docs = result[\"upserted_count\"]\n    return written_docs\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/converters/","title":"Converters","text":""},{"location":"dynamiq/storages/vector/qdrant/converters/#dynamiq.storages.vector.qdrant.converters.convert_id","title":"<code>convert_id(_id)</code>","text":"<p>Converts any string into a UUID-like format in a deterministic way.</p> <p>Qdrant does not accept any string as an id, so an internal id has to be generated for each point. This is a deterministic way of doing so.</p> Source code in <code>dynamiq/storages/vector/qdrant/converters.py</code> <pre><code>def convert_id(_id: str) -&gt; str:\n    \"\"\"\n    Converts any string into a UUID-like format in a deterministic way.\n\n    Qdrant does not accept any string as an id, so an internal id has to be\n    generated for each point. This is a deterministic way of doing so.\n    \"\"\"\n    UUID_NAMESPACE = uuid.UUID(\"00000000-0000-0000-0000-000000000000\")\n    return uuid.uuid5(UUID_NAMESPACE, _id).hex\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/filters/","title":"Filters","text":""},{"location":"dynamiq/storages/vector/qdrant/filters/#dynamiq.storages.vector.qdrant.filters.build_filters_for_repeated_operators","title":"<code>build_filters_for_repeated_operators(must_clauses, should_clauses, must_not_clauses, qdrant_filter)</code>","text":"<p>Flattens the nested lists of clauses by creating separate Filters for each clause of a logical operator.</p> <p>Parameters:</p> Name Type Description Default <code>must_clauses</code> <code>list[Filter]</code> <p>A nested list of must clauses or an empty list.</p> required <code>should_clauses</code> <code>list[Filter]</code> <p>A nested list of should clauses or an empty list.</p> required <code>must_not_clauses</code> <code>list[Filter]</code> <p>A nested list of must_not clauses or an empty list.</p> required <code>qdrant_filter</code> <code>list[Filter]</code> <p>A list where the generated Filter objects will be appended. This list will be modified in-place.</p> required <p>Returns:</p> Type Description <code>list[Filter]</code> <p>The modified <code>qdrant_filter</code> list with appended generated Filter objects.</p> Source code in <code>dynamiq/storages/vector/qdrant/filters.py</code> <pre><code>def build_filters_for_repeated_operators(\n    must_clauses: list[models.Filter],\n    should_clauses: list[models.Filter],\n    must_not_clauses: list[models.Filter],\n    qdrant_filter: list[models.Filter],\n) -&gt; list[models.Filter]:\n    \"\"\"\n    Flattens the nested lists of clauses by creating separate Filters for each clause of a logical\n    operator.\n\n    Args:\n        must_clauses: A nested list of must clauses or an empty list.\n        should_clauses: A nested list of should clauses or an empty list.\n        must_not_clauses: A nested list of must_not clauses or an empty list.\n        qdrant_filter: A list where the generated Filter objects will be appended. This list will be\n            modified in-place.\n\n    Returns:\n        The modified `qdrant_filter` list with appended generated Filter objects.\n    \"\"\"\n\n    if any(isinstance(i, list) for i in must_clauses):\n        for i in must_clauses:\n            qdrant_filter.append(\n                models.Filter(\n                    must=i or None,\n                    should=should_clauses or None,\n                    must_not=must_not_clauses or None,\n                )\n            )\n    if any(isinstance(i, list) for i in should_clauses):\n        for i in should_clauses:\n            qdrant_filter.append(\n                models.Filter(\n                    must=must_clauses or None,\n                    should=i or None,\n                    must_not=must_not_clauses or None,\n                )\n            )\n    if any(isinstance(i, list) for i in must_not_clauses):\n        for i in must_clauses:\n            qdrant_filter.append(\n                models.Filter(\n                    must=must_clauses or None,\n                    should=should_clauses or None,\n                    must_not=i or None,\n                )\n            )\n\n    return qdrant_filter\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/filters/#dynamiq.storages.vector.qdrant.filters.convert_filters_to_qdrant","title":"<code>convert_filters_to_qdrant(filter_term=None, is_parent_call=True)</code>","text":"<p>Converts Dynamiq filters to the format used by Qdrant.</p> <p>Parameters:</p> Name Type Description Default <code>filter_term</code> <code>list[dict] | dict | Filter | None</code> <p>The Dynamiq filter to be converted to Qdrant.</p> <code>None</code> <code>is_parent_call</code> <code>bool</code> <p>Indicates if this is the top-level call to the function. If True, the function returns a single models.Filter object; if False, it may return a list of filters or conditions for further processing.</p> <code>True</code> <p>Returns:</p> Type Description <code>Filter | list[Filter] | list[Condition] | None</code> <p>A single Qdrant Filter in the parent call or a list of such Filters in recursive calls.</p> <p>Raises:</p> Type Description <code>VectorStoreFilterException</code> <p>If the invalid filter criteria is provided or if an unknown operator is encountered.</p> Source code in <code>dynamiq/storages/vector/qdrant/filters.py</code> <pre><code>def convert_filters_to_qdrant(\n    filter_term: list[dict] | dict | models.Filter | None = None, is_parent_call: bool = True\n) -&gt; models.Filter | list[models.Filter] | list[models.Condition] | None:\n    \"\"\"Converts Dynamiq filters to the format used by Qdrant.\n\n    Args:\n        filter_term: The Dynamiq filter to be converted to Qdrant.\n        is_parent_call: Indicates if this is the top-level call to the function. If True, the function\n            returns a single models.Filter object; if False, it may return a list of filters or\n            conditions for further processing.\n\n    Returns:\n        A single Qdrant Filter in the parent call or a list of such Filters in recursive calls.\n\n    Raises:\n        FilterError: If the invalid filter criteria is provided or if an unknown operator is\n            encountered.\n    \"\"\"\n\n    if isinstance(filter_term, models.Filter):\n        return filter_term\n    if not filter_term:\n        return None\n\n    must_clauses: list[models.Filter] = []\n    should_clauses: list[models.Filter] = []\n    must_not_clauses: list[models.Filter] = []\n    # Indicates if there are multiple same LOGICAL OPERATORS on each level\n    # and prevents them from being combined\n    same_operator_flag = False\n    conditions, qdrant_filter, current_level_operators = (\n        [],\n        [],\n        [],\n    )\n\n    if isinstance(filter_term, dict):\n        filter_term = [filter_term]\n\n    # ======== IDENTIFY FILTER ITEMS ON EACH LEVEL ========\n\n    for item in filter_term:\n        operator = item.get(\"operator\")\n\n        # Check for repeated similar operators on each level\n        same_operator_flag = operator in current_level_operators and operator in LOGICAL_OPERATORS\n        if not same_operator_flag:\n            current_level_operators.append(operator)\n\n        if operator is None:\n            msg = \"Operator not found in filters\"\n            raise FilterError(msg)\n\n        if operator in LOGICAL_OPERATORS and \"conditions\" not in item:\n            msg = f\"'conditions' not found for '{operator}'\"\n            raise FilterError(msg)\n\n        if operator in LOGICAL_OPERATORS:\n            # Recursively process nested conditions\n            current_filter = convert_filters_to_qdrant(item.get(\"conditions\", []), is_parent_call=False) or []\n\n            # When same_operator_flag is set to True,\n            # ensure each clause is appended as an independent list to avoid merging distinct clauses.\n            if operator == \"AND\":\n                must_clauses = [must_clauses, current_filter] if same_operator_flag else must_clauses + current_filter\n            elif operator == \"OR\":\n                should_clauses = (\n                    [should_clauses, current_filter] if same_operator_flag else should_clauses + current_filter\n                )\n            elif operator == \"NOT\":\n                must_not_clauses = (\n                    [must_not_clauses, current_filter] if same_operator_flag else must_not_clauses + current_filter\n                )\n\n        elif operator in COMPARISON_OPERATORS:\n            field = item.get(\"field\")\n            if not field.startswith(\"metadata.\"):\n                field = f\"metadata.{field}\"\n            value = item.get(\"value\")\n            if field is None or value is None:\n                msg = f\"'field' or 'value' not found for '{operator}'\"\n                raise FilterError(msg)\n\n            parsed_conditions = _parse_comparison_operation(comparison_operation=operator, key=field, value=value)\n\n            # check if the parsed_conditions are models.Filter or models.Condition\n            for condition in parsed_conditions:\n                if isinstance(condition, models.Filter):\n                    qdrant_filter.append(condition)\n                else:\n                    conditions.append(condition)\n\n        else:\n            msg = f\"Unknown operator {operator} used in filters\"\n            raise FilterError(msg)\n\n    # ======== PROCESS FILTER ITEMS ON EACH LEVEL ========\n\n    # If same logical operators have separate clauses, create separate filters\n    if same_operator_flag:\n        qdrant_filter = build_filters_for_repeated_operators(\n            must_clauses, should_clauses, must_not_clauses, qdrant_filter\n        )\n\n    # else append a single Filter for existing clauses\n    elif must_clauses or should_clauses or must_not_clauses:\n        qdrant_filter.append(\n            models.Filter(\n                must=must_clauses or None,\n                should=should_clauses or None,\n                must_not=must_not_clauses or None,\n            )\n        )\n\n    # In case of parent call, a single Filter is returned\n    if is_parent_call:\n        # If qdrant_filter has just a single Filter in parent call,\n        # then it might be returned instead.\n        if len(qdrant_filter) == 1 and isinstance(qdrant_filter[0], models.Filter):\n            return qdrant_filter[0]\n        else:\n            must_clauses.extend(conditions)\n            return models.Filter(\n                must=must_clauses or None,\n                should=should_clauses or None,\n                must_not=must_not_clauses or None,\n            )\n\n    # Store conditions of each level in output of the loop\n    elif conditions:\n        qdrant_filter.extend(conditions)\n\n    return qdrant_filter\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/","title":"Qdrant","text":""},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore","title":"<code>QdrantVectorStore</code>","text":"<p>               Bases: <code>BaseVectorStore</code>, <code>DryRunMixin</code></p> <p>QdrantVectorStore a Document Store for Qdrant.</p> <p>Usage example:</p> <pre><code>from dynamiq.types import Document\nfrom dynamiq.storages.vector.qdrant import QdrantVectorStore\n\ndocument_store = QdrantVectorStore(\n        url=\"https://xxxxxx-xxxxx-xxxxx-xxxx-xxxxxxxxx.us-east.aws.cloud.qdrant.io:6333\",\n    api_key=\"&lt;your-api-key&gt;\",\n)\n\ndocument_store.count_documents()\n</code></pre> <p>Attributes:</p> Name Type Description <code>DISTANCE_BY_SIMILARITY</code> <code>ClassVar[dict[QdrantSimilarityMetric, str]]</code> <p>Mapping of metrics to distances.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>class QdrantVectorStore(BaseVectorStore, DryRunMixin):\n    \"\"\"QdrantVectorStore a Document Store for Qdrant.\n\n    Usage example:\n\n    ```python\n    from dynamiq.types import Document\n    from dynamiq.storages.vector.qdrant import QdrantVectorStore\n\n    document_store = QdrantVectorStore(\n            url=\"https://xxxxxx-xxxxx-xxxxx-xxxx-xxxxxxxxx.us-east.aws.cloud.qdrant.io:6333\",\n        api_key=\"&lt;your-api-key&gt;\",\n    )\n\n    document_store.count_documents()\n    ```\n\n    Attributes:\n        DISTANCE_BY_SIMILARITY (ClassVar[dict[QdrantSimilarityMetric, str]]): Mapping of metrics to distances.\n    \"\"\"\n\n    DISTANCE_BY_SIMILARITY: ClassVar[dict[QdrantSimilarityMetric, str]] = {\n        QdrantSimilarityMetric.COSINE: rest.Distance.COSINE,\n        QdrantSimilarityMetric.DOT_PRODUCT: rest.Distance.DOT,\n        QdrantSimilarityMetric.L2: rest.Distance.EUCLID,\n    }\n    _MISSING_INDEX_PATTERN: ClassVar[Pattern[str]] = re.compile(\n        r'Index required but not found for \"(?P&lt;field&gt;[^\"]+)\" of one of the following types: \\[(?P&lt;types&gt;[^\\]]+)\\]',\n        re.IGNORECASE,\n    )\n    _PAYLOAD_SCHEMA_BY_NAME: ClassVar[dict[str, rest.PayloadSchemaType]] = {\n        schema.value.lower(): schema for schema in rest.PayloadSchemaType\n    }\n\n    def __init__(\n        self,\n        connection: QdrantConnection | None = None,\n        client: Optional[\"QdrantClient\"] = None,\n        location: str | None = None,\n        url: str | None = None,\n        port: int = 6333,\n        grpc_port: int = 6334,\n        prefer_grpc: bool = False,\n        https: bool | None = None,\n        api_key: str | None = None,\n        prefix: str | None = None,\n        timeout: int | None = None,\n        host: str | None = None,\n        path: str | None = None,\n        force_disable_check_same_thread: bool = False,\n        index_name: str = \"Document\",\n        dimension: int = 1536,\n        on_disk: bool = False,\n        use_sparse_embeddings: bool = False,\n        sparse_idf: bool = False,\n        metric: QdrantSimilarityMetric = QdrantSimilarityMetric.COSINE,\n        return_embedding: bool = False,\n        create_if_not_exist: bool = False,\n        recreate_index: bool = False,\n        shard_number: int | None = None,\n        replication_factor: int | None = None,\n        write_consistency_factor: int | None = None,\n        on_disk_payload: bool | None = None,\n        hnsw_config: dict | None = None,\n        optimizers_config: dict | None = None,\n        wal_config: dict | None = None,\n        quantization_config: dict | None = None,\n        init_from: dict | None = None,\n        wait_result_from_api: bool = True,\n        metadata: dict | None = None,\n        write_batch_size: int = 100,\n        scroll_size: int = 10_000,\n        payload_fields_to_index: list[dict] | None = None,\n        content_key: str = \"content\",\n        dry_run_config: DryRunConfig | None = None,\n    ):\n        \"\"\"Initializes the QdrantDocumentStore.\n\n        Args:\n            location: If `memory` - use in-memory Qdrant instance. If `str` - use it as a URL parameter. If `None` - use\n                default values for host and port.\n            url: Either host or str of `Optional[scheme], host, Optional[port], Optional[prefix]`.\n            port: Port of the REST API interface.\n            grpc_port: Port of the gRPC interface.\n            prefer_grpc: If `True` - use gRPC interface whenever possible in custom methods.\n            https: If `True` - use HTTPS(SSL) protocol.\n            api_key: API key for authentication in Qdrant Cloud.\n            prefix: If not `None` - add prefix to the REST URL path. Example: service/v1 will result in\n                http://localhost:6333/service/v1/{qdrant-endpoint} for REST API.\n            timeout: Timeout for REST and gRPC API requests.\n            host: Host name of Qdrant service. If `url` and `host` are `None`, set to `localhost`.\n            path: Persistence path for QdrantLocal.\n            force_disable_check_same_thread: For QdrantLocal, force disable check_same_thread. Only use this if you can\n                guarantee that you can resolve the thread safety outside QdrantClient.\n            index_name: Name of the index.\n            dimension: Dimension of the embeddings.\n            on_disk: Whether to store the collection on disk.\n            use_sparse_embedding: If set to `True`, enables support for sparse embeddings.\n            sparse_idf: If set to `True`, computes the Inverse Document Frequency (IDF) when using sparse embeddings. It\n                is required to use techniques like BM42. It is ignored if `use_sparse_embeddings` is `False`.\n            metric: The similarity metric to use.\n            return_embedding: Whether to return embeddings in the search results.\n            recreate_index: Whether to recreate the index.\n            shard_number: Number of shards in the collection.\n            replication_factor: Replication factor for the collection. Defines how many copies of each shard will be\n                created. Effective only in distributed mode.\n            write_consistency_factor: Write consistency factor for the collection. Minimum value is 1. Defines how many\n                replicas should apply to the operation for it to be considered successful. Increasing this number makes\n                the collection more resilient to inconsistencies but will cause failures if not enough replicas are\n                available. Effective only in distributed mode.\n            on_disk_payload: If `True`, the point's payload will not be stored in memory and will be read from the disk\n                every time it is requested. This setting saves RAM by slightly increasing response time. Note: indexed\n                payload values remain in RAM.\n            hnsw_config: Params for HNSW index.\n            optimizers_config: Params for optimizer.\n            wal_config: Params for Write-Ahead-Log.\n            quantization_config: Params for quantization. If `None`, quantization will be disabled.\n            init_from: Use data stored in another collection to initialize this collection.\n            wait_result_from_api: Whether to wait for the result from the API after each request.\n            metadata: Additional metadata to include with the documents.\n            write_batch_size: The batch size for writing documents.\n            scroll_size: The scroll size for reading documents.\n            payload_fields_to_index: List of payload fields to index.\n            content_key (Optional[str]): The field used to store content in the storage.\n            dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n        \"\"\"\n        super().__init__(dry_run_config=dry_run_config)\n\n        self._client = client\n        if self._client is None:\n            connection = connection or QdrantConnection()\n            self._client = connection.connect()\n\n        # Store the Qdrant client specific attributes\n        self.location = location\n        self.url = url\n        self.port = port\n        self.grpc_port = grpc_port\n        self.prefer_grpc = prefer_grpc\n        self.https = https\n        self.api_key = api_key\n        self.prefix = prefix\n        self.timeout = timeout\n        self.host = host\n        self.path = path\n        self.force_disable_check_same_thread = force_disable_check_same_thread\n        self.metadata = metadata or {}\n        self.api_key = api_key\n\n        # Store the Qdrant collection specific attributes\n        self.shard_number = shard_number\n        self.replication_factor = replication_factor\n        self.write_consistency_factor = write_consistency_factor\n        self.on_disk_payload = on_disk_payload\n        self.hnsw_config = hnsw_config\n        self.optimizers_config = optimizers_config\n        self.wal_config = wal_config\n        self.quantization_config = quantization_config\n        self.init_from = init_from\n        self.wait_result_from_api = wait_result_from_api\n        self.create_if_not_exist = create_if_not_exist\n        self.recreate_index = recreate_index\n        self.payload_fields_to_index = payload_fields_to_index\n        self.use_sparse_embeddings = use_sparse_embeddings\n        self.sparse_idf = use_sparse_embeddings and sparse_idf\n        self.dimension = dimension\n        self.on_disk = on_disk\n        self.metric = metric\n        self.index_name = index_name\n        self.return_embedding = return_embedding\n        self.write_batch_size = write_batch_size\n        self.scroll_size = scroll_size\n        self.content_key = content_key\n        self._indexed_payload_fields: set[str] = set()\n        self._auto_index_attempted: set[str] = set()\n\n    @property\n    def client(self):\n        if not self._client:\n            self._client = qdrant_client.QdrantClient(\n                location=self.location,\n                url=self.url,\n                port=self.port,\n                grpc_port=self.grpc_port,\n                prefer_grpc=self.prefer_grpc,\n                https=self.https,\n                api_key=self.api_key.resolve_value() if self.api_key else None,\n                prefix=self.prefix,\n                timeout=self.timeout,\n                host=self.host,\n                path=self.path,\n                metadata=self.metadata,\n                force_disable_check_same_thread=self.force_disable_check_same_thread,\n            )\n            # Make sure the collection is properly set up\n            self._set_up_collection(\n                collection_name=self.index_name,\n                embedding_dim=self.dimension,\n                create_if_not_exist=self.create_if_not_exist,\n                recreate_collection=self.recreate_index,\n                similarity=self.metric,\n                use_sparse_embeddings=self.use_sparse_embeddings,\n                sparse_idf=self.sparse_idf,\n                on_disk=self.on_disk,\n                payload_fields_to_index=self.payload_fields_to_index,\n            )\n        return self._client\n\n    def _collection_exists(self, collection_name: str) -&gt; bool:\n        \"\"\"Safely determine if the collection is present in Qdrant.\"\"\"\n\n        client = self._client or self.client\n\n        try:\n            return client.collection_exists(collection_name)\n        except UnexpectedResponse as exc:\n            if getattr(exc, \"status_code\", None) == 404:\n                try:\n                    client.get_collection(collection_name)\n                    return True\n                except UnexpectedResponse as inner_exc:\n                    if getattr(inner_exc, \"status_code\", None) == 404:\n                        return False\n                    raise\n            raise\n        except ValueError:\n            return False\n\n    def count_documents(self) -&gt; int:\n        \"\"\"Returns the number of documents present in the Document Store.\n\n        Returns:\n            The number of documents in the Document Store.\n        \"\"\"\n        try:\n            response = self.client.count(\n                collection_name=self.index_name,\n            )\n            return response.count\n        except (UnexpectedResponse, ValueError):\n            # Qdrant local raises ValueError if the collection is not found, but\n            # with the remote server UnexpectedResponse is raised. Until that's unified,\n            # we need to catch both.\n            return 0\n\n    def filter_documents(\n        self,\n        filters: dict[str, Any] | rest.Filter | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"Returns the documents that match the provided filters.\n\n        For a detailed specification of the filters, refer to the\n        [documentation](https://docs.dynamiq.deepset.ai/docs/metadata-filtering)\n\n        Args:\n            filters: The filters to apply to the document list.\n\n        Returns:\n            A list of documents that match the given filters.\n        \"\"\"\n        if filters and not isinstance(filters, dict) and not isinstance(filters, rest.Filter):\n            msg = \"Filter must be a dictionary or an instance of `qdrant_client.http.models.Filter`\"\n            raise ValueError(msg)\n\n        if filters and not isinstance(filters, rest.Filter) and \"operator\" not in filters:\n            raise ValueError(\"Filter must contain an 'operator' key\")\n\n        return list(\n            self.get_documents_generator(\n                filters,\n            )\n        )\n\n    def write_documents(\n        self,\n        documents: list[Document],\n        policy: DuplicatePolicy = DuplicatePolicy.FAIL,\n        content_key: str | None = None,\n    ) -&gt; int:\n        \"\"\"Writes documents to Qdrant using the specified policy.\n\n        The QdrantDocumentStore can handle duplicate documents based on the given policy. The available policies are:\n        - `FAIL`: The operation will raise an error if any document already exists.\n        - `OVERWRITE`: Existing documents will be overwritten with the new ones.\n        - `SKIP`: Existing documents will be skipped, and only new documents will be added.\n\n        Args:\n            documents: A list of Document objects to write to Qdrant.\n            policy: The policy for handling duplicate documents.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            The number of documents written to the document store.\n        \"\"\"\n        if not self._collection_exists(self.index_name):\n            if self.create_if_not_exist:\n                logger.info(f\"Collection {self.index_name} doesn't exist. Creating...\")\n                self._set_up_collection(\n                    collection_name=self.index_name,\n                    embedding_dim=self.dimension,\n                    create_if_not_exist=True,\n                    recreate_collection=self.recreate_index,\n                    similarity=self.metric,\n                    use_sparse_embeddings=self.use_sparse_embeddings,\n                    sparse_idf=self.sparse_idf,\n                    on_disk=self.on_disk,\n                )\n            else:\n                raise QdrantStoreError(f\"Collection {self.index_name} doesn't exist\")\n        for doc in documents:\n            if not isinstance(doc, Document):\n                msg = f\"DocumentStore.write_documents() expects a list of Documents but got an element of {type(doc)}.\"\n                raise ValueError(msg)\n\n        if len(documents) == 0:\n            logger.warning(\"Calling QdrantDocumentStore.write_documents() with empty list\")\n            return 0\n\n        document_objects = self._handle_duplicate_documents(\n            documents=documents,\n            index=self.index_name,\n            policy=policy,\n        )\n\n        batched_documents = get_batches_from_generator(document_objects, self.write_batch_size)\n        for document_batch in batched_documents:\n            batch = convert_dynamiq_documents_to_qdrant_points(\n                document_batch,\n                use_sparse_embeddings=self.use_sparse_embeddings,\n                content_key=content_key or self.content_key,\n            )\n\n            self.client.upsert(\n                collection_name=self.index_name,\n                points=batch,\n                wait=self.wait_result_from_api,\n            )\n\n        self._track_documents([doc.id for doc in documents])\n\n        return len(document_objects)\n\n    def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n        \"\"\"Deletes documents that match the provided `document_ids` from the document store.\n\n        Args:\n            document_ids: The document ids to delete.\n            delete_all (bool): If True, delete all documents. Defaults to False.\n        \"\"\"\n        if delete_all:\n            self.client.delete_collection(collection_name=self.index_name)\n        elif document_ids:\n            ids = [convert_id(_id) for _id in document_ids]\n            try:\n                self.client.delete(\n                    collection_name=self.index_name,\n                    points_selector=ids,\n                    wait=self.wait_result_from_api,\n                )\n            except KeyError:\n                logger.warning(\n                    \"Called QdrantDocumentStore.delete_documents() on a non-existing ID\",\n                )\n        else:\n            raise ValueError(\"Either `document_ids` or `delete_all` must be provided.\")\n\n    def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n        \"\"\"\n        Delete documents from the DocumentStore based on the provided filters.\n\n        Args:\n            filters (dict[str, Any]): The filters to apply to the document list.\n        \"\"\"\n        if filters:\n            documents = self.filter_documents(filters=filters)\n            document_ids = [doc.id for doc in documents]\n            self.delete_documents(document_ids=document_ids)\n        else:\n            raise ValueError(\"No filters provided to delete documents.\")\n\n    def delete_collection(self, collection_name: str | None = None):\n        \"\"\"\n        Delete a Qdrant collection.\n\n        Args:\n            collection_name (str | None): Name of the collection to delete.\n        \"\"\"\n        try:\n            collection_to_delete = collection_name or self.index_name\n            self.client.delete_collection(collection_name=collection_to_delete)\n            logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n        except Exception as e:\n            logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n            raise\n\n    def get_documents_generator(\n        self,\n        filters: dict[str, Any] | rest.Filter | None = None,\n        include_embeddings: bool = False,\n        content_key: str | None = None,\n    ) -&gt; Generator[Document, None, None]:\n        \"\"\"Returns a generator that yields documents from Qdrant based on the provided filters.\n\n        Args:\n            filters: Filters applied to the retrieved documents.\n            include_embeddings: Whether to include the embeddings of the retrieved documents.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            A generator that yields documents retrieved from Qdrant.\n        \"\"\"\n\n        index = self.index_name\n        qdrant_filters = convert_filters_to_qdrant(filters)\n\n        next_offset = None\n        stop_scrolling = False\n        while not stop_scrolling:\n            records, next_offset = self._execute_with_payload_index_retry(\n                lambda: self.client.scroll(\n                    collection_name=index,\n                    scroll_filter=qdrant_filters,\n                    limit=self.scroll_size,\n                    offset=next_offset,\n                    with_payload=True,\n                    with_vectors=include_embeddings,\n                )\n            )\n            stop_scrolling = next_offset is None or (\n                isinstance(next_offset, grpc.PointId) and next_offset.num == 0 and next_offset.uuid == \"\"\n            )\n\n            for record in records:\n                yield convert_qdrant_point_to_dynamiq_document(\n                    record,\n                    use_sparse_embeddings=self.use_sparse_embeddings,\n                    content_key=content_key or self.content_key,\n                )\n\n    def list_documents(self, include_embeddings: bool = False, content_key: str | None = None) -&gt; list[Document]:\n        \"\"\"Returns a list of all documents in the Document Store.\n\n        Args:\n            include_embeddings: Whether to include the embeddings of the retrieved documents.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            A list of all documents in the Document Store.\n        \"\"\"\n        return list(\n            self.get_documents_generator(\n                include_embeddings=include_embeddings, content_key=content_key or self.content_key\n            )\n        )\n\n    def get_documents_by_id(\n        self, ids: list[str], index: str | None = None, content_key: str | None = None\n    ) -&gt; list[Document]:\n        \"\"\"Retrieves documents from Qdrant by their IDs.\n\n        Args:\n            ids: A list of document IDs to retrieve.\n            index: The name of the index to retrieve documents from.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            A list of documents.\n        \"\"\"\n        index = index or self.index_name\n\n        documents: list[Document] = []\n\n        ids = [convert_id(_id) for _id in ids]\n        records = self.client.retrieve(\n            collection_name=index,\n            ids=ids,\n            with_payload=True,\n            with_vectors=True,\n        )\n\n        for record in records:\n            documents.append(\n                convert_qdrant_point_to_dynamiq_document(\n                    record,\n                    use_sparse_embeddings=self.use_sparse_embeddings,\n                    content_key=content_key or self.content_key,\n                )\n            )\n        return documents\n\n    def _query_by_sparse(\n        self,\n        query_sparse_embedding: SparseEmbedding,\n        filters: dict[str, Any] | rest.Filter | None = None,\n        top_k: int = 10,\n        scale_score: bool = False,\n        return_embedding: bool = False,\n        score_threshold: float | None = None,\n        content_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"Queries Qdrant using a sparse embedding and returns the most relevant documents.\n\n        Args:\n            query_sparse_embedding: Sparse embedding of the query.\n            filters: Filters applied to the retrieved documents.\n            top_k: Maximum number of documents to return.\n            scale_score: Whether to scale the scores of the retrieved documents.\n            return_embedding: Whether to return the embeddings of the retrieved documents.\n            score_threshold: A minimal score threshold for the result. Score of the returned result might be higher or\n                smaller than the threshold depending on the Distance function used. E.g. for cosine similarity only\n                higher scores will be returned.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            List of documents that are most similar to `query_sparse_embedding`.\n\n        Raises:\n            QdrantStoreError: If the Document Store was initialized with `use_sparse_embeddings=False`.\n        \"\"\"\n\n        if not self.use_sparse_embeddings:\n            message = (\n                \"You are trying to query using sparse embeddings, but the Document Store \"\n                \"was initialized with `use_sparse_embeddings=False`. \"\n            )\n            raise QdrantStoreError(message)\n\n        qdrant_filters = convert_filters_to_qdrant(filters)\n        query_indices = query_sparse_embedding.indices\n        query_values = query_sparse_embedding.values\n        response = self._execute_with_payload_index_retry(\n            lambda: self.client.query_points(\n                collection_name=self.index_name,\n                query=rest.SparseVector(\n                    indices=query_indices,\n                    values=query_values,\n                ),\n                using=SPARSE_VECTORS_NAME,\n                query_filter=qdrant_filters,\n                limit=top_k,\n                with_vectors=return_embedding,\n                score_threshold=score_threshold,\n            )\n        )\n        points = response.points\n        results = [\n            convert_qdrant_point_to_dynamiq_document(\n                point, use_sparse_embeddings=self.use_sparse_embeddings, content_key=content_key or self.content_key\n            )\n            for point in points\n        ]\n        if scale_score:\n            for document in results:\n                score = document.score\n                score = float(1 / (1 + np.exp(-score / 100)))\n                document.score = score\n        return results\n\n    def _query_by_embedding(\n        self,\n        query_embedding: list[float],\n        filters: dict[str, Any] | rest.Filter | None = None,\n        top_k: int = 10,\n        scale_score: bool = False,\n        return_embedding: bool = False,\n        score_threshold: float | None = None,\n        content_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"Queries Qdrant using a dense embedding and returns the most relevant documents.\n\n        Args:\n            query_embedding: Dense embedding of the query.\n            filters: Filters applied to the retrieved documents.\n            top_k: Maximum number of documents to return.\n            scale_score: Whether to scale the scores of the retrieved documents.\n            return_embedding: Whether to return the embeddings of the retrieved documents.\n            score_threshold: A minimal score threshold for the result. Score of the returned result might be higher or\n                smaller than the threshold depending on the Distance function used. E.g. for cosine similarity only\n                higher scores will be returned.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            List of documents that are most similar to `query_embedding`.\n        \"\"\"\n        qdrant_filters = convert_filters_to_qdrant(filters)\n\n        response = self._execute_with_payload_index_retry(\n            lambda: self.client.query_points(\n                collection_name=self.index_name,\n                query=query_embedding,\n                using=DENSE_VECTORS_NAME if self.use_sparse_embeddings else None,\n                query_filter=qdrant_filters,\n                limit=top_k,\n                with_vectors=return_embedding,\n                score_threshold=score_threshold,\n            )\n        )\n        points = response.points\n        results = [\n            convert_qdrant_point_to_dynamiq_document(\n                point, use_sparse_embeddings=self.use_sparse_embeddings, content_key=content_key or self.content_key\n            )\n            for point in points\n        ]\n        if scale_score:\n            for document in results:\n                score = document.score\n                if str(self.metric).lower() == \"cosine\":\n                    score = (score + 1) / 2\n                else:\n                    score = float(1 / (1 + np.exp(-score / 100)))\n                document.score = score\n        return results\n\n    def _query_hybrid(\n        self,\n        query_embedding: list[float],\n        query_sparse_embedding: SparseEmbedding,\n        filters: dict[str, Any] | rest.Filter | None = None,\n        top_k: int = 10,\n        return_embedding: bool = False,\n        score_threshold: float | None = None,\n        content_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"Retrieves documents based on dense and sparse embeddings and fuses the results using Reciprocal Rank Fusion.\n\n        This method is not part of the public interface of `QdrantDocumentStore` and shouldn't be used directly. Use the\n        `QdrantHybridRetriever` instead.\n\n        Args:\n            query_embedding: Dense embedding of the query.\n            query_sparse_embedding: Sparse embedding of the query.\n            filters: Filters applied to the retrieved documents.\n            top_k: Maximum number of documents to return.\n            return_embedding: Whether to return the embeddings of the retrieved documents.\n            score_threshold: A minimal score threshold for the result. Score of the returned result might be higher or\n                smaller than the threshold depending on the Distance function used. E.g. for cosine similarity only\n                higher scores will be returned.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            List of Document that are most similar to `query_embedding` and `query_sparse_embedding`.\n\n        Raises:\n            QdrantStoreError: If the Document Store was initialized with `use_sparse_embeddings=False`.\n        \"\"\"\n\n        # This implementation is based on the code from the Python Qdrant client:\n        # https://github.com/qdrant/qdrant-client/blob/8e3ea58f781e4110d11c0a6985b5e6bb66b85d33/qdrant_client/qdrant_fastembed.py#L519\n        if not self.use_sparse_embeddings:\n            message = (\n                \"You are trying to query using sparse embeddings, but the Document Store \"\n                \"was initialized with `use_sparse_embeddings=False`. \"\n            )\n            raise QdrantStoreError(message)\n\n        qdrant_filters = convert_filters_to_qdrant(filters)\n\n        try:\n            response = self._execute_with_payload_index_retry(\n                lambda: self.client.query_points(\n                    collection_name=self.index_name,\n                    prefetch=[\n                        rest.Prefetch(\n                            query=rest.SparseVector(\n                                indices=query_sparse_embedding.indices,\n                                values=query_sparse_embedding.values,\n                            ),\n                            using=SPARSE_VECTORS_NAME,\n                            filter=qdrant_filters,\n                        ),\n                        rest.Prefetch(\n                            query=query_embedding,\n                            using=DENSE_VECTORS_NAME,\n                            filter=qdrant_filters,\n                        ),\n                    ],\n                    query=rest.FusionQuery(fusion=rest.Fusion.RRF),\n                    limit=top_k,\n                    score_threshold=score_threshold,\n                    with_payload=True,\n                    with_vectors=return_embedding,\n                )\n            )\n            points = response.points\n        except Exception as e:\n            msg = \"Error during hybrid search\"\n            raise QdrantStoreError(msg) from e\n\n        results = [\n            convert_qdrant_point_to_dynamiq_document(\n                point, use_sparse_embeddings=True, content_key=content_key or self.content_key\n            )\n            for point in points\n        ]\n\n        return results\n\n    def get_distance(self, similarity: str | QdrantSimilarityMetric) -&gt; rest.Distance:\n        \"\"\"Retrieves the distance metric for the specified similarity measure.\n\n        Args:\n            similarity: The similarity measure to retrieve the distance.\n\n        Returns:\n            The corresponding rest.Distance object.\n\n        Raises:\n            QdrantStoreError: If the provided similarity measure is not supported.\n        \"\"\"\n        if isinstance(similarity, str):\n            try:\n                similarity = QdrantSimilarityMetric(similarity.lower())\n            except ValueError as exc:\n                msg = (\n                    f\"Provided similarity '{similarity}' is not supported by Qdrant document store. \"\n                    f\"Please choose one of the options: {', '.join(metric.value for metric in QdrantSimilarityMetric)}\"\n                )\n                raise QdrantStoreError(msg) from exc\n\n        try:\n            return self.DISTANCE_BY_SIMILARITY[similarity]\n        except KeyError as ke:\n            msg = (\n                f\"Provided similarity '{similarity}' is not supported by Qdrant \"\n                f\"document store. Please choose one of the options: \"\n                f\"{', '.join(metric.value for metric in QdrantSimilarityMetric)}\"\n            )\n            raise QdrantStoreError(msg) from ke\n\n    def _create_payload_index(self, collection_name: str, payload_fields_to_index: list[dict] | None = None):\n        \"\"\"Create payload index for the collection if payload_fields_to_index is provided.\"\"\"\n\n        if not payload_fields_to_index:\n            return\n\n        for payload_index in payload_fields_to_index:\n            field_name = payload_index[\"field_name\"]\n            field_schema = payload_index[\"field_schema\"]\n\n            if field_name in self._indexed_payload_fields:\n                continue\n\n            try:\n                self.client.create_payload_index(\n                    collection_name=collection_name,\n                    field_name=field_name,\n                    field_schema=field_schema,\n                    wait=True,\n                )\n            except UnexpectedResponse as exc:\n                status_code = getattr(exc, \"status_code\", None)\n                content = exc.content.decode(\"utf-8\", \"ignore\") if getattr(exc, \"content\", None) else \"\"\n                if status_code in {400, 409} and \"already exists\" in content.lower():\n                    logger.debug(\n                        \"Payload index for field %s already exists in collection %s\", field_name, collection_name\n                    )\n                else:\n                    raise\n\n            self._indexed_payload_fields.add(field_name)\n            self._auto_index_attempted.add(field_name)\n\n    def _execute_with_payload_index_retry(self, operation: Callable[[], T]) -&gt; T:\n        \"\"\"Execute and auto-create missing payload indexes, retrying a few times if needed.\"\"\"\n\n        attempts = 0\n        last_exc: UnexpectedResponse | None = None\n\n        while True:\n            try:\n                return operation()\n            except UnexpectedResponse as exc:\n                last_exc = exc\n                attempts += 1\n\n                if not self._try_create_missing_payload_index(exc):\n                    raise\n\n                if attempts &gt; 5:\n                    raise last_exc\n\n    def _extract_error_text(self, exc: UnexpectedResponse) -&gt; str:\n        \"\"\"Extract the error text from a Qdrant UnexpectedResponse.\"\"\"\n\n        if not getattr(exc, \"content\", None):\n            return \"\"\n\n        payload = exc.content.decode(\"utf-8\", \"ignore\")\n\n        try:\n            data = json.loads(payload)\n        except Exception:\n            return payload\n\n        if isinstance(data, dict):\n            status = data.get(\"status\")\n            if isinstance(status, dict):\n                error = status.get(\"error\")\n                if isinstance(error, str):\n                    return error\n        return payload\n\n    def _try_create_missing_payload_index(self, exc: UnexpectedResponse) -&gt; bool:\n        \"\"\"Inspect an error and create the required payload index if the server requests it.\"\"\"\n\n        if getattr(exc, \"status_code\", None) != 400 or not getattr(exc, \"content\", None):\n            return False\n\n        message = self._extract_error_text(exc).replace('\"', '\"')\n        logger.debug(\"Qdrant query error: %s\", message)\n\n        match = self._MISSING_INDEX_PATTERN.search(message)\n        if not match:\n            logger.debug(\"No payload index hint found in error message\")\n            return False\n\n        field_name = match.group(\"field\")\n        if field_name in self._auto_index_attempted:\n            return False\n\n        type_candidates = [candidate.strip().strip(\"\\\"' \") for candidate in match.group(\"types\").split(\",\")]\n        schema = self._resolve_payload_schema(type_candidates)\n\n        logger.info(\n            \"Creating payload index for missing field %s in collection %s (schema=%s)\",\n            field_name,\n            self.index_name,\n            schema.value,\n        )\n\n        self._auto_index_attempted.add(field_name)\n        self._create_payload_index(\n            collection_name=self.index_name,\n            payload_fields_to_index=[{\"field_name\": field_name, \"field_schema\": schema}],\n        )\n        return True\n\n    def _resolve_payload_schema(self, type_candidates: list[str]) -&gt; rest.PayloadSchemaType:\n        \"\"\"Resolve the payload schema type, defaulting to KEYWORD when unknown.\"\"\"\n\n        for candidate in type_candidates:\n            schema = self._PAYLOAD_SCHEMA_BY_NAME.get(candidate.lower())\n            if schema:\n                return schema\n        return rest.PayloadSchemaType.KEYWORD\n\n    def _set_up_collection(\n        self,\n        collection_name: str,\n        embedding_dim: int,\n        create_if_not_exist: bool,\n        recreate_collection: bool,\n        similarity: str,\n        use_sparse_embeddings: bool,\n        sparse_idf: bool,\n        on_disk: bool = False,\n        payload_fields_to_index: list[dict] | None = None,\n    ):\n        \"\"\"Sets up the Qdrant collection with the specified parameters.\n\n        Args:\n            collection_name: The name of the collection to set up.\n            embedding_dim: The dimension of the embeddings.\n            recreate_collection: Whether to recreate the collection if it already exists.\n            similarity: The similarity measure to use.\n            use_sparse_embeddings: Whether to use sparse embeddings.\n            sparse_idf: Whether to compute the Inverse Document Frequency (IDF) when using sparse embeddings. Required\n                for BM42.\n            on_disk: Whether to store the collection on disk.\n            payload_fields_to_index: List of payload fields to index.\n\n        Raises:\n            QdrantStoreError: If the collection exists with incompatible settings.\n            ValueError: If the collection exists with a different similarity measure or embedding dimension.\n        \"\"\"\n        distance = self.get_distance(similarity)\n        collection_exists = self._collection_exists(collection_name)\n\n        should_create = (not collection_exists and create_if_not_exist) or recreate_collection\n\n        if not collection_exists and not create_if_not_exist:\n            msg = f\"Collection '{collection_name}' does not exist in Qdrant.\"\n            raise QdrantStoreError(msg)\n\n        if should_create:\n            logger.info(f\"{'Creating' if not collection_exists else 'Recreating'} collection {collection_name}\")\n            self.recreate_collection(\n                collection_name=collection_name,\n                distance=distance,\n                embedding_dim=embedding_dim,\n                on_disk=on_disk,\n                use_sparse_embeddings=use_sparse_embeddings,\n                sparse_idf=sparse_idf,\n            )\n            self._track_collection(collection_name)\n            if payload_fields_to_index:\n                self._create_payload_index(collection_name, payload_fields_to_index)\n            return\n\n        collection_info = self.client.get_collection(collection_name)\n\n        has_named_vectors = (\n            isinstance(collection_info.config.params.vectors, dict)\n            and DENSE_VECTORS_NAME in collection_info.config.params.vectors\n        )\n\n        if self.use_sparse_embeddings and not has_named_vectors:\n            msg = (\n                f\"Collection '{collection_name}' already exists in Qdrant, \"\n                f\"but it has been originally created without sparse embedding vectors. \"\n                f\"If you want to use that collection, you can set `use_sparse_embeddings=False`. \"\n                f\"To use sparse embeddings, you need to recreate the collection or migrate the existing one. \"\n                f\"See `migrate_to_sparse_embeddings_support` function in \"\n                f\"`dynamiq_integrations.document_stores.qdrant`.\"\n            )\n            raise QdrantStoreError(msg)\n\n        elif not self.use_sparse_embeddings and has_named_vectors:\n            msg = (\n                f\"Collection '{collection_name}' already exists in Qdrant, \"\n                f\"but it has been originally created with sparse embedding vectors.\"\n                f\"If you want to use that collection, please set `use_sparse_embeddings=True`.\"\n            )\n            raise QdrantStoreError(msg)\n\n        if self.use_sparse_embeddings:\n            current_distance = collection_info.config.params.vectors[DENSE_VECTORS_NAME].distance\n            current_vector_size = collection_info.config.params.vectors[DENSE_VECTORS_NAME].size\n        else:\n            current_distance = collection_info.config.params.vectors.distance\n            current_vector_size = collection_info.config.params.vectors.size\n\n        if current_distance != distance:\n            msg = (\n                f\"Collection '{collection_name}' already exists in Qdrant, \"\n                f\"but it is configured with a similarity '{current_distance.name}'. \"\n                f\"If you want to use that collection, but with a different \"\n                f\"similarity, please set `recreate_collection=True` argument.\"\n            )\n            raise ValueError(msg)\n\n        if current_vector_size != embedding_dim:\n            msg = (\n                f\"Collection '{collection_name}' already exists in Qdrant, \"\n                f\"but it is configured with a vector size '{current_vector_size}'. \"\n                f\"If you want to use that collection, but with a different \"\n                f\"vector size, please set `recreate_collection=True` argument.\"\n            )\n            raise ValueError(msg)\n\n    def recreate_collection(\n        self,\n        collection_name: str,\n        distance,\n        embedding_dim: int,\n        on_disk: bool | None = None,\n        use_sparse_embeddings: bool | None = None,\n        sparse_idf: bool = False,\n    ):\n        \"\"\"Recreates the Qdrant collection with the specified parameters.\n\n        Args:\n            collection_name: The name of the collection to recreate.\n            distance: The distance metric to use for the collection.\n            embedding_dim: The dimension of the embeddings.\n            on_disk: Whether to store the collection on disk.\n            use_sparse_embeddings: Whether to use sparse embeddings.\n            sparse_idf: Whether to compute the Inverse Document Frequency (IDF) when using sparse embeddings. Required\n                for BM42.\n        \"\"\"\n        if on_disk is None:\n            on_disk = self.on_disk\n\n        if use_sparse_embeddings is None:\n            use_sparse_embeddings = self.use_sparse_embeddings\n\n        # dense vectors configuration\n        vectors_config = rest.VectorParams(size=embedding_dim, on_disk=on_disk, distance=distance)\n\n        # Reset cached payload index information when recreating a collection\n        self._indexed_payload_fields.clear()\n        self._auto_index_attempted.clear()\n\n        if use_sparse_embeddings:\n            # in this case, we need to define named vectors\n            vectors_config = {DENSE_VECTORS_NAME: vectors_config}\n\n            sparse_vectors_config = {\n                SPARSE_VECTORS_NAME: rest.SparseVectorParams(\n                    index=rest.SparseIndexParams(\n                        on_disk=on_disk,\n                    ),\n                    modifier=rest.Modifier.IDF if sparse_idf else None,\n                ),\n            }\n\n        if self._collection_exists(collection_name):\n            self.client.delete_collection(collection_name)\n\n        try:\n            self.client.create_collection(\n                collection_name=collection_name,\n                vectors_config=vectors_config,\n                sparse_vectors_config=sparse_vectors_config if use_sparse_embeddings else None,\n                shard_number=self.shard_number,\n                replication_factor=self.replication_factor,\n                write_consistency_factor=self.write_consistency_factor,\n                on_disk_payload=self.on_disk_payload,\n                hnsw_config=self.hnsw_config,\n                optimizers_config=self.optimizers_config,\n                wal_config=self.wal_config,\n                quantization_config=self.quantization_config,\n                init_from=self.init_from,\n            )\n        except UnexpectedResponse as exc:\n            if getattr(exc, \"status_code\", None) == 404:\n                msg = (\n                    f\"Failed to create collection '{collection_name}'. Qdrant returned 404 for the create API. \"\n                    f\"Double-check the service URL or required prefix for your deployment.\"\n                )\n                raise QdrantStoreError(msg) from exc\n            raise\n\n    def _handle_duplicate_documents(\n        self,\n        documents: list[Document],\n        index: str | None = None,\n        policy: DuplicatePolicy = None,\n    ):\n        \"\"\"Checks whether any of the passed documents is already existing in the chosen index and returns a list of\n        documents that are not in the index yet.\n\n        Args:\n            documents: A list of Dynamiq Document objects.\n            index: Name of the index.\n            policy: The duplicate policy to use when writing documents.\n\n        Returns:\n            A list of Dynamiq Document objects.\n        \"\"\"\n\n        index = index or self.index_name\n        if policy in (DuplicatePolicy.SKIP, DuplicatePolicy.FAIL):\n            documents = self._drop_duplicate_documents(documents, index)\n            documents_found = self.get_documents_by_id(ids=[doc.id for doc in documents], index=index)\n            ids_exist_in_db: list[str] = [doc.id for doc in documents_found]\n\n            if len(ids_exist_in_db) &gt; 0 and policy == DuplicatePolicy.FAIL:\n                msg = f\"Document with ids '{', '.join(ids_exist_in_db)} already exists in index = '{index}'.\"\n                raise DuplicateDocumentError(msg)\n\n            documents = list(filter(lambda doc: doc.id not in ids_exist_in_db, documents))\n\n        return documents\n\n    def _drop_duplicate_documents(self, documents: list[Document], index: str | None = None) -&gt; list[Document]:\n        \"\"\"Drop duplicate documents based on same hash ID.\n\n        Args:\n            documents: A list of Dynamiq Document objects.\n            index: Name of the index.\n\n        Returns:\n            A list of Dynamiq Document objects.\n        \"\"\"\n        _hash_ids: set = set()\n        _documents: list[Document] = []\n\n        for document in documents:\n            if document.id in _hash_ids:\n                logger.info(\n                    \"Duplicate Documents: Document with id '%s' already exists in index '%s'\",\n                    document.id,\n                    index or self.index_name,\n                )\n                continue\n            _documents.append(document)\n            _hash_ids.add(document.id)\n\n        return _documents\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.__init__","title":"<code>__init__(connection=None, client=None, location=None, url=None, port=6333, grpc_port=6334, prefer_grpc=False, https=None, api_key=None, prefix=None, timeout=None, host=None, path=None, force_disable_check_same_thread=False, index_name='Document', dimension=1536, on_disk=False, use_sparse_embeddings=False, sparse_idf=False, metric=QdrantSimilarityMetric.COSINE, return_embedding=False, create_if_not_exist=False, recreate_index=False, shard_number=None, replication_factor=None, write_consistency_factor=None, on_disk_payload=None, hnsw_config=None, optimizers_config=None, wal_config=None, quantization_config=None, init_from=None, wait_result_from_api=True, metadata=None, write_batch_size=100, scroll_size=10000, payload_fields_to_index=None, content_key='content', dry_run_config=None)</code>","text":"<p>Initializes the QdrantDocumentStore.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str | None</code> <p>If <code>memory</code> - use in-memory Qdrant instance. If <code>str</code> - use it as a URL parameter. If <code>None</code> - use default values for host and port.</p> <code>None</code> <code>url</code> <code>str | None</code> <p>Either host or str of <code>Optional[scheme], host, Optional[port], Optional[prefix]</code>.</p> <code>None</code> <code>port</code> <code>int</code> <p>Port of the REST API interface.</p> <code>6333</code> <code>grpc_port</code> <code>int</code> <p>Port of the gRPC interface.</p> <code>6334</code> <code>prefer_grpc</code> <code>bool</code> <p>If <code>True</code> - use gRPC interface whenever possible in custom methods.</p> <code>False</code> <code>https</code> <code>bool | None</code> <p>If <code>True</code> - use HTTPS(SSL) protocol.</p> <code>None</code> <code>api_key</code> <code>str | None</code> <p>API key for authentication in Qdrant Cloud.</p> <code>None</code> <code>prefix</code> <code>str | None</code> <p>If not <code>None</code> - add prefix to the REST URL path. Example: service/v1 will result in http://localhost:6333/service/v1/{qdrant-endpoint} for REST API.</p> <code>None</code> <code>timeout</code> <code>int | None</code> <p>Timeout for REST and gRPC API requests.</p> <code>None</code> <code>host</code> <code>str | None</code> <p>Host name of Qdrant service. If <code>url</code> and <code>host</code> are <code>None</code>, set to <code>localhost</code>.</p> <code>None</code> <code>path</code> <code>str | None</code> <p>Persistence path for QdrantLocal.</p> <code>None</code> <code>force_disable_check_same_thread</code> <code>bool</code> <p>For QdrantLocal, force disable check_same_thread. Only use this if you can guarantee that you can resolve the thread safety outside QdrantClient.</p> <code>False</code> <code>index_name</code> <code>str</code> <p>Name of the index.</p> <code>'Document'</code> <code>dimension</code> <code>int</code> <p>Dimension of the embeddings.</p> <code>1536</code> <code>on_disk</code> <code>bool</code> <p>Whether to store the collection on disk.</p> <code>False</code> <code>use_sparse_embedding</code> <p>If set to <code>True</code>, enables support for sparse embeddings.</p> required <code>sparse_idf</code> <code>bool</code> <p>If set to <code>True</code>, computes the Inverse Document Frequency (IDF) when using sparse embeddings. It is required to use techniques like BM42. It is ignored if <code>use_sparse_embeddings</code> is <code>False</code>.</p> <code>False</code> <code>metric</code> <code>QdrantSimilarityMetric</code> <p>The similarity metric to use.</p> <code>COSINE</code> <code>return_embedding</code> <code>bool</code> <p>Whether to return embeddings in the search results.</p> <code>False</code> <code>recreate_index</code> <code>bool</code> <p>Whether to recreate the index.</p> <code>False</code> <code>shard_number</code> <code>int | None</code> <p>Number of shards in the collection.</p> <code>None</code> <code>replication_factor</code> <code>int | None</code> <p>Replication factor for the collection. Defines how many copies of each shard will be created. Effective only in distributed mode.</p> <code>None</code> <code>write_consistency_factor</code> <code>int | None</code> <p>Write consistency factor for the collection. Minimum value is 1. Defines how many replicas should apply to the operation for it to be considered successful. Increasing this number makes the collection more resilient to inconsistencies but will cause failures if not enough replicas are available. Effective only in distributed mode.</p> <code>None</code> <code>on_disk_payload</code> <code>bool | None</code> <p>If <code>True</code>, the point's payload will not be stored in memory and will be read from the disk every time it is requested. This setting saves RAM by slightly increasing response time. Note: indexed payload values remain in RAM.</p> <code>None</code> <code>hnsw_config</code> <code>dict | None</code> <p>Params for HNSW index.</p> <code>None</code> <code>optimizers_config</code> <code>dict | None</code> <p>Params for optimizer.</p> <code>None</code> <code>wal_config</code> <code>dict | None</code> <p>Params for Write-Ahead-Log.</p> <code>None</code> <code>quantization_config</code> <code>dict | None</code> <p>Params for quantization. If <code>None</code>, quantization will be disabled.</p> <code>None</code> <code>init_from</code> <code>dict | None</code> <p>Use data stored in another collection to initialize this collection.</p> <code>None</code> <code>wait_result_from_api</code> <code>bool</code> <p>Whether to wait for the result from the API after each request.</p> <code>True</code> <code>metadata</code> <code>dict | None</code> <p>Additional metadata to include with the documents.</p> <code>None</code> <code>write_batch_size</code> <code>int</code> <p>The batch size for writing documents.</p> <code>100</code> <code>scroll_size</code> <code>int</code> <p>The scroll size for reading documents.</p> <code>10000</code> <code>payload_fields_to_index</code> <code>list[dict] | None</code> <p>List of payload fields to index.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>'content'</code> <code>dry_run_config</code> <code>Optional[DryRunConfig]</code> <p>Configuration for dry run mode. Defaults to None.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def __init__(\n    self,\n    connection: QdrantConnection | None = None,\n    client: Optional[\"QdrantClient\"] = None,\n    location: str | None = None,\n    url: str | None = None,\n    port: int = 6333,\n    grpc_port: int = 6334,\n    prefer_grpc: bool = False,\n    https: bool | None = None,\n    api_key: str | None = None,\n    prefix: str | None = None,\n    timeout: int | None = None,\n    host: str | None = None,\n    path: str | None = None,\n    force_disable_check_same_thread: bool = False,\n    index_name: str = \"Document\",\n    dimension: int = 1536,\n    on_disk: bool = False,\n    use_sparse_embeddings: bool = False,\n    sparse_idf: bool = False,\n    metric: QdrantSimilarityMetric = QdrantSimilarityMetric.COSINE,\n    return_embedding: bool = False,\n    create_if_not_exist: bool = False,\n    recreate_index: bool = False,\n    shard_number: int | None = None,\n    replication_factor: int | None = None,\n    write_consistency_factor: int | None = None,\n    on_disk_payload: bool | None = None,\n    hnsw_config: dict | None = None,\n    optimizers_config: dict | None = None,\n    wal_config: dict | None = None,\n    quantization_config: dict | None = None,\n    init_from: dict | None = None,\n    wait_result_from_api: bool = True,\n    metadata: dict | None = None,\n    write_batch_size: int = 100,\n    scroll_size: int = 10_000,\n    payload_fields_to_index: list[dict] | None = None,\n    content_key: str = \"content\",\n    dry_run_config: DryRunConfig | None = None,\n):\n    \"\"\"Initializes the QdrantDocumentStore.\n\n    Args:\n        location: If `memory` - use in-memory Qdrant instance. If `str` - use it as a URL parameter. If `None` - use\n            default values for host and port.\n        url: Either host or str of `Optional[scheme], host, Optional[port], Optional[prefix]`.\n        port: Port of the REST API interface.\n        grpc_port: Port of the gRPC interface.\n        prefer_grpc: If `True` - use gRPC interface whenever possible in custom methods.\n        https: If `True` - use HTTPS(SSL) protocol.\n        api_key: API key for authentication in Qdrant Cloud.\n        prefix: If not `None` - add prefix to the REST URL path. Example: service/v1 will result in\n            http://localhost:6333/service/v1/{qdrant-endpoint} for REST API.\n        timeout: Timeout for REST and gRPC API requests.\n        host: Host name of Qdrant service. If `url` and `host` are `None`, set to `localhost`.\n        path: Persistence path for QdrantLocal.\n        force_disable_check_same_thread: For QdrantLocal, force disable check_same_thread. Only use this if you can\n            guarantee that you can resolve the thread safety outside QdrantClient.\n        index_name: Name of the index.\n        dimension: Dimension of the embeddings.\n        on_disk: Whether to store the collection on disk.\n        use_sparse_embedding: If set to `True`, enables support for sparse embeddings.\n        sparse_idf: If set to `True`, computes the Inverse Document Frequency (IDF) when using sparse embeddings. It\n            is required to use techniques like BM42. It is ignored if `use_sparse_embeddings` is `False`.\n        metric: The similarity metric to use.\n        return_embedding: Whether to return embeddings in the search results.\n        recreate_index: Whether to recreate the index.\n        shard_number: Number of shards in the collection.\n        replication_factor: Replication factor for the collection. Defines how many copies of each shard will be\n            created. Effective only in distributed mode.\n        write_consistency_factor: Write consistency factor for the collection. Minimum value is 1. Defines how many\n            replicas should apply to the operation for it to be considered successful. Increasing this number makes\n            the collection more resilient to inconsistencies but will cause failures if not enough replicas are\n            available. Effective only in distributed mode.\n        on_disk_payload: If `True`, the point's payload will not be stored in memory and will be read from the disk\n            every time it is requested. This setting saves RAM by slightly increasing response time. Note: indexed\n            payload values remain in RAM.\n        hnsw_config: Params for HNSW index.\n        optimizers_config: Params for optimizer.\n        wal_config: Params for Write-Ahead-Log.\n        quantization_config: Params for quantization. If `None`, quantization will be disabled.\n        init_from: Use data stored in another collection to initialize this collection.\n        wait_result_from_api: Whether to wait for the result from the API after each request.\n        metadata: Additional metadata to include with the documents.\n        write_batch_size: The batch size for writing documents.\n        scroll_size: The scroll size for reading documents.\n        payload_fields_to_index: List of payload fields to index.\n        content_key (Optional[str]): The field used to store content in the storage.\n        dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode. Defaults to None.\n    \"\"\"\n    super().__init__(dry_run_config=dry_run_config)\n\n    self._client = client\n    if self._client is None:\n        connection = connection or QdrantConnection()\n        self._client = connection.connect()\n\n    # Store the Qdrant client specific attributes\n    self.location = location\n    self.url = url\n    self.port = port\n    self.grpc_port = grpc_port\n    self.prefer_grpc = prefer_grpc\n    self.https = https\n    self.api_key = api_key\n    self.prefix = prefix\n    self.timeout = timeout\n    self.host = host\n    self.path = path\n    self.force_disable_check_same_thread = force_disable_check_same_thread\n    self.metadata = metadata or {}\n    self.api_key = api_key\n\n    # Store the Qdrant collection specific attributes\n    self.shard_number = shard_number\n    self.replication_factor = replication_factor\n    self.write_consistency_factor = write_consistency_factor\n    self.on_disk_payload = on_disk_payload\n    self.hnsw_config = hnsw_config\n    self.optimizers_config = optimizers_config\n    self.wal_config = wal_config\n    self.quantization_config = quantization_config\n    self.init_from = init_from\n    self.wait_result_from_api = wait_result_from_api\n    self.create_if_not_exist = create_if_not_exist\n    self.recreate_index = recreate_index\n    self.payload_fields_to_index = payload_fields_to_index\n    self.use_sparse_embeddings = use_sparse_embeddings\n    self.sparse_idf = use_sparse_embeddings and sparse_idf\n    self.dimension = dimension\n    self.on_disk = on_disk\n    self.metric = metric\n    self.index_name = index_name\n    self.return_embedding = return_embedding\n    self.write_batch_size = write_batch_size\n    self.scroll_size = scroll_size\n    self.content_key = content_key\n    self._indexed_payload_fields: set[str] = set()\n    self._auto_index_attempted: set[str] = set()\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.count_documents","title":"<code>count_documents()</code>","text":"<p>Returns the number of documents present in the Document Store.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of documents in the Document Store.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def count_documents(self) -&gt; int:\n    \"\"\"Returns the number of documents present in the Document Store.\n\n    Returns:\n        The number of documents in the Document Store.\n    \"\"\"\n    try:\n        response = self.client.count(\n            collection_name=self.index_name,\n        )\n        return response.count\n    except (UnexpectedResponse, ValueError):\n        # Qdrant local raises ValueError if the collection is not found, but\n        # with the remote server UnexpectedResponse is raised. Until that's unified,\n        # we need to catch both.\n        return 0\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.delete_collection","title":"<code>delete_collection(collection_name=None)</code>","text":"<p>Delete a Qdrant collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str | None</code> <p>Name of the collection to delete.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def delete_collection(self, collection_name: str | None = None):\n    \"\"\"\n    Delete a Qdrant collection.\n\n    Args:\n        collection_name (str | None): Name of the collection to delete.\n    \"\"\"\n    try:\n        collection_to_delete = collection_name or self.index_name\n        self.client.delete_collection(collection_name=collection_to_delete)\n        logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n    except Exception as e:\n        logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.delete_documents","title":"<code>delete_documents(document_ids=None, delete_all=False)</code>","text":"<p>Deletes documents that match the provided <code>document_ids</code> from the document store.</p> <p>Parameters:</p> Name Type Description Default <code>document_ids</code> <code>list[str] | None</code> <p>The document ids to delete.</p> <code>None</code> <code>delete_all</code> <code>bool</code> <p>If True, delete all documents. Defaults to False.</p> <code>False</code> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n    \"\"\"Deletes documents that match the provided `document_ids` from the document store.\n\n    Args:\n        document_ids: The document ids to delete.\n        delete_all (bool): If True, delete all documents. Defaults to False.\n    \"\"\"\n    if delete_all:\n        self.client.delete_collection(collection_name=self.index_name)\n    elif document_ids:\n        ids = [convert_id(_id) for _id in document_ids]\n        try:\n            self.client.delete(\n                collection_name=self.index_name,\n                points_selector=ids,\n                wait=self.wait_result_from_api,\n            )\n        except KeyError:\n            logger.warning(\n                \"Called QdrantDocumentStore.delete_documents() on a non-existing ID\",\n            )\n    else:\n        raise ValueError(\"Either `document_ids` or `delete_all` must be provided.\")\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.delete_documents_by_filters","title":"<code>delete_documents_by_filters(filters)</code>","text":"<p>Delete documents from the DocumentStore based on the provided filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any]</code> <p>The filters to apply to the document list.</p> required Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Delete documents from the DocumentStore based on the provided filters.\n\n    Args:\n        filters (dict[str, Any]): The filters to apply to the document list.\n    \"\"\"\n    if filters:\n        documents = self.filter_documents(filters=filters)\n        document_ids = [doc.id for doc in documents]\n        self.delete_documents(document_ids=document_ids)\n    else:\n        raise ValueError(\"No filters provided to delete documents.\")\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.filter_documents","title":"<code>filter_documents(filters=None)</code>","text":"<p>Returns the documents that match the provided filters.</p> <p>For a detailed specification of the filters, refer to the documentation</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any] | Filter | None</code> <p>The filters to apply to the document list.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>A list of documents that match the given filters.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def filter_documents(\n    self,\n    filters: dict[str, Any] | rest.Filter | None = None,\n) -&gt; list[Document]:\n    \"\"\"Returns the documents that match the provided filters.\n\n    For a detailed specification of the filters, refer to the\n    [documentation](https://docs.dynamiq.deepset.ai/docs/metadata-filtering)\n\n    Args:\n        filters: The filters to apply to the document list.\n\n    Returns:\n        A list of documents that match the given filters.\n    \"\"\"\n    if filters and not isinstance(filters, dict) and not isinstance(filters, rest.Filter):\n        msg = \"Filter must be a dictionary or an instance of `qdrant_client.http.models.Filter`\"\n        raise ValueError(msg)\n\n    if filters and not isinstance(filters, rest.Filter) and \"operator\" not in filters:\n        raise ValueError(\"Filter must contain an 'operator' key\")\n\n    return list(\n        self.get_documents_generator(\n            filters,\n        )\n    )\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.get_distance","title":"<code>get_distance(similarity)</code>","text":"<p>Retrieves the distance metric for the specified similarity measure.</p> <p>Parameters:</p> Name Type Description Default <code>similarity</code> <code>str | QdrantSimilarityMetric</code> <p>The similarity measure to retrieve the distance.</p> required <p>Returns:</p> Type Description <code>Distance</code> <p>The corresponding rest.Distance object.</p> <p>Raises:</p> Type Description <code>QdrantStoreError</code> <p>If the provided similarity measure is not supported.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def get_distance(self, similarity: str | QdrantSimilarityMetric) -&gt; rest.Distance:\n    \"\"\"Retrieves the distance metric for the specified similarity measure.\n\n    Args:\n        similarity: The similarity measure to retrieve the distance.\n\n    Returns:\n        The corresponding rest.Distance object.\n\n    Raises:\n        QdrantStoreError: If the provided similarity measure is not supported.\n    \"\"\"\n    if isinstance(similarity, str):\n        try:\n            similarity = QdrantSimilarityMetric(similarity.lower())\n        except ValueError as exc:\n            msg = (\n                f\"Provided similarity '{similarity}' is not supported by Qdrant document store. \"\n                f\"Please choose one of the options: {', '.join(metric.value for metric in QdrantSimilarityMetric)}\"\n            )\n            raise QdrantStoreError(msg) from exc\n\n    try:\n        return self.DISTANCE_BY_SIMILARITY[similarity]\n    except KeyError as ke:\n        msg = (\n            f\"Provided similarity '{similarity}' is not supported by Qdrant \"\n            f\"document store. Please choose one of the options: \"\n            f\"{', '.join(metric.value for metric in QdrantSimilarityMetric)}\"\n        )\n        raise QdrantStoreError(msg) from ke\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.get_documents_by_id","title":"<code>get_documents_by_id(ids, index=None, content_key=None)</code>","text":"<p>Retrieves documents from Qdrant by their IDs.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str]</code> <p>A list of document IDs to retrieve.</p> required <code>index</code> <code>str | None</code> <p>The name of the index to retrieve documents from.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>A list of documents.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def get_documents_by_id(\n    self, ids: list[str], index: str | None = None, content_key: str | None = None\n) -&gt; list[Document]:\n    \"\"\"Retrieves documents from Qdrant by their IDs.\n\n    Args:\n        ids: A list of document IDs to retrieve.\n        index: The name of the index to retrieve documents from.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        A list of documents.\n    \"\"\"\n    index = index or self.index_name\n\n    documents: list[Document] = []\n\n    ids = [convert_id(_id) for _id in ids]\n    records = self.client.retrieve(\n        collection_name=index,\n        ids=ids,\n        with_payload=True,\n        with_vectors=True,\n    )\n\n    for record in records:\n        documents.append(\n            convert_qdrant_point_to_dynamiq_document(\n                record,\n                use_sparse_embeddings=self.use_sparse_embeddings,\n                content_key=content_key or self.content_key,\n            )\n        )\n    return documents\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.get_documents_generator","title":"<code>get_documents_generator(filters=None, include_embeddings=False, content_key=None)</code>","text":"<p>Returns a generator that yields documents from Qdrant based on the provided filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any] | Filter | None</code> <p>Filters applied to the retrieved documents.</p> <code>None</code> <code>include_embeddings</code> <code>bool</code> <p>Whether to include the embeddings of the retrieved documents.</p> <code>False</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>A generator that yields documents retrieved from Qdrant.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def get_documents_generator(\n    self,\n    filters: dict[str, Any] | rest.Filter | None = None,\n    include_embeddings: bool = False,\n    content_key: str | None = None,\n) -&gt; Generator[Document, None, None]:\n    \"\"\"Returns a generator that yields documents from Qdrant based on the provided filters.\n\n    Args:\n        filters: Filters applied to the retrieved documents.\n        include_embeddings: Whether to include the embeddings of the retrieved documents.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        A generator that yields documents retrieved from Qdrant.\n    \"\"\"\n\n    index = self.index_name\n    qdrant_filters = convert_filters_to_qdrant(filters)\n\n    next_offset = None\n    stop_scrolling = False\n    while not stop_scrolling:\n        records, next_offset = self._execute_with_payload_index_retry(\n            lambda: self.client.scroll(\n                collection_name=index,\n                scroll_filter=qdrant_filters,\n                limit=self.scroll_size,\n                offset=next_offset,\n                with_payload=True,\n                with_vectors=include_embeddings,\n            )\n        )\n        stop_scrolling = next_offset is None or (\n            isinstance(next_offset, grpc.PointId) and next_offset.num == 0 and next_offset.uuid == \"\"\n        )\n\n        for record in records:\n            yield convert_qdrant_point_to_dynamiq_document(\n                record,\n                use_sparse_embeddings=self.use_sparse_embeddings,\n                content_key=content_key or self.content_key,\n            )\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.list_documents","title":"<code>list_documents(include_embeddings=False, content_key=None)</code>","text":"<p>Returns a list of all documents in the Document Store.</p> <p>Parameters:</p> Name Type Description Default <code>include_embeddings</code> <code>bool</code> <p>Whether to include the embeddings of the retrieved documents.</p> <code>False</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>A list of all documents in the Document Store.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def list_documents(self, include_embeddings: bool = False, content_key: str | None = None) -&gt; list[Document]:\n    \"\"\"Returns a list of all documents in the Document Store.\n\n    Args:\n        include_embeddings: Whether to include the embeddings of the retrieved documents.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        A list of all documents in the Document Store.\n    \"\"\"\n    return list(\n        self.get_documents_generator(\n            include_embeddings=include_embeddings, content_key=content_key or self.content_key\n        )\n    )\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.recreate_collection","title":"<code>recreate_collection(collection_name, distance, embedding_dim, on_disk=None, use_sparse_embeddings=None, sparse_idf=False)</code>","text":"<p>Recreates the Qdrant collection with the specified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str</code> <p>The name of the collection to recreate.</p> required <code>distance</code> <p>The distance metric to use for the collection.</p> required <code>embedding_dim</code> <code>int</code> <p>The dimension of the embeddings.</p> required <code>on_disk</code> <code>bool | None</code> <p>Whether to store the collection on disk.</p> <code>None</code> <code>use_sparse_embeddings</code> <code>bool | None</code> <p>Whether to use sparse embeddings.</p> <code>None</code> <code>sparse_idf</code> <code>bool</code> <p>Whether to compute the Inverse Document Frequency (IDF) when using sparse embeddings. Required for BM42.</p> <code>False</code> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def recreate_collection(\n    self,\n    collection_name: str,\n    distance,\n    embedding_dim: int,\n    on_disk: bool | None = None,\n    use_sparse_embeddings: bool | None = None,\n    sparse_idf: bool = False,\n):\n    \"\"\"Recreates the Qdrant collection with the specified parameters.\n\n    Args:\n        collection_name: The name of the collection to recreate.\n        distance: The distance metric to use for the collection.\n        embedding_dim: The dimension of the embeddings.\n        on_disk: Whether to store the collection on disk.\n        use_sparse_embeddings: Whether to use sparse embeddings.\n        sparse_idf: Whether to compute the Inverse Document Frequency (IDF) when using sparse embeddings. Required\n            for BM42.\n    \"\"\"\n    if on_disk is None:\n        on_disk = self.on_disk\n\n    if use_sparse_embeddings is None:\n        use_sparse_embeddings = self.use_sparse_embeddings\n\n    # dense vectors configuration\n    vectors_config = rest.VectorParams(size=embedding_dim, on_disk=on_disk, distance=distance)\n\n    # Reset cached payload index information when recreating a collection\n    self._indexed_payload_fields.clear()\n    self._auto_index_attempted.clear()\n\n    if use_sparse_embeddings:\n        # in this case, we need to define named vectors\n        vectors_config = {DENSE_VECTORS_NAME: vectors_config}\n\n        sparse_vectors_config = {\n            SPARSE_VECTORS_NAME: rest.SparseVectorParams(\n                index=rest.SparseIndexParams(\n                    on_disk=on_disk,\n                ),\n                modifier=rest.Modifier.IDF if sparse_idf else None,\n            ),\n        }\n\n    if self._collection_exists(collection_name):\n        self.client.delete_collection(collection_name)\n\n    try:\n        self.client.create_collection(\n            collection_name=collection_name,\n            vectors_config=vectors_config,\n            sparse_vectors_config=sparse_vectors_config if use_sparse_embeddings else None,\n            shard_number=self.shard_number,\n            replication_factor=self.replication_factor,\n            write_consistency_factor=self.write_consistency_factor,\n            on_disk_payload=self.on_disk_payload,\n            hnsw_config=self.hnsw_config,\n            optimizers_config=self.optimizers_config,\n            wal_config=self.wal_config,\n            quantization_config=self.quantization_config,\n            init_from=self.init_from,\n        )\n    except UnexpectedResponse as exc:\n        if getattr(exc, \"status_code\", None) == 404:\n            msg = (\n                f\"Failed to create collection '{collection_name}'. Qdrant returned 404 for the create API. \"\n                f\"Double-check the service URL or required prefix for your deployment.\"\n            )\n            raise QdrantStoreError(msg) from exc\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.QdrantVectorStore.write_documents","title":"<code>write_documents(documents, policy=DuplicatePolicy.FAIL, content_key=None)</code>","text":"<p>Writes documents to Qdrant using the specified policy.</p> <p>The QdrantDocumentStore can handle duplicate documents based on the given policy. The available policies are: - <code>FAIL</code>: The operation will raise an error if any document already exists. - <code>OVERWRITE</code>: Existing documents will be overwritten with the new ones. - <code>SKIP</code>: Existing documents will be skipped, and only new documents will be added.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>A list of Document objects to write to Qdrant.</p> required <code>policy</code> <code>DuplicatePolicy</code> <p>The policy for handling duplicate documents.</p> <code>FAIL</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>The number of documents written to the document store.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def write_documents(\n    self,\n    documents: list[Document],\n    policy: DuplicatePolicy = DuplicatePolicy.FAIL,\n    content_key: str | None = None,\n) -&gt; int:\n    \"\"\"Writes documents to Qdrant using the specified policy.\n\n    The QdrantDocumentStore can handle duplicate documents based on the given policy. The available policies are:\n    - `FAIL`: The operation will raise an error if any document already exists.\n    - `OVERWRITE`: Existing documents will be overwritten with the new ones.\n    - `SKIP`: Existing documents will be skipped, and only new documents will be added.\n\n    Args:\n        documents: A list of Document objects to write to Qdrant.\n        policy: The policy for handling duplicate documents.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        The number of documents written to the document store.\n    \"\"\"\n    if not self._collection_exists(self.index_name):\n        if self.create_if_not_exist:\n            logger.info(f\"Collection {self.index_name} doesn't exist. Creating...\")\n            self._set_up_collection(\n                collection_name=self.index_name,\n                embedding_dim=self.dimension,\n                create_if_not_exist=True,\n                recreate_collection=self.recreate_index,\n                similarity=self.metric,\n                use_sparse_embeddings=self.use_sparse_embeddings,\n                sparse_idf=self.sparse_idf,\n                on_disk=self.on_disk,\n            )\n        else:\n            raise QdrantStoreError(f\"Collection {self.index_name} doesn't exist\")\n    for doc in documents:\n        if not isinstance(doc, Document):\n            msg = f\"DocumentStore.write_documents() expects a list of Documents but got an element of {type(doc)}.\"\n            raise ValueError(msg)\n\n    if len(documents) == 0:\n        logger.warning(\"Calling QdrantDocumentStore.write_documents() with empty list\")\n        return 0\n\n    document_objects = self._handle_duplicate_documents(\n        documents=documents,\n        index=self.index_name,\n        policy=policy,\n    )\n\n    batched_documents = get_batches_from_generator(document_objects, self.write_batch_size)\n    for document_batch in batched_documents:\n        batch = convert_dynamiq_documents_to_qdrant_points(\n            document_batch,\n            use_sparse_embeddings=self.use_sparse_embeddings,\n            content_key=content_key or self.content_key,\n        )\n\n        self.client.upsert(\n            collection_name=self.index_name,\n            points=batch,\n            wait=self.wait_result_from_api,\n        )\n\n    self._track_documents([doc.id for doc in documents])\n\n    return len(document_objects)\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.SparseEmbedding","title":"<code>SparseEmbedding</code>","text":"<p>Class representing a sparse embedding.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>class SparseEmbedding:\n    \"\"\"Class representing a sparse embedding.\"\"\"\n\n    indices: list[int]\n    values: list[float]\n</code></pre>"},{"location":"dynamiq/storages/vector/qdrant/qdrant/#dynamiq.storages.vector.qdrant.qdrant.get_batches_from_generator","title":"<code>get_batches_from_generator(iterable, n)</code>","text":"<p>Batch elements of an iterable into fixed-length chunks or blocks.</p> <p>Parameters:</p> Name Type Description Default <code>iterable</code> <p>The iterable to batch.</p> required <code>n</code> <p>The size of each batch.</p> required <p>Yields:</p> Type Description <p>Batches of the iterable.</p> Source code in <code>dynamiq/storages/vector/qdrant/qdrant.py</code> <pre><code>def get_batches_from_generator(iterable, n):\n    \"\"\"Batch elements of an iterable into fixed-length chunks or blocks.\n\n    Args:\n        iterable: The iterable to batch.\n        n: The size of each batch.\n\n    Yields:\n        Batches of the iterable.\n    \"\"\"\n    it = iter(iterable)\n    x = tuple(islice(it, n))\n    while x:\n        yield x\n        x = tuple(islice(it, n))\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/filters/","title":"Filters","text":""},{"location":"dynamiq/storages/vector/weaviate/filters/#dynamiq.storages.vector.weaviate.filters.convert_filters","title":"<code>convert_filters(filters)</code>","text":"<p>Convert filters from dynamiq format to Weaviate format.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any]</code> <p>Filters in dynamiq format.</p> required <p>Returns:</p> Name Type Description <code>FilterReturn</code> <code>FilterReturn</code> <p>Filters in Weaviate format.</p> <p>Raises:</p> Type Description <code>VectorStoreFilterException</code> <p>If filters are not a dictionary.</p> Source code in <code>dynamiq/storages/vector/weaviate/filters.py</code> <pre><code>def convert_filters(filters: dict[str, Any]) -&gt; FilterReturn:\n    \"\"\"\n    Convert filters from dynamiq format to Weaviate format.\n\n    Args:\n        filters (dict[str, Any]): Filters in dynamiq format.\n\n    Returns:\n        FilterReturn: Filters in Weaviate format.\n\n    Raises:\n        VectorStoreFilterException: If filters are not a dictionary.\n    \"\"\"\n    if not isinstance(filters, dict):\n        msg = \"Filters must be a dictionary\"\n        raise VectorStoreFilterException(msg)\n\n    if \"field\" in filters:\n        return Filter.all_of([_parse_comparison_condition(filters)])\n    return _parse_logical_condition(filters)\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/","title":"Weaviate","text":""},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateRetrieverVectorStoreParams","title":"<code>WeaviateRetrieverVectorStoreParams</code>","text":"<p>               Bases: <code>BaseVectorStoreParams</code></p> <p>Parameters for using existing Weaviate collections with tenant context.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>class WeaviateRetrieverVectorStoreParams(BaseVectorStoreParams):\n    \"\"\"Parameters for using existing Weaviate collections with tenant context.\"\"\"\n    alpha: float = 0.5\n    tenant_name: str | None = None\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore","title":"<code>WeaviateVectorStore</code>","text":"<p>               Bases: <code>BaseVectorStore</code>, <code>DryRunMixin</code></p> <p>A Document Store for Weaviate.</p> <p>This class can be used with Weaviate Cloud Services or self-hosted instances.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>class WeaviateVectorStore(BaseVectorStore, DryRunMixin):\n    \"\"\"\n    A Document Store for Weaviate.\n\n    This class can be used with Weaviate Cloud Services or self-hosted instances.\n    \"\"\"\n\n    PATTERN_COLLECTION_NAME = re.compile(r\"^[A-Z][_0-9A-Za-z]*$\")\n    PATTERN_PROPERTY_NAME = re.compile(r\"^[_A-Za-z][_0-9A-Za-z]*$\")\n    _PROPERTY_DATA_TYPES: dict[str, str] = {\n        \"content\": DataType.TEXT,\n        \"message_content\": DataType.TEXT,\n        \"message_role\": DataType.TEXT,\n        \"message_timestamp\": DataType.NUMBER,\n        \"message_id\": DataType.TEXT,\n        \"user_id\": DataType.TEXT,\n        \"session_id\": DataType.TEXT,\n    }\n\n    def _get_property_type(self, property_name: str) -&gt; str:\n        \"\"\"Gets the Weaviate data type for a known property, defaults to TEXT.\"\"\"\n        if property_name == self.content_key:\n            return DataType.TEXT\n        return self._PROPERTY_DATA_TYPES.get(property_name, DataType.TEXT)\n\n    @staticmethod\n    def is_valid_collection_name(name: str) -&gt; bool:\n        return bool(WeaviateVectorStore.PATTERN_COLLECTION_NAME.fullmatch(name))\n\n    @staticmethod\n    def is_valid_property_name(name: str) -&gt; bool:\n        \"\"\"\n        Check if a property name is valid according to Weaviate naming rules.\n\n        Args:\n            name (str): The property name to check\n\n        Returns:\n            bool: True if the name is valid, False otherwise\n        \"\"\"\n        return bool(WeaviateVectorStore.PATTERN_PROPERTY_NAME.fullmatch(name))\n\n    @classmethod\n    def _fix_and_validate_index_name(cls, index_name: str) -&gt; str:\n        \"\"\"\n        Fix the index name if it starts with a lowercase letter and then validate it.\n        Logs a warning if the index name is corrected.\n        \"\"\"\n        if index_name and index_name[0].islower():\n            fixed_name = index_name[0].upper() + index_name[1:]\n            logger.warning(\n                f\"Index name '{index_name}' starts with a lowercase letter. \"\n                f\"Automatically updating it to '{fixed_name}'.\"\n            )\n            index_name = fixed_name\n        if not cls.is_valid_collection_name(index_name):\n            msg = (\n                f\"Collection name '{index_name}' is invalid. It must match the pattern \"\n                f\"{cls.PATTERN_COLLECTION_NAME.pattern}\"\n            )\n            raise ValueError(msg)\n        return index_name\n\n    def __init__(\n        self,\n        connection: Weaviate | None = None,\n        client: Optional[\"WeaviateClient\"] = None,\n        index_name: str = \"default\",\n        create_if_not_exist: bool = False,\n        content_key: str = \"content\",\n        tenant_name: str | None = None,\n        alpha: float = 0.5,\n        dry_run_config: DryRunConfig | None = None,\n    ):\n        \"\"\"\n        Initialize a new instance of WeaviateDocumentStore and connect to the\n        Weaviate instance.\n\n        Args:\n            connection (Weaviate | None): A Weaviate connection object. If None, a\n                new one is created.\n            client (Optional[WeaviateClient]): A Weaviate client. If None, one is\n                created from the connection.\n            index_name (str): The name of the index to use. Defaults to \"default\".\n            content_key (Optional[str]): The field used to store content in the\n                storage.\n            tenant_name (str | None): The name of the tenant to use for all operations.\n                If provided, multi-tenancy will be enabled for the collection.\n            alpha (float): The alpha value used for hybrid retrieval operations. Controls\n                the balance between keyword and vector search. Defaults to 0.5.\n            dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode.\n        \"\"\"\n        super().__init__(dry_run_config=dry_run_config)\n\n        # Validate and normalize the index name\n        index_name = self._fix_and_validate_index_name(index_name)\n        collection_name = index_name\n\n        # Initialize client\n        self.client = client\n        if self.client is None:\n            if connection is None:\n                connection = Weaviate()\n            self.client = connection.connect()\n\n        # Store multi-tenancy configuration\n        self._multi_tenancy_enabled = tenant_name is not None\n        self.content_key = content_key\n        self.alpha = alpha\n\n        # Create collection if needed or validate existing collection\n        if not self.client.collections.exists(collection_name):\n            if create_if_not_exist:\n                self._create_collection(collection_name, tenant_name)\n                self._track_collection(collection_name)\n            else:\n                raise ValueError(\n                    f\"Collection '{collection_name}' does not exist. Set 'create_if_not_exist' to True to create it.\"\n                )\n\n        # Get the base collection\n        base_collection = self.client.collections.get(collection_name)\n\n        # Get the actual multi-tenancy configuration from the collection\n        self._update_multi_tenancy_status(base_collection)\n\n        # Set up the collection - either with tenant context or without\n        self._setup_collection(base_collection, collection_name, tenant_name)\n\n    def _create_collection(\n        self, collection_name: str, tenant_name: str | None, properties_to_define: list[str] | None = None\n    ):\n        \"\"\"\n        Create a new Weaviate collection with appropriate configuration and properties.\n\n        Args:\n            collection_name: Name of the collection to create\n            tenant_name: Optional tenant name to enable multi-tenancy\n            properties_to_define: List of property names to explicitly define in the schema.\n        \"\"\"\n        collection_config_params = {\n            \"name\": collection_name,\n            \"inverted_index_config\": Configure.inverted_index(index_null_state=True),\n            \"vector_index_config\": Configure.VectorIndex.hnsw(),\n        }\n\n        if tenant_name is not None:\n            collection_config_params[\"multi_tenancy_config\"] = Configure.multi_tenancy(enabled=True)\n\n        properties = []\n        all_props_to_define = set(properties_to_define or [])\n        all_props_to_define.add(self.content_key)\n        all_props_to_define.add(\"_original_id\")\n\n        for prop_name in all_props_to_define:\n            if self.is_valid_property_name(prop_name):\n                prop_type = self._get_property_type(prop_name)\n                properties.append(Property(name=prop_name, data_type=prop_type))\n                logger.debug(f\"Prepared property definition: {prop_name} (Type: {prop_type})\")\n            else:\n                logger.warning(f\"Skipping definition for invalid property name: '{prop_name}'\")\n\n        if properties:\n            collection_config_params[\"properties\"] = properties\n        try:\n            self.client.collections.create(**collection_config_params)\n            logger.info(f\"Created collection '{collection_name}' with defined properties.\")\n        except ObjectAlreadyExistsException:\n            logger.warning(f\"Collection '{collection_name}' already exists. Skipping creation.\")\n        except Exception as e:\n            logger.error(f\"Failed to create collection '{collection_name}': {e}\")\n            raise\n\n    def delete_collection(self, collection_name: str | None = None):\n        \"\"\"\n        Delete a Weaviate collection.\n\n        Args:\n            collection_name (str | None): Name of the collection to delete.\n        \"\"\"\n        try:\n            collection_to_delete = collection_name or self.index_name\n            self.client.collections.delete(collection_to_delete)\n            logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n        except Exception as e:\n            logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n            raise\n\n    def ensure_properties_exist(self, properties_to_ensure: list[str]):\n        \"\"\"\n        Checks if properties exist in the schema and adds them if they don't.\n\n        Args:\n            properties_to_ensure: A list of property names to check/add.\n        \"\"\"\n        if not properties_to_ensure:\n            return\n\n        try:\n            collection_config = self._collection.config.get()\n            existing_properties = {prop.name for prop in collection_config.properties}\n\n            for prop_name in properties_to_ensure:\n                if prop_name not in existing_properties and self.is_valid_property_name(prop_name):\n                    prop_type = self._get_property_type(prop_name)\n                    try:\n                        self._collection.config.add_property(Property(name=prop_name, data_type=prop_type))\n                        logger.info(\n                            f\"Added missing property '{prop_name}' \"\n                            f\"(Type: {prop_type}) to collection \"\n                            f\"'{self._collection.name}' schema.\"\n                        )\n                    except Exception as add_err:\n                        logger.error(f\"Failed to add property '{prop_name}' to schema: {add_err}\")\n                elif prop_name in existing_properties:\n                    logger.debug(f\"Property '{prop_name}' already exists in schema.\")\n                elif not self.is_valid_property_name(prop_name):\n                    logger.warning(f\"Cannot ensure invalid property name: '{prop_name}'\")\n\n        except Exception as e:\n            logger.error(f\"Failed to check or update schema properties for collection '{self._collection.name}': {e}\")\n\n    def _update_multi_tenancy_status(self, collection):\n        \"\"\"\n        Update the multi-tenancy status based on the actual collection configuration.\n\n        Args:\n            collection: The Weaviate collection\n        \"\"\"\n        try:\n            collection_config = collection.config.get()\n            actual_multi_tenancy_enabled = False\n\n            if hasattr(collection_config, \"multi_tenancy_config\") and collection_config.multi_tenancy_config:\n                actual_multi_tenancy_enabled = collection_config.multi_tenancy_config.enabled\n\n            # Update instance variable to reflect actual configuration\n            self._multi_tenancy_enabled = actual_multi_tenancy_enabled\n\n        except Exception as e:\n            logger.warning(f\"Failed to retrieve multi-tenancy configuration: {str(e)}\")\n            # Keep the inferred multi-tenancy setting as fallback\n\n    def _setup_collection(self, base_collection, collection_name, tenant_name):\n        \"\"\"\n        Set up the collection with or without tenant context.\n\n        Args:\n            base_collection: The base Weaviate collection\n            collection_name: Name of the collection\n            tenant_name: Optional tenant name to use\n        \"\"\"\n        # No tenant specified - use the base collection\n        if not tenant_name:\n            self._collection = base_collection\n            self._tenant_name = None\n            return\n\n        # Tenant specified but multi-tenancy is disabled in the collection\n        if not self._multi_tenancy_enabled:\n            raise ValueError(\n                f\"Collection '{collection_name}' has multi-tenancy disabled, \"\n                f\"but tenant_name '{tenant_name}' was provided. \"\n                f\"To use a tenant, create the collection with a tenant_name parameter.\"\n            )\n\n        # Tenant specified and multi-tenancy is enabled\n        self._ensure_tenant_exists(base_collection, tenant_name)\n        self._collection = base_collection.with_tenant(tenant_name)\n        self._tenant_name = tenant_name\n\n    def _ensure_tenant_exists(self, collection, tenant_name):\n        \"\"\"\n        Check if the tenant exists and create it if it doesn't.\n\n        Args:\n            collection: The Weaviate collection\n            tenant_name: Name of the tenant to check/create\n        \"\"\"\n        try:\n            # Use get_by_name method from Weaviate client if available\n            tenant = None\n            try:\n                # Modern Weaviate client approach\n                tenant = collection.tenants.get_by_name(tenant_name)\n            except AttributeError:\n                # Fallback for older clients - search in the list\n                tenants = collection.tenants.get()\n\n                # Handle different response formats\n                if isinstance(tenants, dict) and tenant_name in tenants:\n                    tenant = tenants[tenant_name]\n                elif isinstance(tenants, list):\n                    for t in tenants:\n                        if (\n                            (isinstance(t, dict) and t.get(\"name\") == tenant_name)\n                            or (hasattr(t, \"name\") and t.name == tenant_name)\n                            or (str(t) == tenant_name)\n                        ):\n                            tenant = t\n                            break\n\n            # Create tenant if it doesn't exist\n            if not tenant:\n                logger.info(f\"Creating new tenant '{tenant_name}' in collection\")\n                collection.tenants.create(tenants=[Tenant(name=tenant_name)])\n                logger.info(f\"Successfully created tenant '{tenant_name}'\")\n            else:\n                logger.info(f\"Tenant '{tenant_name}' already exists, no need to create\")\n\n        except Exception as e:\n            logger.warning(\n                f\"Error while checking/creating tenant '{tenant_name}': {str(e)}\\n\"\n                f\"Error type: {type(e).__name__}\\n\"\n                f\"Will continue with the assumption that the tenant exists.\"\n            )\n\n    def close(self):\n        \"\"\"Close the connection to Weaviate.\"\"\"\n        if self.client:\n            self.client.close()\n\n    def count_documents(self) -&gt; int:\n        \"\"\"\n        Count the number of documents in the DocumentStore.\n\n        Returns:\n            int: The number of documents in the store.\n        \"\"\"\n        total = self._collection.aggregate.over_all(total_count=True).total_count\n        return total if total else 0\n\n    def _to_data_object(self, document: Document, content_key: str | None = None) -&gt; dict[str, Any]:\n        \"\"\"\n        Convert a Document to a Weaviate data object ready to be saved.\n\n        Args:\n            document (Document): The document to convert.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            dict[str, Any]: A dictionary representing the Weaviate data object.\n\n        Raises:\n            ValueError: If any property name is invalid according to Weaviate naming rules\n        \"\"\"\n        data = document.to_dict()\n        data[content_key or self.content_key] = data.pop(\"content\", \"\")\n        data[\"_original_id\"] = data.pop(\"id\")\n        metadata = data.get(\"metadata\", {})\n\n        # Validate and add metadata properties\n        for key, val in metadata.items():\n            if not self.is_valid_property_name(key):\n                raise ValueError(\n                    f\"Invalid property name: '{key}'. Property names must match the pattern: [_A-Za-z][_0-9A-Za-z]*\"\n                )\n            data[key] = val\n\n        # Ensure all property names in the data object are valid\n        invalid_props = []\n        for key in data:\n            if key not in [\"_original_id\", \"embedding\", \"metadata\"] and not self.is_valid_property_name(key):\n                invalid_props.append(key)\n\n        if invalid_props:\n            raise ValueError(\n                f\"Invalid property names: {invalid_props}. \"\n                \"Property names must match the pattern: [_A-Za-z][_0-9A-Za-z]*\"\n            )\n\n        del data[\"embedding\"]\n        del data[\"metadata\"]\n\n        return data\n\n    def _to_document(\n        self,\n        data: \"DataObject[dict[str, Any], None]\",\n        content_key: str | None = None,\n    ) -&gt; Document:\n        \"\"\"\n        Convert a data object read from Weaviate into a Document.\n\n        Args:\n            data (DataObject[dict[str, Any], None]): The data object from Weaviate.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            Document: The converted Document object.\n        \"\"\"\n        document_data = data.properties\n        document_id = document_data.pop(\"_original_id\")\n\n        content = document_data.pop(content_key or self.content_key) or \"\"\n\n        if isinstance(data.vector, list):\n            document_data[\"embedding\"] = data.vector\n        elif isinstance(data.vector, dict):\n            document_data[\"embedding\"] = data.vector.get(\"default\")\n        else:\n            document_data[\"embedding\"] = None\n\n        for key, value in document_data.items():\n            if isinstance(value, datetime.datetime):\n                document_data[key] = value.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n\n        if weaviate_meta := getattr(data, \"metadata\", None):\n            if weaviate_meta.score is not None:\n                document_data[\"score\"] = weaviate_meta.score\n            elif weaviate_meta.certainty is not None:\n                document_data[\"score\"] = weaviate_meta.certainty\n\n        score = document_data.pop(\"score\", None)\n        embedding = document_data.pop(\"embedding\", None)\n\n        data = {\n            \"id\": str(document_id),\n            \"content\": content,\n            \"metadata\": document_data,\n            \"score\": score,\n            \"embedding\": embedding,\n        }\n\n        logger.debug(f\"Document loaded from Weaviate: {data}\")\n\n        return Document(**data)\n\n    def add_tenants(self, tenant_names: list[str]) -&gt; None:\n        \"\"\"\n        Add new tenants to the collection.\n\n        Args:\n            tenant_names (list[str]): List of tenant names to add.\n        \"\"\"\n        if not self._multi_tenancy_enabled:\n            raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n        tenants = [Tenant(name=name) for name in tenant_names]\n        self._collection.tenants.create(tenants=tenants)\n\n    def remove_tenants(self, tenant_names: list[str]) -&gt; None:\n        \"\"\"\n        Remove tenants from the collection.\n\n        Args:\n            tenant_names (list[str]): List of tenant names to remove.\n        \"\"\"\n        if not self._multi_tenancy_enabled:\n            raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n        self._collection.tenants.remove(tenant_names)\n\n    def list_tenants(self) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        List all tenants in the collection.\n\n        Returns:\n            list[dict[str, Any]]: List of tenant information.\n        \"\"\"\n        if not self._multi_tenancy_enabled:\n            raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n        return self._collection.tenants.get()\n\n    def get_tenant(self, tenant_name: str) -&gt; dict[str, Any] | None:\n        \"\"\"\n        Get information about a specific tenant.\n\n        Args:\n            tenant_name (str): Name of the tenant to get.\n\n        Returns:\n            dict[str, Any] | None: Tenant information or None if tenant doesn't exist.\n        \"\"\"\n        if not self._multi_tenancy_enabled:\n            raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n        try:\n            # Try using direct tenant lookup if available in the client version\n            try:\n                return self._collection.tenants.get_by_name(tenant_name)\n            except AttributeError:\n                # Fallback for older client versions\n                tenants = self.list_tenants()\n\n                # Search through the list of tenants\n                for tenant in tenants:\n                    if isinstance(tenant, dict) and tenant.get(\"name\") == tenant_name:\n                        return tenant\n                    elif hasattr(tenant, \"name\") and tenant.name == tenant_name:\n                        return tenant\n\n                # Not found\n                return None\n        except Exception as e:\n            logger.warning(f\"Error getting tenant '{tenant_name}': {str(e)}\")\n            return None\n\n    def update_tenant_status(self, tenant_name: str, status: TenantActivityStatus) -&gt; None:\n        \"\"\"\n        Update the activity status of a tenant.\n\n        Args:\n            tenant_name (str): Name of the tenant to update.\n            status (TenantActivityStatus): New activity status (ACTIVE, INACTIVE, or OFFLOADED).\n\n        Raises:\n            ValueError: If multi-tenancy is not enabled or the tenant doesn't exist.\n        \"\"\"\n        if not self._multi_tenancy_enabled:\n            raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n        # Check if tenant exists\n        tenant = self.get_tenant(tenant_name)\n        if not tenant:\n            raise ValueError(f\"Tenant '{tenant_name}' does not exist\")\n\n        try:\n            self._collection.tenants.update(tenants=[Tenant(name=tenant_name, activity_status=status)])\n            logger.info(f\"Updated tenant '{tenant_name}' status to {status}\")\n        except Exception as e:\n            logger.error(f\"Failed to update tenant '{tenant_name}' status: {str(e)}\")\n            raise\n\n    def _query(self) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        Query all documents from Weaviate.\n\n        Returns:\n            list[dict[str, Any]]: A list of all documents in the store.\n\n        Raises:\n            VectorStoreException: If the query fails.\n        \"\"\"\n        properties = [p.name for p in self._collection.config.get().properties]\n        try:\n            result = self._collection.iterator(\n                include_vector=True, return_properties=properties\n            )\n        except WeaviateQueryError as e:\n            msg = f\"Failed to query documents in Weaviate. Error: {e.message}\"\n            raise VectorStoreException(msg) from e\n        return result\n\n    def _query_with_filters(self, filters: dict[str, Any]) -&gt; list[dict[str, Any]]:\n        \"\"\"\n        Query documents from Weaviate with filters.\n\n        Args:\n            filters (dict[str, Any]): The filters to apply to the query.\n\n        Returns:\n            list[dict[str, Any]]: A list of documents matching the filters.\n\n        Raises:\n            VectorStoreException: If the query fails.\n        \"\"\"\n        properties = [p.name for p in self._collection.config.get().properties]\n\n        offset = 0\n        partial_result = None\n        result = []\n        while partial_result is None or len(partial_result.objects) == DEFAULT_QUERY_LIMIT:\n            try:\n                partial_result = self._collection.query.fetch_objects(\n                    filters=convert_filters(filters),\n                    include_vector=True,\n                    limit=DEFAULT_QUERY_LIMIT,\n                    offset=offset,\n                    return_properties=properties,\n                )\n            except WeaviateQueryError as e:\n                msg = f\"Failed to query documents in Weaviate. Error: {e.message}\"\n                raise VectorStoreException(msg) from e\n            result.extend(partial_result.objects)\n            offset += DEFAULT_QUERY_LIMIT\n        return result\n\n    def filter_documents(self, filters: dict[str, Any] | None = None, content_key: str | None = None) -&gt; list[Document]:\n        \"\"\"\n        Filter documents based on the provided filters.\n\n        Args:\n            filters (dict[str, Any] | None): The filters to apply to the document list.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            list[Document]: A list of Documents that match the given filters.\n        \"\"\"\n        if filters:\n            result = self._query_with_filters(filters)\n        else:\n            result = self._query()\n        return [self._to_document(doc, content_key=content_key) for doc in result]\n\n    def list_documents(self, include_embeddings: bool = False, content_key: str | None = None) -&gt; list[Document]:\n        \"\"\"\n        List all documents in the DocumentStore.\n\n        Args:\n            include_embeddings (bool): Whether to include document embeddings in the result.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            list[Document]: A list of all documents in the store.\n        \"\"\"\n        documents = []\n        for item in self._collection.iterator(include_vector=include_embeddings):\n            document = self._to_document(item, content_key=content_key or self.content_key)\n            documents.append(document)\n        return documents\n\n    def _batch_write(self, documents: list[Document], content_key: str | None = None) -&gt; int:\n        \"\"\"\n        Write documents to Weaviate in batches.\n\n        Args:\n            documents (list[Document]): The list of documents to write.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            int: The number of documents written.\n\n        Raises:\n            ValueError: If any of the input is not a Document.\n            VectorStoreException: If the write operation fails.\n        \"\"\"\n        with self.client.batch.dynamic() as batch:\n            for doc in documents:\n                if not isinstance(doc, Document):\n                    msg = f\"Expected a Document, got '{type(doc)}' instead.\"\n                    raise ValueError(msg)\n\n                # Create the batch add parameters\n                batch_params = {\n                    \"properties\": self._to_data_object(doc, content_key=content_key),\n                    \"collection\": self._collection.name,\n                    \"uuid\": generate_uuid5(doc.id),\n                    \"vector\": doc.embedding,\n                }\n\n                # Add tenant parameter if multi-tenancy is enabled and tenant is specified\n                if self._multi_tenancy_enabled and self._tenant_name:\n                    batch_params[\"tenant\"] = self._tenant_name\n\n                # Add the object with the appropriate parameters\n                batch.add_object(**batch_params)\n\n        if failed_objects := self.client.batch.failed_objects:\n            mapped_objects = {}\n            for obj in failed_objects:\n                properties = obj.object_.properties or {}\n                id_ = properties.get(\"_original_id\", obj.object_.uuid)\n                mapped_objects[id_] = obj.message if hasattr(obj, \"message\") else str(obj)\n\n            msg = \"\\n\".join(\n                [\n                    f\"Failed to write object with id '{id_}'. Error: '{message}'\"\n                    for id_, message in mapped_objects.items()\n                ]\n            )\n            raise VectorStoreException(msg)\n\n        return len(documents)\n\n    def _write(self, documents: list[Document], policy: DuplicatePolicy, content_key: str | None = None) -&gt; int:\n        \"\"\"\n        Write documents to Weaviate using the specified policy.\n\n        Args:\n            documents (list[Document]): The list of documents to write.\n            policy (DuplicatePolicy): The policy to use for handling duplicates.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            int: The number of documents written.\n\n        Raises:\n            ValueError: If any of the input is not a Document.\n            VectorStoreDuplicateDocumentException: If duplicates are found with FAIL policy.\n        \"\"\"\n        written = 0\n        duplicate_errors_ids = []\n        for doc in documents:\n            if not isinstance(doc, Document):\n                msg = f\"Expected a Document, got '{type(doc)}' instead.\"\n                raise ValueError(msg)\n\n            if policy == DuplicatePolicy.SKIP and self._collection.data.exists(uuid=generate_uuid5(doc.id)):\n                continue\n\n            try:\n                # Create the insert parameters\n                insert_params = {\n                    \"uuid\": generate_uuid5(doc.id),\n                    \"properties\": self._to_data_object(doc, content_key=content_key),\n                    \"vector\": doc.embedding,\n                }\n\n                # Add tenant parameter if multi-tenancy is enabled and tenant is specified\n                # Note: This shouldn't be necessary when using self._collection with tenant context,\n                # but added for consistency with _batch_write\n                if self._multi_tenancy_enabled and self._tenant_name:\n                    insert_params[\"tenant\"] = self._tenant_name\n\n                self._collection.data.insert(**insert_params)\n                written += 1\n            except UnexpectedStatusCodeError:\n                if policy == DuplicatePolicy.FAIL:\n                    duplicate_errors_ids.append(doc.id)\n        if duplicate_errors_ids:\n            msg = f\"IDs '{', '.join(duplicate_errors_ids)}' already exist in the document store.\"\n            raise VectorStoreDuplicateDocumentException(msg)\n        return written\n\n    def write_documents(\n        self, documents: list[Document], policy: DuplicatePolicy = DuplicatePolicy.NONE, content_key: str | None = None\n    ) -&gt; int:\n        \"\"\"\n        Write documents to Weaviate using the specified policy.\n\n        Args:\n            documents (list[Document]): The list of documents to write.\n            policy (DuplicatePolicy): The policy to use for handling duplicates.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            int: The number of documents written.\n        \"\"\"\n        self._track_documents([doc.id for doc in documents])\n\n        if policy in [DuplicatePolicy.NONE, DuplicatePolicy.OVERWRITE]:\n            return self._batch_write(documents, content_key=content_key)\n\n        return self._write(documents, policy, content_key=content_key)\n\n    def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n        \"\"\"\n        Delete documents from the DocumentStore.\n\n        Args:\n            document_ids (list[str], optional): The IDs of documents to delete.\n            delete_all (bool): If True, delete all documents. Defaults to False.\n\n        Raises:\n            ValueError: If neither document_ids nor delete_all is provided.\n        \"\"\"\n        if delete_all:\n            weaviate_ids = [item.uuid for item in self._collection.iterator()]\n        elif document_ids:\n            weaviate_ids = [generate_uuid5(doc_id) for doc_id in document_ids]\n        else:\n            msg = \"Either 'document_ids' or 'delete_all' must be set.\"\n            raise ValueError(msg)\n        self._collection.data.delete_many(\n            where=Filter.by_id().contains_any(weaviate_ids)\n        )\n\n    def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n        \"\"\"\n        Delete documents from the DocumentStore based on the provided filters.\n\n        Args:\n            filters (dict[str, Any]): The filters to apply to the document list.\n        \"\"\"\n        if filters:\n            self._collection.data.delete_many(where=convert_filters(filters))\n        else:\n            raise ValueError(\"No filters provided to delete documents.\")\n\n    def _keyword_retrieval(\n        self,\n        query: str,\n        filters: dict[str, Any] | None = None,\n        top_k: int | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Perform BM25 retrieval on the documents.\n\n        Args:\n            query (str): The query string.\n            filters (dict[str, Any] | None): Filters to apply to the query.\n            top_k (int | None): The number of top results to return.\n\n        Returns:\n            list[Document]: A list of retrieved documents.\n        \"\"\"\n        properties = [p.name for p in self._collection.config.get().properties]\n        result = self._collection.query.bm25(\n            query=query,\n            filters=convert_filters(filters) if filters else None,\n            limit=top_k,\n            include_vector=True,\n            query_properties=[\"content\"],\n            return_properties=properties,\n            return_metadata=[\"score\"],\n        )\n\n        return [self._to_document(doc) for doc in result.objects]\n\n    def _embedding_retrieval(\n        self,\n        query_embedding: list[float],\n        filters: dict[str, Any] | None = None,\n        top_k: int | None = None,\n        exclude_document_embeddings=True,\n        distance: float | None = None,\n        certainty: float | None = None,\n        content_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Perform embedding-based retrieval on the documents.\n\n        Args:\n            query_embedding (list[float]): The query embedding.\n            filters (dict[str, Any] | None): Filters to apply to the query.\n            top_k (int | None): The number of top results to return.\n            exclude_document_embeddings (bool): Whether to exclude document embeddings in the result.\n            distance (float | None): The maximum distance for retrieval.\n            certainty (float | None): The minimum certainty for retrieval.\n            content_key (Optional[str]): The field used to store content in the storage.\n\n        Returns:\n            list[Document]: A list of retrieved documents.\n\n        Raises:\n            ValueError: If both distance and certainty are provided.\n        \"\"\"\n        if distance is not None and certainty is not None:\n            msg = \"Can't use 'distance' and 'certainty' parameters together\"\n            raise ValueError(msg)\n\n        properties = [p.name for p in self._collection.config.get().properties]\n        result = self._collection.query.near_vector(\n            near_vector=query_embedding,\n            distance=distance,\n            certainty=certainty,\n            include_vector=not exclude_document_embeddings,\n            filters=convert_filters(filters) if filters else None,\n            limit=top_k,\n            return_properties=properties,\n            return_metadata=[\"certainty\"],\n        )\n\n        return [self._to_document(doc, content_key=content_key) for doc in result.objects]\n\n    def _hybrid_retrieval(\n        self,\n        query_embedding: list[float],\n        query: str,\n        filters: dict[str, Any] | None = None,\n        top_k: int | None = None,\n        exclude_document_embeddings=True,\n        alpha: float = 0.5,\n        fusion_type: HybridFusion = HybridFusion.RELATIVE_SCORE,\n        content_key: str | None = None,\n    ) -&gt; list[Document]:\n        \"\"\"\n        Perform hybrid retrieval on the documents.\n\n        Args:\n            query (str): The query string.\n            filters (dict[str, Any] | None): Filters to apply to the query.\n            top_k (int | None): The number of top results to return.\n\n        Returns:\n            list[Document]: A list of retrieved documents.\n        \"\"\"\n        properties = [p.name for p in self._collection.config.get().properties]\n\n        query_alpha = self.alpha if alpha is None else alpha\n        result = self._collection.query.hybrid(\n            query=query,\n            vector=query_embedding,\n            filters=convert_filters(filters) if filters else None,\n            limit=top_k,\n            include_vector=not exclude_document_embeddings,\n            query_properties=[content_key or self.content_key],\n            return_properties=properties,\n            return_metadata=[\"score\"],\n            alpha=query_alpha,\n            fusion_type=fusion_type,\n        )\n\n        return [self._to_document(doc) for doc in result.objects]\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.__init__","title":"<code>__init__(connection=None, client=None, index_name='default', create_if_not_exist=False, content_key='content', tenant_name=None, alpha=0.5, dry_run_config=None)</code>","text":"<p>Initialize a new instance of WeaviateDocumentStore and connect to the Weaviate instance.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>Weaviate | None</code> <p>A Weaviate connection object. If None, a new one is created.</p> <code>None</code> <code>client</code> <code>Optional[WeaviateClient]</code> <p>A Weaviate client. If None, one is created from the connection.</p> <code>None</code> <code>index_name</code> <code>str</code> <p>The name of the index to use. Defaults to \"default\".</p> <code>'default'</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>'content'</code> <code>tenant_name</code> <code>str | None</code> <p>The name of the tenant to use for all operations. If provided, multi-tenancy will be enabled for the collection.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>The alpha value used for hybrid retrieval operations. Controls the balance between keyword and vector search. Defaults to 0.5.</p> <code>0.5</code> <code>dry_run_config</code> <code>Optional[DryRunConfig]</code> <p>Configuration for dry run mode.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def __init__(\n    self,\n    connection: Weaviate | None = None,\n    client: Optional[\"WeaviateClient\"] = None,\n    index_name: str = \"default\",\n    create_if_not_exist: bool = False,\n    content_key: str = \"content\",\n    tenant_name: str | None = None,\n    alpha: float = 0.5,\n    dry_run_config: DryRunConfig | None = None,\n):\n    \"\"\"\n    Initialize a new instance of WeaviateDocumentStore and connect to the\n    Weaviate instance.\n\n    Args:\n        connection (Weaviate | None): A Weaviate connection object. If None, a\n            new one is created.\n        client (Optional[WeaviateClient]): A Weaviate client. If None, one is\n            created from the connection.\n        index_name (str): The name of the index to use. Defaults to \"default\".\n        content_key (Optional[str]): The field used to store content in the\n            storage.\n        tenant_name (str | None): The name of the tenant to use for all operations.\n            If provided, multi-tenancy will be enabled for the collection.\n        alpha (float): The alpha value used for hybrid retrieval operations. Controls\n            the balance between keyword and vector search. Defaults to 0.5.\n        dry_run_config (Optional[DryRunConfig]): Configuration for dry run mode.\n    \"\"\"\n    super().__init__(dry_run_config=dry_run_config)\n\n    # Validate and normalize the index name\n    index_name = self._fix_and_validate_index_name(index_name)\n    collection_name = index_name\n\n    # Initialize client\n    self.client = client\n    if self.client is None:\n        if connection is None:\n            connection = Weaviate()\n        self.client = connection.connect()\n\n    # Store multi-tenancy configuration\n    self._multi_tenancy_enabled = tenant_name is not None\n    self.content_key = content_key\n    self.alpha = alpha\n\n    # Create collection if needed or validate existing collection\n    if not self.client.collections.exists(collection_name):\n        if create_if_not_exist:\n            self._create_collection(collection_name, tenant_name)\n            self._track_collection(collection_name)\n        else:\n            raise ValueError(\n                f\"Collection '{collection_name}' does not exist. Set 'create_if_not_exist' to True to create it.\"\n            )\n\n    # Get the base collection\n    base_collection = self.client.collections.get(collection_name)\n\n    # Get the actual multi-tenancy configuration from the collection\n    self._update_multi_tenancy_status(base_collection)\n\n    # Set up the collection - either with tenant context or without\n    self._setup_collection(base_collection, collection_name, tenant_name)\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.add_tenants","title":"<code>add_tenants(tenant_names)</code>","text":"<p>Add new tenants to the collection.</p> <p>Parameters:</p> Name Type Description Default <code>tenant_names</code> <code>list[str]</code> <p>List of tenant names to add.</p> required Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def add_tenants(self, tenant_names: list[str]) -&gt; None:\n    \"\"\"\n    Add new tenants to the collection.\n\n    Args:\n        tenant_names (list[str]): List of tenant names to add.\n    \"\"\"\n    if not self._multi_tenancy_enabled:\n        raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n    tenants = [Tenant(name=name) for name in tenant_names]\n    self._collection.tenants.create(tenants=tenants)\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.close","title":"<code>close()</code>","text":"<p>Close the connection to Weaviate.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def close(self):\n    \"\"\"Close the connection to Weaviate.\"\"\"\n    if self.client:\n        self.client.close()\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.count_documents","title":"<code>count_documents()</code>","text":"<p>Count the number of documents in the DocumentStore.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents in the store.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def count_documents(self) -&gt; int:\n    \"\"\"\n    Count the number of documents in the DocumentStore.\n\n    Returns:\n        int: The number of documents in the store.\n    \"\"\"\n    total = self._collection.aggregate.over_all(total_count=True).total_count\n    return total if total else 0\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.delete_collection","title":"<code>delete_collection(collection_name=None)</code>","text":"<p>Delete a Weaviate collection.</p> <p>Parameters:</p> Name Type Description Default <code>collection_name</code> <code>str | None</code> <p>Name of the collection to delete.</p> <code>None</code> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def delete_collection(self, collection_name: str | None = None):\n    \"\"\"\n    Delete a Weaviate collection.\n\n    Args:\n        collection_name (str | None): Name of the collection to delete.\n    \"\"\"\n    try:\n        collection_to_delete = collection_name or self.index_name\n        self.client.collections.delete(collection_to_delete)\n        logger.info(f\"Deleted collection '{collection_to_delete}'.\")\n    except Exception as e:\n        logger.error(f\"Failed to delete collection '{collection_to_delete}': {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.delete_documents","title":"<code>delete_documents(document_ids=None, delete_all=False)</code>","text":"<p>Delete documents from the DocumentStore.</p> <p>Parameters:</p> Name Type Description Default <code>document_ids</code> <code>list[str]</code> <p>The IDs of documents to delete.</p> <code>None</code> <code>delete_all</code> <code>bool</code> <p>If True, delete all documents. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither document_ids nor delete_all is provided.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def delete_documents(self, document_ids: list[str] | None = None, delete_all: bool = False) -&gt; None:\n    \"\"\"\n    Delete documents from the DocumentStore.\n\n    Args:\n        document_ids (list[str], optional): The IDs of documents to delete.\n        delete_all (bool): If True, delete all documents. Defaults to False.\n\n    Raises:\n        ValueError: If neither document_ids nor delete_all is provided.\n    \"\"\"\n    if delete_all:\n        weaviate_ids = [item.uuid for item in self._collection.iterator()]\n    elif document_ids:\n        weaviate_ids = [generate_uuid5(doc_id) for doc_id in document_ids]\n    else:\n        msg = \"Either 'document_ids' or 'delete_all' must be set.\"\n        raise ValueError(msg)\n    self._collection.data.delete_many(\n        where=Filter.by_id().contains_any(weaviate_ids)\n    )\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.delete_documents_by_filters","title":"<code>delete_documents_by_filters(filters)</code>","text":"<p>Delete documents from the DocumentStore based on the provided filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any]</code> <p>The filters to apply to the document list.</p> required Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def delete_documents_by_filters(self, filters: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Delete documents from the DocumentStore based on the provided filters.\n\n    Args:\n        filters (dict[str, Any]): The filters to apply to the document list.\n    \"\"\"\n    if filters:\n        self._collection.data.delete_many(where=convert_filters(filters))\n    else:\n        raise ValueError(\"No filters provided to delete documents.\")\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.ensure_properties_exist","title":"<code>ensure_properties_exist(properties_to_ensure)</code>","text":"<p>Checks if properties exist in the schema and adds them if they don't.</p> <p>Parameters:</p> Name Type Description Default <code>properties_to_ensure</code> <code>list[str]</code> <p>A list of property names to check/add.</p> required Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def ensure_properties_exist(self, properties_to_ensure: list[str]):\n    \"\"\"\n    Checks if properties exist in the schema and adds them if they don't.\n\n    Args:\n        properties_to_ensure: A list of property names to check/add.\n    \"\"\"\n    if not properties_to_ensure:\n        return\n\n    try:\n        collection_config = self._collection.config.get()\n        existing_properties = {prop.name for prop in collection_config.properties}\n\n        for prop_name in properties_to_ensure:\n            if prop_name not in existing_properties and self.is_valid_property_name(prop_name):\n                prop_type = self._get_property_type(prop_name)\n                try:\n                    self._collection.config.add_property(Property(name=prop_name, data_type=prop_type))\n                    logger.info(\n                        f\"Added missing property '{prop_name}' \"\n                        f\"(Type: {prop_type}) to collection \"\n                        f\"'{self._collection.name}' schema.\"\n                    )\n                except Exception as add_err:\n                    logger.error(f\"Failed to add property '{prop_name}' to schema: {add_err}\")\n            elif prop_name in existing_properties:\n                logger.debug(f\"Property '{prop_name}' already exists in schema.\")\n            elif not self.is_valid_property_name(prop_name):\n                logger.warning(f\"Cannot ensure invalid property name: '{prop_name}'\")\n\n    except Exception as e:\n        logger.error(f\"Failed to check or update schema properties for collection '{self._collection.name}': {e}\")\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.filter_documents","title":"<code>filter_documents(filters=None, content_key=None)</code>","text":"<p>Filter documents based on the provided filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, Any] | None</code> <p>The filters to apply to the document list.</p> <code>None</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: A list of Documents that match the given filters.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def filter_documents(self, filters: dict[str, Any] | None = None, content_key: str | None = None) -&gt; list[Document]:\n    \"\"\"\n    Filter documents based on the provided filters.\n\n    Args:\n        filters (dict[str, Any] | None): The filters to apply to the document list.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        list[Document]: A list of Documents that match the given filters.\n    \"\"\"\n    if filters:\n        result = self._query_with_filters(filters)\n    else:\n        result = self._query()\n    return [self._to_document(doc, content_key=content_key) for doc in result]\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.get_tenant","title":"<code>get_tenant(tenant_name)</code>","text":"<p>Get information about a specific tenant.</p> <p>Parameters:</p> Name Type Description Default <code>tenant_name</code> <code>str</code> <p>Name of the tenant to get.</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>dict[str, Any] | None: Tenant information or None if tenant doesn't exist.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def get_tenant(self, tenant_name: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Get information about a specific tenant.\n\n    Args:\n        tenant_name (str): Name of the tenant to get.\n\n    Returns:\n        dict[str, Any] | None: Tenant information or None if tenant doesn't exist.\n    \"\"\"\n    if not self._multi_tenancy_enabled:\n        raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n    try:\n        # Try using direct tenant lookup if available in the client version\n        try:\n            return self._collection.tenants.get_by_name(tenant_name)\n        except AttributeError:\n            # Fallback for older client versions\n            tenants = self.list_tenants()\n\n            # Search through the list of tenants\n            for tenant in tenants:\n                if isinstance(tenant, dict) and tenant.get(\"name\") == tenant_name:\n                    return tenant\n                elif hasattr(tenant, \"name\") and tenant.name == tenant_name:\n                    return tenant\n\n            # Not found\n            return None\n    except Exception as e:\n        logger.warning(f\"Error getting tenant '{tenant_name}': {str(e)}\")\n        return None\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.is_valid_property_name","title":"<code>is_valid_property_name(name)</code>  <code>staticmethod</code>","text":"<p>Check if a property name is valid according to Weaviate naming rules.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The property name to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the name is valid, False otherwise</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>@staticmethod\ndef is_valid_property_name(name: str) -&gt; bool:\n    \"\"\"\n    Check if a property name is valid according to Weaviate naming rules.\n\n    Args:\n        name (str): The property name to check\n\n    Returns:\n        bool: True if the name is valid, False otherwise\n    \"\"\"\n    return bool(WeaviateVectorStore.PATTERN_PROPERTY_NAME.fullmatch(name))\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.list_documents","title":"<code>list_documents(include_embeddings=False, content_key=None)</code>","text":"<p>List all documents in the DocumentStore.</p> <p>Parameters:</p> Name Type Description Default <code>include_embeddings</code> <code>bool</code> <p>Whether to include document embeddings in the result.</p> <code>False</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Document]</code> <p>list[Document]: A list of all documents in the store.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def list_documents(self, include_embeddings: bool = False, content_key: str | None = None) -&gt; list[Document]:\n    \"\"\"\n    List all documents in the DocumentStore.\n\n    Args:\n        include_embeddings (bool): Whether to include document embeddings in the result.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        list[Document]: A list of all documents in the store.\n    \"\"\"\n    documents = []\n    for item in self._collection.iterator(include_vector=include_embeddings):\n        document = self._to_document(item, content_key=content_key or self.content_key)\n        documents.append(document)\n    return documents\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.list_tenants","title":"<code>list_tenants()</code>","text":"<p>List all tenants in the collection.</p> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>list[dict[str, Any]]: List of tenant information.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def list_tenants(self) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    List all tenants in the collection.\n\n    Returns:\n        list[dict[str, Any]]: List of tenant information.\n    \"\"\"\n    if not self._multi_tenancy_enabled:\n        raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n    return self._collection.tenants.get()\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.remove_tenants","title":"<code>remove_tenants(tenant_names)</code>","text":"<p>Remove tenants from the collection.</p> <p>Parameters:</p> Name Type Description Default <code>tenant_names</code> <code>list[str]</code> <p>List of tenant names to remove.</p> required Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def remove_tenants(self, tenant_names: list[str]) -&gt; None:\n    \"\"\"\n    Remove tenants from the collection.\n\n    Args:\n        tenant_names (list[str]): List of tenant names to remove.\n    \"\"\"\n    if not self._multi_tenancy_enabled:\n        raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n    self._collection.tenants.remove(tenant_names)\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.update_tenant_status","title":"<code>update_tenant_status(tenant_name, status)</code>","text":"<p>Update the activity status of a tenant.</p> <p>Parameters:</p> Name Type Description Default <code>tenant_name</code> <code>str</code> <p>Name of the tenant to update.</p> required <code>status</code> <code>TenantActivityStatus</code> <p>New activity status (ACTIVE, INACTIVE, or OFFLOADED).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If multi-tenancy is not enabled or the tenant doesn't exist.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def update_tenant_status(self, tenant_name: str, status: TenantActivityStatus) -&gt; None:\n    \"\"\"\n    Update the activity status of a tenant.\n\n    Args:\n        tenant_name (str): Name of the tenant to update.\n        status (TenantActivityStatus): New activity status (ACTIVE, INACTIVE, or OFFLOADED).\n\n    Raises:\n        ValueError: If multi-tenancy is not enabled or the tenant doesn't exist.\n    \"\"\"\n    if not self._multi_tenancy_enabled:\n        raise ValueError(\"Multi-tenancy is not enabled for this collection\")\n\n    # Check if tenant exists\n    tenant = self.get_tenant(tenant_name)\n    if not tenant:\n        raise ValueError(f\"Tenant '{tenant_name}' does not exist\")\n\n    try:\n        self._collection.tenants.update(tenants=[Tenant(name=tenant_name, activity_status=status)])\n        logger.info(f\"Updated tenant '{tenant_name}' status to {status}\")\n    except Exception as e:\n        logger.error(f\"Failed to update tenant '{tenant_name}' status: {str(e)}\")\n        raise\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateVectorStore.write_documents","title":"<code>write_documents(documents, policy=DuplicatePolicy.NONE, content_key=None)</code>","text":"<p>Write documents to Weaviate using the specified policy.</p> <p>Parameters:</p> Name Type Description Default <code>documents</code> <code>list[Document]</code> <p>The list of documents to write.</p> required <code>policy</code> <code>DuplicatePolicy</code> <p>The policy to use for handling duplicates.</p> <code>NONE</code> <code>content_key</code> <code>Optional[str]</code> <p>The field used to store content in the storage.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of documents written.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>def write_documents(\n    self, documents: list[Document], policy: DuplicatePolicy = DuplicatePolicy.NONE, content_key: str | None = None\n) -&gt; int:\n    \"\"\"\n    Write documents to Weaviate using the specified policy.\n\n    Args:\n        documents (list[Document]): The list of documents to write.\n        policy (DuplicatePolicy): The policy to use for handling duplicates.\n        content_key (Optional[str]): The field used to store content in the storage.\n\n    Returns:\n        int: The number of documents written.\n    \"\"\"\n    self._track_documents([doc.id for doc in documents])\n\n    if policy in [DuplicatePolicy.NONE, DuplicatePolicy.OVERWRITE]:\n        return self._batch_write(documents, content_key=content_key)\n\n    return self._write(documents, policy, content_key=content_key)\n</code></pre>"},{"location":"dynamiq/storages/vector/weaviate/weaviate/#dynamiq.storages.vector.weaviate.weaviate.WeaviateWriterVectorStoreParams","title":"<code>WeaviateWriterVectorStoreParams</code>","text":"<p>               Bases: <code>BaseWriterVectorStoreParams</code></p> <p>Parameters for creating and managing Weaviate collections with multi-tenancy.</p> Source code in <code>dynamiq/storages/vector/weaviate/weaviate.py</code> <pre><code>class WeaviateWriterVectorStoreParams(BaseWriterVectorStoreParams):\n    \"\"\"Parameters for creating and managing Weaviate collections with multi-tenancy.\"\"\"\n    tenant_name: str | None = None\n</code></pre>"},{"location":"dynamiq/types/document/","title":"Document","text":""},{"location":"dynamiq/types/document/#dynamiq.types.document.Document","title":"<code>Document</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Document class for Dynamiq.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>Callable[[], Any] | str | None</code> <p>Unique identifier. Defaults to UUID4 hex.</p> <code>content</code> <code>str</code> <p>Main content of the document.</p> <code>metadata</code> <code>dict | None</code> <p>Additional metadata. Defaults to None.</p> <code>embedding</code> <code>list | None</code> <p>Vector representation. Defaults to None.</p> <code>score</code> <code>float | None</code> <p>Relevance or similarity score. Defaults to None.</p> Source code in <code>dynamiq/types/document.py</code> <pre><code>class Document(BaseModel):\n    \"\"\"Document class for Dynamiq.\n\n    Attributes:\n        id (Callable[[], Any] | str | None): Unique identifier. Defaults to UUID4 hex.\n        content (str): Main content of the document.\n        metadata (dict | None): Additional metadata. Defaults to None.\n        embedding (list | None): Vector representation. Defaults to None.\n        score (float | None): Relevance or similarity score. Defaults to None.\n    \"\"\"\n    id: Callable[[], Any] | str | None = Field(default_factory=lambda: uuid.uuid4().hex)\n    content: str\n    metadata: dict | None = None\n    embedding: list | None = None\n    score: float | None = None\n\n    def to_dict(self, for_tracing: bool = False, truncate_limit: int = TRUNCATE_EMBEDDINGS_LIMIT, **kwargs) -&gt; dict:\n        \"\"\"Convert the Document object to a dictionary.\n\n        Returns:\n            dict: Dictionary representation of the Document.\n        \"\"\"\n        data = self.model_dump(exclude={\"embedding\"}, **kwargs)\n\n        if for_tracing and self.embedding is not None and len(self.embedding) &gt; truncate_limit:\n            data[\"embedding\"] = self.embedding[:truncate_limit]\n        else:\n            data[\"embedding\"] = self.embedding\n\n        return data\n</code></pre>"},{"location":"dynamiq/types/document/#dynamiq.types.document.Document.to_dict","title":"<code>to_dict(for_tracing=False, truncate_limit=TRUNCATE_EMBEDDINGS_LIMIT, **kwargs)</code>","text":"<p>Convert the Document object to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary representation of the Document.</p> Source code in <code>dynamiq/types/document.py</code> <pre><code>def to_dict(self, for_tracing: bool = False, truncate_limit: int = TRUNCATE_EMBEDDINGS_LIMIT, **kwargs) -&gt; dict:\n    \"\"\"Convert the Document object to a dictionary.\n\n    Returns:\n        dict: Dictionary representation of the Document.\n    \"\"\"\n    data = self.model_dump(exclude={\"embedding\"}, **kwargs)\n\n    if for_tracing and self.embedding is not None and len(self.embedding) &gt; truncate_limit:\n        data[\"embedding\"] = self.embedding[:truncate_limit]\n    else:\n        data[\"embedding\"] = self.embedding\n\n    return data\n</code></pre>"},{"location":"dynamiq/types/document/#dynamiq.types.document.DocumentCreationMode","title":"<code>DocumentCreationMode</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration for document creation modes.</p> Source code in <code>dynamiq/types/document.py</code> <pre><code>class DocumentCreationMode(str, enum.Enum):\n    \"\"\"Enumeration for document creation modes.\"\"\"\n    ONE_DOC_PER_FILE = \"one-doc-per-file\"\n    ONE_DOC_PER_PAGE = \"one-doc-per-page\"\n    ONE_DOC_PER_ELEMENT = \"one-doc-per-element\"\n</code></pre>"},{"location":"dynamiq/types/dry_run/","title":"Dry run","text":""},{"location":"dynamiq/types/dry_run/#dynamiq.types.dry_run.DryRunConfig","title":"<code>DryRunConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for dry run.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether dry run is enabled. Defaults to False.</p> <code>delete_documents</code> <code>bool</code> <p>Whether to delete the ingested documents after the dry run. Defaults to True.</p> <code>delete_collection</code> <code>bool</code> <p>Whether to delete the created collection after the dry run. Defaults to False.</p> Source code in <code>dynamiq/types/dry_run.py</code> <pre><code>class DryRunConfig(BaseModel):\n    \"\"\"Configuration for dry run.\n\n    Attributes:\n        enabled (bool): Whether dry run is enabled. Defaults to False.\n        delete_documents: Whether to delete the ingested documents after the dry run. Defaults to True.\n        delete_collection: Whether to delete the created collection after the dry run. Defaults to False.\n    \"\"\"\n\n    enabled: bool = False\n    delete_documents: bool = Field(default=True, description=\"Delete the ingested documents\")\n    delete_collection: bool = Field(default=True, description=\"Delete the created collection\")\n</code></pre>"},{"location":"dynamiq/types/feedback/","title":"Feedback","text":""},{"location":"dynamiq/types/llm_tool/","title":"Llm tool","text":""},{"location":"dynamiq/types/streaming/","title":"Streaming","text":""},{"location":"dynamiq/types/streaming/#dynamiq.types.streaming.StreamingConfig","title":"<code>StreamingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for streaming.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether streaming is enabled. Defaults to False.</p> <code>event</code> <code>str</code> <p>Event name. Defaults to \"streaming\".</p> <code>timeout</code> <code>float | None</code> <p>Timeout for streaming. Defaults to None.</p> <code>input_queue</code> <code>Queue | None</code> <p>Input queue for streaming. Defaults to None.</p> <code>input_queue_done_event</code> <code>Event | None</code> <p>Event to signal input queue completion. Defaults to None.</p> <code>mode</code> <code>StreamingMode</code> <p>Streaming mode. Defaults to StreamingMode.ANSWER.</p> <code>include_usage</code> <code>bool</code> <p>Whether to include usage information. Defaults to False.</p> Source code in <code>dynamiq/types/streaming.py</code> <pre><code>class StreamingConfig(BaseModel):\n    \"\"\"Configuration for streaming.\n\n    Attributes:\n        enabled (bool): Whether streaming is enabled. Defaults to False.\n        event (str): Event name. Defaults to \"streaming\".\n        timeout (float | None): Timeout for streaming. Defaults to None.\n        input_queue (Queue | None): Input queue for streaming. Defaults to None.\n        input_queue_done_event (Event | None): Event to signal input queue completion. Defaults to None.\n        mode (StreamingMode): Streaming mode. Defaults to StreamingMode.ANSWER.\n        include_usage (bool): Whether to include usage information. Defaults to False.\n    \"\"\"\n    enabled: bool = False\n    event: str = STREAMING_EVENT\n    timeout: float | None = None\n    input_queue: Queue | None = None\n    input_queue_done_event: Event | None = None\n    mode: StreamingMode = StreamingMode.FINAL\n    include_usage: bool = False\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @cached_property\n    def input_streaming_enabled(self) -&gt; bool:\n        \"\"\"Check if input streaming is enabled.\n\n        Returns:\n            bool: True if input streaming is enabled, False otherwise.\n        \"\"\"\n        return self.enabled and self.input_queue\n\n    def to_dict(self, for_tracing: bool = False, **kwargs) -&gt; dict:\n        if for_tracing and not self.enabled:\n            return {\"enabled\": False}\n        return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/types/streaming/#dynamiq.types.streaming.StreamingConfig.input_streaming_enabled","title":"<code>input_streaming_enabled: bool</code>  <code>cached</code> <code>property</code>","text":"<p>Check if input streaming is enabled.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if input streaming is enabled, False otherwise.</p>"},{"location":"dynamiq/types/streaming/#dynamiq.types.streaming.StreamingEventMessage","title":"<code>StreamingEventMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Message for streaming events.</p> <p>Attributes:</p> Name Type Description <code>run_id</code> <code>str | None</code> <p>Run ID.</p> <code>wf_run_id</code> <code>str | None</code> <p>Workflow run ID. Defaults to a generated UUID.</p> <code>entity_id</code> <code>str</code> <p>Entity ID.</p> <code>data</code> <code>Any</code> <p>Data associated with the event.</p> <code>event</code> <code>str | None</code> <p>Event name. Defaults to \"streaming\".</p> <code>source</code> <code>StreamingEntitySource | None</code> <p>Entity details.</p> Source code in <code>dynamiq/types/streaming.py</code> <pre><code>class StreamingEventMessage(BaseModel):\n    \"\"\"Message for streaming events.\n\n    Attributes:\n        run_id (str | None): Run ID.\n        wf_run_id (str | None): Workflow run ID. Defaults to a generated UUID.\n        entity_id (str): Entity ID.\n        data (Any): Data associated with the event.\n        event (str | None): Event name. Defaults to \"streaming\".\n        source (StreamingEntitySource | None): Entity details.\n    \"\"\"\n\n    run_id: str | None = None\n    wf_run_id: str | None = Field(default_factory=generate_uuid)\n    entity_id: str | None = None\n    data: Any\n    event: str | None = None\n    source: StreamingEntitySource | None = None\n\n    @field_validator(\"event\")\n    @classmethod\n    def set_event(cls, value: str | None) -&gt; str:\n        \"\"\"Set the event name.\n\n        Args:\n            value (str | None): Event name.\n\n        Returns:\n            str: Event name or default.\n        \"\"\"\n        return value or STREAMING_EVENT\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        \"\"\"Convert to dictionary.\n\n        Returns:\n            dict: Dictionary representation.\n        \"\"\"\n        return self.model_dump(**kwargs)\n\n    def to_json(self, **kwargs) -&gt; str:\n        \"\"\"Convert to JSON string.\n\n        Returns:\n            str: JSON string representation.\n        \"\"\"\n        return self.model_dump_json(**kwargs)\n</code></pre>"},{"location":"dynamiq/types/streaming/#dynamiq.types.streaming.StreamingEventMessage.set_event","title":"<code>set_event(value)</code>  <code>classmethod</code>","text":"<p>Set the event name.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str | None</code> <p>Event name.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Event name or default.</p> Source code in <code>dynamiq/types/streaming.py</code> <pre><code>@field_validator(\"event\")\n@classmethod\ndef set_event(cls, value: str | None) -&gt; str:\n    \"\"\"Set the event name.\n\n    Args:\n        value (str | None): Event name.\n\n    Returns:\n        str: Event name or default.\n    \"\"\"\n    return value or STREAMING_EVENT\n</code></pre>"},{"location":"dynamiq/types/streaming/#dynamiq.types.streaming.StreamingEventMessage.to_dict","title":"<code>to_dict(**kwargs)</code>","text":"<p>Convert to dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary representation.</p> Source code in <code>dynamiq/types/streaming.py</code> <pre><code>def to_dict(self, **kwargs) -&gt; dict:\n    \"\"\"Convert to dictionary.\n\n    Returns:\n        dict: Dictionary representation.\n    \"\"\"\n    return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/types/streaming/#dynamiq.types.streaming.StreamingEventMessage.to_json","title":"<code>to_json(**kwargs)</code>","text":"<p>Convert to JSON string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>JSON string representation.</p> Source code in <code>dynamiq/types/streaming.py</code> <pre><code>def to_json(self, **kwargs) -&gt; str:\n    \"\"\"Convert to JSON string.\n\n    Returns:\n        str: JSON string representation.\n    \"\"\"\n    return self.model_dump_json(**kwargs)\n</code></pre>"},{"location":"dynamiq/types/streaming/#dynamiq.types.streaming.StreamingMode","title":"<code>StreamingMode</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enumeration for streaming modes.</p> Source code in <code>dynamiq/types/streaming.py</code> <pre><code>class StreamingMode(str, Enum):\n    \"\"\"Enumeration for streaming modes.\"\"\"\n\n    FINAL = \"final\"  # Streams only final output in agents nodes.\n    ALL = \"all\"  # Streams all intermediate steps and final output in agents and llms nodes.\n</code></pre>"},{"location":"dynamiq/types/streaming/#dynamiq.types.streaming.StreamingThought","title":"<code>StreamingThought</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model for reasoning/thought streaming chunks.</p> Source code in <code>dynamiq/types/streaming.py</code> <pre><code>class StreamingThought(BaseModel):\n    \"\"\"Model for reasoning/thought streaming chunks.\"\"\"\n\n    thought: str\n    loop_num: int\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    def to_dict(self, **kwargs) -&gt; dict:\n        return self.model_dump(**kwargs)\n</code></pre>"},{"location":"dynamiq/utils/chat/","title":"Chat","text":""},{"location":"dynamiq/utils/chat/#dynamiq.utils.chat.format_chat_history","title":"<code>format_chat_history(chat_history)</code>","text":"<p>Format chat history for the orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>chat_history</code> <code>list[dict[str, str]]</code> <p>List of chat entries.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Formatted chat history.</p> Source code in <code>dynamiq/utils/chat.py</code> <pre><code>def format_chat_history(chat_history: list[dict[str, str]]) -&gt; str:\n    \"\"\"Format chat history for the orchestrator.\n\n    Args:\n        chat_history (list[dict[str, str]]): List of chat entries.\n\n    Returns:\n        str: Formatted chat history.\n    \"\"\"\n    formatted_history = \"\"\n    for entry in chat_history:\n        role = entry[\"role\"].title()\n        content = entry[\"content\"]\n        formatted_history += f\"{role}: {content}\\n\"\n    return formatted_history\n</code></pre>"},{"location":"dynamiq/utils/duration/","title":"Duration","text":""},{"location":"dynamiq/utils/duration/#dynamiq.utils.duration.format_duration","title":"<code>format_duration(start, end)</code>","text":"<p>Format the duration between two datetime objects into a human-readable string.</p> <p>This function calculates the time difference between the start and end datetimes and returns a formatted string representing the duration in milliseconds, seconds, minutes, or hours, depending on the length of the duration.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime</code> <p>The starting datetime.</p> required <code>end</code> <code>datetime</code> <p>The ending datetime.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A formatted string representing the duration.  - For durations less than 1 second: \"Xms\" (milliseconds)  - For durations between 1 second and 1 minute: \"Xs\" (seconds)  - For durations between 1 minute and 1 hour: \"Xm\" (minutes)  - For durations of 1 hour or more: \"Xh\" (hours)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timedelta\n&gt;&gt;&gt; start = datetime(2023, 1, 1, 12, 0, 0)\n&gt;&gt;&gt; print(format_duration(start, start + timedelta(milliseconds=500)))\n500ms\n&gt;&gt;&gt; print(format_duration(start, start + timedelta(seconds=45)))\n45.0s\n&gt;&gt;&gt; print(format_duration(start, start + timedelta(minutes=30)))\n30.0m\n&gt;&gt;&gt; print(format_duration(start, start + timedelta(hours=2)))\n2.0h\n</code></pre> Source code in <code>dynamiq/utils/duration.py</code> <pre><code>def format_duration(start: datetime, end: datetime) -&gt; str:\n    \"\"\"\n    Format the duration between two datetime objects into a human-readable string.\n\n    This function calculates the time difference between the start and end datetimes and\n    returns a formatted string representing the duration in milliseconds, seconds, minutes,\n    or hours, depending on the length of the duration.\n\n    Args:\n        start (datetime): The starting datetime.\n        end (datetime): The ending datetime.\n\n    Returns:\n        str: A formatted string representing the duration.\n             - For durations less than 1 second: \"Xms\" (milliseconds)\n             - For durations between 1 second and 1 minute: \"Xs\" (seconds)\n             - For durations between 1 minute and 1 hour: \"Xm\" (minutes)\n             - For durations of 1 hour or more: \"Xh\" (hours)\n\n    Examples:\n        &gt;&gt;&gt; from datetime import datetime, timedelta\n        &gt;&gt;&gt; start = datetime(2023, 1, 1, 12, 0, 0)\n        &gt;&gt;&gt; print(format_duration(start, start + timedelta(milliseconds=500)))\n        500ms\n        &gt;&gt;&gt; print(format_duration(start, start + timedelta(seconds=45)))\n        45.0s\n        &gt;&gt;&gt; print(format_duration(start, start + timedelta(minutes=30)))\n        30.0m\n        &gt;&gt;&gt; print(format_duration(start, start + timedelta(hours=2)))\n        2.0h\n    \"\"\"\n    delta = end - start\n    total_seconds = delta.total_seconds()\n\n    if total_seconds &lt; 1:\n        return f\"{total_seconds * 1000:.0f}ms\"\n    elif total_seconds &lt; 60:\n        return f\"{round(total_seconds, 1)}s\"\n    elif total_seconds &lt; 3600:\n        return f\"{round(total_seconds / 60, 1)}m\"\n    else:\n        return f\"{round(total_seconds / 3600, 1)}h\"\n</code></pre>"},{"location":"dynamiq/utils/env/","title":"Env","text":""},{"location":"dynamiq/utils/env/#dynamiq.utils.env.get_env_var","title":"<code>get_env_var(var_name, default_value=None)</code>","text":"<p>Retrieves the value of an environment variable.</p> <p>This function attempts to retrieve the value of the specified environment variable. If the variable is not found and no default value is provided, it raises a ValueError.</p> <p>Parameters:</p> Name Type Description Default <code>var_name</code> <code>str</code> <p>The name of the environment variable to retrieve.</p> required <code>default_value</code> <code>str</code> <p>The default value to return if the environment variable is not found. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The value of the environment variable.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the environment variable is not found and no default value is provided.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_env_var(\"HOME\")\n'/home/user'\n&gt;&gt;&gt; get_env_var(\"NONEXISTENT_VAR\", \"default\")\n'default'\n&gt;&gt;&gt; get_env_var(\"NONEXISTENT_VAR\")\nTraceback (most recent call last):\n    ...\nValueError: Environment variable 'NONEXISTENT_VAR' not found.\n</code></pre> Source code in <code>dynamiq/utils/env.py</code> <pre><code>def get_env_var(var_name: str, default_value: Any = None):\n    \"\"\"Retrieves the value of an environment variable.\n\n    This function attempts to retrieve the value of the specified environment variable. If the\n    variable is not found and no default value is provided, it raises a ValueError.\n\n    Args:\n        var_name (str): The name of the environment variable to retrieve.\n        default_value (str, optional): The default value to return if the environment variable\n            is not found. Defaults to None.\n\n    Returns:\n        str: The value of the environment variable.\n\n    Raises:\n        ValueError: If the environment variable is not found and no default value is provided.\n\n    Examples:\n        &gt;&gt;&gt; get_env_var(\"HOME\")\n        '/home/user'\n        &gt;&gt;&gt; get_env_var(\"NONEXISTENT_VAR\", \"default\")\n        'default'\n        &gt;&gt;&gt; get_env_var(\"NONEXISTENT_VAR\")\n        Traceback (most recent call last):\n            ...\n        ValueError: Environment variable 'NONEXISTENT_VAR' not found.\n    \"\"\"\n    value = os.environ.get(var_name, default_value)\n\n    if value is None:\n        logger.warning(f\"Environment variable '{var_name}' not found\")\n\n    return value\n</code></pre>"},{"location":"dynamiq/utils/feedback/","title":"Feedback","text":""},{"location":"dynamiq/utils/feedback/#dynamiq.utils.feedback.send_message","title":"<code>send_message(event_message, config, feedback_method=FeedbackMethod.STREAM)</code>","text":"<p>Emits message</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>StreamingEventMessage</code> <p>Message to send.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the runnable.</p> required <code>feedback_method</code> <code>FeedbackMethod</code> <p>Sets up where message is sent. Defaults to \"stream\".</p> <code>STREAM</code> Source code in <code>dynamiq/utils/feedback.py</code> <pre><code>def send_message(\n    event_message: StreamingEventMessage,\n    config: RunnableConfig,\n    feedback_method: FeedbackMethod = FeedbackMethod.STREAM,\n) -&gt; None:\n    \"\"\"Emits message\n\n    Args:\n        message (StreamingEventMessage): Message to send.\n        config (RunnableConfig): Configuration for the runnable.\n        feedback_method (FeedbackMethod, optional): Sets up where message is sent. Defaults to \"stream\".\n    \"\"\"\n\n    match feedback_method:\n        case FeedbackMethod.CONSOLE:\n            print(event_message.data)\n        case FeedbackMethod.STREAM:\n            for callback in config.callbacks:\n                callback.on_node_execute_stream({}, event=event_message)\n</code></pre>"},{"location":"dynamiq/utils/file_types/","title":"File types","text":""},{"location":"dynamiq/utils/json_parser/","title":"Json parser","text":""},{"location":"dynamiq/utils/json_parser/#dynamiq.utils.json_parser.clean_json_string","title":"<code>clean_json_string(json_str)</code>","text":"<p>Clean a JSON-like string so that it can be parsed by the built-in <code>json</code> module.</p> <ol> <li>Remove single-line (//...) and multi-line (/.../) comments outside of    string literals.</li> <li>Convert single-quoted string literals to double-quoted ones, preserving    internal apostrophes.</li> <li>Replace Python-specific boolean/null literals (True, False, None) with their    JSON equivalents (true, false, null).</li> <li>Remove trailing commas in objects and arrays.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>json_str</code> <code>str</code> <p>The raw JSON-like string to clean.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A cleaned JSON string suitable for json.loads.</p> Source code in <code>dynamiq/utils/json_parser.py</code> <pre><code>def clean_json_string(json_str: str) -&gt; str:\n    \"\"\"\n    Clean a JSON-like string so that it can be parsed by the built-in `json` module.\n\n    1. Remove single-line (//...) and multi-line (/*...*/) comments outside of\n       string literals.\n    2. Convert single-quoted string literals to double-quoted ones, preserving\n       internal apostrophes.\n    3. Replace Python-specific boolean/null literals (True, False, None) with their\n       JSON equivalents (true, false, null).\n    4. Remove trailing commas in objects and arrays.\n\n    Args:\n        json_str: The raw JSON-like string to clean.\n\n    Returns:\n        A cleaned JSON string suitable for json.loads.\n    \"\"\"\n    # 1. Remove comments\n    json_str = _remove_comments_outside_strings(json_str)\n\n    # 2. Convert single\u2010quoted string literals -&gt; double\u2010quoted\n    pattern = r\"'((?:\\\\'|[^'])*)'\"\n    json_str = re.sub(pattern, single_quoted_replacer, json_str)\n\n    # 3. Replace Python-specific boolean/null with JSON equivalents\n    json_str = re.sub(r\"\\bTrue\\b\", \"true\", json_str)\n    json_str = re.sub(r\"\\bFalse\\b\", \"false\", json_str)\n    json_str = re.sub(r\"\\bNone\\b\", \"null\", json_str)\n\n    # 4. Remove trailing commas before a closing bracket or brace\n    json_str = re.sub(r\",\\s*(\\]|\\})\", r\"\\1\", json_str)\n\n    return json_str\n</code></pre>"},{"location":"dynamiq/utils/json_parser/#dynamiq.utils.json_parser.extract_json_string","title":"<code>extract_json_string(s)</code>","text":"<p>Extract the first JSON object or array from the string by balancing brackets. The function looks for '{' or '[' and keeps track of nested brackets until they are balanced, returning the substring that contains the complete JSON.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>The input string potentially containing a JSON object or array.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>The extracted JSON string if found and balanced, otherwise None.</p> Source code in <code>dynamiq/utils/json_parser.py</code> <pre><code>def extract_json_string(s: str) -&gt; str | None:\n    \"\"\"\n    Extract the first JSON object or array from the string by balancing brackets.\n    The function looks for '{' or '[' and keeps track of nested brackets until\n    they are balanced, returning the substring that contains the complete JSON.\n\n    Args:\n        s: The input string potentially containing a JSON object or array.\n\n    Returns:\n        The extracted JSON string if found and balanced, otherwise None.\n    \"\"\"\n    bracket_stack: list[str] = []\n    start_index: int | None = None\n    in_string = False\n    escape = False\n\n    for i, char in enumerate(s):\n        # Toggle in_string when encountering an unescaped double quote\n        if char == '\"' and not escape:\n            in_string = not in_string\n        elif char == \"\\\\\" and not escape:\n            escape = True\n            continue\n\n        if not in_string:\n            if char in \"{[\":\n                if not bracket_stack:\n                    start_index = i\n                bracket_stack.append(char)\n            elif char in \"}]\":\n                if bracket_stack:\n                    opening_bracket = bracket_stack.pop()\n                    if (opening_bracket == \"{\" and char != \"}\") or (opening_bracket == \"[\" and char != \"]\"):\n                        # Mismatched brackets\n                        return None\n                    # If stack is empty, we've balanced everything\n                    if not bracket_stack and start_index is not None:\n                        return s[start_index : i + 1]\n                else:\n                    # Found a closing bracket without a matching opener\n                    return None\n        escape = False\n\n    # If brackets never fully balanced, return None\n    return None\n</code></pre>"},{"location":"dynamiq/utils/json_parser/#dynamiq.utils.json_parser.parse_llm_json_output","title":"<code>parse_llm_json_output(response)</code>","text":"<p>Attempt to parse the received LLM output into a JSON object or array. If direct parsing fails, looks for the first balanced JSON substring, then tries corrections.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>str</code> <p>The raw output from the LLM.</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | list[Any]</code> <p>A Python dict or list representing the parsed JSON.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the output cannot be parsed into valid JSON.</p> Source code in <code>dynamiq/utils/json_parser.py</code> <pre><code>def parse_llm_json_output(response: str) -&gt; dict[str, Any] | list[Any]:\n    \"\"\"\n    Attempt to parse the received LLM output into a JSON object or array.\n    If direct parsing fails, looks for the first balanced JSON substring,\n    then tries corrections.\n\n    Args:\n        response: The raw output from the LLM.\n\n    Returns:\n        A Python dict or list representing the parsed JSON.\n\n    Raises:\n        ValueError: If the output cannot be parsed into valid JSON.\n    \"\"\"\n    # Try directly parsing\n    try:\n        return json.loads(response)\n    except json.JSONDecodeError:\n        pass\n\n    # Attempt bracket extraction\n    json_str = extract_json_string(response)\n    if not json_str:\n        raise ValueError(f\"Response from LLM is not valid JSON: {response}\")\n\n    # Try parsing the extracted substring\n    try:\n        return json.loads(json_str)\n    except json.JSONDecodeError:\n        pass\n\n    # Clean and try again\n    cleaned_json_str = clean_json_string(json_str)\n    try:\n        return json.loads(cleaned_json_str)\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Failed to parse JSON after corrections: {e}\")\n</code></pre>"},{"location":"dynamiq/utils/json_parser/#dynamiq.utils.json_parser.single_quoted_replacer","title":"<code>single_quoted_replacer(match)</code>","text":"<p>A helper function for clean_json_string to replace single-quoted JSON-like string literals with double-quoted equivalents, preserving internal apostrophes.</p> <p>Parameters:</p> Name Type Description Default <code>match</code> <code>Match[str]</code> <p>The regular expression match object for a single-quoted string.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The corresponding double-quoted string literal.</p> Source code in <code>dynamiq/utils/json_parser.py</code> <pre><code>def single_quoted_replacer(match: Match[str]) -&gt; str:\n    \"\"\"\n    A helper function for clean_json_string to replace single-quoted JSON-like\n    string literals with double-quoted equivalents, preserving internal\n    apostrophes.\n\n    Args:\n        match: The regular expression match object for a single-quoted string.\n\n    Returns:\n        The corresponding double-quoted string literal.\n    \"\"\"\n    content = match.group(1)\n    # Convert escaped \\' to an actual apostrophe\n    content = content.replace(\"\\\\'\", \"'\")\n    # Escape any double quotes inside\n    content = content.replace('\"', '\\\\\"')\n    return f'\"{content}\"'\n</code></pre>"},{"location":"dynamiq/utils/jsonpath/","title":"Jsonpath","text":""},{"location":"dynamiq/utils/jsonpath/#dynamiq.utils.jsonpath.filter","title":"<code>filter(json, expression_filter)</code>","text":"<p>Filter a JSON object based on a JSONPath expression.</p> <p>Parameters:</p> Name Type Description Default <code>json</code> <code>dict</code> <p>The input JSON object to be filtered.</p> required <code>expression_filter</code> <code>str</code> <p>A JSONPath expression used to filter the JSON object.</p> required <p>Returns:</p> Type Description <p>The filtered data, which can be a single value, a list of values, or None if no match is found.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the filter is not a valid JSONPath expression or if there's an error in parsing.</p> Source code in <code>dynamiq/utils/jsonpath.py</code> <pre><code>def filter(json: dict, expression_filter: str):\n    \"\"\"\n    Filter a JSON object based on a JSONPath expression.\n\n    Args:\n        json (dict): The input JSON object to be filtered.\n        expression_filter (str): A JSONPath expression used to filter the JSON object.\n\n    Returns:\n        The filtered data, which can be a single value, a list of values, or None if no match is found.\n\n    Raises:\n        ValueError: If the filter is not a valid JSONPath expression or if there's an error in parsing.\n    \"\"\"\n    if not expression_filter:\n        return json\n    if not is_jsonpath(expression_filter):\n        raise ValueError(f\"Invalid `expression_filter` {expression_filter}: must be a jsonpath\")\n\n    filtered_data = None\n    try:\n        value = parse(expression_filter).find(json)\n        if value:\n            filtered_data = [v.value for v in value]\n            if len(filtered_data) == 1:\n                filtered_data = filtered_data[0]\n    except Exception as e:\n        raise ValueError(f\"Error in path during parsing with `expression_filter` {expression_filter}: {e}\")\n\n    return filtered_data\n</code></pre>"},{"location":"dynamiq/utils/jsonpath/#dynamiq.utils.jsonpath.is_jsonpath","title":"<code>is_jsonpath(path)</code>","text":"<p>Check if the given string is a valid JSONPath expression.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The string to be checked.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the string is a valid JSONPath expression, False otherwise.</p> Source code in <code>dynamiq/utils/jsonpath.py</code> <pre><code>def is_jsonpath(path: str) -&gt; bool:\n    \"\"\"\n    Check if the given string is a valid JSONPath expression.\n\n    Args:\n        path (str): The string to be checked.\n\n    Returns:\n        bool: True if the string is a valid JSONPath expression, False otherwise.\n    \"\"\"\n    try:\n        parse(path)\n        return True\n    except JsonPathParserError:\n        return False\n</code></pre>"},{"location":"dynamiq/utils/jsonpath/#dynamiq.utils.jsonpath.mapper","title":"<code>mapper(json, expression_map, expression_prefixes=JSONPATH_EXPRESSION_PREFIXES, use_expression_as_value=True)</code>","text":"<p>Map values from a JSON object or list to a new dictionary based on a mapping configuration.</p> <p>Parameters:</p> Name Type Description Default <code>json</code> <code>dict | list</code> <p>The input JSON object or list to be mapped.</p> required <code>expression_map</code> <code>dict</code> <p>A dictionary defining the mapping configuration.</p> required <code>expression_prefixes</code> <code>tuple</code> <p>The prefixes of the JSONPath expressions.</p> <code>JSONPATH_EXPRESSION_PREFIXES</code> <code>use_expression_as_value</code> <code>bool</code> <p>Whether to use the expression as value if the value is not found.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A new dictionary with mapped values according to the provided configuration.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the map is not a dictionary or if the json is neither a dictionary nor a list.</p> <code>ValueError</code> <p>If there's an error in JSONPath parsing.</p> Source code in <code>dynamiq/utils/jsonpath.py</code> <pre><code>def mapper(\n    json: dict | list,\n    expression_map: dict,\n    expression_prefixes: tuple = JSONPATH_EXPRESSION_PREFIXES,\n    use_expression_as_value: bool = True,\n) -&gt; dict:\n    \"\"\"\n    Map values from a JSON object or list to a new dictionary based on a mapping configuration.\n\n    Args:\n        json (dict | list): The input JSON object or list to be mapped.\n        expression_map (dict): A dictionary defining the mapping configuration.\n        expression_prefixes (tuple): The prefixes of the JSONPath expressions.\n        use_expression_as_value (bool): Whether to use the expression as value if the value is not found.\n\n    Returns:\n        dict: A new dictionary with mapped values according to the provided configuration.\n\n    Raises:\n        TypeError: If the map is not a dictionary or if the json is neither a dictionary nor a list.\n        ValueError: If there's an error in JSONPath parsing.\n    \"\"\"\n    if not expression_map:\n        return json\n    if not isinstance(expression_map, dict):\n        raise TypeError(\"Invalid `expression_map`: must be a dictionary\")\n    if not isinstance(json, dict) and not isinstance(json, list):\n        raise TypeError(\"Invalid `json`: must be a dictionary or a list\")\n\n    new_json = {}\n    for key, path in expression_map.items():\n        if not is_jsonpath(path):\n            new_json[key] = path\n            continue\n        try:\n            found = parse(path).find(json)\n            if not found:\n                if use_expression_as_value and not path.startswith(expression_prefixes):\n                    new_json[key] = path\n                else:\n                    new_json[key] = None\n            elif len(found) == 1:\n                new_json[key] = found[0].value\n            else:\n                new_json[key] = [v.value for v in found]\n        except Exception as e:\n            raise ValueError(f\"Error in jsonpath during parsing: {e}\")\n\n    return new_json\n</code></pre>"},{"location":"dynamiq/utils/logger/","title":"Logger","text":""},{"location":"dynamiq/utils/utils/","title":"Utils","text":""},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.JsonWorkflowEncoder","title":"<code>JsonWorkflowEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>A custom JSON encoder for handling specific object types in workflow serialization.</p> <p>This encoder extends the default JSONEncoder to provide custom serialization for Enum, UUID, and datetime objects.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>class JsonWorkflowEncoder(JSONEncoder):\n    \"\"\"\n    A custom JSON encoder for handling specific object types in workflow serialization.\n\n    This encoder extends the default JSONEncoder to provide custom serialization for Enum, UUID,\n    and datetime objects.\n    \"\"\"\n\n    def default(self, obj: Any) -&gt; Any:\n        \"\"\"\n        Encode the given object into a JSON-serializable format.\n\n        Args:\n            obj (Any): The object to be encoded.\n\n        Returns:\n            Any: A JSON-serializable representation of the object.\n\n        Raises:\n            TypeError: If the object type is not handled by this encoder or the default encoder.\n        \"\"\"\n        encoded_value = encode(obj)\n        if encoded_value is obj:\n            encoded_value = JSONEncoder.default(self, obj)\n\n        return encoded_value\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.JsonWorkflowEncoder.default","title":"<code>default(obj)</code>","text":"<p>Encode the given object into a JSON-serializable format.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The object to be encoded.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>A JSON-serializable representation of the object.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the object type is not handled by this encoder or the default encoder.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def default(self, obj: Any) -&gt; Any:\n    \"\"\"\n    Encode the given object into a JSON-serializable format.\n\n    Args:\n        obj (Any): The object to be encoded.\n\n    Returns:\n        Any: A JSON-serializable representation of the object.\n\n    Raises:\n        TypeError: If the object type is not handled by this encoder or the default encoder.\n    \"\"\"\n    encoded_value = encode(obj)\n    if encoded_value is obj:\n        encoded_value = JSONEncoder.default(self, obj)\n\n    return encoded_value\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.TruncationMethod","title":"<code>TruncationMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for text truncation methods.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>class TruncationMethod(str, Enum):\n    \"\"\"Enum for text truncation methods.\"\"\"\n\n    START = \"START\"\n    END = \"END\"\n    MIDDLE = \"MIDDLE\"\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.clear_annotation","title":"<code>clear_annotation(annotation)</code>","text":"<p>Returns the first non-None type if the annotation allows multiple types; otherwise, returns the annotation itself.</p> <p>Parameters:</p> Name Type Description Default <code>annotation</code> <code>Any</code> <p>Provided annotation.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Cleared annotation.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def clear_annotation(annotation: Any) -&gt; Any:\n    \"\"\"\n    Returns the first non-None type if the annotation allows multiple types;\n    otherwise, returns the annotation itself.\n\n    Args:\n        annotation (Any): Provided annotation.\n\n    Returns:\n        Any: Cleared annotation.\n    \"\"\"\n    if get_origin(annotation) in (Union, UnionType):\n        first_non_none = next((t for t in get_args(annotation) if t is not NoneType), None)\n        return first_non_none\n    return annotation\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.deep_merge","title":"<code>deep_merge(source, destination)</code>","text":"<p>Recursively merge dictionaries with proper override behavior.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>dict</code> <p>Source dictionary with higher priority values</p> required <code>destination</code> <code>dict</code> <p>Destination dictionary with lower priority values</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Merged dictionary where source values override destination values,   and lists are concatenated when both source and destination have lists</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def deep_merge(source: dict, destination: dict) -&gt; dict:\n    \"\"\"\n    Recursively merge dictionaries with proper override behavior.\n\n    Args:\n        source: Source dictionary with higher priority values\n        destination: Destination dictionary with lower priority values\n\n    Returns:\n        dict: Merged dictionary where source values override destination values,\n              and lists are concatenated when both source and destination have lists\n    \"\"\"\n    result = destination.copy()\n    for key, value in source.items():\n        if key in result:\n            if isinstance(value, dict) and isinstance(result[key], dict):\n                result[key] = deep_merge(value, result[key])\n            elif isinstance(value, list) and isinstance(result[key], list):\n                result[key] = result[key] + value\n            else:\n                result[key] = value\n        else:\n            result[key] = value\n    return result\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.encode","title":"<code>encode(value)</code>","text":"<p>Encode a value into a JSON/YAML-serializable format.</p> <p>Handles specific object types like Enum, UUID, datetime objects, and other complex types to convert them into serializable formats.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to be encoded.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>A serializable representation of the value.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def encode(value: Any) -&gt; Any:\n    \"\"\"\n    Encode a value into a JSON/YAML-serializable format.\n\n    Handles specific object types like Enum, UUID, datetime objects, and other complex types\n    to convert them into serializable formats.\n\n    Args:\n        value (Any): The value to be encoded.\n\n    Returns:\n        Any: A serializable representation of the value.\n    \"\"\"\n    if isinstance(value, Enum):\n        return value.value\n    if isinstance(value, UUID):\n        return str(value)\n    if isinstance(value, (datetime, date)):\n        return value.isoformat()\n    if isinstance(value, (BytesIO, bytes, Exception)) or callable(value):\n        return format_value(value)\n    return value\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.encode_bytes","title":"<code>encode_bytes(value)</code>","text":"<p>Encode a bytes object to an encoded string.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>bytes</code> <p>The bytes object to be encoded.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>encoded string representation of the bytes object.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def encode_bytes(value: bytes) -&gt; str:\n    \"\"\"\n    Encode a bytes object to an encoded string.\n\n    Args:\n        value (bytes): The bytes object to be encoded.\n\n    Returns:\n        str: encoded string representation of the bytes object.\n    \"\"\"\n    try:\n        return value.decode()\n    except UnicodeDecodeError:\n        return base64.b64encode(value).decode()\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.format_value","title":"<code>format_value(value, skip_format_types=None, force_format_types=None, for_tracing=False, truncate_limit=TRUNCATE_LIST_LIMIT, **kwargs)</code>","text":"<p>Format a value for serialization.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to format.</p> required <code>skip_format_types</code> <code>set</code> <p>Types to skip formatting.</p> <code>None</code> <code>force_format_types</code> <code>set</code> <p>Types to force formatting.</p> <code>None</code> <code>for_tracing</code> <code>bool</code> <p>Whether to format value regarding tracing standard.</p> <code>False</code> <code>truncate_limit</code> <code>int</code> <p>The maximum allowed length for the value; if exceeded, the value will be truncated.</p> <code>TRUNCATE_LIST_LIMIT</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Formatted value.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def format_value(\n    value: Any,\n    skip_format_types: set = None,\n    force_format_types: set = None,\n    for_tracing: bool = False,\n    truncate_limit: int = TRUNCATE_LIST_LIMIT,\n    **kwargs,\n) -&gt; Any:\n    \"\"\"Format a value for serialization.\n\n    Args:\n        value (Any): The value to format.\n        skip_format_types (set, optional): Types to skip formatting.\n        force_format_types (set, optional): Types to force formatting.\n        for_tracing (bool, optional): Whether to format value regarding tracing standard.\n        truncate_limit (int): The maximum allowed length for the value; if exceeded, the value will be truncated.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Any: Formatted value.\n    \"\"\"\n    from dynamiq.nodes.tools.python import PythonInputSchema\n    from dynamiq.runnables import RunnableResult\n\n    if skip_format_types is None:\n        skip_format_types = set()\n    if force_format_types is None:\n        force_format_types = set()\n\n    truncate_metadata = {}\n    if not isinstance(value, tuple(force_format_types)) and isinstance(\n        value, tuple(skip_format_types)\n    ):\n        return value\n\n    if isinstance(value, BytesIO):\n        return getattr(value, \"name\", None) or encode_bytes(value.getvalue())\n    if isinstance(value, bytes):\n        return encode_bytes(value)\n\n    path = kwargs.get(\"path\", \"\")\n    if isinstance(value, dict):\n        formatted_dict = {}\n        for k, v in value.items():\n            new_path = f\"{path}.{k}\" if path else k\n            formatted_v = format_value(\n                v,\n                skip_format_types,\n                force_format_types,\n                for_tracing,\n                path=new_path,\n                truncate_limit=truncate_limit,\n            )\n            formatted_dict[k] = formatted_v\n        return formatted_dict\n\n    if for_tracing and isinstance(value, list) and len(value) &gt; truncate_limit:\n        value = value[:truncate_limit]\n\n    if isinstance(value, (list, tuple, set)):\n        formatted_list = []\n        for i, v in enumerate(value):\n            new_path = f\"{path}[{i}]\"\n            formatted_v = format_value(\n                v,\n                skip_format_types,\n                force_format_types,\n                for_tracing,\n                path=new_path,\n                truncate_limit=truncate_limit,\n            )\n            formatted_list.append(formatted_v)\n\n        return type(value)(formatted_list)\n\n    if isinstance(value, (RunnableResult, PythonInputSchema)):\n        return value.to_dict(skip_format_types=skip_format_types, force_format_types=force_format_types)\n    if isinstance(value, BaseModel):\n        dict_kwargs = {\"for_tracing\": for_tracing} if for_tracing else {}\n        if hasattr(value, \"to_dict\"):\n            try:\n                base_dict = value.to_dict(**dict_kwargs)\n            except Exception:\n                base_dict = value.to_dict()\n        else:\n            base_dict = value.model_dump()\n\n        return base_dict\n    if isinstance(value, Exception):\n        recoverable = bool(kwargs.get(\"recoverable\"))\n        return {\n            \"message\": f\"{str(value)}\",\n            \"type\": type(value).__name__,\n            \"recoverable\": recoverable,\n        }, truncate_metadata\n    if callable(value):\n        return f\"func: {getattr(value, '__name__', str(value))}\"\n\n    try:\n        return RootModel[type(value)](value).model_dump()\n    except PydanticUserError:\n        return str(value)\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.generate_uuid","title":"<code>generate_uuid()</code>","text":"<p>Generate a UUID4 string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string representation of a UUID4.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def generate_uuid() -&gt; str:\n    \"\"\"\n    Generate a UUID4 string.\n\n    Returns:\n        str: A string representation of a UUID4.\n    \"\"\"\n    return str(uuid4())\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.is_called_from_async_context","title":"<code>is_called_from_async_context()</code>","text":"<p>Attempt to detect if the function is being called from an async context.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if called from an async context, False otherwise</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def is_called_from_async_context() -&gt; bool:\n    \"\"\"\n    Attempt to detect if the function is being called from an async context.\n\n    Returns:\n        bool: True if called from an async context, False otherwise\n    \"\"\"\n    try:\n        asyncio.get_running_loop()\n        frame = inspect.currentframe()\n        while frame:\n            if frame.f_code.co_flags &amp; inspect.CO_COROUTINE:\n                return True\n            frame = frame.f_back\n        return False\n    except Exception:\n        return False\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.merge","title":"<code>merge(a, b)</code>","text":"<p>Merge two dictionaries or objects.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>Any</code> <p>The first dictionary or object.</p> required <code>b</code> <code>Any</code> <p>The second dictionary or object.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A new dictionary containing the merged key-value pairs from both inputs.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def merge(a: Any, b: Any) -&gt; dict[str, Any]:\n    \"\"\"\n    Merge two dictionaries or objects.\n\n    Args:\n        a (Any): The first dictionary or object.\n        b (Any): The second dictionary or object.\n\n    Returns:\n        dict[str, Any]: A new dictionary containing the merged key-value pairs from both inputs.\n    \"\"\"\n    return {**a, **b}\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.orjson_encode","title":"<code>orjson_encode(obj)</code>","text":"<p>orjson-compatible default function that replicates dynamiq JsonWorkflowEncoder behavior.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def orjson_encode(obj: Any) -&gt; Any:\n    \"\"\"\n    orjson-compatible default function that replicates dynamiq JsonWorkflowEncoder behavior.\n    \"\"\"\n    encoded_value = encode(value=obj)\n    if encoded_value is obj:\n        try:\n            formatted_value, _ = format_value(obj)\n            return formatted_value\n        except Exception:\n            return str(obj)\n    else:\n        return encoded_value\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.serialize","title":"<code>serialize(obj)</code>","text":"<p>Serialize an object to a JSON-compatible dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The object to be serialized.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary representation of the object, suitable for JSON serialization.</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def serialize(obj: Any) -&gt; dict[str, Any]:\n    \"\"\"\n    Serialize an object to a JSON-compatible dictionary.\n\n    Args:\n        obj (Any): The object to be serialized.\n\n    Returns:\n        dict[str, Any]: A dictionary representation of the object, suitable for JSON serialization.\n    \"\"\"\n    import jsonpickle\n\n    return loads(jsonpickle.encode(obj, unpicklable=False))\n</code></pre>"},{"location":"dynamiq/utils/utils/#dynamiq.utils.utils.truncate_text_for_embedding","title":"<code>truncate_text_for_embedding(text, max_tokens=8192, truncation_method=TruncationMethod.MIDDLE, truncation_message='...[truncated for embedding]...')</code>","text":"<p>Truncate text for embedding models to prevent token limit exceeded errors.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to potentially truncate</p> required <code>max_tokens</code> <code>int</code> <p>Maximum allowed token count (default: 8192 for most embedding models)</p> <code>8192</code> <code>truncation_method</code> <code>TruncationMethod | str</code> <p>Method to use for truncation (TruncationMethod.START/END/MIDDLE)</p> <code>MIDDLE</code> <code>truncation_message</code> <code>str</code> <p>Message to insert when truncating</p> <code>'...[truncated for embedding]...'</code> <p>Returns:</p> Type Description <code>str</code> <p>Truncated text that should fit within the embedding model's token limits</p> Source code in <code>dynamiq/utils/utils.py</code> <pre><code>def truncate_text_for_embedding(\n    text: str,\n    max_tokens: int = 8192,\n    truncation_method: TruncationMethod | str = TruncationMethod.MIDDLE,\n    truncation_message: str = \"...[truncated for embedding]...\",\n) -&gt; str:\n    \"\"\"\n    Truncate text for embedding models to prevent token limit exceeded errors.\n\n    Args:\n        text: The text to potentially truncate\n        max_tokens: Maximum allowed token count (default: 8192 for most embedding models)\n        truncation_method: Method to use for truncation (TruncationMethod.START/END/MIDDLE)\n        truncation_message: Message to insert when truncating\n\n    Returns:\n        Truncated text that should fit within the embedding model's token limits\n    \"\"\"\n    if not text:\n        return text\n\n    max_chars = max_tokens * CHARS_PER_TOKEN\n\n    if len(text) &lt;= max_chars:\n        return text\n\n    truncation_msg_len = len(truncation_message)\n\n    if max_chars &lt;= truncation_msg_len:\n        simple_msg = \"...[truncated]...\"\n        if max_chars &lt;= len(simple_msg):\n            return text[:max_chars]\n        return simple_msg\n\n    if truncation_method == TruncationMethod.START or truncation_method == \"START\":\n        return truncation_message + text[-(max_chars - truncation_msg_len) :]\n    elif truncation_method == TruncationMethod.END or truncation_method == \"END\":\n        return text[: max_chars - truncation_msg_len] + truncation_message\n    else:\n        half_length = (max_chars - truncation_msg_len) // 2\n        return text[:half_length] + truncation_message + text[-half_length:]\n</code></pre>"},{"location":"dynamiq/utils/workflow_generation/mock_knowledgebase/","title":"Mock knowledgebase","text":""},{"location":"dynamiq/utils/workflow_generation/mock_knowledgebase/#dynamiq.utils.workflow_generation.mock_knowledgebase.KnowledgebaseRetriever","title":"<code>KnowledgebaseRetriever</code>","text":"<p>               Bases: <code>Node</code></p> <p>A Mock Node for representing a knowledge base</p> Source code in <code>dynamiq/utils/workflow_generation/mock_knowledgebase.py</code> <pre><code>class KnowledgebaseRetriever(Node):\n    \"\"\"\n    A Mock Node for representing a knowledge base\n    \"\"\"\n\n    name: str = \"KnowledgebaseRetriever\"\n    group: Literal[NodeGroup.TOOLS] = NodeGroup.TOOLS\n    description: str = \"A node for retrieving relevant documents from a knowledge base.\"\n    input_schema: ClassVar[type[KnowledgebaseRetrieverInputSchema]] = KnowledgebaseRetrieverInputSchema\n\n    def execute(self, input_data: dict[str, Any] | BaseModel, config: RunnableConfig = None, **kwargs) -&gt; Any:\n        return\n</code></pre>"},{"location":"dynamiq/utils/workflow_generation/node_generation/","title":"Node generation","text":""},{"location":"dynamiq/utils/workflow_generation/node_generation/#dynamiq.utils.workflow_generation.node_generation.add_connection","title":"<code>add_connection(node, data)</code>","text":"<p>Add connections generation data.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>Target node for adding a connection.</p> required <code>data</code> <code>dict[str, Any]</code> <p>Generation data.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>New connection id.</p> Source code in <code>dynamiq/utils/workflow_generation/node_generation.py</code> <pre><code>def add_connection(node: Node, data: dict[str, Any]) -&gt; str:\n    \"\"\"Add connections generation data.\n\n    Args:\n        node (Node): Target node for adding a connection.\n        data (dict[str, Any]): Generation data.\n\n    Returns:\n        str: New connection id.\n    \"\"\"\n    node_connection_annotation = node.model_fields[\"connection\"].annotation\n    if type(node_connection_annotation) in (Union, types.UnionType):\n        connection = next((x for x in get_args(node_connection_annotation) if x is not None), None)\n    else:\n        connection = node_connection_annotation\n\n    connection_type = connection(api_key=\"\").type\n    connection_id = generate_uuid()\n\n    if \"connections\" not in data:\n        data[\"connections\"] = {connection_id: {\"type\": connection_type, \"api_key\": \"\"}}\n    else:\n        data[\"connections\"][connection_id] = {\"type\": connection_type, \"api_key\": \"\"}\n\n    return connection_id\n</code></pre>"},{"location":"dynamiq/utils/workflow_generation/node_generation/#dynamiq.utils.workflow_generation.node_generation.generate_boolean","title":"<code>generate_boolean()</code>","text":"<p>Generate a random boolean value (True or False).</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>A randomly chosen boolean value.</p> Source code in <code>dynamiq/utils/workflow_generation/node_generation.py</code> <pre><code>def generate_boolean() -&gt; bool:\n    \"\"\"\n    Generate a random boolean value (True or False).\n\n    Returns:\n        bool: A randomly chosen boolean value.\n    \"\"\"\n    return random.choice([False, True])  # nosec\n</code></pre>"},{"location":"dynamiq/utils/workflow_generation/node_generation/#dynamiq.utils.workflow_generation.node_generation.generate_data_from_schema","title":"<code>generate_data_from_schema(schema)</code>","text":"<p>Recursive function that generates mock data based on provided schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>dict[str, Any]</code> <p>Schema for data generation</p> required Source code in <code>dynamiq/utils/workflow_generation/node_generation.py</code> <pre><code>def generate_data_from_schema(schema: dict[str, Any]) -&gt; Any:\n    \"\"\"\n    Recursive function that generates mock data based on provided schema.\n\n    Args:\n        schema (dict[str, Any]): Schema for data generation\n    \"\"\"\n    schema_type = schema.get(\"type\")\n\n    if schema_type == \"string\":\n        return schema.get(\"enum\", [\"mocked_data\"])[0]\n\n    elif schema_type == \"integer\":\n        return generate_integer(minimum=schema.get(\"minimum\", 0), maximum=schema.get(\"maximum\", 100))\n    elif schema_type == \"number\":\n        return generate_number(minimum=schema.get(\"minimum\", 0), maximum=schema.get(\"maximum\", 1))\n\n    elif schema_type == \"boolean\":\n        return generate_boolean()\n\n    elif schema_type == \"object\":\n        obj = {}\n        props = schema.get(\"properties\", {})\n        required = schema.get(\"required\", [])\n        for key, value_schema in props.items():\n            if key in required:\n                obj[key] = generate_data_from_schema(value_schema)\n        return obj\n\n    elif schema_type == \"array\":\n        item_schema = schema.get(\"items\", {})\n        if list_elements := item_schema.get(\"anyOf\"):\n            return [generate_data_from_schema(list_elements[0])]\n        return [generate_data_from_schema(item_schema)]\n\n    elif any_object := schema.get(\"anyOf\"):\n        return generate_data_from_schema(any_object[0])\n\n    return None\n</code></pre>"},{"location":"dynamiq/utils/workflow_generation/node_generation/#dynamiq.utils.workflow_generation.node_generation.generate_integer","title":"<code>generate_integer(minimum, maximum)</code>","text":"<p>Generate a random integer between the specified minimum and maximum values (inclusive).</p> <p>Parameters:</p> Name Type Description Default <code>minimum</code> <code>int</code> <p>The lower bound of the range.</p> required <code>maximum</code> <code>int</code> <p>The upper bound of the range.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>A integer between minimum and maximum.</p> Source code in <code>dynamiq/utils/workflow_generation/node_generation.py</code> <pre><code>def generate_integer(minimum: int, maximum: int) -&gt; int:\n    \"\"\"\n    Generate a random integer between the specified minimum and maximum values (inclusive).\n\n    Args:\n        minimum (int): The lower bound of the range.\n        maximum (int): The upper bound of the range.\n\n    Returns:\n        int: A integer between minimum and maximum.\n    \"\"\"\n    return random.randint(minimum, maximum)  # nosec\n</code></pre>"},{"location":"dynamiq/utils/workflow_generation/node_generation/#dynamiq.utils.workflow_generation.node_generation.generate_node","title":"<code>generate_node(node_cls, node_info, taken_names)</code>","text":"<p>Generates instance of node with unique name.</p> <p>Supported Nodes: Simple (non-nested) nodes and agents.</p> <p>Parameters:</p> Name Type Description Default <code>node_cls</code> <code>type[Node]</code> <p>Class of node to generate.</p> required <code>node_info</code> <code>dict[str, Any]</code> <p>Node details.</p> required <code>taken_names</code> <code>list[str]</code> <p>List of taken names.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Generated id of the node.</p> <code>Node</code> <p>Generated node.</p> Source code in <code>dynamiq/utils/workflow_generation/node_generation.py</code> <pre><code>def generate_node(node_cls: type[Node], node_info: dict[str, Any], taken_names: list[str]):\n    \"\"\"\n    Generates instance of node with unique name.\n\n    Supported Nodes: Simple (non-nested) nodes and agents.\n\n    Args:\n        node_cls (type[Node]): Class of node to generate.\n        node_info (dict[str, Any]): Node details.\n        taken_names (list[str]): List of taken names.\n\n    Returns:\n        str: Generated id of the node.\n        Node: Generated node.\n    \"\"\"\n\n    node_id, data = generate_yaml_data(node_cls, node_info)\n    result = WorkflowYAMLLoader.parse(data)\n    node = result.nodes[node_id]\n\n    if isinstance(node, Agent):\n        node.llm.name = node.llm.name.lower().replace(\" \", \"-\")\n        for tool in node.tools:\n            tool.name = tool.name.lower().replace(\" \", \"-\")\n    node.name = node.name.lower().replace(\" \", \"-\")\n\n    if node.input_transformer.selector:\n        if isinstance(node, BaseLLM) and node.prompt:\n            validate_input_transformer(node.prompt.messages, node)\n\n        elif isinstance(node, Agent):\n            validate_input_transformer([Message(role=MessageRole.USER, content=\"{{input}}\")], node)\n    if node.name in taken_names:\n        raise ValueError(f\"Name {node.name} is already taken.\")\n\n    return node_id, node\n</code></pre>"},{"location":"dynamiq/utils/workflow_generation/node_generation/#dynamiq.utils.workflow_generation.node_generation.generate_number","title":"<code>generate_number(minimum, maximum)</code>","text":"<p>Generate a random floating-point number between the specified minimum and maximum values.</p> <p>Parameters:</p> Name Type Description Default <code>minimum</code> <code>float</code> <p>The lower bound of the range.</p> required <code>maximum</code> <code>float</code> <p>The upper bound of the range.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>A random float between minimum and maximum.</p> Source code in <code>dynamiq/utils/workflow_generation/node_generation.py</code> <pre><code>def generate_number(minimum: float, maximum: float) -&gt; float:\n    \"\"\"\n    Generate a random floating-point number between the specified minimum and maximum values.\n\n    Args:\n        minimum (float): The lower bound of the range.\n        maximum (float): The upper bound of the range.\n\n    Returns:\n        float: A random float between minimum and maximum.\n    \"\"\"\n    return random.uniform(minimum, maximum)  # nosec\n</code></pre>"},{"location":"dynamiq/utils/workflow_generation/node_generation/#dynamiq.utils.workflow_generation.node_generation.validate_input_transformer","title":"<code>validate_input_transformer(messages, node_data)</code>","text":"<p>Validates input transformer for Agents and LLM nodes</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list[Message]</code> <p>Input message node accepts</p> required <code>node_data</code> <code>dict[str, Any]</code> <p>Generated node data.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Empty string if node information was successfully validated. Error message if not.</p> Source code in <code>dynamiq/utils/workflow_generation/node_generation.py</code> <pre><code>def validate_input_transformer(messages: list[Message], node_data: Node) -&gt; str:\n    \"\"\"\n    Validates input transformer for Agents and LLM nodes\n\n    Args:\n        messages (list[Message]): Input message node accepts\n        node_data (dict[str, Any]): Generated node data.\n\n    Returns:\n        str: Empty string if node information was successfully validated. Error message if not.\n    \"\"\"\n    prompt = Prompt(messages=messages)\n    required_parameters = prompt.get_required_parameters()\n\n    provided_parameters = {element for element in list(node_data.input_transformer.selector.keys())}\n    provided_parameters.discard(\"files\")\n\n    if required_parameters != provided_parameters:\n        raise ValueError(\n            f\"Invalid parameters provided in node data. Required parameters: {list(required_parameters)}. \"\n            f\"Provided parameters in InputTransformer {list(provided_parameters)}.\"\n        )\n</code></pre>"},{"location":"dynamiq/workflow/workflow/","title":"Workflow","text":""},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow","title":"<code>Workflow</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Runnable</code></p> <p>A container for a flow that manages its lifecycle, YAML serialization, versioning, metadata, callbacks, and configuration.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of workflow.</p> <code>id</code> <code>str</code> <p>Unique identifier for the workflow.</p> <code>flow</code> <code>BaseFlow</code> <p>The flow associated with the workflow.</p> <code>version</code> <code>str | None</code> <p>Version of the workflow.</p> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>class Workflow(BaseModel, Runnable):\n    \"\"\"\n    A container for a flow that manages its lifecycle, YAML serialization,\n    versioning, metadata, callbacks, and configuration.\n\n    Attributes:\n        name (str): Name of workflow.\n        id (str): Unique identifier for the workflow.\n        flow (BaseFlow): The flow associated with the workflow.\n        version (str | None): Version of the workflow.\n    \"\"\"\n\n    name: str = \"Workflow\"\n    id: str = Field(default_factory=generate_uuid)\n    flow: BaseFlow = Field(default_factory=Flow)\n    version: str | None = None\n\n    @computed_field\n    @cached_property\n    def type(self) -&gt; str:\n        return \"dynamiq.workflows.Workflow\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        pass\n\n    @classmethod\n    def from_yaml_file(\n        cls,\n        file_path: str,\n        wf_id: str = None,\n        connection_manager: ConnectionManager | None = None,\n        init_components: bool = False,\n    ):\n        \"\"\"Load workflow from a YAML file.\n\n        Args:\n            file_path (str): Path to the YAML file.\n            wf_id (str, optional): Workflow ID. Defaults to None.\n            connection_manager (ConnectionManager | None, optional): Connection manager. Defaults to None.\n            init_components (bool, optional): Whether to initialize components. Defaults to False.\n\n        Returns:\n            Workflow: Loaded workflow instance.\n        \"\"\"\n        from dynamiq.serializers.loaders.yaml import WorkflowYAMLLoader\n\n        try:\n            wf_data = WorkflowYAMLLoader.load(\n                file_path, connection_manager, init_components\n            )\n        except Exception as e:\n            logger.error(f\"Failed to load workflow from YAML. {e}\")\n            raise\n\n        return cls.from_yaml_file_data(wf_data, wf_id)\n\n    @classmethod\n    def from_yaml_file_data(cls, file_data: \"WorkflowYamlData\", wf_id: str = None):\n        \"\"\"Load workflow from YAML file data.\n\n        Args:\n            file_data (WorkflowYamlData): Data loaded from the YAML file.\n            wf_id (str, optional): Workflow ID. Defaults to None.\n\n        Returns:\n            Workflow: Loaded workflow instance.\n        \"\"\"\n        try:\n            if wf_id is None:\n                if len(file_data.workflows) &gt; 1:\n                    raise ValueError(\n                        \"Multiple workflows found in YAML. Please specify 'wf_id'\"\n                    )\n                return list(file_data.workflows.values())[0]\n\n            if wf := file_data.workflows.get(wf_id):\n                return wf\n            else:\n                raise ValueError(f\"Workflow '{wf_id}' not found in YAML\")\n        except Exception as e:\n            logger.error(f\"Failed to load workflow from YAML. {e}\")\n            raise\n\n    @property\n    def to_dict_exclude_params(self):\n        return {\"flow\": True}\n\n    def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict:\n        \"\"\"Converts the instance to a dictionary.\n\n        Returns:\n            dict: A dictionary representation of the instance.\n        \"\"\"\n        exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params)\n        for_tracing: bool = kwargs.pop(\"for_tracing\", False)\n        data = self.model_dump(\n            exclude=exclude,\n            serialize_as_any=kwargs.pop(\"serialize_as_any\", True),\n            **kwargs,\n        )\n        data[\"flow\"] = self.flow.to_dict(include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs)\n        return data\n\n    def to_yaml_file_data(self) -&gt; \"WorkflowYamlData\":\n        \"\"\"Dump the workflow to a YAML file data.\n\n        Returns:\n            WorkflowYamlData: Data for the YAML dump.\n        \"\"\"\n        from dynamiq.serializers.loaders.yaml import WorkflowYamlData\n\n        return WorkflowYamlData(\n            workflows={self.id: self},\n            flows={self.flow.id: self.flow},\n            nodes={node.id: node for node in self.flow.nodes},\n            connections={},\n        )\n\n    def to_yaml_file(self, file_path: str | PathLike | IO[Any]):\n        \"\"\"\n        Dump the workflow to a YAML file.\n\n        Args:\n            file_path(str | PathLike | IO[Any]): Path to the YAML file.\n        \"\"\"\n        from dynamiq.serializers.dumpers.yaml import WorkflowYAMLDumper\n\n        yaml_file_data = self.to_yaml_file_data()\n\n        try:\n            WorkflowYAMLDumper.dump(file_path, yaml_file_data)\n        except Exception as e:\n            logger.error(f\"Failed to dump workflow to YAML. {e}\")\n            raise\n\n    def run_sync(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n        \"\"\"Run the workflow synchronously with given input data and configuration.\n\n        Args:\n            input_data (Any): Input data for the workflow.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: Result of the workflow execution.\n        \"\"\"\n        run_id = uuid4()\n        logger.info(f\"Workflow {self.id}: execution started.\")\n\n        # update kwargs with run_id\n        merged_kwargs = merge(kwargs, {\"run_id\": run_id, \"wf_run_id\": getattr(config, \"run_id\", None)})\n        self.run_on_workflow_start(input_data, config, **merged_kwargs)\n        time_start = datetime.now()\n\n        result = self.flow.run_sync(input_data, config, **merge(merged_kwargs, {\"parent_run_id\": run_id}))\n        if result.status == RunnableStatus.SUCCESS:\n            self.run_on_workflow_end(result.output, config, **merged_kwargs)\n            logger.info(f\"Workflow {self.id}: execution succeeded in {format_duration(time_start, datetime.now())}.\")\n        else:\n            error = result.error.type(result.error.message)\n            self.run_on_workflow_error(error, config, **merged_kwargs)\n            logger.error(f\"Workflow {self.id}: execution failed in {format_duration(time_start, datetime.now())}.\")\n\n        return RunnableResult(status=result.status, input=input_data, output=result.output, error=result.error)\n\n    async def run_async(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n        \"\"\"Run the workflow asynchronously with given input data and configuration.\n\n        Args:\n            input_data (Any): Input data for the workflow.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            RunnableResult: Result of the workflow execution.\n        \"\"\"\n        run_id = uuid4()\n        logger.info(f\"Workflow {self.id}: execution started.\")\n\n        # update kwargs with run_id\n        merged_kwargs = merge(kwargs, {\"run_id\": run_id, \"wf_run_id\": getattr(config, \"run_id\", None)})\n        self.run_on_workflow_start(input_data, config, **merged_kwargs)\n        time_start = datetime.now()\n\n        result = await self.flow.run_async(input_data, config, **merge(merged_kwargs, {\"parent_run_id\": run_id}))\n        if result.status == RunnableStatus.SUCCESS:\n            self.run_on_workflow_end(result.output, config, **merged_kwargs)\n            logger.info(\n                f\"Workflow {self.id}: execution succeeded in {format_duration(time_start, datetime.now())}.\"\n            )\n        else:\n            error = result.error.type(result.error.message)\n            self.run_on_workflow_error(error, config, **merged_kwargs)\n            logger.error(\n                f\"Workflow {self.id}: execution failed in {format_duration(time_start, datetime.now())}.\"\n            )\n\n        return RunnableResult(status=result.status, input=input_data, output=result.output, error=result.error)\n\n    def run_on_workflow_start(self, input_data: Any, config: RunnableConfig = None, **kwargs: Any):\n        \"\"\"Run callbacks on workflow start.\n\n        Args:\n            input_data (Any): Input data for the workflow.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if config and config.callbacks:\n            for callback in config.callbacks:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_workflow_start(self.to_dict(**dict_kwargs), input_data, **kwargs)\n\n    def run_on_workflow_end(\n        self, output: Any, config: RunnableConfig = None, **kwargs: Any\n    ):\n        \"\"\"Run callbacks on workflow end.\n\n        Args:\n            output (Any): Output data from the workflow.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if config and config.callbacks:\n            for callback in config.callbacks:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_workflow_end(self.to_dict(**dict_kwargs), output, **kwargs)\n\n    def run_on_workflow_error(\n        self, error: BaseException, config: RunnableConfig = None, **kwargs: Any\n    ):\n        \"\"\"Run callbacks on workflow error.\n\n        Args:\n            error (BaseException): The error that occurred.\n            config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        if config and config.callbacks:\n            for callback in config.callbacks:\n                dict_kwargs = {}\n                if isinstance(callback, TracingCallbackHandler):\n                    dict_kwargs[\"for_tracing\"] = True\n                callback.on_workflow_error(self.to_dict(**dict_kwargs), error, **kwargs)\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.from_yaml_file","title":"<code>from_yaml_file(file_path, wf_id=None, connection_manager=None, init_components=False)</code>  <code>classmethod</code>","text":"<p>Load workflow from a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the YAML file.</p> required <code>wf_id</code> <code>str</code> <p>Workflow ID. Defaults to None.</p> <code>None</code> <code>connection_manager</code> <code>ConnectionManager | None</code> <p>Connection manager. Defaults to None.</p> <code>None</code> <code>init_components</code> <code>bool</code> <p>Whether to initialize components. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Workflow</code> <p>Loaded workflow instance.</p> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>@classmethod\ndef from_yaml_file(\n    cls,\n    file_path: str,\n    wf_id: str = None,\n    connection_manager: ConnectionManager | None = None,\n    init_components: bool = False,\n):\n    \"\"\"Load workflow from a YAML file.\n\n    Args:\n        file_path (str): Path to the YAML file.\n        wf_id (str, optional): Workflow ID. Defaults to None.\n        connection_manager (ConnectionManager | None, optional): Connection manager. Defaults to None.\n        init_components (bool, optional): Whether to initialize components. Defaults to False.\n\n    Returns:\n        Workflow: Loaded workflow instance.\n    \"\"\"\n    from dynamiq.serializers.loaders.yaml import WorkflowYAMLLoader\n\n    try:\n        wf_data = WorkflowYAMLLoader.load(\n            file_path, connection_manager, init_components\n        )\n    except Exception as e:\n        logger.error(f\"Failed to load workflow from YAML. {e}\")\n        raise\n\n    return cls.from_yaml_file_data(wf_data, wf_id)\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.from_yaml_file_data","title":"<code>from_yaml_file_data(file_data, wf_id=None)</code>  <code>classmethod</code>","text":"<p>Load workflow from YAML file data.</p> <p>Parameters:</p> Name Type Description Default <code>file_data</code> <code>WorkflowYamlData</code> <p>Data loaded from the YAML file.</p> required <code>wf_id</code> <code>str</code> <p>Workflow ID. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Workflow</code> <p>Loaded workflow instance.</p> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>@classmethod\ndef from_yaml_file_data(cls, file_data: \"WorkflowYamlData\", wf_id: str = None):\n    \"\"\"Load workflow from YAML file data.\n\n    Args:\n        file_data (WorkflowYamlData): Data loaded from the YAML file.\n        wf_id (str, optional): Workflow ID. Defaults to None.\n\n    Returns:\n        Workflow: Loaded workflow instance.\n    \"\"\"\n    try:\n        if wf_id is None:\n            if len(file_data.workflows) &gt; 1:\n                raise ValueError(\n                    \"Multiple workflows found in YAML. Please specify 'wf_id'\"\n                )\n            return list(file_data.workflows.values())[0]\n\n        if wf := file_data.workflows.get(wf_id):\n            return wf\n        else:\n            raise ValueError(f\"Workflow '{wf_id}' not found in YAML\")\n    except Exception as e:\n        logger.error(f\"Failed to load workflow from YAML. {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.run_async","title":"<code>run_async(input_data, config=None, **kwargs)</code>  <code>async</code>","text":"<p>Run the workflow asynchronously with given input data and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the workflow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>RunnableResult</code> <code>RunnableResult</code> <p>Result of the workflow execution.</p> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>async def run_async(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n    \"\"\"Run the workflow asynchronously with given input data and configuration.\n\n    Args:\n        input_data (Any): Input data for the workflow.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        RunnableResult: Result of the workflow execution.\n    \"\"\"\n    run_id = uuid4()\n    logger.info(f\"Workflow {self.id}: execution started.\")\n\n    # update kwargs with run_id\n    merged_kwargs = merge(kwargs, {\"run_id\": run_id, \"wf_run_id\": getattr(config, \"run_id\", None)})\n    self.run_on_workflow_start(input_data, config, **merged_kwargs)\n    time_start = datetime.now()\n\n    result = await self.flow.run_async(input_data, config, **merge(merged_kwargs, {\"parent_run_id\": run_id}))\n    if result.status == RunnableStatus.SUCCESS:\n        self.run_on_workflow_end(result.output, config, **merged_kwargs)\n        logger.info(\n            f\"Workflow {self.id}: execution succeeded in {format_duration(time_start, datetime.now())}.\"\n        )\n    else:\n        error = result.error.type(result.error.message)\n        self.run_on_workflow_error(error, config, **merged_kwargs)\n        logger.error(\n            f\"Workflow {self.id}: execution failed in {format_duration(time_start, datetime.now())}.\"\n        )\n\n    return RunnableResult(status=result.status, input=input_data, output=result.output, error=result.error)\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.run_on_workflow_end","title":"<code>run_on_workflow_end(output, config=None, **kwargs)</code>","text":"<p>Run callbacks on workflow end.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Any</code> <p>Output data from the workflow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>def run_on_workflow_end(\n    self, output: Any, config: RunnableConfig = None, **kwargs: Any\n):\n    \"\"\"Run callbacks on workflow end.\n\n    Args:\n        output (Any): Output data from the workflow.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if config and config.callbacks:\n        for callback in config.callbacks:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_workflow_end(self.to_dict(**dict_kwargs), output, **kwargs)\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.run_on_workflow_error","title":"<code>run_on_workflow_error(error, config=None, **kwargs)</code>","text":"<p>Run callbacks on workflow error.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>BaseException</code> <p>The error that occurred.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>def run_on_workflow_error(\n    self, error: BaseException, config: RunnableConfig = None, **kwargs: Any\n):\n    \"\"\"Run callbacks on workflow error.\n\n    Args:\n        error (BaseException): The error that occurred.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if config and config.callbacks:\n        for callback in config.callbacks:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_workflow_error(self.to_dict(**dict_kwargs), error, **kwargs)\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.run_on_workflow_start","title":"<code>run_on_workflow_start(input_data, config=None, **kwargs)</code>","text":"<p>Run callbacks on workflow start.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the workflow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>def run_on_workflow_start(self, input_data: Any, config: RunnableConfig = None, **kwargs: Any):\n    \"\"\"Run callbacks on workflow start.\n\n    Args:\n        input_data (Any): Input data for the workflow.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        **kwargs: Additional keyword arguments.\n    \"\"\"\n    if config and config.callbacks:\n        for callback in config.callbacks:\n            dict_kwargs = {}\n            if isinstance(callback, TracingCallbackHandler):\n                dict_kwargs[\"for_tracing\"] = True\n            callback.on_workflow_start(self.to_dict(**dict_kwargs), input_data, **kwargs)\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.run_sync","title":"<code>run_sync(input_data, config=None, **kwargs)</code>","text":"<p>Run the workflow synchronously with given input data and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>Any</code> <p>Input data for the workflow.</p> required <code>config</code> <code>RunnableConfig</code> <p>Configuration for the run. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>RunnableResult</code> <code>RunnableResult</code> <p>Result of the workflow execution.</p> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>def run_sync(self, input_data: Any, config: RunnableConfig = None, **kwargs) -&gt; RunnableResult:\n    \"\"\"Run the workflow synchronously with given input data and configuration.\n\n    Args:\n        input_data (Any): Input data for the workflow.\n        config (RunnableConfig, optional): Configuration for the run. Defaults to None.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        RunnableResult: Result of the workflow execution.\n    \"\"\"\n    run_id = uuid4()\n    logger.info(f\"Workflow {self.id}: execution started.\")\n\n    # update kwargs with run_id\n    merged_kwargs = merge(kwargs, {\"run_id\": run_id, \"wf_run_id\": getattr(config, \"run_id\", None)})\n    self.run_on_workflow_start(input_data, config, **merged_kwargs)\n    time_start = datetime.now()\n\n    result = self.flow.run_sync(input_data, config, **merge(merged_kwargs, {\"parent_run_id\": run_id}))\n    if result.status == RunnableStatus.SUCCESS:\n        self.run_on_workflow_end(result.output, config, **merged_kwargs)\n        logger.info(f\"Workflow {self.id}: execution succeeded in {format_duration(time_start, datetime.now())}.\")\n    else:\n        error = result.error.type(result.error.message)\n        self.run_on_workflow_error(error, config, **merged_kwargs)\n        logger.error(f\"Workflow {self.id}: execution failed in {format_duration(time_start, datetime.now())}.\")\n\n    return RunnableResult(status=result.status, input=input_data, output=result.output, error=result.error)\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.to_dict","title":"<code>to_dict(include_secure_params=False, **kwargs)</code>","text":"<p>Converts the instance to a dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representation of the instance.</p> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>def to_dict(self, include_secure_params: bool = False, **kwargs) -&gt; dict:\n    \"\"\"Converts the instance to a dictionary.\n\n    Returns:\n        dict: A dictionary representation of the instance.\n    \"\"\"\n    exclude = kwargs.pop(\"exclude\", self.to_dict_exclude_params)\n    for_tracing: bool = kwargs.pop(\"for_tracing\", False)\n    data = self.model_dump(\n        exclude=exclude,\n        serialize_as_any=kwargs.pop(\"serialize_as_any\", True),\n        **kwargs,\n    )\n    data[\"flow\"] = self.flow.to_dict(include_secure_params=include_secure_params, for_tracing=for_tracing, **kwargs)\n    return data\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.to_yaml_file","title":"<code>to_yaml_file(file_path)</code>","text":"<p>Dump the workflow to a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path(str</code> <code>| PathLike | IO[Any]</code> <p>Path to the YAML file.</p> required Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>def to_yaml_file(self, file_path: str | PathLike | IO[Any]):\n    \"\"\"\n    Dump the workflow to a YAML file.\n\n    Args:\n        file_path(str | PathLike | IO[Any]): Path to the YAML file.\n    \"\"\"\n    from dynamiq.serializers.dumpers.yaml import WorkflowYAMLDumper\n\n    yaml_file_data = self.to_yaml_file_data()\n\n    try:\n        WorkflowYAMLDumper.dump(file_path, yaml_file_data)\n    except Exception as e:\n        logger.error(f\"Failed to dump workflow to YAML. {e}\")\n        raise\n</code></pre>"},{"location":"dynamiq/workflow/workflow/#dynamiq.workflow.workflow.Workflow.to_yaml_file_data","title":"<code>to_yaml_file_data()</code>","text":"<p>Dump the workflow to a YAML file data.</p> <p>Returns:</p> Name Type Description <code>WorkflowYamlData</code> <code>WorkflowYamlData</code> <p>Data for the YAML dump.</p> Source code in <code>dynamiq/workflow/workflow.py</code> <pre><code>def to_yaml_file_data(self) -&gt; \"WorkflowYamlData\":\n    \"\"\"Dump the workflow to a YAML file data.\n\n    Returns:\n        WorkflowYamlData: Data for the YAML dump.\n    \"\"\"\n    from dynamiq.serializers.loaders.yaml import WorkflowYamlData\n\n    return WorkflowYamlData(\n        workflows={self.id: self},\n        flows={self.flow.id: self.flow},\n        nodes={node.id: node for node in self.flow.nodes},\n        connections={},\n    )\n</code></pre>"},{"location":"tutorials/agents/","title":"Agents Tutorial","text":""},{"location":"tutorials/agents/#simple-agent","title":"Simple Agent","text":"<p>An agent that has access to the E2B Code Interpreter and is capable of solving complex coding tasks.</p>"},{"location":"tutorials/agents/#step-by-step-guide","title":"Step-by-Step Guide","text":"<p>Import Necessary Libraries</p> <pre><code>from dynamiq.nodes.llms.openai import OpenAI\nfrom dynamiq.connections import OpenAI as OpenAIConnection, E2B as E2BConnection\nfrom dynamiq.nodes.agents import Agent\nfrom dynamiq.nodes.tools.e2b_sandbox import E2BInterpreterTool\n</code></pre> <p>Initialize the E2B Tool</p> <p>Set up the E2B tool with the necessary API key.</p> <pre><code>e2b_tool = E2BInterpreterTool(\n    connection=E2BConnection(api_key=\"$API_KEY\")\n)\n</code></pre> <p>Setup Your LLM</p> <p>Configure the Large Language Model (LLM) with the necessary parameters such as the model, temperature, and maximum tokens.</p> <pre><code>llm = OpenAI(\n    id=\"openai\",\n    connection=OpenAIConnection(api_key=\"$API_KEY\"),\n    model=\"gpt-4o\",\n    temperature=0.3,\n    max_tokens=1000,\n)\n</code></pre> <p>Create the Agent</p> <p>Create an agent that uses the LLM and the E2B tool to solve coding tasks.</p> <pre><code>agent = Agent(\n    name=\"react-agent\",\n    llm=llm,\n    tools=[e2b_tool],\n    role=\"Senior Data Scientist\",\n    max_loops=10,\n)\n</code></pre> <p>Run the Agent with an Input</p> <p>Execute the agent with a specific input task.</p> <pre><code>result = agent.run(\n    input_data={\n        \"input\": \"Add the first 10 numbers and tell if the result is prime.\",\n    }\n)\n\nprint(result.output.get(\"content\"))\n</code></pre>"},{"location":"tutorials/agents/#manager-led-multi-agent-workflow","title":"Manager-led Multi-Agent Workflow","text":"<p>This pattern treats specialist agents as tools that a manager agent can call, allowing you to parallelize work and keep responsibilities focused.</p>"},{"location":"tutorials/agents/#step-by-step-guide_1","title":"Step-by-Step Guide","text":"<p>Import Necessary Libraries</p> <pre><code>from dynamiq import Workflow\nfrom dynamiq.connections import OpenAI as OpenAIConnection, ScaleSerp as ScaleSerpConnection\nfrom dynamiq.flows import Flow\nfrom dynamiq.nodes.agents import Agent\nfrom dynamiq.nodes.llms import OpenAI\nfrom dynamiq.nodes.tools.scale_serp import ScaleSerpTool\nfrom dynamiq.nodes.types import Behavior, InferenceMode\n</code></pre> <p>Initialize Tools</p> <p>Set up any external tools your specialists need. Here we use a web search tool to gather fresh market information.</p> <pre><code>search_tool = ScaleSerpTool(\n    connection=ScaleSerpConnection(api_key=\"$SCALESERP_API_KEY\")\n)\n</code></pre> <p>Initialize LLM</p> <p>Configure the shared Large Language Model that all agents will use.</p> <pre><code>llm = OpenAI(\n    connection=OpenAIConnection(api_key=\"$OPENAI_API_KEY\"),\n    model=\"gpt-4o\",\n    temperature=0.1,\n)\n</code></pre> <p>Define Specialist Agents</p> <p>Create the agents that perform research and writing. Each specializes in a single task and expects inputs under the <code>\"input\"</code> key when invoked as a tool.</p> <pre><code>research_agent = Agent(\n    name=\"Research Analyst\",\n    role=\"Find recent market news and provide referenced highlights.\",\n    llm=llm,\n    tools=[search_tool],\n    inference_mode=InferenceMode.XML,\n    max_loops=6,\n    behaviour_on_max_loops=Behavior.RETURN,\n)\n\nwriter_agent = Agent(\n    name=\"Brief Writer\",\n    role=\"Turn research highlights into a concise executive brief.\",\n    llm=llm,\n    inference_mode=InferenceMode.XML,\n    max_loops=4,\n    behaviour_on_max_loops=Behavior.RETURN,\n)\n</code></pre> <p>Define the Manager Agent</p> <p>The manager agent coordinates the specialists, calls them as tools, and assembles the final answer.</p> <pre><code>manager_agent = Agent(\n    name=\"Manager\",\n    role=(\n        \"Delegate research and writing to sub-agents.\\n\"\n        \"Always call tools with {'input': '&lt;task&gt;'} payloads and assemble the final brief.\"\n    ),\n    llm=llm,\n    tools=[research_agent, writer_agent],\n    inference_mode=InferenceMode.XML,\n    parallel_tool_calls_enabled=True,\n    max_loops=8,\n    behaviour_on_max_loops=Behavior.RETURN,\n)\n</code></pre> <p>Create and Run the Workflow</p> <p>Wrap the manager agent in a workflow and provide an input brief. The manager will delegate work to the sub-agents and return a synthesized result.</p> <pre><code>workflow = Workflow(flow=Flow(nodes=[manager_agent]))\n\nresult = workflow.run(\n    input_data={\"input\": \"Summarize the latest developments in battery technology for investors.\"},\n)\n\nprint(result.output[manager_agent.id][\"output\"][\"content\"])\n</code></pre> <p>This tutorial provides a comprehensive guide to setting up and running agents using Dynamiq. By following these steps, you can create individual agents to tackle complex tasks and combine specialists under a manager to deliver richer multi-agent workflows.</p>"},{"location":"tutorials/quickstart/","title":"Quickstart Tutorial","text":""},{"location":"tutorials/quickstart/#getting-started","title":"Getting Started","text":"<p>Ready to dive in? Here's how you can get started with Dynamiq:</p>"},{"location":"tutorials/quickstart/#installation","title":"Installation","text":"<p>First, let's get Dynamiq installed. You'll need Python, so make sure that's set up on your machine. Then run:</p> <pre><code>pip install dynamiq\n</code></pre> <p>Or build the Python package from the source code:</p> <pre><code>git clone https://github.com/dynamiq-ai/dynamiq.git\ncd dynamiq\npoetry install\n</code></pre>"},{"location":"tutorials/quickstart/#examples","title":"Examples","text":""},{"location":"tutorials/quickstart/#simple-llm-flow","title":"Simple LLM Flow","text":"<p>Here's a simple example to get you started with Dynamiq:</p> <p>Import Necessary Libraries</p> <pre><code>from dynamiq.nodes.llms.openai import OpenAI\nfrom dynamiq.connections import OpenAI as OpenAIConnection\nfrom dynamiq import Workflow\nfrom dynamiq.prompts import Prompt, Message\n</code></pre> <p>Define the Prompt Template for Translation</p> <p>Create a template for the prompt that will be used to translate text into English.</p> <pre><code>prompt_template = \"\"\"\nTranslate the following text into English: {{ text }}\n\"\"\"\n</code></pre> <p>Create a Prompt Object with the Defined Template</p> <pre><code>prompt = Prompt(messages=[Message(content=prompt_template, role=\"user\")])\n</code></pre> <p>Setup Your LLM (Large Language Model) Node</p> <p>Configure the LLM node with the necessary parameters such as the model, temperature, and maximum tokens.</p> <pre><code>llm = OpenAI(\n    id=\"openai\",  # Unique identifier for the node\n    connection=OpenAIConnection(api_key=\"$OPENAI_API_KEY\"),  # Connection using API key\n    model=\"gpt-4o\",  # Model to be used\n    temperature=0.3,  # Sampling temperature for the model\n    max_tokens=1000,  # Maximum number of tokens in the output\n    prompt=prompt  # Prompt to be used for the model\n)\n</code></pre> <p>Create a Workflow Object</p> <p>Initialize a workflow to manage the nodes and their execution.</p> <pre><code>workflow = Workflow()\n</code></pre> <p>Add the LLM Node to the Workflow</p> <p>Add the configured LLM node to the workflow.</p> <pre><code>workflow.flow.add_nodes(llm)\n</code></pre> <p>Run the Workflow with the Input Data</p> <p>Execute the workflow with the input data that needs to be translated.</p> <pre><code>result = workflow.run(\n    input_data={\n        \"text\": \"Hola Mundo!\"  # Text to be translated\n    }\n)\n</code></pre> <p>Print the Result of the Translation</p> <p>Output the result of the translation to the console.</p> <pre><code>print(result.output)\n</code></pre> <p>This tutorial provides a quick and easy way to get started with Dynamiq. By following these steps, you can set up a simple workflow to translate text using a large language model.</p>"},{"location":"tutorials/rag/","title":"RAG Tutorial","text":""},{"location":"tutorials/rag/#rag-document-indexing-flow","title":"RAG - Document Indexing Flow","text":"<p>This workflow takes input PDF files, pre-processes them, converts them to vector embeddings, and stores them in a vector database (Pinecone, Elasticsearch, etc.).</p>"},{"location":"tutorials/rag/#step-by-step-guide","title":"Step-by-Step Guide","text":"<p>Import Necessary Libraries</p> <pre><code>from io import BytesIO\nfrom dynamiq import Workflow\nfrom dynamiq.nodes import InputTransformer\nfrom dynamiq.connections import (\n    OpenAI as OpenAIConnection,\n    Pinecone as PineconeConnection,\n    Elasticsearch as ElasticsearchConnection\n)\nfrom dynamiq.nodes.converters import PyPDFConverter\nfrom dynamiq.nodes.splitters.document import DocumentSplitter\nfrom dynamiq.nodes.embedders import OpenAIDocumentEmbedder\nfrom dynamiq.nodes.writers import PineconeDocumentWriter, ElasticsearchDocumentWriter\n</code></pre> <p>Initialize the RAG Workflow</p> <pre><code>rag_wf = Workflow()\n</code></pre> <p>PyPDF Document Converter</p> <p>Convert the PDF documents into a format suitable for processing.</p> <pre><code>converter = PyPDFConverter(document_creation_mode=\"one-doc-per-page\")\nrag_wf.flow.add_nodes(converter)  # Add node to the DAG\n</code></pre> <p>Document Splitter</p> <p>Split the documents into smaller chunks for better processing.</p> <pre><code>document_splitter = DocumentSplitter(\n    split_by=\"sentence\",\n    split_length=10,\n    split_overlap=1,\n    input_transformer=InputTransformer(\n        selector={\n            \"documents\": f\"${[converter.id]}.output.documents\",\n        },  # Map output of the previous node to the expected input of the current node\n    ),\n).depends_on(converter)\nrag_wf.flow.add_nodes(document_splitter)\n</code></pre> <p>OpenAI Vector Embeddings</p> <p>Convert the document chunks into vector embeddings using OpenAI.</p> <pre><code>embedder = OpenAIDocumentEmbedder(\n    connection=OpenAIConnection(api_key=\"$OPENAI_API_KEY\"),\n    model=\"text-embedding-3-small\",\n    input_transformer=InputTransformer(\n        selector={\n            \"documents\": f\"${[document_splitter.id]}.output.documents\",\n        },\n    ),\n).depends_on(document_splitter)\nrag_wf.flow.add_nodes(embedder)\n</code></pre> <p>Vector Storage Options</p> <p>You can choose between different vector stores for document storage. Here are examples for both Pinecone and Elasticsearch:</p>"},{"location":"tutorials/rag/#option-1-pinecone-vector-storage","title":"Option 1: Pinecone Vector Storage","text":"<p>Store the vector embeddings in the Pinecone vector database.</p> <pre><code>vector_store = PineconeDocumentWriter(\n    connection=PineconeConnection(api_key=\"$PINECONE_API_KEY\"),\n    index_name=\"default\",\n    dimension=1536,\n    input_transformer=InputTransformer(\n        selector={\n            \"documents\": f\"${[embedder.id]}.output.documents\",\n        },\n    ),\n).depends_on(embedder)\nrag_wf.flow.add_nodes(vector_store)\n</code></pre> <p>If you don't have an index in the database and want to create it programmatically, you need to specify the parameter <code>create_if_not_exist=True</code> and, depending on your deployment type, specify the additional parameters needed for index creation.</p> <p>If you have a <code>serverless</code> Pinecone deployment, your vector store initialization might look like this:</p> <pre><code># Pinecone vector storage\nvector_store = (\n    PineconeDocumentWriter(\n        connection=PineconeConnection(),\n        index_name=\"quickstart\",\n        dimension=1536,\n        create_if_not_exist=True,\n        index_type=\"serverless\",\n        cloud=\"aws\",\n        region=\"us-east-1\"\n    )\n    .inputs(documents=embedder.outputs.documents)\n    .depends_on(embedder)\n)\n</code></pre> <p>If you have a pod-based deployment, your vector store initialization could look like this:</p> <pre><code># Pinecone vector storage\nvector_store = (\n    PineconeDocumentWriter(\n        connection=PineconeConnection(),\n        index_name=\"quickstart\",\n        dimension=1536,\n        create_if_not_exist=True,\n        index_type=\"pod\",\n        environment=\"us-west1-gcp\",\n        pod_type=\"p1.x1\",\n        pods=1\n    )\n    .inputs(documents=embedder.outputs.documents)\n    .depends_on(embedder)\n)\n</code></pre>"},{"location":"tutorials/rag/#option-2-elasticsearch-vector-storage","title":"Option 2: Elasticsearch Vector Storage","text":"<p>Store the vector embeddings in Elasticsearch.</p> <p>For local setup: <pre><code>vector_store = ElasticsearchDocumentWriter(\n    connection=ElasticsearchConnection(\n        url=\"$ELASTICSEARCH_URL\",\n        api_key=\"$ELASTICSEARCH_API_KEY\",\n    ),\n    index_name=\"documents\",\n    dimension=1536,\n    similarity=\"cosine\",\n    input_transformer=InputTransformer(\n        selector={\n            \"documents\": f\"${[embedder.id]}.output.documents\",\n        },\n    ),\n).depends_on(embedder)\nrag_wf.flow.add_nodes(vector_store)\n</code></pre></p> <p>For Elastic Cloud deployment:</p> <pre><code>vector_store = ElasticsearchDocumentWriter(\n    connection=ElasticsearchConnection(\n        username=\"$ELASTICSEARCH_USERNAME\",\n        password=\"$ELASTICSEARCH_PASSWORD\",\n        cloud_id=\"$ELASTICSEARCH_CLOUD_ID\",\n    ),\n    index_name=\"documents\",\n    dimension=1536,\n    create_if_not_exist=True,\n    index_settings={\n        \"number_of_shards\": 1,\n        \"number_of_replicas\": 1\n    },\n    mapping_settings={\n        \"dynamic\": \"strict\"\n    }\n).depends_on(embedder)\n</code></pre> <p>Prepare Input PDF Files</p> <p>Prepare the input PDF files for processing.</p> <pre><code>file_paths = [\"example.pdf\"]\ninput_data = {\n    \"files\": [\n        BytesIO(open(path, \"rb\").read()) for path in file_paths\n    ],\n    \"metadata\": [\n        {\"filename\": path} for path in file_paths\n    ],\n}\n</code></pre> <p>Run RAG Indexing Flow</p> <p>Execute the workflow to process and store the documents.</p> <pre><code>rag_wf.run(input_data=input_data)\n</code></pre>"},{"location":"tutorials/rag/#rag-document-retrieval-flow","title":"RAG - Document Retrieval Flow","text":"<p>This simple retrieval RAG flow searches for relevant documents and answers the original user question using the retrieved documents.</p>"},{"location":"tutorials/rag/#step-by-step-guide_1","title":"Step-by-Step Guide","text":"<p>Import Necessary Libraries</p> <pre><code>from dynamiq import Workflow\nfrom dynamiq.nodes import InputTransformer\nfrom dynamiq.connections import (\n    OpenAI as OpenAIConnection,\n    Pinecone as PineconeConnection,\n    Elasticsearch as ElasticsearchConnection\n)\nfrom dynamiq.nodes.embedders import OpenAITextEmbedder\nfrom dynamiq.nodes.retrievers import PineconeDocumentRetriever, ElasticsearchDocumentRetriever\nfrom dynamiq.nodes.llms import OpenAI\nfrom dynamiq.prompts import Message, Prompt\n</code></pre> <p>Initialize the RAG Retrieval Workflow</p> <pre><code>retrieval_wf = Workflow()\n</code></pre> <p>Shared OpenAI Connection</p> <p>Set up a shared connection to OpenAI.</p> <pre><code>openai_connection = OpenAIConnection(api_key=\"$OPENAI_API_KEY\")\n</code></pre> <p>OpenAI Text Embedder for Query Embedding</p> <p>Embed the user query into a vector format.</p> <pre><code>embedder = OpenAITextEmbedder(\n    connection=openai_connection,\n    model=\"text-embedding-3-small\",\n)\nretrieval_wf.flow.add_nodes(embedder)\n</code></pre> <p>Document Retriever Options</p> <p>You can choose between different retrievers. Here are examples for both Pinecone and Elasticsearch:</p>"},{"location":"tutorials/rag/#option-1-pinecone-document-retriever","title":"Option 1: Pinecone Document Retriever","text":"<pre><code>document_retriever = PineconeDocumentRetriever(\n    connection=PineconeConnection(api_key=\"$PINECONE_API_KEY\"),\n    index_name=\"default\",\n    dimension=1536,\n    top_k=5,\n    input_transformer=InputTransformer(\n        selector={\n            \"embedding\": f\"${[embedder.id]}.output.embedding\",\n        },\n    ),\n).depends_on(embedder)\nretrieval_wf.flow.add_nodes(document_retriever)\n</code></pre>"},{"location":"tutorials/rag/#option-2-elasticsearch-document-retriever","title":"Option 2: Elasticsearch Document Retriever","text":"<p>For local setup:</p> <pre><code># Vector similarity search with Elasticsearch\ndocument_retriever = ElasticsearchDocumentRetriever(\n    connection=ElasticsearchConnection(\n        url=\"$ELASTICSEARCH_URL\",\n        api_key=\"$ELASTICSEARCH_API_KEY\",\n    ),\n    index_name=\"documents\",\n    top_k=5,\n    input_transformer=InputTransformer(\n        selector={\n            \"query\": f\"${[embedder.id]}.output.embedding\",  # Vector query for similarity search\n        },\n    ),\n).depends_on(embedder)\nretrieval_wf.flow.add_nodes(document_retriever)\n</code></pre> <p>For cloud deployment with score normalization:</p> <pre><code>document_retriever = ElasticsearchDocumentRetriever(\n    connection=ElasticsearchConnection(\n        username=\"$ELASTICSEARCH_USERNAME\",\n        password=\"$ELASTICSEARCH_PASSWORD\",\n        cloud_id=\"$ELASTICSEARCH_CLOUD_ID\",\n    ),\n    index_name=\"documents\",\n    top_k=5,\n    scale_scores=True,  # Scale scores to 0-1 range\n    input_transformer=InputTransformer(\n        selector={\n            \"query\": f\"${[embedder.id]}.output.embedding\",  # Vector query for similarity search\n        },\n    ),\n).depends_on(embedder)\n</code></pre> <p>Define the Prompt Template</p> <p>Create a template for generating answers based on the retrieved documents.</p> <pre><code>prompt_template = \"\"\"\nPlease answer the question based on the provided context.\n\nQuestion: {{ query }}\n\nContext:\n{% for document in documents %}\n- {{ document.content }}\n{% endfor %}\n\"\"\"\n</code></pre> <p>OpenAI LLM for Answer Generation</p> <p>Generate an answer to the user query using OpenAI's language model.</p> <pre><code>prompt = Prompt(messages=[Message(content=prompt_template, role=\"user\")])\n\nanswer_generator = OpenAI(\n    connection=openai_connection,\n    model=\"gpt-4o\",\n    prompt=prompt,\n    input_transformer=InputTransformer(\n        selector={\n            \"documents\": f\"${[document_retriever.id]}.output.documents\",\n            \"query\": f\"${[embedder.id]}.output.query\",\n        },  # Take documents from the vector store node and query from the embedder\n    ),\n).depends_on([embedder, document_retriever])\nretrieval_wf.flow.add_nodes(answer_generator)\n</code></pre> <p>Run the RAG Retrieval Flow</p> <p>Execute the workflow to retrieve and answer the user query.</p> <pre><code>question = \"What are the line items provided in the invoice?\"\nresult = retrieval_wf.run(input_data={\"query\": question})\n\n# Print the answer\nanswer = result.output.get(answer_generator.id).get(\"output\", {}).get(\"content\")\nprint(answer)\n</code></pre>"}]}